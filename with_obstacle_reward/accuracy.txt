D:\Software\anaconda\python.exe D:/Study/mojoco/2048-python/openai_fetch/DDPG_main.py
Box_Position: [[1.50148576 1.00892657 0.5603476 ]]
Creating window glfw
Step:200, total reward:-200.60829511626702, average reward:-1.003041475581335,----
Box_Position: [[1.3550191  0.85438045 0.65082763]]
Step:165, total reward:-102.35523279427579, average reward:-0.620334744207732,success
Box_Position: [[1.50613489 0.52204534 0.54141583]]
Step:200, total reward:-219.65630788085926, average reward:-1.0982815394042964,----
Box_Position: [[1.37784743 1.04922556 0.70371532]]
Step:200, total reward:-206.12767389231183, average reward:-1.030638369461559,----
Box_Position: [[1.25728331 0.84731564 0.61078546]]
Step:200, total reward:-177.76263616825676, average reward:-0.8888131808412838,----
Box_Position: [[1.4401784  0.52068234 0.72095158]]
Step:200, total reward:-210.67090956936437, average reward:-1.0533545478468218,----
Box_Position: [[1.46992686 0.60095845 0.60259137]]
Step:200, total reward:-194.83388658061884, average reward:-0.9741694329030942,----
Box_Position: [[1.43802686 0.61563844 0.49639398]]
Step:200, total reward:-186.7944653953195, average reward:-0.9339723269765975,----
Box_Position: [[1.48367046 0.94135737 0.51901395]]
Step:200, total reward:-206.77952402469612, average reward:-1.0338976201234806,----
Box_Position: [[1.4168793  0.93681867 0.55376599]]
Step:200, total reward:-222.69002270217933, average reward:-1.1134501135108967,----
Box_Position: [[1.36993006 0.86861139 0.66728877]]
Step:200, total reward:-213.72230475934813, average reward:-1.0686115237967406,----
Box_Position: [[1.29867536 0.55703308 0.65970525]]
Step:200, total reward:-238.17762280168083, average reward:-1.1908881140084042,----
Box_Position: [[1.32621232 0.85349738 0.45881965]]
Step:200, total reward:-184.3206819959197, average reward:-0.9216034099795984,----
Box_Position: [[1.27568289 0.84240287 0.71545278]]
Step:200, total reward:-171.78424283164784, average reward:-0.8589212141582392,----
Box_Position: [[1.50963483 0.72208143 0.69834354]]
Step:200, total reward:-208.62105654872045, average reward:-1.0431052827436023,----
Box_Position: [[1.33253097 0.71547249 0.68847843]]
Step:44, total reward:-37.40085489555603, average reward:-0.8500194294444552,success
Box_Position: [[1.49119607 0.50665717 0.7250993 ]]
Step:200, total reward:-206.23618029208103, average reward:-1.0311809014604052,----
Box_Position: [[1.51325645 1.05085638 0.60643561]]
Step:200, total reward:-222.7798850942196, average reward:-1.1138994254710979,----
Box_Position: [[1.41455705 0.80823374 0.61615041]]
Step:200, total reward:-201.7154781666491, average reward:-1.0085773908332454,----
Box_Position: [[1.33453817 0.74043295 0.60825313]]
Step:200, total reward:-153.5115586082392, average reward:-0.767557793041196,----
Box_Position: [[1.42535663 0.85884482 0.53713221]]
Step:200, total reward:-196.65093668378748, average reward:-0.9832546834189374,----
Box_Position: [[1.33466033 0.60546213 0.45304901]]
Step:200, total reward:-171.44731165160437, average reward:-0.8572365582580218,----
Box_Position: [[1.25757788 0.59896423 0.53871782]]
Step:200, total reward:-209.36664475985904, average reward:-1.0468332237992952,----
Box_Position: [[1.40871504 0.55390509 0.53149574]]
Step:200, total reward:-201.68100442409033, average reward:-1.0084050221204517,----
Box_Position: [[1.39262465 0.92746402 0.4687446 ]]
Step:200, total reward:-200.31335838784236, average reward:-1.0015667919392117,----
Box_Position: [[1.3519385  0.74722591 0.46901179]]
Step:141, total reward:-115.51985741343644, average reward:-0.8192897688896201,success
Box_Position: [[1.32165869 1.10792454 0.6813959 ]]
Step:200, total reward:-190.33940069532355, average reward:-0.9516970034766178,----
Box_Position: [[1.32887987 0.93533645 0.65598651]]
Step:200, total reward:-180.4109758785886, average reward:-0.902054879392943,----
Box_Position: [[1.52574323 0.71242546 0.60383827]]
Step:200, total reward:-201.134776569936, average reward:-1.00567388284968,----
Box_Position: [[1.44371727 0.74737629 0.68422482]]
Step:200, total reward:-183.18518727849286, average reward:-0.9159259363924643,----
Box_Position: [[1.40303629 0.86284103 0.61152215]]
Step:200, total reward:-218.73485080144687, average reward:-1.0936742540072344,----
Box_Position: [[1.33878067 0.71249697 0.57050076]]
Step:200, total reward:-168.1148976744286, average reward:-0.840574488372143,----
Box_Position: [[1.52599369 0.53927772 0.53606255]]
Step:200, total reward:-195.75951655297308, average reward:-0.9787975827648654,----
Box_Position: [[1.34288911 0.60405389 0.61842411]]
Step:200, total reward:-181.89504902356524, average reward:-0.9094752451178262,----
Box_Position: [[1.48398594 0.81627151 0.65545744]]
Step:200, total reward:-201.94359271736406, average reward:-1.0097179635868203,----
Box_Position: [[1.43119073 0.53277459 0.69684551]]
Step:200, total reward:-139.85356857243158, average reward:-0.6992678428621579,----
Box_Position: [[1.32502216 0.97534893 0.63207192]]
Step:200, total reward:-186.62212614031768, average reward:-0.9331106307015884,----
Box_Position: [[1.36584032 0.86411575 0.61256846]]
Step:200, total reward:-173.04419933460974, average reward:-0.8652209966730487,----
Box_Position: [[1.54678159 0.68726944 0.6467198 ]]
Step:200, total reward:-199.4767179281188, average reward:-0.997383589640594,----
Box_Position: [[1.25903323 0.71453455 0.68709857]]
Step:200, total reward:-135.1715271086244, average reward:-0.675857635543122,----
Box_Position: [[1.35593483 0.54520635 0.7301324 ]]
Step:153, total reward:-135.48792337413667, average reward:-0.8855419828374945,success
Box_Position: [[1.44555331 0.71190833 0.72380578]]
Step:200, total reward:-169.10884000091136, average reward:-0.8455442000045568,----
Box_Position: [[1.37307685 1.00519954 0.55581642]]
Step:200, total reward:-242.67107420710536, average reward:-1.2133553710355267,----
Box_Position: [[1.46720325 0.78411243 0.69127663]]
Step:200, total reward:-159.97469385242866, average reward:-0.7998734692621433,----
Box_Position: [[1.54458481 0.79850517 0.72374502]]
Step:200, total reward:-161.4626730085332, average reward:-0.8073133650426659,----
Box_Position: [[1.25062797 0.77323468 0.72839639]]
Step:200, total reward:-169.1242249565973, average reward:-0.8456211247829865,----
Box_Position: [[1.28217818 0.69695096 0.5402485 ]]
Step:200, total reward:-198.52606349867483, average reward:-0.9926303174933742,----
Box_Position: [[1.33166693 0.84431395 0.68334199]]
Step:19, total reward:-10.40678558121297, average reward:-0.5477255569059458,success
Box_Position: [[1.46659487 0.67724325 0.68885073]]
Step:200, total reward:-137.42767053065276, average reward:-0.6871383526532638,----
Box_Position: [[1.38221331 0.87652057 0.74675289]]

------------------Episode:50------------------
Step:200, total reward:-137.4033894884691, average reward:-0.6870169474423454,----
Box_Position: [[1.25279593 0.87502362 0.56549321]]
Step:200, total reward:-171.9938801567563, average reward:-0.8599694007837815,----
Box_Position: [[1.47280533 0.75822751 0.4854784 ]]
Step:200, total reward:-209.8617064659693, average reward:-1.0493085323298466,----
Box_Position: [[1.4906561  0.79125318 0.62746517]]
Step:200, total reward:-251.98489911161946, average reward:-1.2599244955580973,----
Box_Position: [[1.53658544 0.94747258 0.62761555]]
Step:200, total reward:-231.12361892809125, average reward:-1.1556180946404562,----
Box_Position: [[1.46140765 0.92296632 0.46068217]]
Step:200, total reward:-229.4646641746771, average reward:-1.1473233208733855,----
Box_Position: [[1.50355874 0.74781424 0.73557218]]
Step:178, total reward:-191.60670725088815, average reward:-1.0764421755667875,success
Box_Position: [[1.49022667 0.96021143 0.63595624]]
Step:200, total reward:-183.16909728414632, average reward:-0.9158454864207316,----
Box_Position: [[1.3463416  0.86532936 0.62987487]]
Step:165, total reward:-123.67247057069358, average reward:-0.7495301246708702,success
Box_Position: [[1.25614961 0.8144032  0.74480731]]
Step:200, total reward:-133.4294934256422, average reward:-0.6671474671282109,----
Box_Position: [[1.25295393 0.65548946 0.61113602]]
Step:200, total reward:-181.89312615768384, average reward:-0.9094656307884192,----
Box_Position: [[1.27329738 0.75811915 0.66979286]]
Step:200, total reward:-246.93426401642742, average reward:-1.234671320082137,----
Box_Position: [[1.43279055 0.83054433 0.71719151]]
Step:140, total reward:-113.87024123222714, average reward:-0.8133588659444796,success
Box_Position: [[1.4566748  0.56733152 0.6985181 ]]
Step:200, total reward:-181.11899299450485, average reward:-0.9055949649725242,----
Box_Position: [[1.42374375 0.71094875 0.58382986]]
Step:200, total reward:-157.98634618837806, average reward:-0.7899317309418903,----
Box_Position: [[1.54477762 0.90826596 0.56936923]]
Step:200, total reward:-184.74538740606505, average reward:-0.9237269370303253,----
Box_Position: [[1.32828245 0.76196323 0.63190318]]
Step:200, total reward:-177.7502300372496, average reward:-0.888751150186248,----
Box_Position: [[1.36286012 0.69065087 0.57489055]]
Step:200, total reward:-149.65369104430135, average reward:-0.7482684552215068,----
Box_Position: [[1.5274094  0.91143487 0.53135194]]
Step:200, total reward:-316.10369859523854, average reward:-1.5805184929761926,----
Box_Position: [[1.40289661 0.7555093  0.73308498]]
Step:200, total reward:-179.5830143756122, average reward:-0.8979150718780611,----
Box_Position: [[1.42523616 1.02300646 0.59338079]]
Step:200, total reward:-224.1409554015541, average reward:-1.1207047770077705,----
Box_Position: [[1.29829558 0.65655118 0.607472  ]]
Step:200, total reward:-188.92957365248043, average reward:-0.9446478682624021,----
Box_Position: [[1.5328852  1.03224971 0.49726977]]
Step:200, total reward:-260.45557267488226, average reward:-1.3022778633744112,----
Box_Position: [[1.28310988 0.95025692 0.4984232 ]]
Step:200, total reward:-173.5653018442504, average reward:-0.867826509221252,----
Box_Position: [[1.52421177 0.83286085 0.45221491]]
Step:200, total reward:-197.10942270218362, average reward:-0.9855471135109181,----
Box_Position: [[1.43284442 0.80443759 0.49900141]]
Step:200, total reward:-183.7947440813258, average reward:-0.9189737204066291,----
Box_Position: [[1.45199044 0.76854915 0.61569583]]
Step:134, total reward:-126.28088515820248, average reward:-0.94239466535972,success
Box_Position: [[1.44541811 0.60532591 0.71633416]]
Step:200, total reward:-169.32992873691975, average reward:-0.8466496436845987,----
Box_Position: [[1.31504418 0.84779871 0.68241326]]
Step:200, total reward:-120.48203619205114, average reward:-0.6024101809602557,----
Box_Position: [[1.53027857 0.68733523 0.62526581]]
Step:200, total reward:-167.84036309922007, average reward:-0.8392018154961004,----
Box_Position: [[1.34003022 1.02767765 0.69442144]]
Step:200, total reward:-189.85875442959974, average reward:-0.9492937721479987,----
Box_Position: [[1.48339318 0.75031852 0.49613591]]
Step:200, total reward:-176.60102409906122, average reward:-0.8830051204953061,----
Box_Position: [[1.39316657 0.82674374 0.54407131]]
Step:200, total reward:-188.95973293577808, average reward:-0.9447986646788904,----
Box_Position: [[1.40069951 0.84608385 0.64499567]]
Step:200, total reward:-155.91933871302115, average reward:-0.7795966935651057,----
Box_Position: [[1.35933349 0.79184035 0.71136099]]
Step:200, total reward:-208.137322251076, average reward:-1.04068661125538,----
Box_Position: [[1.53613436 0.69040201 0.46692327]]
Step:200, total reward:-191.84526855624296, average reward:-0.9592263427812148,----
Box_Position: [[1.40807603 0.93215733 0.45956148]]
Step:200, total reward:-297.4668541276383, average reward:-1.4873342706381916,----
Box_Position: [[1.28313449 0.81722099 0.61933023]]
Step:200, total reward:-153.22179441088718, average reward:-0.766108972054436,----
Box_Position: [[1.41021012 0.94919648 0.65210802]]
Step:200, total reward:-154.28165157386783, average reward:-0.7714082578693392,----
Box_Position: [[1.52085948 1.13929429 0.66100979]]
Step:200, total reward:-214.3513680336847, average reward:-1.0717568401684234,----
Box_Position: [[1.28200449 0.5663585  0.5241977 ]]
Step:200, total reward:-222.79194551489945, average reward:-1.1139597275744972,----
Box_Position: [[1.29983376 0.65664724 0.62447346]]
Step:200, total reward:-286.35604980617927, average reward:-1.4317802490308964,----
Box_Position: [[1.53602355 0.98309279 0.5645509 ]]
Step:200, total reward:-202.34137146274094, average reward:-1.0117068573137047,----
Box_Position: [[1.37271602 0.8007851  0.62967687]]
Step:200, total reward:-146.46596100489296, average reward:-0.7323298050244648,----
Box_Position: [[1.40582848 0.98024686 0.52123314]]
Step:200, total reward:-227.94883671044064, average reward:-1.1397441835522033,----
Box_Position: [[1.35542289 1.09112525 0.59659303]]
Step:200, total reward:-210.4133051741559, average reward:-1.0520665258707795,----
Box_Position: [[1.509125   1.13672207 0.66334667]]
Step:200, total reward:-249.64435535472978, average reward:-1.248221776773649,----
Box_Position: [[1.458741   0.69955654 0.74975377]]
Step:200, total reward:-125.78938253585886, average reward:-0.6289469126792944,----
Box_Position: [[1.28681238 0.70312367 0.49996993]]
Step:146, total reward:-121.6777325482974, average reward:-0.8334091270431329,success
Box_Position: [[1.3836106  0.63477024 0.47991454]]
Step:33, total reward:-43.425180459424276, average reward:-1.3159145593764932,success
Box_Position: [[1.34432125 0.8355075  0.72735254]]

------------------Episode:100------------------
Step:200, total reward:-243.89972086577941, average reward:-1.2194986043288971,----
episode 100, the accuracy is: 11%
Box_Position: [[1.41415762 1.01346174 0.74201447]]
Step:200, total reward:-203.39911181197118, average reward:-1.0169955590598558,----
Box_Position: [[1.50620911 0.8377353  0.59317586]]
Step:200, total reward:-259.1690358842582, average reward:-1.295845179421291,----
Box_Position: [[1.51020959 0.90366109 0.49820998]]
Step:200, total reward:-147.49500522421056, average reward:-0.7374750261210528,----
Box_Position: [[1.27369515 0.74426373 0.54444301]]
Step:200, total reward:-152.99780935699272, average reward:-0.7649890467849636,----
Box_Position: [[1.50556078 0.8213546  0.65318265]]
Step:200, total reward:-189.18594298615696, average reward:-0.9459297149307848,----
Box_Position: [[1.41799438 0.88362571 0.71873017]]
Step:200, total reward:-173.18093700295904, average reward:-0.8659046850147952,----
Box_Position: [[1.40781394 0.9601699  0.74939448]]
Step:200, total reward:-173.00530931333554, average reward:-0.8650265465666778,----
Box_Position: [[1.4995034  0.9595695  0.62467006]]
Step:200, total reward:-332.3471163061054, average reward:-1.661735581530527,----
Box_Position: [[1.34606994 0.90659038 0.50923064]]
Step:200, total reward:-191.77537118982625, average reward:-0.9588768559491312,----
Box_Position: [[1.5274176  0.49405226 0.705193  ]]
Step:200, total reward:-212.66646353741493, average reward:-1.0633323176870746,----
Box_Position: [[1.51400355 0.97641925 0.45005291]]
Step:200, total reward:-319.46142969211064, average reward:-1.5973071484605532,----
Box_Position: [[1.52374418 0.98784645 0.67381891]]
Step:200, total reward:-190.2807842428414, average reward:-0.951403921214207,----
Box_Position: [[1.38858943 0.87598436 0.73190411]]
Step:200, total reward:-164.22479826496766, average reward:-0.8211239913248383,----
Box_Position: [[1.37855399 0.94099232 0.60123638]]
Step:200, total reward:-183.64039418021034, average reward:-0.9182019709010517,----
Box_Position: [[1.27219632 0.82851415 0.62082527]]
Step:200, total reward:-163.7180927243345, average reward:-0.8185904636216725,----
Box_Position: [[1.2561428  0.811461   0.66882246]]
Step:200, total reward:-226.65616590948216, average reward:-1.1332808295474108,----
Box_Position: [[1.48357776 0.81538137 0.53916622]]
Step:200, total reward:-189.2907100135769, average reward:-0.9464535500678845,----
Box_Position: [[1.30012149 0.75929028 0.52848179]]
Step:200, total reward:-164.46432059857122, average reward:-0.8223216029928561,----
Box_Position: [[1.28949325 0.92331794 0.57183176]]
Step:200, total reward:-188.9510533283481, average reward:-0.9447552666417406,----
Box_Position: [[1.36355459 0.85374366 0.60598154]]
Step:200, total reward:-197.61387930121475, average reward:-0.9880693965060737,----
Box_Position: [[1.32520693 1.06522292 0.45069425]]
Step:200, total reward:-217.87730322884937, average reward:-1.0893865161442469,----
Box_Position: [[1.53783163 0.94885873 0.50681232]]
Step:200, total reward:-217.89318214393822, average reward:-1.0894659107196911,----
Box_Position: [[1.30109582 0.57616175 0.46265199]]
Step:89, total reward:-70.33789772096142, average reward:-0.7903134575388924,success
Box_Position: [[1.53119693 0.57371092 0.45282977]]
Step:200, total reward:-223.78729441869632, average reward:-1.1189364720934816,----
Box_Position: [[1.409541   0.55998244 0.58830886]]
Step:200, total reward:-168.79206623497072, average reward:-0.8439603311748536,----
Box_Position: [[1.39015546 0.90917833 0.72459106]]
Step:200, total reward:-162.6561300907862, average reward:-0.813280650453931,----
Box_Position: [[1.44914089 0.47719027 0.67221896]]
Step:200, total reward:-236.62172294141524, average reward:-1.1831086147070762,----
Box_Position: [[1.3037236  0.84339786 0.73113749]]
Step:200, total reward:-244.26357738931142, average reward:-1.221317886946557,----
Box_Position: [[1.30018792 0.84148205 0.55751064]]
Step:200, total reward:-263.1012240891817, average reward:-1.3155061204459084,----
Box_Position: [[1.508487   0.94239041 0.68919698]]
Step:200, total reward:-197.995817927973, average reward:-0.989979089639865,----
Box_Position: [[1.389381   0.71168456 0.49160546]]
Step:200, total reward:-243.25186759688236, average reward:-1.2162593379844118,----
Box_Position: [[1.3280483  1.1362125  0.46732657]]
Step:200, total reward:-247.78584782634348, average reward:-1.2389292391317175,----
Box_Position: [[1.32087372 0.51976874 0.65344157]]
Step:200, total reward:-238.44405949919445, average reward:-1.1922202974959724,----
Box_Position: [[1.54881424 0.77509363 0.60618979]]
Step:200, total reward:-221.35856669696065, average reward:-1.1067928334848032,----
Box_Position: [[1.4473798  0.67696326 0.45893718]]
Step:200, total reward:-197.15769322143876, average reward:-0.9857884661071938,----
Box_Position: [[1.35793468 0.88635077 0.71370755]]
Step:200, total reward:-145.17348564267536, average reward:-0.7258674282133768,----
Box_Position: [[1.27570419 0.90803417 0.47786911]]
Step:200, total reward:-184.80742667755652, average reward:-0.9240371333877826,----
Box_Position: [[1.34659767 0.71354065 0.55397425]]
Step:200, total reward:-178.96188884750717, average reward:-0.8948094442375358,----
Box_Position: [[1.37573964 0.71917615 0.58850377]]
Step:24, total reward:-30.94628660849749, average reward:-1.2894286086873954,success
Box_Position: [[1.39775386 0.68942448 0.56978851]]
Step:200, total reward:-160.25694866511085, average reward:-0.8012847433255543,----
Box_Position: [[1.31022502 0.94409409 0.57761336]]
Step:200, total reward:-171.823338878259, average reward:-0.859116694391295,----
Box_Position: [[1.46373348 0.52422348 0.74446629]]
Step:200, total reward:-205.79219757342383, average reward:-1.028960987867119,----
Box_Position: [[1.33447265 0.98228234 0.61511055]]
Step:200, total reward:-227.7045675076908, average reward:-1.138522837538454,----
Box_Position: [[1.40484788 0.70681825 0.48281196]]
Step:200, total reward:-176.5078817881615, average reward:-0.8825394089408075,----
Box_Position: [[1.540799   0.86696872 0.49561248]]
Step:200, total reward:-195.2856014026104, average reward:-0.9764280070130521,----
Box_Position: [[1.40950806 0.55104323 0.49630661]]
Step:200, total reward:-212.74341652369137, average reward:-1.0637170826184568,----
Box_Position: [[1.39337055 0.95521037 0.58710984]]
Step:200, total reward:-200.72798344470746, average reward:-1.0036399172235373,----
Box_Position: [[1.53258639 0.69010849 0.66033129]]
Step:200, total reward:-185.44245533847644, average reward:-0.9272122766923822,----
Box_Position: [[1.39430019 0.89677979 0.48490824]]
Step:200, total reward:-223.02140513608313, average reward:-1.1151070256804156,----
Box_Position: [[1.27717363 0.71809852 0.61984146]]

------------------Episode:150------------------
Step:200, total reward:-190.77445016344927, average reward:-0.9538722508172464,----
Box_Position: [[1.34670487 0.87941196 0.54355293]]
Step:200, total reward:-197.67792237573371, average reward:-0.9883896118786686,----
Box_Position: [[1.36757622 0.90805647 0.45669003]]
Step:200, total reward:-226.8955290878521, average reward:-1.1344776454392607,----
Box_Position: [[1.4578997  0.82786377 0.74798256]]
Step:200, total reward:-168.54386300903857, average reward:-0.8427193150451928,----
Box_Position: [[1.31239987 0.80929451 0.73724364]]
Step:200, total reward:-206.7665617565835, average reward:-1.0338328087829176,----
Box_Position: [[1.44650406 0.98837578 0.66819514]]
Step:200, total reward:-215.2840155069195, average reward:-1.0764200775345976,----
Box_Position: [[1.31459437 0.5878565  0.47313911]]
Step:200, total reward:-214.61270644196904, average reward:-1.0730635322098452,----
Box_Position: [[1.51925948 0.94433362 0.59225613]]
Step:200, total reward:-191.14260738094276, average reward:-0.9557130369047138,----
Box_Position: [[1.35145054 1.00943542 0.71202857]]
Step:200, total reward:-174.73530522725196, average reward:-0.8736765261362598,----
Box_Position: [[1.3381869  0.64063685 0.74980929]]
Step:200, total reward:-200.08349088051577, average reward:-1.0004174544025788,----
Box_Position: [[1.35471441 1.02921891 0.72904843]]
Step:200, total reward:-218.63151730983438, average reward:-1.0931575865491718,----
Box_Position: [[1.3393688  0.90526123 0.71149546]]
Step:200, total reward:-227.58099071564806, average reward:-1.1379049535782402,----
Box_Position: [[1.37534501 0.88290782 0.64775046]]
Step:200, total reward:-197.55476783883765, average reward:-0.9877738391941883,----
Box_Position: [[1.27488014 0.74344711 0.6855346 ]]
Step:200, total reward:-143.63328569944585, average reward:-0.7181664284972292,----
Box_Position: [[1.51615464 0.52963479 0.47103772]]
Step:200, total reward:-193.07432969137128, average reward:-0.9653716484568564,----
Box_Position: [[1.46671473 0.56030216 0.67072919]]
Step:173, total reward:-237.6844965335649, average reward:-1.3738988238934386,success
Box_Position: [[1.28994761 0.84211598 0.68026303]]
Step:200, total reward:-134.5795509232165, average reward:-0.6728977546160825,----
Box_Position: [[1.44718595 0.64274022 0.50933739]]
Step:200, total reward:-185.88672014076275, average reward:-0.9294336007038138,----
Box_Position: [[1.54027722 0.70569775 0.61298627]]
Step:200, total reward:-184.56835886990172, average reward:-0.9228417943495085,----
Box_Position: [[1.26274259 1.00328941 0.59283397]]
Step:200, total reward:-188.80467036399742, average reward:-0.9440233518199871,----
Box_Position: [[1.25157129 0.93739787 0.73551756]]
Step:200, total reward:-160.04321850633215, average reward:-0.8002160925316608,----
Box_Position: [[1.5430113  0.76075327 0.57832391]]
Step:200, total reward:-233.97948202223125, average reward:-1.1698974101111563,----
Box_Position: [[1.25058357 0.92610873 0.61102554]]
Step:200, total reward:-189.04757891908613, average reward:-0.9452378945954307,----
Box_Position: [[1.53966165 0.8125679  0.57432071]]
Step:200, total reward:-252.43886074176146, average reward:-1.2621943037088073,----
Box_Position: [[1.3986583  0.68126051 0.63204942]]
Step:200, total reward:-164.23559182784857, average reward:-0.8211779591392429,----
Box_Position: [[1.2901062  0.70712876 0.68543165]]
Step:200, total reward:-225.72802661885837, average reward:-1.128640133094292,----
Box_Position: [[1.25886383 0.5581675  0.70505875]]
Step:47, total reward:-46.18074571195844, average reward:-0.9825690577012434,success
Box_Position: [[1.33419617 0.75204061 0.59604263]]
Step:200, total reward:-163.0108668630185, average reward:-0.8150543343150924,----
Box_Position: [[1.4001626  0.46741672 0.70072086]]
Step:200, total reward:-153.5851354090929, average reward:-0.7679256770454645,----
Box_Position: [[1.4735032  0.62320001 0.51248   ]]
Step:200, total reward:-222.4412657913651, average reward:-1.1122063289568256,----
Box_Position: [[1.46670038 0.85963681 0.72240579]]
Step:200, total reward:-189.3699646018135, average reward:-0.9468498230090675,----
Box_Position: [[1.51232334 0.60365697 0.54341277]]
Step:200, total reward:-257.64266320814653, average reward:-1.2882133160407327,----
Box_Position: [[1.39713643 1.13652872 0.50066644]]
Step:200, total reward:-207.2566061137289, average reward:-1.0362830305686446,----
Box_Position: [[1.37068748 0.73182809 0.52443215]]
Step:200, total reward:-293.2060238556867, average reward:-1.4660301192784333,----
Box_Position: [[1.39107901 0.67448788 0.50607102]]
Step:200, total reward:-193.8527361021768, average reward:-0.9692636805108841,----
Box_Position: [[1.52380496 0.95529637 0.47577289]]
Step:200, total reward:-211.77529393740463, average reward:-1.0588764696870232,----
Box_Position: [[1.53881266 0.98128798 0.55228796]]
Step:200, total reward:-218.75983531596452, average reward:-1.0937991765798225,----
Box_Position: [[1.30510327 0.96387187 0.45669431]]
Step:200, total reward:-208.7920042995539, average reward:-1.0439600214977696,----
Box_Position: [[1.444128   0.58129663 0.69942293]]
Step:200, total reward:-149.7637384850397, average reward:-0.7488186924251985,----
Box_Position: [[1.26859886 0.84444336 0.60397409]]
Step:200, total reward:-161.57551630777533, average reward:-0.8078775815388767,----
Box_Position: [[1.26086753 0.93242674 0.63971607]]
Step:200, total reward:-163.71727672419885, average reward:-0.8185863836209942,----
Box_Position: [[1.29624514 0.93333195 0.66295877]]
Step:166, total reward:-131.66769221361477, average reward:-0.7931788687567155,success
Box_Position: [[1.31721968 0.66764269 0.51949491]]
Step:200, total reward:-210.12319749302048, average reward:-1.0506159874651024,----
Box_Position: [[1.40580551 0.83610832 0.57503092]]
Step:200, total reward:-165.91717746455848, average reward:-0.8295858873227924,----
Box_Position: [[1.39850989 0.73821142 0.57173812]]
Step:200, total reward:-177.94291313846355, average reward:-0.8897145656923178,----
Box_Position: [[1.52681197 0.83032466 0.68507081]]
Step:200, total reward:-192.63086945284914, average reward:-0.9631543472642456,----
Box_Position: [[1.38622418 0.87969033 0.61600811]]
Step:200, total reward:-158.6365838715201, average reward:-0.7931829193576004,----
Box_Position: [[1.45174338 0.76680816 0.591548  ]]
Step:200, total reward:-220.73427693307244, average reward:-1.103671384665362,----
Box_Position: [[1.50366145 0.45339416 0.54400415]]
Step:200, total reward:-250.0545027935964, average reward:-1.250272513967982,----
Box_Position: [[1.3093193  0.88538159 0.52385008]]
Step:200, total reward:-182.95277419186485, average reward:-0.9147638709593242,----
Box_Position: [[1.35740337 0.93798627 0.58098707]]

------------------Episode:200------------------
Step:200, total reward:-151.0066854941597, average reward:-0.7550334274707986,----
episode 200, the accuracy is: 5%
Box_Position: [[1.32249082 0.5117719  0.59359183]]
Step:200, total reward:-187.93132295223617, average reward:-0.9396566147611809,----
Box_Position: [[1.28902861 1.06791041 0.61672417]]
Step:200, total reward:-172.9870537811149, average reward:-0.8649352689055745,----
Box_Position: [[1.46344314 0.73537327 0.71415127]]
Step:200, total reward:-172.70469207372867, average reward:-0.8635234603686434,----
Box_Position: [[1.27045474 0.86319462 0.51395496]]
Step:200, total reward:-223.61873340295764, average reward:-1.1180936670147883,----
Box_Position: [[1.36806862 0.71804099 0.51028323]]
Step:200, total reward:-180.96520445140146, average reward:-0.9048260222570073,----
Box_Position: [[1.31603943 0.78480384 0.5177754 ]]
Step:91, total reward:-96.6875555368688, average reward:-1.0625006102952614,success
Box_Position: [[1.27125015 0.96554095 0.74417185]]
Step:200, total reward:-152.6819566888897, average reward:-0.7634097834444485,----
Box_Position: [[1.44473827 0.81983895 0.64042033]]
Step:200, total reward:-348.9819196635245, average reward:-1.7449095983176224,----
Box_Position: [[1.38277352 0.90240844 0.73338378]]
Step:200, total reward:-213.3876841616297, average reward:-1.0669384208081485,----
Box_Position: [[1.29420657 0.64060753 0.50272932]]
Step:200, total reward:-179.06547290534326, average reward:-0.8953273645267162,----
Box_Position: [[1.38110681 0.58107959 0.6440377 ]]
Step:200, total reward:-164.08202577016692, average reward:-0.8204101288508346,----
Box_Position: [[1.25845249 1.10863821 0.45063382]]
Step:200, total reward:-282.92921393281347, average reward:-1.4146460696640673,----
Box_Position: [[1.4471425  0.61834063 0.66280829]]
Step:200, total reward:-199.39746072338667, average reward:-0.9969873036169333,----
Box_Position: [[1.51576047 0.86829158 0.60960407]]
Step:200, total reward:-284.80026089444914, average reward:-1.4240013044722457,----
Box_Position: [[1.39920367 1.04007328 0.47310648]]
Step:200, total reward:-254.0388157065409, average reward:-1.2701940785327046,----
Box_Position: [[1.45757626 0.8169872  0.6050448 ]]
Step:200, total reward:-193.29758890800068, average reward:-0.9664879445400034,----
Box_Position: [[1.26771567 1.08678716 0.45126833]]
Step:200, total reward:-214.64713818472242, average reward:-1.073235690923612,----
Box_Position: [[1.45752136 0.90535796 0.49020899]]
Step:200, total reward:-182.07904577795455, average reward:-0.9103952288897728,----
Box_Position: [[1.35436844 0.87634679 0.68189359]]
Step:88, total reward:-69.07579615244153, average reward:-0.7849522290050174,success
Box_Position: [[1.34319391 0.71383156 0.67195255]]
Step:200, total reward:-151.3534424395597, average reward:-0.7567672121977985,----
Box_Position: [[1.49394853 1.07589631 0.60087632]]
Step:200, total reward:-191.33133191365837, average reward:-0.9566566595682918,----
Box_Position: [[1.46929897 1.09941384 0.51126302]]
Step:200, total reward:-194.79919024647793, average reward:-0.9739959512323897,----
Box_Position: [[1.36007946 1.09363938 0.62467988]]
Step:200, total reward:-261.27404872009737, average reward:-1.306370243600487,----
Box_Position: [[1.49499153 0.84355742 0.54637033]]
Step:200, total reward:-224.86672297972027, average reward:-1.1243336148986014,----
Box_Position: [[1.39764843 0.85970621 0.49354581]]
Step:200, total reward:-242.10170418758838, average reward:-1.2105085209379418,----
Box_Position: [[1.33420439 0.44882224 0.48583587]]
Step:200, total reward:-183.7961537165958, average reward:-0.918980768582979,----
Box_Position: [[1.32689059 0.65340375 0.57022244]]
Step:200, total reward:-154.7659210419718, average reward:-0.773829605209859,----
Box_Position: [[1.4153496  0.90302357 0.65790162]]
Step:200, total reward:-208.94078720639513, average reward:-1.0447039360319756,----
Box_Position: [[1.5138019  1.04453413 0.51082162]]
Step:28, total reward:-25.755282870939745, average reward:-0.9198315311049908,success
Box_Position: [[1.30579839 0.94427483 0.61029524]]
Step:200, total reward:-221.93431652905338, average reward:-1.1096715826452668,----
Box_Position: [[1.32906772 0.71646981 0.60932637]]
Step:200, total reward:-142.86230829704175, average reward:-0.7143115414852087,----
Box_Position: [[1.30919071 1.13861947 0.63621509]]
Step:200, total reward:-212.2299754101229, average reward:-1.0611498770506145,----
Box_Position: [[1.51026654 0.96643862 0.51099958]]
Step:200, total reward:-204.92427955068646, average reward:-1.0246213977534324,----
Box_Position: [[1.27966293 0.711429   0.70196496]]
Step:200, total reward:-156.55840595811725, average reward:-0.7827920297905863,----
Box_Position: [[1.49819725 0.69973949 0.68230632]]
Step:200, total reward:-182.63958789562733, average reward:-0.9131979394781367,----
Box_Position: [[1.54395921 0.68125936 0.62289063]]
Step:200, total reward:-167.67804534524063, average reward:-0.8383902267262031,----
Box_Position: [[1.35839571 0.9768232  0.58896707]]
Step:200, total reward:-196.9889531950355, average reward:-0.9849447659751774,----
Box_Position: [[1.47672525 0.61471178 0.62104557]]
Step:200, total reward:-176.19754805173378, average reward:-0.8809877402586689,----
Box_Position: [[1.5284241  0.52226213 0.53071493]]
Step:200, total reward:-190.30010878561134, average reward:-0.9515005439280567,----
Box_Position: [[1.36542288 0.7150863  0.67171425]]
Step:200, total reward:-216.80433741364004, average reward:-1.0840216870682002,----
Box_Position: [[1.44778296 0.57503407 0.7034082 ]]
Step:200, total reward:-150.32455779436188, average reward:-0.7516227889718095,----
Box_Position: [[1.28289579 0.42186625 0.66237531]]
Step:200, total reward:-187.224662494133, average reward:-0.936123312470665,----
Box_Position: [[1.25453405 0.9364733  0.6574029 ]]
Step:132, total reward:-146.64343187979017, average reward:-1.1109350899984103,success
Box_Position: [[1.31058838 0.97344303 0.62903599]]
Step:200, total reward:-188.40799380127953, average reward:-0.9420399690063976,----
Box_Position: [[1.35079838 0.69309244 0.58602304]]
Step:200, total reward:-202.62188948144356, average reward:-1.0131094474072178,----
Box_Position: [[1.54544619 0.76931794 0.74860952]]
Step:200, total reward:-175.19976688175245, average reward:-0.8759988344087623,----
Box_Position: [[1.44090687 0.96866857 0.59460463]]
Step:200, total reward:-257.82122924846567, average reward:-1.2891061462423283,----
Box_Position: [[1.34995893 0.83469184 0.50061669]]
Step:200, total reward:-275.0422539126032, average reward:-1.375211269563016,----
Box_Position: [[1.38428578 1.16536525 0.52043445]]
Step:200, total reward:-213.9321237195039, average reward:-1.0696606185975195,----
Box_Position: [[1.29208933 0.58034369 0.71690257]]

------------------Episode:250------------------
Step:83, total reward:-75.20853310297133, average reward:-0.9061269048550763,success
Box_Position: [[1.51212866 0.70518575 0.58463738]]
Step:200, total reward:-162.38864646099432, average reward:-0.8119432323049716,----
Box_Position: [[1.3590312  1.03976719 0.50419673]]
Step:200, total reward:-242.6489129065719, average reward:-1.2132445645328596,----
Box_Position: [[1.53716791 0.66361248 0.49313412]]
Step:192, total reward:-246.22259160783406, average reward:-1.2824093312908025,success
Box_Position: [[1.27366597 0.56276767 0.52828534]]
Step:200, total reward:-183.44401771547828, average reward:-0.9172200885773915,----
Box_Position: [[1.32001898 0.96895849 0.66129339]]
Step:38, total reward:-25.6662006077637, average reward:-0.6754263317832553,success
Box_Position: [[1.27286712 0.65196926 0.59968341]]
Step:200, total reward:-176.29833842072492, average reward:-0.8814916921036245,----
Box_Position: [[1.43862134 0.69656462 0.62823353]]
Step:200, total reward:-249.26013466516545, average reward:-1.2463006733258273,----
Box_Position: [[1.25040016 1.15870202 0.51375816]]
Step:200, total reward:-207.17174533516396, average reward:-1.03585872667582,----
Box_Position: [[1.34485298 0.72419124 0.66028808]]
Step:200, total reward:-187.7017124420029, average reward:-0.9385085622100146,----
Box_Position: [[1.34918023 0.827897   0.45456409]]
Step:200, total reward:-164.62212846564472, average reward:-0.8231106423282236,----
Box_Position: [[1.40405774 0.93663659 0.65250214]]
Step:200, total reward:-215.358580853961, average reward:-1.076792904269805,----
Box_Position: [[1.37746314 0.64921375 0.67017632]]
Step:200, total reward:-207.17523839791428, average reward:-1.0358761919895714,----
Box_Position: [[1.2899538  0.88037253 0.6949157 ]]
Step:131, total reward:-106.76973882036505, average reward:-0.81503617420126,success
Box_Position: [[1.52901617 0.97698404 0.71977575]]
Step:200, total reward:-263.08559821852606, average reward:-1.3154279910926303,----
Box_Position: [[1.29281374 1.02162851 0.58909034]]
Step:182, total reward:-170.47243621723075, average reward:-0.9366617374573118,success
Box_Position: [[1.28690157 0.67874487 0.70236711]]
Step:200, total reward:-213.21716562932505, average reward:-1.0660858281466252,----
Box_Position: [[1.37304469 0.93294368 0.69806868]]
Step:200, total reward:-196.33247640203373, average reward:-0.9816623820101686,----
Box_Position: [[1.3014506  0.84349261 0.72583445]]
Step:200, total reward:-189.84042370132866, average reward:-0.9492021185066433,----
Box_Position: [[1.39931356 0.85305622 0.64662502]]
Step:200, total reward:-234.69812164907674, average reward:-1.1734906082453838,----
Box_Position: [[1.49479397 0.68498944 0.49547467]]
Step:200, total reward:-210.6772484175451, average reward:-1.0533862420877254,----
Box_Position: [[1.53192614 0.59452788 0.49191694]]
Step:200, total reward:-188.18058997035698, average reward:-0.9409029498517849,----
Box_Position: [[1.35753082 0.64619749 0.53528775]]
Step:200, total reward:-187.95696370369262, average reward:-0.9397848185184631,----
Box_Position: [[1.42726027 0.85085818 0.70395334]]
Step:200, total reward:-202.104507445927, average reward:-1.010522537229635,----
Box_Position: [[1.43449131 0.72674543 0.57467642]]
Step:200, total reward:-172.30043741129901, average reward:-0.8615021870564951,----
Box_Position: [[1.52545859 0.46914636 0.64863144]]
Step:200, total reward:-179.38675288248686, average reward:-0.8969337644124343,----
Box_Position: [[1.4184766  0.86570022 0.46757058]]
Step:200, total reward:-177.10594700289343, average reward:-0.8855297350144672,----
Box_Position: [[1.50224916 0.62896514 0.54430256]]
Step:200, total reward:-189.9836640448579, average reward:-0.9499183202242896,----
Box_Position: [[1.27218494 1.02436225 0.46609137]]
Step:200, total reward:-228.99253235574693, average reward:-1.1449626617787347,----
Box_Position: [[1.36060484 0.8791755  0.48231153]]
Step:78, total reward:-58.64707225134575, average reward:-0.7518855416839199,success
Box_Position: [[1.50259634 0.75632155 0.51534672]]
Step:200, total reward:-202.66903211119038, average reward:-1.0133451605559518,----
Box_Position: [[1.46803901 0.69530743 0.48711344]]
Step:200, total reward:-205.5862962258908, average reward:-1.027931481129454,----
Box_Position: [[1.45294073 0.9406233  0.53815838]]
Step:200, total reward:-194.95096924903044, average reward:-0.9747548462451522,----
Box_Position: [[1.31815175 0.74639    0.70833203]]
Step:200, total reward:-165.98867455288982, average reward:-0.8299433727644491,----
Box_Position: [[1.30851025 0.58892207 0.66780487]]
Step:200, total reward:-147.38032874858578, average reward:-0.7369016437429289,----
Box_Position: [[1.46064751 0.67169454 0.50773222]]
Step:200, total reward:-187.32569164561224, average reward:-0.9366284582280612,----
Box_Position: [[1.25675675 0.96353187 0.54462561]]
Step:200, total reward:-189.110936658978, average reward:-0.94555468329489,----
Box_Position: [[1.54654232 0.96291985 0.6805966 ]]
Step:200, total reward:-172.05625876253814, average reward:-0.8602812938126907,----
Box_Position: [[1.29200401 0.52588045 0.57790711]]
Step:200, total reward:-161.81340188322002, average reward:-0.8090670094161001,----
Box_Position: [[1.28816701 1.08827421 0.68796283]]
Step:4, total reward:-7.37432842964112, average reward:-1.84358210741028,success
Box_Position: [[1.47171249 0.77099876 0.62023356]]
Step:200, total reward:-262.3725148037629, average reward:-1.3118625740188146,----
Box_Position: [[1.46837668 0.86971458 0.67095677]]
Step:200, total reward:-201.92153357491335, average reward:-1.0096076678745667,----
Box_Position: [[1.30265169 0.95456036 0.62125784]]
Step:200, total reward:-161.5349915828139, average reward:-0.8076749579140694,----
Box_Position: [[1.3091908  0.76798671 0.45452822]]
Step:200, total reward:-186.0956232082945, average reward:-0.9304781160414726,----
Box_Position: [[1.31772895 0.82534279 0.5133662 ]]
Step:200, total reward:-225.79328873590566, average reward:-1.1289664436795284,----
Box_Position: [[1.46277268 0.92178555 0.53244831]]
Step:200, total reward:-189.40679777726, average reward:-0.9470339888863001,----
Box_Position: [[1.29227739 0.68260899 0.71975421]]
Step:200, total reward:-189.25139578393453, average reward:-0.9462569789196726,----
Box_Position: [[1.34384414 0.5368164  0.51168493]]
Step:200, total reward:-212.32461769712137, average reward:-1.0616230884856068,----
Box_Position: [[1.34848356 0.68318349 0.69953979]]
Step:200, total reward:-182.20526429341314, average reward:-0.9110263214670656,----
Box_Position: [[1.25942099 0.7729594  0.59112958]]
Step:200, total reward:-204.08631900559797, average reward:-1.0204315950279899,----
Box_Position: [[1.45745085 0.59447858 0.45674766]]

------------------Episode:300------------------
Step:200, total reward:-208.48000594973843, average reward:-1.0424000297486922,----
episode 300, the accuracy is: 11%
Box_Position: [[1.42353658 0.55927839 0.54970742]]
Step:200, total reward:-215.98430598579822, average reward:-1.079921529928991,----
Box_Position: [[1.49681096 0.71439994 0.48257629]]
Step:200, total reward:-186.54464646674154, average reward:-0.9327232323337077,----
Box_Position: [[1.52279319 0.77380181 0.48468929]]
Step:200, total reward:-199.48018609511217, average reward:-0.9974009304755609,----
Box_Position: [[1.40918537 0.73126283 0.56502919]]
Step:200, total reward:-167.39623596944182, average reward:-0.8369811798472091,----
Box_Position: [[1.42764922 0.54131414 0.55923159]]
Step:200, total reward:-182.75749017310875, average reward:-0.9137874508655437,----
Box_Position: [[1.48237312 0.9489345  0.62873628]]
Step:200, total reward:-185.68246441237108, average reward:-0.9284123220618554,----
Box_Position: [[1.27138536 0.86501653 0.71436055]]
Step:200, total reward:-173.66168783451778, average reward:-0.8683084391725889,----
Box_Position: [[1.28466971 0.85408746 0.55518512]]
Step:200, total reward:-171.94304696715375, average reward:-0.8597152348357687,----
Box_Position: [[1.26485907 1.15272058 0.5370536 ]]
Step:200, total reward:-259.22071059211754, average reward:-1.2961035529605878,----
Box_Position: [[1.25054066 0.98066748 0.72334086]]
Step:200, total reward:-156.55513355799746, average reward:-0.7827756677899873,----
Box_Position: [[1.26057495 0.72955552 0.6068321 ]]
Step:200, total reward:-154.7091037546455, average reward:-0.7735455187732275,----
Box_Position: [[1.41030816 0.76432893 0.69936085]]
Step:200, total reward:-154.6210744380408, average reward:-0.773105372190204,----
Box_Position: [[1.34591463 1.06202711 0.65938697]]
Step:200, total reward:-234.34692413227953, average reward:-1.1717346206613977,----
Box_Position: [[1.46121644 0.68503072 0.72560734]]
Step:200, total reward:-178.137041295718, average reward:-0.8906852064785901,----
Box_Position: [[1.33047835 0.86970404 0.47708205]]
Step:200, total reward:-192.27246246935428, average reward:-0.9613623123467714,----
Box_Position: [[1.48116668 1.03215326 0.52807483]]
Step:200, total reward:-208.06879310972883, average reward:-1.0403439655486442,----
Box_Position: [[1.35564846 0.65081206 0.66536004]]
Step:200, total reward:-148.13362626650718, average reward:-0.7406681313325358,----
Box_Position: [[1.33624541 0.75778882 0.52975599]]
Step:200, total reward:-134.71843571101334, average reward:-0.6735921785550667,----
Box_Position: [[1.28207847 0.74769915 0.53748189]]
Step:200, total reward:-167.7817700834098, average reward:-0.8389088504170491,----
Box_Position: [[1.52022627 0.99360632 0.7172787 ]]
Step:200, total reward:-214.632686090463, average reward:-1.073163430452315,----
Box_Position: [[1.42099133 0.95486976 0.5320755 ]]
Step:200, total reward:-177.131303998613, average reward:-0.8856565199930649,----
Box_Position: [[1.33959339 0.59797459 0.61267119]]
Step:200, total reward:-153.95396210113108, average reward:-0.7697698105056554,----
Box_Position: [[1.27177428 0.64367693 0.56029609]]
Step:200, total reward:-173.29895639264177, average reward:-0.8664947819632088,----
Box_Position: [[1.39998411 0.85427535 0.55230561]]
Step:200, total reward:-183.46681383738144, average reward:-0.9173340691869072,----
Box_Position: [[1.2541052  0.4700645  0.60708861]]
Step:200, total reward:-193.3150300646762, average reward:-0.9665751503233809,----
Box_Position: [[1.3127545  0.88426323 0.45471969]]
Step:200, total reward:-205.18397395972596, average reward:-1.0259198697986298,----
Box_Position: [[1.54993328 0.67791653 0.7480092 ]]
Step:200, total reward:-192.29789399287577, average reward:-0.9614894699643789,----
Box_Position: [[1.52036834 0.58722357 0.60396434]]
Step:200, total reward:-187.54587043438298, average reward:-0.9377293521719149,----
Box_Position: [[1.32147124 0.83187044 0.5476219 ]]
Step:200, total reward:-181.25770427679592, average reward:-0.9062885213839796,----
Box_Position: [[1.3630073  0.55437642 0.62146134]]
Step:200, total reward:-155.2346978205474, average reward:-0.7761734891027371,----
Box_Position: [[1.47797057 0.63814664 0.53999187]]
Step:200, total reward:-226.60812553719995, average reward:-1.1330406276859997,----
Box_Position: [[1.45624443 0.72673721 0.68569097]]
Step:200, total reward:-188.37974424043392, average reward:-0.9418987212021697,----
Box_Position: [[1.26321151 0.51014844 0.6389551 ]]
Step:200, total reward:-188.8784413329518, average reward:-0.9443922066647591,----
Box_Position: [[1.32479528 1.11149623 0.58748669]]
Step:200, total reward:-241.21385466705695, average reward:-1.2060692733352847,----
Box_Position: [[1.37728361 1.01608187 0.48112239]]
Step:122, total reward:-132.9078993549325, average reward:-1.0894090111060042,success
Box_Position: [[1.35562129 0.88661182 0.71128535]]
Step:200, total reward:-153.87321632807001, average reward:-0.76936608164035,----
Box_Position: [[1.40076354 0.76060654 0.7298329 ]]
Step:200, total reward:-188.71728199924493, average reward:-0.9435864099962247,----
Box_Position: [[1.37004767 0.92495439 0.55730482]]
Step:200, total reward:-198.24146065624691, average reward:-0.9912073032812345,----
Box_Position: [[1.47764563 0.95607899 0.59674844]]
Step:200, total reward:-212.26937899187726, average reward:-1.0613468949593863,----
Box_Position: [[1.31477261 0.8633946  0.52448336]]
Step:200, total reward:-178.05006726121906, average reward:-0.8902503363060953,----
Box_Position: [[1.4233843  0.89346758 0.51700542]]
Step:200, total reward:-208.20027495452513, average reward:-1.0410013747726257,----
Box_Position: [[1.38898668 0.80841284 0.65746299]]
Step:200, total reward:-171.20240406901712, average reward:-0.8560120203450856,----
Box_Position: [[1.4462862  0.82946756 0.64770527]]
Step:200, total reward:-155.26310848583253, average reward:-0.7763155424291627,----
Box_Position: [[1.48420862 0.73660271 0.71991312]]
Step:200, total reward:-164.38535763082876, average reward:-0.8219267881541438,----
Box_Position: [[1.28584634 0.82095204 0.47642939]]
Step:200, total reward:-206.25118552114165, average reward:-1.0312559276057083,----
Box_Position: [[1.45512509 0.84407055 0.56143314]]
Step:200, total reward:-197.28691700737787, average reward:-0.9864345850368893,----
Box_Position: [[1.35074261 0.94803568 0.60736542]]
Step:200, total reward:-153.24092112703485, average reward:-0.7662046056351742,----
Box_Position: [[1.49053377 0.60663047 0.55208651]]
Step:200, total reward:-216.68681788597138, average reward:-1.0834340894298569,----
Box_Position: [[1.45778207 0.76346934 0.4998956 ]]
Step:200, total reward:-231.8526810045635, average reward:-1.1592634050228174,----
Box_Position: [[1.32581295 1.09705406 0.72568053]]

------------------Episode:350------------------
Step:200, total reward:-235.76813692763955, average reward:-1.1788406846381978,----
Box_Position: [[1.30249922 0.96513409 0.63178176]]
Step:200, total reward:-193.227671269197, average reward:-0.966138356345985,----
Box_Position: [[1.49178206 0.98522405 0.74365613]]
Step:200, total reward:-177.59670816579379, average reward:-0.8879835408289689,----
Box_Position: [[1.31547773 0.74919722 0.61619026]]
Step:200, total reward:-200.47427715092684, average reward:-1.0023713857546341,----
Box_Position: [[1.35987216 0.8205981  0.7355261 ]]
Step:200, total reward:-152.89647376928832, average reward:-0.7644823688464416,----
Box_Position: [[1.25494858 0.92978556 0.56449064]]
Step:200, total reward:-181.58296179935584, average reward:-0.9079148089967792,----
Box_Position: [[1.44899866 0.80342269 0.65243435]]
Step:200, total reward:-188.54999301656864, average reward:-0.9427499650828431,----
Box_Position: [[1.34805106 0.87763629 0.68122307]]
Step:200, total reward:-175.33187503599132, average reward:-0.8766593751799566,----
Box_Position: [[1.34290222 1.11138969 0.67840346]]
Step:200, total reward:-255.4177750926852, average reward:-1.277088875463426,----
Box_Position: [[1.33538429 0.86669098 0.53104769]]
Step:200, total reward:-216.8789938475843, average reward:-1.0843949692379216,----
Box_Position: [[1.42144089 0.48627968 0.73669414]]
Step:200, total reward:-231.65382218091702, average reward:-1.158269110904585,----
Box_Position: [[1.50422376 0.43731466 0.5955089 ]]
Step:200, total reward:-196.84381124381179, average reward:-0.9842190562190589,----
Box_Position: [[1.40417561 0.60947868 0.5676747 ]]
Step:200, total reward:-176.79729826561567, average reward:-0.8839864913280784,----
Box_Position: [[1.25695003 0.85258873 0.60053365]]
Step:84, total reward:-64.97054614572743, average reward:-0.7734588826872313,success
Box_Position: [[1.38966272 0.73956615 0.73113097]]
Step:200, total reward:-120.08567761652374, average reward:-0.6004283880826187,----
Box_Position: [[1.26989826 0.61217135 0.65691952]]
Step:200, total reward:-222.34702085262072, average reward:-1.1117351042631036,----
Box_Position: [[1.28412291 0.57958217 0.65454191]]
Step:200, total reward:-177.88183659903535, average reward:-0.8894091829951768,----
Box_Position: [[1.33139714 0.97246535 0.60842063]]
Step:200, total reward:-203.69203163893826, average reward:-1.0184601581946913,----
Box_Position: [[1.40370397 0.77229294 0.49324203]]
Step:200, total reward:-200.322491757429, average reward:-1.0016124587871449,----
Box_Position: [[1.54713526 0.4301766  0.72908384]]
Step:200, total reward:-219.91714507652702, average reward:-1.099585725382635,----
Box_Position: [[1.32418678 0.7672247  0.65817479]]
Step:67, total reward:-45.16135294232208, average reward:-0.6740500439152549,success
Box_Position: [[1.29382741 1.00255763 0.46475615]]
Step:200, total reward:-192.09459466738778, average reward:-0.9604729733369389,----
Box_Position: [[1.54351632 0.84914098 0.58105191]]
Step:200, total reward:-214.55078781836212, average reward:-1.0727539390918106,----
Box_Position: [[1.41948351 0.64798758 0.67978107]]
Step:200, total reward:-176.26321892657668, average reward:-0.8813160946328834,----
Box_Position: [[1.40758149 0.93205875 0.57963881]]
Step:200, total reward:-170.66593352171532, average reward:-0.8533296676085765,----
Box_Position: [[1.45154982 0.60636696 0.59070301]]
Step:200, total reward:-161.64350196847946, average reward:-0.8082175098423973,----
Box_Position: [[1.53421451 0.76446659 0.69442393]]
Step:200, total reward:-182.7023786640004, average reward:-0.913511893320002,----
Box_Position: [[1.40213036 0.50775018 0.62867776]]
Step:200, total reward:-149.06415290800757, average reward:-0.7453207645400378,----
Box_Position: [[1.50420085 0.53938245 0.49269578]]
Step:200, total reward:-172.07319319412312, average reward:-0.8603659659706157,----
Box_Position: [[1.47619502 0.7854786  0.72420412]]
Step:200, total reward:-221.55092665134148, average reward:-1.1077546332567074,----
Box_Position: [[1.28904883 0.47457029 0.68605771]]
Step:200, total reward:-166.7710629394784, average reward:-0.833855314697392,----
Box_Position: [[1.52471233 0.62140165 0.59388548]]
Step:200, total reward:-180.7026240092525, average reward:-0.9035131200462625,----
Box_Position: [[1.3077631  0.84433321 0.49670894]]
Step:200, total reward:-161.98734861020398, average reward:-0.8099367430510199,----
Box_Position: [[1.33676793 1.0091335  0.72026675]]
Step:200, total reward:-187.7922367496866, average reward:-0.938961183748433,----
Box_Position: [[1.34250368 0.59086569 0.53062675]]
Step:200, total reward:-150.8085907932761, average reward:-0.7540429539663804,----
Box_Position: [[1.30604949 1.00275428 0.62592141]]
Step:200, total reward:-242.9108473727252, average reward:-1.214554236863626,----
Box_Position: [[1.27938601 0.79896211 0.46649415]]
Step:200, total reward:-192.59338351259032, average reward:-0.9629669175629516,----
Box_Position: [[1.54480193 0.51430661 0.73447561]]
Step:200, total reward:-160.15412576082105, average reward:-0.8007706288041052,----
Box_Position: [[1.38727399 0.92766381 0.60414476]]
Step:200, total reward:-227.62766243055478, average reward:-1.138138312152774,----
Box_Position: [[1.32188737 0.93655442 0.48735594]]
Step:149, total reward:-195.82116707336922, average reward:-1.314236020626639,success
Box_Position: [[1.2612356  1.00318589 0.7186013 ]]
Step:200, total reward:-167.0856871436443, average reward:-0.8354284357182215,----
Box_Position: [[1.36603651 0.85650968 0.5838081 ]]
Step:200, total reward:-214.36242205013866, average reward:-1.0718121102506932,----
Box_Position: [[1.41825955 1.13396013 0.70437875]]
Step:200, total reward:-229.98680992587245, average reward:-1.1499340496293622,----
Box_Position: [[1.37945538 0.49246778 0.68087412]]
Step:200, total reward:-289.94893519542114, average reward:-1.4497446759771058,----
Box_Position: [[1.32385117 0.55706553 0.67463083]]
Step:200, total reward:-178.38954607351312, average reward:-0.8919477303675656,----
Box_Position: [[1.54350158 0.72970573 0.61916283]]
Step:200, total reward:-206.76213952898863, average reward:-1.033810697644943,----
Box_Position: [[1.46578045 0.80863148 0.59918038]]
Step:200, total reward:-153.08515013356993, average reward:-0.7654257506678497,----
Box_Position: [[1.42070095 0.65826809 0.56491847]]
Step:200, total reward:-208.80654579484946, average reward:-1.0440327289742473,----
Box_Position: [[1.53599626 0.82431597 0.65496632]]
Step:200, total reward:-249.0067130318937, average reward:-1.2450335651594684,----
Box_Position: [[1.36490734 0.97438514 0.53395066]]
Step:200, total reward:-256.17998754133595, average reward:-1.2808999377066796,----
Box_Position: [[1.25065826 0.76699004 0.638546  ]]

------------------Episode:400------------------
Step:200, total reward:-205.8370982053687, average reward:-1.0291854910268434,----
episode 400, the accuracy is: 4%
Box_Position: [[1.49977672 1.01679978 0.58128403]]
Step:200, total reward:-210.42399743954053, average reward:-1.0521199871977027,----
Box_Position: [[1.47356312 0.83088353 0.4869989 ]]
Step:200, total reward:-167.25045397828873, average reward:-0.8362522698914436,----
Box_Position: [[1.33171797 0.90543694 0.72953423]]
Step:200, total reward:-147.27761235795944, average reward:-0.7363880617897972,----
Box_Position: [[1.50526996 1.08641826 0.59198909]]
Step:200, total reward:-211.54585842014518, average reward:-1.057729292100726,----
Box_Position: [[1.48821302 1.03039374 0.6863781 ]]
Step:200, total reward:-262.7187105257403, average reward:-1.3135935526287015,----
Box_Position: [[1.52278598 0.77903641 0.49683398]]
Step:200, total reward:-227.55586970605262, average reward:-1.1377793485302632,----
Box_Position: [[1.30579484 0.83304498 0.51315252]]
Step:200, total reward:-155.01705851535172, average reward:-0.7750852925767586,----
Box_Position: [[1.47496272 1.09406667 0.72327661]]
Step:200, total reward:-220.13510211494133, average reward:-1.1006755105747066,----
Box_Position: [[1.34738518 0.83748792 0.61860959]]
Step:200, total reward:-196.16632238584754, average reward:-0.9808316119292377,----
Box_Position: [[1.4105516  0.645764   0.74330763]]
Step:200, total reward:-234.99085840888745, average reward:-1.1749542920444371,----
Box_Position: [[1.26351728 0.80157595 0.58326388]]
Step:11, total reward:-13.45742098866947, average reward:-1.223401908060861,success
Box_Position: [[1.25910587 1.04178883 0.52782796]]
Step:200, total reward:-177.535691799529, average reward:-0.887678458997645,----
Box_Position: [[1.34576791 0.83177261 0.62274758]]
Step:200, total reward:-180.05684135045288, average reward:-0.9002842067522644,----
Box_Position: [[1.42301347 0.6443492  0.54662996]]
Step:200, total reward:-193.58451981322366, average reward:-0.9679225990661183,----
Box_Position: [[1.44271236 0.71738068 0.47606377]]
Step:200, total reward:-229.3449076670108, average reward:-1.146724538335054,----
Box_Position: [[1.39555429 0.46510844 0.69678455]]
Step:200, total reward:-159.0982627816961, average reward:-0.7954913139084805,----
Box_Position: [[1.45520377 0.63771775 0.55341257]]
Step:200, total reward:-197.59589761720994, average reward:-0.9879794880860497,----
Box_Position: [[1.37746946 0.78721749 0.73551305]]
Step:200, total reward:-144.08809161736437, average reward:-0.7204404580868219,----
Box_Position: [[1.48704135 0.49926335 0.63637165]]
Step:200, total reward:-166.40653512660782, average reward:-0.8320326756330391,----
Box_Position: [[1.49970916 0.78216352 0.71873134]]
Step:200, total reward:-149.64713211067107, average reward:-0.7482356605533553,----
Box_Position: [[1.27421385 0.60465752 0.68504413]]
Step:200, total reward:-200.0327088518959, average reward:-1.0001635442594796,----
Box_Position: [[1.2680327  0.94006749 0.64643594]]
Step:200, total reward:-177.20549100156157, average reward:-0.8860274550078079,----
Box_Position: [[1.30300186 0.89869286 0.65649402]]
Step:200, total reward:-188.18158361711835, average reward:-0.9409079180855917,----
Box_Position: [[1.41497282 0.79526103 0.49631712]]
Step:200, total reward:-183.33825948183946, average reward:-0.9166912974091973,----
Box_Position: [[1.50239229 0.81370191 0.54099231]]
Step:200, total reward:-300.67144263333546, average reward:-1.5033572131666773,----
Box_Position: [[1.53647399 0.96297476 0.55243501]]
Step:200, total reward:-218.05515138650742, average reward:-1.0902757569325372,----
Box_Position: [[1.34395251 0.79424108 0.52414002]]
Step:163, total reward:-139.35940087689985, average reward:-0.8549656495515329,success
Box_Position: [[1.35962311 0.79326901 0.6130357 ]]
Step:200, total reward:-212.0167847932274, average reward:-1.060083923966137,----
Box_Position: [[1.41115417 0.79912444 0.65953647]]
Step:200, total reward:-184.75191811308994, average reward:-0.9237595905654498,----
Box_Position: [[1.51155314 0.78086042 0.68185041]]
Step:200, total reward:-214.25185767150202, average reward:-1.07125928835751,----
Box_Position: [[1.4949532  1.04299066 0.66050641]]
Step:200, total reward:-201.73308354700234, average reward:-1.0086654177350116,----
Box_Position: [[1.29624172 0.83067927 0.59742828]]
Step:200, total reward:-147.39909324217052, average reward:-0.7369954662108527,----
Box_Position: [[1.53401695 0.61342616 0.6797277 ]]
Step:200, total reward:-191.71477173879748, average reward:-0.9585738586939874,----
Box_Position: [[1.48602699 0.63352322 0.62158803]]
Step:200, total reward:-185.02398839090253, average reward:-0.9251199419545126,----
Box_Position: [[1.25365664 1.03927142 0.67358039]]
Step:200, total reward:-177.92260758702923, average reward:-0.8896130379351461,----
Box_Position: [[1.39997494 0.92707567 0.70703928]]
Step:200, total reward:-167.88103219392767, average reward:-0.8394051609696384,----
Box_Position: [[1.37355605 0.98151394 0.6480719 ]]
Step:200, total reward:-184.3377367196724, average reward:-0.921688683598362,----
Box_Position: [[1.26784638 0.779402   0.45668226]]
Step:86, total reward:-80.6092739325839, average reward:-0.9373171387509757,success
Box_Position: [[1.31398663 0.91090504 0.68427662]]
Step:200, total reward:-162.70178241231244, average reward:-0.8135089120615622,----
Box_Position: [[1.45305431 0.70727491 0.58904493]]
Step:200, total reward:-218.16418163363198, average reward:-1.09082090816816,----
Box_Position: [[1.40059544 0.66204723 0.68770302]]
Step:200, total reward:-158.17032986975195, average reward:-0.7908516493487597,----
Box_Position: [[1.34932631 0.9913603  0.50291784]]
Step:200, total reward:-222.71413308244502, average reward:-1.113570665412225,----
Box_Position: [[1.36703614 0.72871298 0.70343292]]
Step:173, total reward:-174.76659015571812, average reward:-1.0102115037902781,success
Box_Position: [[1.54822763 0.57986315 0.53304838]]
Step:200, total reward:-250.09545855873213, average reward:-1.2504772927936607,----
Box_Position: [[1.25817867 1.12973922 0.62686069]]
Step:200, total reward:-166.61484030505696, average reward:-0.8330742015252848,----
Box_Position: [[1.26855233 0.71080259 0.63107273]]
Step:200, total reward:-241.0251210872951, average reward:-1.2051256054364756,----
Box_Position: [[1.37967188 0.81194429 0.56637578]]
Step:200, total reward:-172.31610222289558, average reward:-0.8615805111144779,----
Box_Position: [[1.25420916 0.80831289 0.74994039]]
Step:200, total reward:-156.81037100685106, average reward:-0.7840518550342552,----
Box_Position: [[1.26342693 0.71778335 0.59406908]]
Step:200, total reward:-176.4106697639581, average reward:-0.8820533488197906,----
Box_Position: [[1.31099887 0.72620527 0.55851767]]

------------------Episode:450------------------
Step:99, total reward:-70.04023076632534, average reward:-0.7074770784477307,success
Box_Position: [[1.26588186 0.71332656 0.62207702]]
Step:200, total reward:-162.7356416016586, average reward:-0.813678208008293,----
Box_Position: [[1.39051106 0.90884652 0.70828453]]
Step:155, total reward:-133.73543987413825, average reward:-0.8628092895105693,success
Box_Position: [[1.37944133 1.00134756 0.50367317]]
Step:200, total reward:-219.47482066178412, average reward:-1.0973741033089206,----
Box_Position: [[1.33059666 0.89837394 0.6128339 ]]
Step:200, total reward:-178.3592137823947, average reward:-0.8917960689119735,----
Box_Position: [[1.52230426 0.93356185 0.73477459]]
Step:200, total reward:-209.95517185416017, average reward:-1.0497758592708009,----
Box_Position: [[1.43588102 0.87551766 0.73743932]]
Step:200, total reward:-210.81457459109902, average reward:-1.0540728729554951,----
Box_Position: [[1.26286095 1.14701912 0.6856359 ]]
Step:200, total reward:-193.22145346873026, average reward:-0.9661072673436513,----
Box_Position: [[1.45771482 0.92104628 0.68419917]]
Step:200, total reward:-145.84574133092366, average reward:-0.7292287066546183,----
Box_Position: [[1.54272695 0.74335891 0.57963618]]
Step:200, total reward:-164.8089571412682, average reward:-0.824044785706341,----
Box_Position: [[1.37893662 0.80424063 0.48446979]]
Step:200, total reward:-165.86262250514264, average reward:-0.8293131125257132,----
Box_Position: [[1.51554924 0.618258   0.47466381]]
Step:200, total reward:-213.08968703140198, average reward:-1.06544843515701,----
Box_Position: [[1.37744538 0.47276734 0.71960259]]
Step:200, total reward:-179.05437948837667, average reward:-0.8952718974418833,----
Box_Position: [[1.38992585 1.15835608 0.68244646]]
Step:200, total reward:-214.19821557211196, average reward:-1.0709910778605598,----
Box_Position: [[1.42658513 1.07274559 0.64244424]]
Step:200, total reward:-326.42476773744295, average reward:-1.6321238386872148,----
Box_Position: [[1.29162132 0.84310932 0.45779604]]
Step:200, total reward:-171.53469759768134, average reward:-0.8576734879884067,----
Box_Position: [[1.29284794 0.68015725 0.63023026]]
Step:200, total reward:-150.14135443792273, average reward:-0.7507067721896137,----
Box_Position: [[1.31280274 0.92797972 0.52720568]]
Step:200, total reward:-178.01920009923202, average reward:-0.8900960004961601,----
Box_Position: [[1.45720854 0.89570194 0.65584739]]
Step:200, total reward:-191.62282569290466, average reward:-0.9581141284645233,----
Box_Position: [[1.28237187 0.93424405 0.61477124]]
Step:200, total reward:-155.2804579369187, average reward:-0.7764022896845936,----
Box_Position: [[1.42981806 0.71395394 0.66042535]]
Step:200, total reward:-181.6840257249372, average reward:-0.9084201286246859,----
Box_Position: [[1.40463718 0.71777605 0.45407678]]
Step:200, total reward:-206.1903832771556, average reward:-1.030951916385778,----
Box_Position: [[1.32460076 0.87311798 0.4881756 ]]
Step:200, total reward:-167.83359620074364, average reward:-0.8391679810037183,----
Box_Position: [[1.4169066  0.88310395 0.51552553]]
Step:200, total reward:-165.87620749825325, average reward:-0.8293810374912662,----
Box_Position: [[1.26928704 0.86206276 0.5059928 ]]
Step:200, total reward:-201.5216475677462, average reward:-1.007608237838731,----
Box_Position: [[1.29506118 0.87438732 0.51055379]]
Step:200, total reward:-244.2313397322734, average reward:-1.221156698661367,----
Box_Position: [[1.37952171 1.11967137 0.67934951]]
Step:200, total reward:-266.0890261591312, average reward:-1.330445130795656,----
Box_Position: [[1.299139   0.49459463 0.57475171]]
Step:200, total reward:-141.0307675121242, average reward:-0.7051538375606211,----
Box_Position: [[1.49748704 1.07130836 0.72774014]]
Step:200, total reward:-213.8500153956704, average reward:-1.069250076978352,----
Box_Position: [[1.26872947 0.59494422 0.66971918]]
Step:200, total reward:-148.10847650570926, average reward:-0.7405423825285463,----
Box_Position: [[1.36419536 1.04204952 0.73831188]]
Step:200, total reward:-188.96131023774723, average reward:-0.9448065511887361,----
Box_Position: [[1.39782617 0.90982549 0.46486094]]
Step:200, total reward:-232.19508312620894, average reward:-1.1609754156310448,----
Box_Position: [[1.47379141 0.99984137 0.74927679]]
Step:200, total reward:-184.7096824676606, average reward:-0.923548412338303,----
Box_Position: [[1.43020803 0.98237171 0.54776343]]
Step:200, total reward:-193.2168218840544, average reward:-0.966084109420272,----
Box_Position: [[1.50494716 0.75639726 0.72082749]]
Step:200, total reward:-235.7040423022989, average reward:-1.1785202115114943,----
Box_Position: [[1.33879314 0.72235216 0.63634507]]
Step:200, total reward:-160.27900801989588, average reward:-0.8013950400994794,----
Box_Position: [[1.26899207 0.90579199 0.70589837]]
Step:200, total reward:-218.3550598742494, average reward:-1.091775299371247,----
Box_Position: [[1.51983042 0.91905582 0.69140293]]
Step:200, total reward:-196.16826192860134, average reward:-0.9808413096430066,----
Box_Position: [[1.4329091  0.64980191 0.60042144]]
Step:200, total reward:-309.3517535847871, average reward:-1.5467587679239356,----
Box_Position: [[1.41577725 0.67061343 0.71358087]]
Step:200, total reward:-132.6560327071, average reward:-0.6632801635355,----
Box_Position: [[1.39528171 0.72590706 0.58837019]]
Step:200, total reward:-158.86441044492344, average reward:-0.7943220522246172,----
Box_Position: [[1.36349656 0.71968409 0.64748488]]
Step:200, total reward:-157.63544872296035, average reward:-0.7881772436148018,----
Box_Position: [[1.30199216 0.88891119 0.49098914]]
Step:200, total reward:-211.49939457523683, average reward:-1.0574969728761843,----
Box_Position: [[1.36006181 0.62475851 0.57608244]]
Step:44, total reward:-40.201847234687584, average reward:-0.9136783462428997,success
Box_Position: [[1.51188128 0.71951425 0.67195304]]
Step:200, total reward:-162.14267176190356, average reward:-0.8107133588095178,----
Box_Position: [[1.48460578 0.57697954 0.72040303]]
Step:200, total reward:-227.80486086851388, average reward:-1.1390243043425694,----
Box_Position: [[1.28844435 0.83934608 0.48041295]]
Step:200, total reward:-199.73845880969557, average reward:-0.9986922940484778,----
Box_Position: [[1.29729184 0.69709485 0.57162415]]
Step:200, total reward:-189.08994536403256, average reward:-0.9454497268201628,----
Box_Position: [[1.46590307 0.87153574 0.46746756]]
Step:200, total reward:-291.9627213118293, average reward:-1.4598136065591465,----
Box_Position: [[1.47987113 0.4333602  0.4816848 ]]
Step:200, total reward:-181.3349527643129, average reward:-0.9066747638215645,----
Box_Position: [[1.49964475 0.57654705 0.70305928]]

------------------Episode:500------------------
Step:200, total reward:-155.05731670277632, average reward:-0.7752865835138816,----
episode 500, the accuracy is: 7%
Box_Position: [[1.2836241  0.74910631 0.51787603]]
Step:200, total reward:-166.69809565459906, average reward:-0.8334904782729953,----
Box_Position: [[1.33315161 1.07867054 0.65624618]]
Step:200, total reward:-199.64609024579852, average reward:-0.9982304512289926,----
Box_Position: [[1.31676241 0.90601262 0.59056556]]
Step:200, total reward:-222.86432700741756, average reward:-1.1143216350370877,----
Box_Position: [[1.29301839 0.91105763 0.71046965]]
Step:200, total reward:-140.19409271103993, average reward:-0.7009704635551997,----
Box_Position: [[1.50161275 0.70646247 0.73329696]]
Step:200, total reward:-145.56711981444013, average reward:-0.7278355990722006,----
Box_Position: [[1.43131794 0.83429097 0.69791683]]
Step:200, total reward:-196.27512062591316, average reward:-0.9813756031295658,----
Box_Position: [[1.38754349 1.08589117 0.63233415]]
Step:200, total reward:-168.7257826249853, average reward:-0.8436289131249265,----
Box_Position: [[1.45067701 0.75906254 0.62339317]]
Step:200, total reward:-146.49532656389772, average reward:-0.7324766328194886,----
Box_Position: [[1.34091405 1.01276196 0.5087367 ]]
Step:200, total reward:-172.23451432851152, average reward:-0.8611725716425576,----
Box_Position: [[1.4401323  0.71373197 0.48193298]]
Step:200, total reward:-189.73742939450446, average reward:-0.9486871469725223,----
Box_Position: [[1.36097162 0.68693221 0.47865617]]
Step:200, total reward:-317.9348622563778, average reward:-1.589674311281889,----
Box_Position: [[1.26243066 0.68661453 0.50275434]]
Step:200, total reward:-182.18267945094848, average reward:-0.9109133972547424,----
Box_Position: [[1.35543528 1.01712491 0.60681309]]
Step:200, total reward:-188.78898099858793, average reward:-0.9439449049929397,----
Box_Position: [[1.34004035 0.98611834 0.45696016]]
Step:200, total reward:-246.5063448518919, average reward:-1.2325317242594596,----
Box_Position: [[1.44227365 0.77240018 0.73663451]]
Step:200, total reward:-123.82905498621412, average reward:-0.6191452749310706,----
Box_Position: [[1.49723152 1.00912813 0.63341855]]
Step:200, total reward:-237.3397308682972, average reward:-1.1866986543414861,----
Box_Position: [[1.34106849 0.6352916  0.60310386]]
Step:200, total reward:-176.01788616388149, average reward:-0.8800894308194074,----
Box_Position: [[1.4777691  0.82738117 0.72961661]]
Step:200, total reward:-182.31279931025264, average reward:-0.9115639965512632,----
Box_Position: [[1.39938379 0.76399054 0.5174466 ]]
Step:200, total reward:-189.1771200444732, average reward:-0.9458856002223661,----
Box_Position: [[1.52312451 0.50027122 0.68053524]]
Step:200, total reward:-159.44634682256617, average reward:-0.7972317341128309,----
Box_Position: [[1.26758814 0.96696726 0.49546549]]
Step:200, total reward:-292.37526351918655, average reward:-1.4618763175959328,----
Box_Position: [[1.25441748 1.10400622 0.48980059]]
Step:200, total reward:-241.75700010219566, average reward:-1.2087850005109784,----
Box_Position: [[1.33335147 0.86315111 0.71211997]]
Step:200, total reward:-158.18097928236986, average reward:-0.7909048964118494,----
Box_Position: [[1.30667506 0.96840008 0.62510239]]
Step:200, total reward:-178.6761248103792, average reward:-0.893380624051896,----
Box_Position: [[1.53253971 0.91769569 0.72148997]]
Step:65, total reward:-46.918214966958296, average reward:-0.7218186917993584,success
Box_Position: [[1.28156285 0.85690174 0.67746124]]
Step:200, total reward:-181.88946710377735, average reward:-0.9094473355188868,----
Box_Position: [[1.50830551 0.82968615 0.74042197]]
Step:200, total reward:-212.352286443598, average reward:-1.06176143221799,----
Box_Position: [[1.54500562 0.94758142 0.65333855]]
Step:200, total reward:-203.19648301230183, average reward:-1.015982415061509,----
Box_Position: [[1.54038813 1.0238934  0.67692425]]
Step:200, total reward:-238.552444504196, average reward:-1.19276222252098,----
Box_Position: [[1.39854399 0.50773071 0.7113046 ]]
Step:35, total reward:-18.61781034638908, average reward:-0.5319374384682595,success
Box_Position: [[1.27574626 0.90408829 0.61157704]]
Step:200, total reward:-204.2504919549477, average reward:-1.0212524597747386,----
Box_Position: [[1.40043103 0.73565072 0.52129755]]
Step:200, total reward:-183.33414562036467, average reward:-0.9166707281018234,----
Box_Position: [[1.26356747 0.80361925 0.58759149]]
Step:200, total reward:-189.33378570530232, average reward:-0.9466689285265116,----
Box_Position: [[1.4925841  0.77414578 0.51737307]]
Step:200, total reward:-235.093746194861, average reward:-1.175468730974305,----
Box_Position: [[1.27274855 0.81042503 0.50866144]]
Step:200, total reward:-170.68761946401645, average reward:-0.8534380973200822,----
Box_Position: [[1.48092551 1.0577864  0.74637008]]
Step:172, total reward:-147.41338688848677, average reward:-0.8570545749330626,success
Box_Position: [[1.47597294 0.86827109 0.72599611]]
Step:200, total reward:-213.16573058195326, average reward:-1.0658286529097662,----
Box_Position: [[1.40516903 0.84745389 0.65097493]]
Step:200, total reward:-132.87709788977207, average reward:-0.6643854894488603,----
Box_Position: [[1.42306064 0.90034044 0.71861895]]
Step:200, total reward:-163.85707332394483, average reward:-0.8192853666197242,----
Box_Position: [[1.36769629 1.07191502 0.45932097]]
Step:200, total reward:-230.2926858635425, average reward:-1.1514634293177124,----
Box_Position: [[1.48251935 0.84560244 0.53020337]]
Step:200, total reward:-364.6709625342021, average reward:-1.8233548126710104,----
Box_Position: [[1.35211366 0.8007169  0.49017455]]
Step:200, total reward:-217.3163071343848, average reward:-1.086581535671924,----
Box_Position: [[1.5264288  0.8272816  0.65843456]]
Step:200, total reward:-210.11792356503392, average reward:-1.0505896178251697,----
Box_Position: [[1.50700581 0.87777426 0.59708356]]
Step:200, total reward:-197.87437861163733, average reward:-0.9893718930581866,----
Box_Position: [[1.37178976 0.75874211 0.57571562]]
Step:200, total reward:-136.2922047441007, average reward:-0.6814610237205035,----
Box_Position: [[1.29622238 0.99322121 0.55898927]]
Step:200, total reward:-184.1003260922883, average reward:-0.9205016304614415,----
Box_Position: [[1.29925778 0.92294328 0.5524591 ]]
Step:63, total reward:-73.50698763074327, average reward:-1.1667775814403694,success
Box_Position: [[1.37937746 0.5050585  0.57255346]]
Step:200, total reward:-181.54392580653635, average reward:-0.9077196290326818,----
Box_Position: [[1.29540048 0.8497647  0.57479232]]
Step:200, total reward:-206.79999046380036, average reward:-1.0339999523190018,----
Box_Position: [[1.39684637 0.91059389 0.5754998 ]]

------------------Episode:550------------------
Step:200, total reward:-201.51464359258412, average reward:-1.0075732179629207,----
Box_Position: [[1.37255972 0.79419726 0.58617205]]
Step:200, total reward:-170.48400552571815, average reward:-0.8524200276285907,----
Box_Position: [[1.42600711 0.77229543 0.58952893]]
Step:200, total reward:-165.4860280010871, average reward:-0.8274301400054356,----
Box_Position: [[1.44347293 0.96086556 0.49816298]]
Step:200, total reward:-246.89822334210984, average reward:-1.2344911167105492,----
Box_Position: [[1.46226064 0.73638114 0.55977578]]
Step:200, total reward:-206.80930546154744, average reward:-1.0340465273077373,----
Box_Position: [[1.5016212  0.75992181 0.46232369]]
Step:200, total reward:-176.82267889267717, average reward:-0.8841133944633859,----
Box_Position: [[1.52084569 0.88149894 0.66287458]]
Step:200, total reward:-148.92328669606462, average reward:-0.7446164334803231,----
Box_Position: [[1.41852367 0.79561287 0.73136909]]
Step:200, total reward:-158.40519885736074, average reward:-0.7920259942868038,----
Box_Position: [[1.39253932 0.48404364 0.62413841]]
Step:200, total reward:-145.50374342698427, average reward:-0.7275187171349213,----
Box_Position: [[1.26565945 0.74639648 0.72554496]]
Step:200, total reward:-172.06538913368166, average reward:-0.8603269456684083,----
Box_Position: [[1.52630876 0.86964648 0.55788654]]
Step:200, total reward:-278.3055992746012, average reward:-1.391527996373006,----
Box_Position: [[1.38533369 0.75141251 0.56205006]]
Step:200, total reward:-152.32820398126682, average reward:-0.7616410199063341,----
Box_Position: [[1.2991755  0.89222404 0.53062441]]
Step:200, total reward:-194.22597359331627, average reward:-0.9711298679665813,----
Box_Position: [[1.4275813  1.00691587 0.61339857]]
Step:200, total reward:-230.9826772327676, average reward:-1.154913386163838,----
Box_Position: [[1.27950532 0.63616468 0.54892009]]
Step:200, total reward:-177.52442347299197, average reward:-0.8876221173649599,----
Box_Position: [[1.51326044 0.93704167 0.59142022]]
Step:200, total reward:-174.3627316949091, average reward:-0.8718136584745454,----
Box_Position: [[1.43388767 0.75939965 0.46986903]]
Step:200, total reward:-240.43969011932214, average reward:-1.2021984505966108,----
Box_Position: [[1.32417513 0.55062004 0.49663224]]
Step:200, total reward:-194.84310312830883, average reward:-0.9742155156415442,----
Box_Position: [[1.31502157 0.63918149 0.70221755]]
Step:200, total reward:-198.6071258420669, average reward:-0.9930356292103345,----
Box_Position: [[1.44431354 0.94597156 0.4503057 ]]
Step:200, total reward:-196.31805519339522, average reward:-0.9815902759669761,----
Box_Position: [[1.2581155  0.63965042 0.6602332 ]]
Step:200, total reward:-152.1332524183251, average reward:-0.7606662620916255,----
Box_Position: [[1.33656549 0.89567016 0.61062123]]
Step:164, total reward:-121.67476723240074, average reward:-0.7419193123926875,success
Box_Position: [[1.52921294 0.63547694 0.48228366]]
Step:200, total reward:-190.84313242180562, average reward:-0.9542156621090281,----
Box_Position: [[1.32949063 1.01616748 0.67039879]]
Step:200, total reward:-169.2849462205219, average reward:-0.8464247311026095,----
Box_Position: [[1.40654911 0.58674942 0.65416523]]
Step:200, total reward:-145.29434274584042, average reward:-0.7264717137292022,----
Box_Position: [[1.36623773 1.07021702 0.51399283]]
Step:200, total reward:-198.66017077276024, average reward:-0.9933008538638012,----
Box_Position: [[1.42166957 0.72617967 0.56256734]]
Step:200, total reward:-199.3667381186905, average reward:-0.9968336905934525,----
Box_Position: [[1.46634257 0.67183349 0.47036274]]
Step:200, total reward:-249.92538170966523, average reward:-1.2496269085483263,----
Box_Position: [[1.30855485 0.80291932 0.58124663]]
Step:200, total reward:-163.95883987142142, average reward:-0.8197941993571071,----
Box_Position: [[1.40341503 1.14468961 0.63139094]]
Step:200, total reward:-242.21050178866923, average reward:-1.2110525089433462,----
Box_Position: [[1.46200483 0.69209138 0.53219075]]
Step:13, total reward:-8.626547431099867, average reward:-0.6635805716230667,success
Box_Position: [[1.463528   0.78040274 0.71089504]]
Step:200, total reward:-253.6771814692549, average reward:-1.2683859073462744,----
Box_Position: [[1.42152504 0.73554907 0.45842918]]
Step:200, total reward:-213.0330675914123, average reward:-1.0651653379570616,----
Box_Position: [[1.53094769 1.02411716 0.63367698]]
Step:200, total reward:-212.8154242254514, average reward:-1.064077121127257,----
Box_Position: [[1.53305683 0.74953807 0.74775906]]
Step:200, total reward:-240.4459501016612, average reward:-1.202229750508306,----
Box_Position: [[1.33344026 0.75144438 0.49596972]]
Step:200, total reward:-188.88628228634252, average reward:-0.9444314114317126,----
Box_Position: [[1.50257299 0.47182628 0.63728254]]
Step:200, total reward:-186.85887415393046, average reward:-0.9342943707696523,----
Box_Position: [[1.53172772 1.10415868 0.49782698]]
Step:200, total reward:-248.7535854737592, average reward:-1.243767927368796,----
Box_Position: [[1.51646871 0.73931359 0.55419993]]
Step:200, total reward:-203.85836088131333, average reward:-1.0192918044065666,----
Box_Position: [[1.5226169  0.68792922 0.50001108]]
Step:200, total reward:-224.19835805710602, average reward:-1.1209917902855302,----
Box_Position: [[1.47033863 0.79764562 0.68304137]]
Step:200, total reward:-171.8754644911962, average reward:-0.859377322455981,----
Box_Position: [[1.33655812 0.74441882 0.53517524]]
Step:200, total reward:-186.2476406860622, average reward:-0.9312382034303109,----
Box_Position: [[1.31742702 1.0892328  0.71963594]]
Step:200, total reward:-175.13155487413107, average reward:-0.8756577743706554,----
Box_Position: [[1.50298492 0.93819887 0.73204474]]
Step:160, total reward:-182.97491186611356, average reward:-1.1435931991632098,success
Box_Position: [[1.49026095 0.9099064  0.70810479]]
Step:200, total reward:-161.80621395717122, average reward:-0.8090310697858561,----
Box_Position: [[1.34077288 1.04231953 0.644004  ]]
Step:99, total reward:-113.66157980758695, average reward:-1.1480967657332015,success
Box_Position: [[1.50922847 0.70838985 0.51411194]]
Step:200, total reward:-187.28454745645845, average reward:-0.9364227372822923,----
Box_Position: [[1.53891685 0.69649132 0.47465359]]
Step:200, total reward:-261.87307800210596, average reward:-1.3093653900105298,----
Box_Position: [[1.48455208 0.98830159 0.60615173]]
Step:200, total reward:-197.1476894868688, average reward:-0.985738447434344,----
Box_Position: [[1.36691441 0.54288307 0.70894703]]
Step:105, total reward:-82.84632699259635, average reward:-0.7890126380247271,success
Box_Position: [[1.43892354 0.72407655 0.69885935]]

------------------Episode:600------------------
Step:9, total reward:-11.387169209608222, average reward:-1.2652410232898026,success
episode 600, the accuracy is: 10%
Box_Position: [[1.4675874  0.86125332 0.64094066]]
Step:200, total reward:-181.97455914910645, average reward:-0.9098727957455323,----
Box_Position: [[1.46126203 0.9001425  0.53793312]]
Step:200, total reward:-261.92970747405565, average reward:-1.3096485373702782,----
Box_Position: [[1.51365895 0.58154448 0.55471214]]
Step:200, total reward:-262.5346612829651, average reward:-1.3126733064148255,----
Box_Position: [[1.37966492 0.58798857 0.63291322]]
Step:200, total reward:-136.49632651033085, average reward:-0.6824816325516543,----
Box_Position: [[1.4952465  0.80482994 0.53030061]]
Step:200, total reward:-165.35899603460064, average reward:-0.8267949801730032,----
Box_Position: [[1.41573066 0.5977591  0.59772168]]
Step:200, total reward:-198.39378319433834, average reward:-0.9919689159716917,----
Box_Position: [[1.35402092 0.75562985 0.48448121]]
Step:200, total reward:-193.1046055645057, average reward:-0.9655230278225285,----
Box_Position: [[1.37977223 0.77906696 0.50814685]]
Step:200, total reward:-187.0696897581265, average reward:-0.9353484487906324,----
Box_Position: [[1.54873012 1.17406183 0.64511082]]
Step:200, total reward:-241.76473890158627, average reward:-1.2088236945079314,----
Box_Position: [[1.34982262 0.72273695 0.73276522]]
Step:200, total reward:-165.58978661486333, average reward:-0.8279489330743166,----
Box_Position: [[1.44251552 1.07448225 0.66153937]]
Step:200, total reward:-286.30777692869793, average reward:-1.4315388846434898,----
Box_Position: [[1.28338001 0.66775206 0.68312852]]
Step:200, total reward:-141.60060362231738, average reward:-0.708003018111587,----
Box_Position: [[1.46363801 0.99650106 0.70177851]]
Step:200, total reward:-179.25187152634967, average reward:-0.8962593576317484,----
Box_Position: [[1.2538414  0.83669099 0.69298363]]
Step:200, total reward:-131.95983363069396, average reward:-0.6597991681534698,----
Box_Position: [[1.51120524 0.67432138 0.51743663]]
Step:200, total reward:-217.49198893403346, average reward:-1.0874599446701674,----
Box_Position: [[1.33460787 0.54969406 0.46382413]]
Step:200, total reward:-159.9418983625685, average reward:-0.7997094918128426,----
Box_Position: [[1.52409071 0.64064502 0.53427129]]
Step:200, total reward:-224.21289622290013, average reward:-1.1210644811145007,----
Box_Position: [[1.50464693 1.01850459 0.74117311]]
Step:200, total reward:-209.87404038964107, average reward:-1.0493702019482054,----
Box_Position: [[1.37337869 0.58906134 0.57523376]]
Step:200, total reward:-177.51889883318688, average reward:-0.8875944941659344,----
Box_Position: [[1.44255209 1.17451579 0.65492451]]
Step:200, total reward:-206.2462462996819, average reward:-1.0312312314984096,----
Box_Position: [[1.48097075 0.65598788 0.53908191]]
Step:200, total reward:-169.4311060202532, average reward:-0.847155530101266,----
Box_Position: [[1.36532941 0.74151556 0.68789729]]
Step:200, total reward:-167.853445945473, average reward:-0.839267229727365,----
Box_Position: [[1.41974733 0.51429766 0.62602185]]
Step:200, total reward:-246.2055117246673, average reward:-1.2310275586233366,----
Box_Position: [[1.27585919 0.95240887 0.59407784]]
Step:200, total reward:-203.5357616895614, average reward:-1.017678808447807,----
Box_Position: [[1.31876535 0.97857792 0.70875139]]
Step:200, total reward:-218.23386195789956, average reward:-1.0911693097894979,----
Box_Position: [[1.3464313  0.67256486 0.70927579]]
Step:200, total reward:-177.75251681991247, average reward:-0.8887625840995623,----
Box_Position: [[1.4063011  0.83752588 0.50572988]]
Step:200, total reward:-190.06405114210148, average reward:-0.9503202557105074,----
Box_Position: [[1.45881993 0.66643883 0.535016  ]]
Step:200, total reward:-167.338979347126, average reward:-0.83669489673563,----
Box_Position: [[1.4819973  0.65224232 0.74650174]]
Step:200, total reward:-176.56824854149954, average reward:-0.8828412427074978,----
Box_Position: [[1.38694819 0.67512578 0.57734998]]
Step:200, total reward:-191.38267799360403, average reward:-0.9569133899680202,----
Box_Position: [[1.47609704 0.58760345 0.61335273]]
Step:200, total reward:-259.5663597366182, average reward:-1.297831798683091,----
Box_Position: [[1.49518781 0.81204036 0.49659216]]
Step:200, total reward:-179.79008005916708, average reward:-0.8989504002958354,----
Box_Position: [[1.31532633 1.06450448 0.73493151]]
Step:200, total reward:-185.9824336270193, average reward:-0.9299121681350965,----
Box_Position: [[1.29749432 0.59910895 0.56927743]]
Step:200, total reward:-210.01502839742727, average reward:-1.0500751419871364,----
Box_Position: [[1.44042593 0.81114556 0.67343775]]
Step:200, total reward:-202.84352116667898, average reward:-1.014217605833395,----
Box_Position: [[1.44263421 0.67211367 0.68770426]]
Step:200, total reward:-167.87391603987837, average reward:-0.8393695801993918,----
Box_Position: [[1.43837025 0.70099635 0.58863132]]
Step:200, total reward:-223.5906657945325, average reward:-1.1179533289726624,----
Box_Position: [[1.36536449 1.04444304 0.62287555]]
Step:200, total reward:-161.05006765170137, average reward:-0.8052503382585069,----
Box_Position: [[1.32165892 0.76420959 0.5407646 ]]
Step:200, total reward:-137.3827091349404, average reward:-0.686913545674702,----
Box_Position: [[1.4171801  0.5681362  0.72837286]]
Step:200, total reward:-213.79551957256663, average reward:-1.068977597862833,----
Box_Position: [[1.40653012 0.9511408  0.45651665]]
Step:200, total reward:-184.50952069469864, average reward:-0.9225476034734932,----
Box_Position: [[1.50312124 1.01405131 0.60751   ]]
Step:200, total reward:-186.0316501724881, average reward:-0.9301582508624405,----
Box_Position: [[1.36089018 0.85585588 0.69239366]]
Step:200, total reward:-163.22284642499662, average reward:-0.8161142321249831,----
Box_Position: [[1.49746917 0.69087677 0.74228996]]
Step:200, total reward:-288.898296604923, average reward:-1.4444914830246152,----
Box_Position: [[1.28130511 0.98599345 0.58484403]]
Step:200, total reward:-171.21101837815945, average reward:-0.8560550918907972,----
Box_Position: [[1.31316349 0.92990417 0.61961796]]
Step:200, total reward:-154.77407235280583, average reward:-0.7738703617640291,----
Box_Position: [[1.45041657 1.0376948  0.59490896]]
Step:200, total reward:-233.81991200289357, average reward:-1.1690995600144678,----
Box_Position: [[1.51995068 0.98318018 0.57038331]]
Step:200, total reward:-249.13734153785262, average reward:-1.245686707689263,----
Box_Position: [[1.375935   0.9806756  0.62615135]]
Step:200, total reward:-204.05262257991893, average reward:-1.0202631128995947,----
Box_Position: [[1.43865071 0.60691691 0.64343281]]

------------------Episode:650------------------
Step:200, total reward:-155.96457995658452, average reward:-0.7798228997829226,----
Box_Position: [[1.4280084  0.6565411  0.51429685]]
Step:200, total reward:-187.15009003806293, average reward:-0.9357504501903147,----
Box_Position: [[1.53664035 0.93645227 0.68517089]]
Step:200, total reward:-182.37540908541422, average reward:-0.911877045427071,----
Box_Position: [[1.40918641 0.79645364 0.72144197]]
Step:200, total reward:-197.53131445391196, average reward:-0.9876565722695598,----
Box_Position: [[1.34162812 0.60916564 0.62385746]]
Step:200, total reward:-177.68698793287896, average reward:-0.8884349396643948,----
Box_Position: [[1.36314549 1.07074463 0.55831783]]
Step:200, total reward:-173.8379248617984, average reward:-0.869189624308992,----
Box_Position: [[1.42378182 0.70567938 0.45368782]]
Step:200, total reward:-221.98196661738015, average reward:-1.1099098330869008,----
Box_Position: [[1.45487975 0.82913804 0.68263273]]
Step:200, total reward:-184.6696632340099, average reward:-0.9233483161700495,----
Box_Position: [[1.4400158  0.84293209 0.72967788]]
Step:200, total reward:-196.21267791121346, average reward:-0.9810633895560673,----
Box_Position: [[1.26061651 0.95940785 0.54286864]]
Step:200, total reward:-220.05266405119485, average reward:-1.1002633202559742,----
Box_Position: [[1.27612197 0.8374571  0.48158624]]
Step:200, total reward:-213.89376907350257, average reward:-1.0694688453675127,----
Box_Position: [[1.52669193 0.59276272 0.56041997]]
Step:200, total reward:-192.66999300265135, average reward:-0.9633499650132568,----
Box_Position: [[1.47362775 0.96372559 0.48586859]]
Step:200, total reward:-192.43993104925443, average reward:-0.9621996552462722,----
Box_Position: [[1.41476885 0.91011288 0.47861006]]
Step:200, total reward:-197.67993268422865, average reward:-0.9883996634211433,----
Box_Position: [[1.3208747  0.64472795 0.72562016]]
Step:200, total reward:-267.09123393223985, average reward:-1.3354561696611993,----
Box_Position: [[1.4420334  0.79843531 0.71732931]]
Step:200, total reward:-181.19961146662195, average reward:-0.9059980573331097,----
Box_Position: [[1.48242561 0.65747066 0.57807059]]
Step:200, total reward:-225.91845532506525, average reward:-1.1295922766253264,----
Box_Position: [[1.48817887 0.69833953 0.6204316 ]]
Step:200, total reward:-169.623708442193, average reward:-0.8481185422109649,----
Box_Position: [[1.29223015 1.12784144 0.62281112]]
Step:200, total reward:-195.8631586210321, average reward:-0.9793157931051606,----
Box_Position: [[1.34364204 0.67298835 0.68259238]]
Step:200, total reward:-183.21910133317263, average reward:-0.9160955066658631,----
Box_Position: [[1.42910397 0.96612471 0.68253103]]
Step:200, total reward:-171.78980163338784, average reward:-0.8589490081669392,----
Box_Position: [[1.38002407 0.79425499 0.49027294]]
Step:200, total reward:-198.2410129778469, average reward:-0.9912050648892345,----
Box_Position: [[1.48882879 0.94733839 0.66011469]]
Step:200, total reward:-266.88440229180515, average reward:-1.3344220114590257,----
Box_Position: [[1.2978193  1.05417723 0.50238707]]
Step:200, total reward:-212.2099784229702, average reward:-1.061049892114851,----
Box_Position: [[1.3801479  1.07642191 0.51204282]]
Step:200, total reward:-220.7447323503696, average reward:-1.103723661751848,----
Box_Position: [[1.49706759 1.14557578 0.69711985]]
Step:200, total reward:-214.4431645708666, average reward:-1.072215822854333,----
Box_Position: [[1.37537138 1.09745557 0.54235243]]
Step:200, total reward:-262.78839912861156, average reward:-1.3139419956430578,----
Box_Position: [[1.32899458 0.57983038 0.56557548]]
Step:200, total reward:-167.79044510751194, average reward:-0.8389522255375597,----
Box_Position: [[1.44292683 0.87817909 0.681199  ]]
Step:200, total reward:-181.3333437334935, average reward:-0.9066667186674675,----
Box_Position: [[1.54070604 0.75034225 0.74454015]]
Step:200, total reward:-190.280963004196, average reward:-0.95140481502098,----
Box_Position: [[1.52022862 0.58683291 0.53384278]]
Step:200, total reward:-223.7167393093217, average reward:-1.1185836965466085,----
Box_Position: [[1.3599856  0.87267576 0.73500499]]
Step:110, total reward:-79.66287873302318, average reward:-0.7242079884820288,success
Box_Position: [[1.25668017 0.47663567 0.7233074 ]]
Step:200, total reward:-133.88754822217982, average reward:-0.669437741110899,----
Box_Position: [[1.42388351 0.73071892 0.6888444 ]]
Step:23, total reward:-11.875661242655893, average reward:-0.5163330975067779,success
Box_Position: [[1.4405382  0.78095552 0.49627066]]
Step:200, total reward:-170.8934972584773, average reward:-0.8544674862923866,----
Box_Position: [[1.34836497 0.58549979 0.71847872]]
Step:200, total reward:-161.45145489595075, average reward:-0.8072572744797537,----
Box_Position: [[1.273549   1.10478475 0.61340129]]
Step:200, total reward:-221.11014275999057, average reward:-1.1055507137999527,----
Box_Position: [[1.34571053 0.73480931 0.50336812]]
Step:200, total reward:-232.87120205901218, average reward:-1.164356010295061,----
Box_Position: [[1.44029541 0.86997304 0.71654258]]
Step:200, total reward:-197.61407329086848, average reward:-0.9880703664543424,----
Box_Position: [[1.50585392 0.67506065 0.5967186 ]]
Step:200, total reward:-259.1218924809406, average reward:-1.2956094624047028,----
Box_Position: [[1.3282236  0.96318266 0.68761289]]
Step:181, total reward:-142.36888534134897, average reward:-0.7865684273002705,success
Box_Position: [[1.47544123 1.02118698 0.63781204]]
Step:200, total reward:-285.81653085221836, average reward:-1.4290826542610917,----
Box_Position: [[1.35098562 0.64680839 0.59034662]]
Step:200, total reward:-212.30424180695772, average reward:-1.0615212090347885,----
Box_Position: [[1.52748572 0.79310028 0.66887504]]
Step:200, total reward:-142.70690089327064, average reward:-0.7135345044663532,----
Box_Position: [[1.38751694 0.98231732 0.64758046]]
Step:200, total reward:-164.45926770785644, average reward:-0.8222963385392822,----
Box_Position: [[1.43054436 1.11581957 0.64733787]]
Step:200, total reward:-191.6174421426789, average reward:-0.9580872107133945,----
Box_Position: [[1.34523922 1.08595455 0.59983823]]
Step:200, total reward:-238.21343619944727, average reward:-1.1910671809972364,----
Box_Position: [[1.46876851 0.68724969 0.69682381]]
Step:200, total reward:-176.04374782823916, average reward:-0.8802187391411959,----
Box_Position: [[1.42290714 0.68374583 0.50251588]]
Step:200, total reward:-190.05730983081477, average reward:-0.9502865491540738,----
Box_Position: [[1.40432432 1.08230989 0.55329399]]
Step:200, total reward:-179.62238577157402, average reward:-0.8981119288578701,----
Box_Position: [[1.54274426 0.66493933 0.7430423 ]]

------------------Episode:700------------------
Step:200, total reward:-183.93637823677818, average reward:-0.9196818911838909,----
episode 700, the accuracy is: 3%
Box_Position: [[1.3803831  0.61466095 0.45438702]]
Step:140, total reward:-147.25638351511301, average reward:-1.051831310822236,success
Box_Position: [[1.41867379 0.73039075 0.56080559]]
Step:200, total reward:-176.25993905169423, average reward:-0.8812996952584712,----
Box_Position: [[1.41626432 1.07622542 0.48532477]]
Step:200, total reward:-215.48535451540258, average reward:-1.0774267725770128,----
Box_Position: [[1.5145886  0.86115141 0.58116119]]
Step:200, total reward:-208.9913954602413, average reward:-1.0449569773012066,----
Box_Position: [[1.33412565 0.55023123 0.48931406]]
Step:200, total reward:-187.81383393887546, average reward:-0.9390691696943773,----
Box_Position: [[1.424642   0.82951852 0.55220844]]
Step:200, total reward:-169.0346493430874, average reward:-0.845173246715437,----
Box_Position: [[1.36816444 1.04327622 0.47184816]]
Step:133, total reward:-151.27142110728235, average reward:-1.1373791060697922,success
Box_Position: [[1.3861665  0.78439594 0.71077102]]
Step:200, total reward:-145.49546682382615, average reward:-0.7274773341191307,----
Box_Position: [[1.48757143 0.97310291 0.72028311]]
Step:200, total reward:-174.25103633915583, average reward:-0.8712551816957792,----
Box_Position: [[1.42670362 0.70001511 0.74348353]]
Step:200, total reward:-235.55498640582297, average reward:-1.1777749320291149,----
Box_Position: [[1.53643717 0.61793175 0.53849481]]
Step:200, total reward:-220.53765920284997, average reward:-1.10268829601425,----
Box_Position: [[1.38273245 0.67076746 0.46783414]]
Step:200, total reward:-166.4432320380173, average reward:-0.8322161601900865,----
Box_Position: [[1.37095273 0.41271088 0.59964158]]
Step:200, total reward:-125.23507589098577, average reward:-0.6261753794549288,----
Box_Position: [[1.42711878 0.72782284 0.73733829]]
Step:200, total reward:-122.37289882414318, average reward:-0.6118644941207159,----
Box_Position: [[1.35838353 0.87662463 0.47660126]]
Step:200, total reward:-252.02102951202392, average reward:-1.2601051475601195,----
Box_Position: [[1.50361699 0.90162021 0.52293572]]
Step:200, total reward:-173.03237270226333, average reward:-0.8651618635113166,----
Box_Position: [[1.35947524 0.82926071 0.48548139]]
Step:200, total reward:-219.69856884862045, average reward:-1.0984928442431023,----
Box_Position: [[1.28236273 1.06253527 0.72871388]]
Step:200, total reward:-200.4875594278398, average reward:-1.0024377971391991,----
Box_Position: [[1.41636731 0.63810826 0.62542596]]
Step:10, total reward:-12.540326769832133, average reward:-1.2540326769832133,success
Box_Position: [[1.46025321 0.62519119 0.51272902]]
Step:200, total reward:-258.5592339693607, average reward:-1.2927961698468036,----
Box_Position: [[1.51747157 0.89872442 0.60503127]]
Step:200, total reward:-228.6944194568897, average reward:-1.1434720972844485,----
Box_Position: [[1.27246636 0.50152838 0.70254572]]
Step:200, total reward:-143.18450962313955, average reward:-0.7159225481156978,----
Box_Position: [[1.25305761 0.92649962 0.59555533]]
Step:127, total reward:-81.70622097193392, average reward:-0.643356070645149,success
Box_Position: [[1.47485775 0.92235028 0.45554594]]
Step:200, total reward:-255.8177773835557, average reward:-1.2790888869177786,----
Box_Position: [[1.31034773 0.61141964 0.72753559]]
Step:200, total reward:-177.20901139865197, average reward:-0.8860450569932599,----
Box_Position: [[1.35107005 0.91296087 0.56304349]]
Step:200, total reward:-201.2515501881493, average reward:-1.0062577509407467,----
Box_Position: [[1.45507615 0.70523501 0.47350802]]
Step:200, total reward:-230.0467638674748, average reward:-1.150233819337374,----
Box_Position: [[1.35073628 0.77198901 0.70688401]]
Step:153, total reward:-146.6912282624679, average reward:-0.9587661977939078,success
Box_Position: [[1.28072004 0.79702806 0.46345922]]
Step:200, total reward:-157.35613167154781, average reward:-0.786780658357739,----
Box_Position: [[1.48383025 0.83862801 0.56848092]]
Step:200, total reward:-208.49126943356254, average reward:-1.0424563471678128,----
Box_Position: [[1.34843103 0.76123463 0.70127513]]
Step:200, total reward:-167.66179764256083, average reward:-0.8383089882128041,----
Box_Position: [[1.53877666 0.72455718 0.73994998]]
Step:200, total reward:-178.30399280300625, average reward:-0.8915199640150313,----
Box_Position: [[1.31296466 0.60468324 0.71758053]]
Step:155, total reward:-110.91955337286973, average reward:-0.7156100217604499,success
Box_Position: [[1.32491368 0.71727339 0.71032309]]
Step:200, total reward:-119.89462620801876, average reward:-0.5994731310400938,----
Box_Position: [[1.2660355  0.56150268 0.45959103]]
Step:200, total reward:-148.08169266881913, average reward:-0.7404084633440956,----
Box_Position: [[1.41598001 0.83326114 0.47638696]]
Step:91, total reward:-93.70976841022635, average reward:-1.0297776748376521,success
Box_Position: [[1.47304948 0.986608   0.48156547]]
Step:200, total reward:-176.91595340039993, average reward:-0.8845797670019997,----
Box_Position: [[1.51751288 0.89583887 0.56164703]]
Step:200, total reward:-182.37658752917451, average reward:-0.9118829376458726,----
Box_Position: [[1.30398654 0.49258198 0.57026367]]
Step:200, total reward:-143.6188403260336, average reward:-0.7180942016301679,----
Box_Position: [[1.44751397 0.99003372 0.45366486]]
Step:200, total reward:-260.0778516974016, average reward:-1.300389258487008,----
Box_Position: [[1.3110939  1.01737573 0.65806086]]
Step:200, total reward:-229.65668251461258, average reward:-1.148283412573063,----
Box_Position: [[1.3333933  0.51070185 0.59891592]]
Step:200, total reward:-167.66802183032667, average reward:-0.8383401091516334,----
Box_Position: [[1.46463257 0.97312131 0.64334654]]
Step:200, total reward:-164.94308358818594, average reward:-0.8247154179409297,----
Box_Position: [[1.3525013  1.06310965 0.50980475]]
Step:200, total reward:-184.01471487425337, average reward:-0.9200735743712669,----
Box_Position: [[1.30022848 0.59148332 0.71692907]]
Step:200, total reward:-196.11980049121007, average reward:-0.9805990024560504,----
Box_Position: [[1.43612057 0.48264653 0.73551558]]
Step:200, total reward:-156.4555714320791, average reward:-0.7822778571603954,----
Box_Position: [[1.42837613 0.78987842 0.58467047]]
Step:200, total reward:-222.29362568979823, average reward:-1.1114681284489911,----
Box_Position: [[1.45114762 0.62426864 0.67383605]]
Step:200, total reward:-230.26321415873375, average reward:-1.1513160707936687,----
Box_Position: [[1.32669213 0.54295712 0.63200604]]
Step:200, total reward:-183.09933505759895, average reward:-0.9154966752879947,----
Box_Position: [[1.36315367 1.13795071 0.47933893]]

------------------Episode:750------------------
Step:200, total reward:-266.2092977136619, average reward:-1.3310464885683095,----
Box_Position: [[1.40688407 0.93947509 0.50583987]]
Step:200, total reward:-232.27254460869852, average reward:-1.1613627230434926,----
Box_Position: [[1.38802757 0.51323352 0.45548704]]
Step:200, total reward:-239.44878205274586, average reward:-1.1972439102637293,----
Box_Position: [[1.54734233 0.51793776 0.69449584]]
Step:200, total reward:-188.5457730209254, average reward:-0.942728865104627,----
Box_Position: [[1.51961993 0.6647547  0.64145943]]
Step:200, total reward:-232.09320437480181, average reward:-1.160466021874009,----
Box_Position: [[1.34279046 0.54657521 0.72841354]]
Step:200, total reward:-136.67487276431802, average reward:-0.6833743638215901,----
Box_Position: [[1.29756171 0.8260344  0.74264859]]
Step:200, total reward:-186.8740121376694, average reward:-0.934370060688347,----
Box_Position: [[1.27365665 0.59061724 0.57796295]]
Step:26, total reward:-28.059173430331086, average reward:-1.0791989780896571,success
Box_Position: [[1.29211693 1.09363968 0.58259543]]
Step:200, total reward:-241.6866318535979, average reward:-1.2084331592679896,----
Box_Position: [[1.32352694 0.89021121 0.71149923]]
Step:200, total reward:-134.1335099382866, average reward:-0.670667549691433,----
Box_Position: [[1.30909164 0.84484923 0.550817  ]]
Step:200, total reward:-184.0315010878877, average reward:-0.9201575054394385,----
Box_Position: [[1.47552297 0.74883708 0.68836614]]
Step:200, total reward:-202.58814710025584, average reward:-1.0129407355012792,----
Box_Position: [[1.42498459 0.92121686 0.5546143 ]]
Step:200, total reward:-273.84081749036045, average reward:-1.3692040874518023,----
Box_Position: [[1.48308702 0.85774678 0.64097025]]
Step:200, total reward:-157.9275028502205, average reward:-0.7896375142511025,----
Box_Position: [[1.46745623 0.91211889 0.69164735]]
Step:200, total reward:-158.75032694482684, average reward:-0.7937516347241342,----
Box_Position: [[1.31497076 0.7686942  0.46558344]]
Step:200, total reward:-173.30088735089228, average reward:-0.8665044367544614,----
Box_Position: [[1.47347164 0.64703647 0.45363665]]
Step:200, total reward:-167.15728799586162, average reward:-0.8357864399793081,----
Box_Position: [[1.31652927 0.8950246  0.70132827]]
Step:200, total reward:-144.00978677485676, average reward:-0.7200489338742838,----
Box_Position: [[1.2956739  0.63689987 0.6629821 ]]
Step:200, total reward:-154.85065484357867, average reward:-0.7742532742178934,----
Box_Position: [[1.54793125 0.61396304 0.59648147]]
Step:200, total reward:-178.8208957728449, average reward:-0.8941044788642245,----
Box_Position: [[1.4165404  0.96389789 0.62958379]]
Step:200, total reward:-175.83910862641952, average reward:-0.8791955431320976,----
Box_Position: [[1.41311661 0.55046304 0.5926816 ]]
Step:200, total reward:-172.18702724603602, average reward:-0.8609351362301801,----
Box_Position: [[1.43014903 0.66764815 0.72825098]]
Step:200, total reward:-162.3917170792276, average reward:-0.811958585396138,----
Box_Position: [[1.39618986 0.68430861 0.60895296]]
Step:200, total reward:-229.25748045015797, average reward:-1.1462874022507898,----
Box_Position: [[1.30720953 0.58374329 0.50962325]]
Step:200, total reward:-146.2729724117484, average reward:-0.7313648620587421,----
Box_Position: [[1.3923219  0.9344755  0.64127178]]
Step:200, total reward:-158.33717451454027, average reward:-0.7916858725727013,----
Box_Position: [[1.27339157 0.6080655  0.5232574 ]]
Step:200, total reward:-172.21784737293976, average reward:-0.8610892368646987,----
Box_Position: [[1.27061788 1.08328491 0.67444955]]
Step:200, total reward:-177.75157954361526, average reward:-0.8887578977180763,----
Box_Position: [[1.33598165 0.72617248 0.62745422]]
Step:200, total reward:-149.0379684139789, average reward:-0.7451898420698945,----
Box_Position: [[1.39989432 0.81915012 0.51528497]]
actor_loss: tensor(0.5438, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-178.52225895946228, average reward:-0.8926112947973114,----
Box_Position: [[1.36697021 0.63103853 0.73829054]]
actor_loss: tensor(0.6694, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4759, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4929, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5189, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-131.64427168976127, average reward:-0.6582213584488064,----
Box_Position: [[1.28718591 0.82607879 0.71132511]]
actor_loss: tensor(0.4033, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3854, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5127, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-116.60482106916277, average reward:-0.5830241053458138,----
Box_Position: [[1.45600517 0.95267507 0.65612043]]
actor_loss: tensor(0.4925, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4468, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5730, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5670, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-125.94787077832667, average reward:-0.6297393538916334,----
Box_Position: [[1.49860268 0.52473383 0.5066035 ]]
actor_loss: tensor(0.5009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6510, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5897, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4981, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-161.35988780687995, average reward:-0.8067994390343998,----
Box_Position: [[1.47795921 0.63647717 0.71365816]]
actor_loss: tensor(0.5978, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5092, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6057, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5818, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-139.26497622575167, average reward:-0.6963248811287583,----
Box_Position: [[1.29626275 0.84467239 0.65442097]]
actor_loss: tensor(0.6884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6919, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7028, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6439, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-113.99463346448889, average reward:-0.5699731673224444,----
Box_Position: [[1.36859139 0.95356244 0.71578634]]
actor_loss: tensor(0.6855, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7436, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6824, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-112.42680763668871, average reward:-0.5621340381834435,----
Box_Position: [[1.37020193 0.97109228 0.51274569]]
actor_loss: tensor(0.6970, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7467, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-143.8622899226657, average reward:-0.7193114496133285,----
Box_Position: [[1.51757299 0.67827676 0.58662677]]
actor_loss: tensor(0.8172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7733, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8400, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8402, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-130.96955446964867, average reward:-0.6548477723482433,----
Box_Position: [[1.25070536 0.72345304 0.65867674]]
Step:32, total reward:-15.351101729436468, average reward:-0.47972192904488964,success
Box_Position: [[1.43576659 0.92041926 0.74451154]]
actor_loss: tensor(0.8693, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8319, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8422, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-113.93226585808065, average reward:-0.5696613292904033,----
Box_Position: [[1.53080902 0.67804689 0.66356923]]
actor_loss: tensor(0.8953, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0271, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-69.41806022680134, average reward:-0.7628358266681466,success
Box_Position: [[1.39911883 0.87616972 0.53774752]]
actor_loss: tensor(0.9571, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9938, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9095, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9404, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-117.28897338931951, average reward:-0.5864448669465976,----
Box_Position: [[1.34139462 1.08261872 0.48109093]]
actor_loss: tensor(1.0566, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9601, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0439, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-100.58865449667016, average reward:-0.6937148585977252,success
Box_Position: [[1.35806629 0.68704198 0.56319299]]
actor_loss: tensor(1.0343, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0877, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0346, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-152.4970515264699, average reward:-0.7624852576323495,----
Box_Position: [[1.49092153 0.63324823 0.70470994]]
actor_loss: tensor(1.1423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0394, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0625, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0441, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.09978381630981, average reward:-0.530498919081549,----
Box_Position: [[1.34501072 0.49142539 0.50051969]]
actor_loss: tensor(1.0912, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1022, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1123, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1148, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.70100880583924, average reward:-0.5735050440291962,----
Box_Position: [[1.50082346 0.6391492  0.71477125]]
actor_loss: tensor(1.1370, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1135, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1395, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1340, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-105.43609408247471, average reward:-0.5271804704123736,----
Box_Position: [[1.44965154 0.79819615 0.50758735]]
actor_loss: tensor(1.1840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0829, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2109, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1627, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-126.39903578332968, average reward:-0.6319951789166484,----
Box_Position: [[1.32201748 0.6351868  0.55980178]]
actor_loss: tensor(1.1610, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2012, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2502, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-105.24181174518708, average reward:-0.5262090587259354,----
Box_Position: [[1.43680616 0.8178734  0.48834614]]

------------------Episode:800------------------
actor_loss: tensor(1.2300, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1695, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2726, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-140.83987882060103, average reward:-0.7041993941030051,----
episode 800, the accuracy is: 11%
Box_Position: [[1.25415922 0.56170735 0.59733115]]
Step:7, total reward:-2.465039852191166, average reward:-0.3521485503130237,success
Box_Position: [[1.43931268 0.68300596 0.49197567]]
actor_loss: tensor(1.3114, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2865, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3258, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-130.6107680645257, average reward:-0.6530538403226285,----
Box_Position: [[1.27423906 0.89466585 0.51796182]]
actor_loss: tensor(1.1882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2696, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3232, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-131.51446612336008, average reward:-0.6575723306168004,----
Box_Position: [[1.3745256  0.87231429 0.58069428]]
actor_loss: tensor(1.3007, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-42.8199157665355, average reward:-0.6117130823790786,success
Box_Position: [[1.276616   0.79380633 0.54060267]]
actor_loss: tensor(1.3098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2756, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2972, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-77.88231490685867, average reward:-0.5643646007743381,success
Box_Position: [[1.34070552 0.605585   0.73482294]]
actor_loss: tensor(1.3290, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3631, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-42.1213189913562, average reward:-0.6286764028560626,success
Box_Position: [[1.32838512 1.02927014 0.51710398]]
actor_loss: tensor(1.3724, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3992, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-83.70371735712519, average reward:-0.7750344199733813,success
Box_Position: [[1.3512855  0.68895252 0.45983485]]
actor_loss: tensor(1.2662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3880, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3409, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.86694244696501, average reward:-0.604334712234825,----
Box_Position: [[1.3582548  0.7999842  0.65113433]]
actor_loss: tensor(1.4353, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4061, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3973, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4025, device='cuda:0', grad_fn=<NegBackward>)
Step:199, total reward:-124.89387017682324, average reward:-0.6276073878232323,success
Box_Position: [[1.40842041 0.49812567 0.61905293]]
actor_loss: tensor(1.4230, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3874, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4013, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4220, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-152.95081850249323, average reward:-0.7647540925124662,----
Box_Position: [[1.40769157 1.07958057 0.6480768 ]]
actor_loss: tensor(1.4414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4450, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5067, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-100.58505793054229, average reward:-0.5029252896527114,----
Box_Position: [[1.51383829 0.55516344 0.74609139]]
actor_loss: tensor(1.4693, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-56.53102678091851, average reward:-0.7066378347614813,success
Box_Position: [[1.34346217 0.93909427 0.60285483]]
actor_loss: tensor(1.4666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4273, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-83.14256691447174, average reward:-0.7994477587929976,success
Box_Position: [[1.32321084 0.89855525 0.55320812]]
actor_loss: tensor(1.4464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5372, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-47.68385729643214, average reward:-0.6910703956004658,success
Box_Position: [[1.25282312 1.00043319 0.65695276]]
actor_loss: tensor(1.4414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4608, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-86.26239094582813, average reward:-0.7129123218663482,success
Box_Position: [[1.5231106  1.00061134 0.56207474]]
actor_loss: tensor(1.4507, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4980, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3828, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-160.43938118097168, average reward:-0.8021969059048584,----
Box_Position: [[1.30659823 0.89983483 0.57621979]]
actor_loss: tensor(1.5438, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5691, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-141.59220528429864, average reward:-0.7079610264214932,----
Box_Position: [[1.35297968 0.8215036  0.61490746]]
actor_loss: tensor(1.5648, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4186, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4703, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.3573200882262, average reward:-0.766786600441131,----
Box_Position: [[1.25667919 0.77608467 0.62035553]]
actor_loss: tensor(1.5460, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4808, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5369, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-173.21704151386848, average reward:-0.8660852075693424,----
Box_Position: [[1.45242481 0.75979886 0.64507305]]
actor_loss: tensor(1.5549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4883, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4400, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-149.6515797768827, average reward:-0.8650380333923855,success
Box_Position: [[1.45009142 0.9414002  0.69400653]]
actor_loss: tensor(1.5037, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-69.981726423305, average reward:-0.7444864513117554,success
Box_Position: [[1.2763719  0.57928518 0.61665092]]
actor_loss: tensor(1.4947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4405, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-35.21757051722242, average reward:-0.6403194639494986,success
Box_Position: [[1.35624429 0.65138187 0.60227861]]
actor_loss: tensor(1.4521, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4879, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5354, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5711, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-163.65826113200254, average reward:-0.8182913056600127,----
Box_Position: [[1.37791848 1.11457536 0.63182885]]
actor_loss: tensor(1.4514, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5696, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5310, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-133.36014765400265, average reward:-0.6668007382700132,----
Box_Position: [[1.26670545 0.75299949 0.7250254 ]]
actor_loss: tensor(1.4739, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5479, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5249, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-150.40989497265733, average reward:-0.7520494748632867,----
Box_Position: [[1.46901347 0.97950374 0.46199433]]
actor_loss: tensor(1.5488, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5255, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5123, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4873, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-161.44440027863703, average reward:-0.8072220013931851,----
Box_Position: [[1.25943945 0.64463371 0.51418715]]
actor_loss: tensor(1.4654, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-38.89463868380013, average reward:-0.5983790566738482,success
Box_Position: [[1.47551323 0.77611202 0.57566989]]
actor_loss: tensor(1.5564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5406, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4721, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4894, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-151.29819102972743, average reward:-0.7564909551486372,----
Box_Position: [[1.33019883 1.01541114 0.68613557]]
actor_loss: tensor(1.4825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5587, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-99.50836720822336, average reward:-0.8223832000679616,success
Box_Position: [[1.40706071 0.64815149 0.50720641]]
actor_loss: tensor(1.4928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4626, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-161.67023392981008, average reward:-0.8083511696490504,----
Box_Position: [[1.51818754 0.89611439 0.67088285]]
actor_loss: tensor(1.4964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5927, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5431, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-172.60727598912172, average reward:-0.8630363799456086,----
Box_Position: [[1.51967893 0.49014481 0.57900975]]
actor_loss: tensor(1.5742, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4995, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5515, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.05794215170684, average reward:-0.8252897107585342,----
Box_Position: [[1.39217718 0.54161784 0.54497164]]
actor_loss: tensor(1.5345, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5036, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5206, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-98.57215343155451, average reward:-0.8146458961285497,success
Box_Position: [[1.28253088 0.64444938 0.59809635]]
Step:4, total reward:-1.1653838212533154, average reward:-0.29134595531332885,success
Box_Position: [[1.47240618 0.85691092 0.58494959]]
actor_loss: tensor(1.5863, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5633, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5316, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5441, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-168.96308780636087, average reward:-0.8448154390318043,----
Box_Position: [[1.45553855 0.93895633 0.4846167 ]]
actor_loss: tensor(1.4401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5382, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-157.00754374679107, average reward:-0.7850377187339553,----
Box_Position: [[1.29770999 0.67308421 0.70600485]]
actor_loss: tensor(1.4851, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5756, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5362, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5406, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-174.8981156141553, average reward:-0.8744905780707765,----
Box_Position: [[1.32395145 0.54538101 0.56226305]]
actor_loss: tensor(1.5513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5433, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5841, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-184.5265421355203, average reward:-0.9226327106776014,success
Box_Position: [[1.49220245 0.73849451 0.69793609]]
actor_loss: tensor(1.5305, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-47.04034802560852, average reward:-0.6533381670223406,success
Box_Position: [[1.47452532 1.0589181  0.53396626]]
actor_loss: tensor(1.5338, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.6171, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5386, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5218, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.10014164988473, average reward:-0.7655007082494236,----
Box_Position: [[1.4422482  0.88363214 0.66503002]]
actor_loss: tensor(1.5878, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.6008, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5428, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-130.59007349017222, average reward:-0.6529503674508611,----
Box_Position: [[1.46690188 1.0657758  0.60997093]]
actor_loss: tensor(1.5805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4855, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.6141, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.6376, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-162.88351497545267, average reward:-0.8144175748772633,----
Box_Position: [[1.5448583  1.03382334 0.48479474]]
actor_loss: tensor(1.5332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5435, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4828, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.6095, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.49999066940077, average reward:-0.8274999533470039,----
Box_Position: [[1.34452353 0.81370738 0.54952999]]
actor_loss: tensor(1.5141, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-34.853776691776574, average reward:-0.7921312884494676,success
Box_Position: [[1.26490319 0.70498155 0.48943806]]
actor_loss: tensor(1.5094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.6096, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5666, device='cuda:0', grad_fn=<NegBackward>)
Step:193, total reward:-157.17426527329582, average reward:-0.8143744314678539,success
Box_Position: [[1.31722597 0.6654197  0.68238891]]
actor_loss: tensor(1.5472, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5581, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5356, device='cuda:0', grad_fn=<NegBackward>)
Step:132, total reward:-112.82699272174999, average reward:-0.8547499448617424,success
Box_Position: [[1.33488223 0.60322254 0.59240482]]
actor_loss: tensor(1.5462, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5135, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4508, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5206, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.260232229479, average reward:-0.711301161147395,----
Box_Position: [[1.3289139  1.07337377 0.68524664]]
Step:20, total reward:-10.301318707627038, average reward:-0.5150659353813519,success
Box_Position: [[1.37179014 0.97473316 0.73056424]]
actor_loss: tensor(1.4904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5525, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5233, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-178.83187458716216, average reward:-0.8941593729358108,----
Box_Position: [[1.52652666 0.88377572 0.48469485]]

------------------Episode:850------------------
actor_loss: tensor(1.5063, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4764, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4685, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-173.47071431175587, average reward:-0.8673535715587793,----
Box_Position: [[1.29137895 0.8985175  0.67855276]]
actor_loss: tensor(1.4553, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5627, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5717, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5780, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-115.51019742733178, average reward:-0.5775509871366589,----
Box_Position: [[1.4184666  0.69508399 0.66282644]]
actor_loss: tensor(1.5097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5338, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5717, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5323, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.89599644978614, average reward:-0.7694799822489307,----
Box_Position: [[1.26246708 0.72168852 0.63544889]]
actor_loss: tensor(1.5628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4781, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.93111462217304, average reward:-0.6046555731108652,----
Box_Position: [[1.48379336 0.72519209 0.74471801]]
actor_loss: tensor(1.5009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5372, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5106, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.89666274098687, average reward:-0.7394833137049344,----
Box_Position: [[1.40227896 0.71482398 0.72488315]]
Step:16, total reward:-12.461328846942864, average reward:-0.778833052933929,success
Box_Position: [[1.42896405 0.68533932 0.45817079]]
actor_loss: tensor(1.5184, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4548, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-74.57982380860862, average reward:-0.9207385655383781,success
Box_Position: [[1.32804151 0.75159322 0.71412512]]
actor_loss: tensor(1.5047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5466, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-96.46624193474265, average reward:-0.7717299354779412,success
Box_Position: [[1.51963477 0.49826975 0.58060696]]
actor_loss: tensor(1.5000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5469, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4980, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-180.86917298514643, average reward:-0.9043458649257322,----
Box_Position: [[1.30734    0.92648307 0.49881603]]
actor_loss: tensor(1.5618, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4963, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5590, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5035, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-161.70177992958412, average reward:-0.8085088996479206,----
Box_Position: [[1.50603833 1.06749397 0.63763344]]
actor_loss: tensor(1.5399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5369, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4888, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-135.08346387347584, average reward:-0.6754173193673791,----
Box_Position: [[1.46663113 0.82856292 0.73676427]]
actor_loss: tensor(1.5095, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5561, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5282, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-166.55616884902767, average reward:-0.8327808442451383,----
Box_Position: [[1.31656396 0.76727305 0.71614042]]
actor_loss: tensor(1.5296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4862, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4568, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5280, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.22534870374963, average reward:-0.8561267435187482,----
Box_Position: [[1.32562352 0.85868262 0.69291962]]
actor_loss: tensor(1.4751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5220, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5154, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4930, device='cuda:0', grad_fn=<NegBackward>)
Step:176, total reward:-142.4558464282461, average reward:-0.8094082183423074,success
Box_Position: [[1.35918894 0.79155514 0.50553552]]
actor_loss: tensor(1.5035, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5578, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-74.43368455436529, average reward:-0.7918477080251626,success
Box_Position: [[1.37342715 0.52900747 0.56109202]]
actor_loss: tensor(1.4987, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4647, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4670, device='cuda:0', grad_fn=<NegBackward>)
Step:198, total reward:-166.1253078803, average reward:-0.8390167064661617,success
Box_Position: [[1.49490587 0.4872134  0.60858696]]
actor_loss: tensor(1.5536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4903, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5345, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4255, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-167.86734766924516, average reward:-0.8393367383462258,----
Box_Position: [[1.31991611 0.84871381 0.6858165 ]]
actor_loss: tensor(1.4920, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-70.97385888715536, average reward:-0.909921267784043,success
Box_Position: [[1.46848522 1.08107962 0.55623248]]
actor_loss: tensor(1.4420, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5938, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4520, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-170.06324069184012, average reward:-0.8503162034592006,----
Box_Position: [[1.43770534 0.58797471 0.5512076 ]]
actor_loss: tensor(1.4998, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4714, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4164, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-118.56890967062135, average reward:-0.7957644944337003,success
Box_Position: [[1.26108353 0.58007496 0.71507071]]
actor_loss: tensor(1.5459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4806, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5422, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4717, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-183.6870477367812, average reward:-0.9184352386839061,----
Box_Position: [[1.25813484 1.06230768 0.65968138]]
actor_loss: tensor(1.4394, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-19.177351279417593, average reward:-0.710272269608059,success
Box_Position: [[1.2839097  0.97885491 0.55482409]]
actor_loss: tensor(1.5207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5072, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5455, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-88.13748659829298, average reward:-0.6528702710984665,success
Box_Position: [[1.29487631 1.01314266 0.57169343]]
actor_loss: tensor(1.4885, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5124, device='cuda:0', grad_fn=<NegBackward>)
Step:196, total reward:-146.0927522713433, average reward:-0.745371185057874,success
Box_Position: [[1.28837516 0.82623875 0.48082438]]
actor_loss: tensor(1.4856, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5984, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-133.56472526366542, average reward:-0.7997887740339247,success
Box_Position: [[1.5191573  0.89049215 0.63386627]]
actor_loss: tensor(1.5056, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4429, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4623, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.29229604927315, average reward:-0.8564614802463657,----
Box_Position: [[1.42878891 1.05097168 0.74523871]]
actor_loss: tensor(1.5197, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4707, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5024, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-99.63894807166903, average reward:-0.7016827328990777,success
Box_Position: [[1.34843706 0.83056653 0.68063214]]
Step:7, total reward:-3.8336338720555143, average reward:-0.5476619817222164,success
Box_Position: [[1.43640424 0.89529882 0.57324845]]
actor_loss: tensor(1.4912, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-58.937252786951156, average reward:-0.9822875464491859,success
Box_Position: [[1.38149683 0.74169045 0.47704862]]
actor_loss: tensor(1.4265, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4996, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4917, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-121.1215311367702, average reward:-0.8776922546142768,success
Box_Position: [[1.38777629 0.46603338 0.61849236]]
actor_loss: tensor(1.4804, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4267, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4424, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4676, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-176.43444967472684, average reward:-0.8821722483736342,----
Box_Position: [[1.44893551 0.94917597 0.51335361]]
actor_loss: tensor(1.4245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4644, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-175.57812865893942, average reward:-0.8778906432946971,----
Box_Position: [[1.35998986 0.56965618 0.66747303]]
Step:21, total reward:-12.59789175459863, average reward:-0.5998996073618394,success
Box_Position: [[1.4948361  0.83283294 0.50313093]]
actor_loss: tensor(1.4207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.5454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4099, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-161.32990984053924, average reward:-0.8066495492026963,----
Box_Position: [[1.43176526 0.89853501 0.72962147]]
actor_loss: tensor(1.4345, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4809, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3963, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-93.53799637966524, average reward:-0.8205087401725022,success
Box_Position: [[1.44692168 0.63042127 0.60570908]]
actor_loss: tensor(1.4269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3535, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4575, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-186.10140689772442, average reward:-0.930507034488622,----
Box_Position: [[1.25397076 0.82660433 0.67570836]]
actor_loss: tensor(1.4590, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4440, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-81.37409058374347, average reward:-0.7397644598522133,success
Box_Position: [[1.37718982 1.04476086 0.54678322]]
actor_loss: tensor(1.3680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3748, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4482, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-160.58783452910762, average reward:-0.8029391726455382,----
Box_Position: [[1.33873113 0.75187509 0.60373075]]
actor_loss: tensor(1.4126, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3983, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3717, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4227, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.37598276600775, average reward:-0.8268799138300388,----
Box_Position: [[1.50323765 0.62581117 0.63444608]]
actor_loss: tensor(1.4208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4250, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-158.63885652796674, average reward:-0.7931942826398337,----
Box_Position: [[1.29982765 0.85094458 0.48943383]]
actor_loss: tensor(1.3582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3290, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3767, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.4320, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-127.2311119566051, average reward:-0.6361555597830255,----
Box_Position: [[1.54611081 0.71722152 0.45942873]]
actor_loss: tensor(1.4347, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3946, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3140, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3835, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-173.7549394075324, average reward:-0.868774697037662,----
Box_Position: [[1.42362603 0.84768048 0.7362279 ]]
actor_loss: tensor(1.3558, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2983, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3838, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-129.15744904821238, average reward:-0.6457872452410619,----
Box_Position: [[1.392826   0.80358716 0.57876318]]
actor_loss: tensor(1.3117, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3418, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3167, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3518, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-138.41225398645165, average reward:-0.6920612699322582,----
Box_Position: [[1.4271381  0.65307362 0.61454732]]
actor_loss: tensor(1.2671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2865, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2453, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.208215895588, average reward:-0.7660410794779401,----
Box_Position: [[1.29968636 0.67879549 0.52870384]]
Step:35, total reward:-18.461424558555265, average reward:-0.527469273101579,success
Box_Position: [[1.35635426 0.57878669 0.52813237]]
actor_loss: tensor(1.3346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2492, device='cuda:0', grad_fn=<NegBackward>)
Step:102, total reward:-71.01461406044572, average reward:-0.6962217064749581,success
Box_Position: [[1.30214306 0.80146656 0.67731429]]
Step:2, total reward:-0.22515273299726357, average reward:-0.11257636649863179,success
Box_Position: [[1.52326367 1.04867181 0.58795579]]
actor_loss: tensor(1.2522, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2705, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2465, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3005, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.40464744195555, average reward:-0.7120232372097778,----
Box_Position: [[1.26002549 1.00853348 0.74992217]]
actor_loss: tensor(1.2581, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1376, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2246, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-96.32691311728762, average reward:-0.713532689757686,success
Box_Position: [[1.40911453 1.17031394 0.49434213]]

------------------Episode:900------------------
actor_loss: tensor(1.2416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1802, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1246, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-137.20762647582248, average reward:-0.6860381323791124,----
episode 900, the accuracy is: 46%
Box_Position: [[1.51813284 1.10373115 0.57750487]]
actor_loss: tensor(1.1545, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2475, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1687, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1250, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-137.74450215729019, average reward:-0.688722510786451,----
Box_Position: [[1.39099209 0.76991109 0.5142226 ]]
actor_loss: tensor(1.1851, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0854, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-83.01489377585567, average reward:-0.7982201324601507,success
Box_Position: [[1.25893349 0.86561208 0.58168923]]
actor_loss: tensor(1.1442, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1213, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1156, device='cuda:0', grad_fn=<NegBackward>)
Step:197, total reward:-135.67784342687997, average reward:-0.6887200173953298,success
Box_Position: [[1.5340559  0.66735008 0.64994777]]
actor_loss: tensor(1.1272, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0477, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1269, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-154.05412923569924, average reward:-0.7702706461784962,----
Box_Position: [[1.30030383 0.82533366 0.67073515]]
actor_loss: tensor(1.0406, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-46.11407168184354, average reward:-1.07242027167078,success
Box_Position: [[1.44847401 0.9367811  0.55453196]]
actor_loss: tensor(1.1007, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-37.96902615237826, average reward:-0.8830006081948433,success
Box_Position: [[1.5005836  0.75061017 0.68203943]]
actor_loss: tensor(1.0910, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0537, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0450, device='cuda:0', grad_fn=<NegBackward>)
Step:152, total reward:-127.6561701436242, average reward:-0.8398432246291065,success
Box_Position: [[1.33291674 0.70680368 0.52157299]]
actor_loss: tensor(1.0949, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0325, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-73.80859107903144, average reward:-0.9342859630257145,success
Box_Position: [[1.39902618 0.55631897 0.58229336]]
actor_loss: tensor(1.0548, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0344, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0185, device='cuda:0', grad_fn=<NegBackward>)
Step:199, total reward:-144.58810606032495, average reward:-0.726573397288065,success
Box_Position: [[1.36483318 0.66036678 0.63451021]]
actor_loss: tensor(1.0238, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9431, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0024, device='cuda:0', grad_fn=<NegBackward>)
Step:182, total reward:-169.661699157973, average reward:-0.9322071382306208,success
Box_Position: [[1.5308309  0.60930267 0.71096437]]
actor_loss: tensor(0.9354, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9615, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9763, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9913, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-168.5586979468059, average reward:-0.8427934897340295,----
Box_Position: [[1.30378967 1.06095265 0.62783612]]
Step:6, total reward:-3.045277605580807, average reward:-0.5075462675968011,success
Box_Position: [[1.28783146 0.66984397 0.56070494]]
actor_loss: tensor(0.9581, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9523, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9193, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0172, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.15282757973188, average reward:-0.8557641378986593,----
Box_Position: [[1.28838858 0.82296662 0.58469354]]
actor_loss: tensor(0.9623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9157, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-53.89321461918815, average reward:-0.8043763375998232,success
Box_Position: [[1.46193356 0.6566907  0.57125937]]
actor_loss: tensor(0.9529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0105, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9540, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9871, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-169.42487228220978, average reward:-0.8471243614110489,----
Box_Position: [[1.33876481 0.72702498 0.73752237]]
Step:31, total reward:-26.823048088339732, average reward:-0.8652596157528946,success
Box_Position: [[1.49461592 0.69592976 0.63027707]]
actor_loss: tensor(0.9054, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0279, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9501, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-136.74589754053753, average reward:-0.772575692319421,success
Box_Position: [[1.39678163 0.81493289 0.57732447]]
Step:16, total reward:-14.1858662205547, average reward:-0.8866166387846688,success
Box_Position: [[1.26468941 0.87800739 0.52084108]]
actor_loss: tensor(0.9615, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0324, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0238, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-173.7839145781361, average reward:-0.8689195728906804,----
Box_Position: [[1.4067418  0.8263531  0.51498988]]
actor_loss: tensor(1.0317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0398, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-88.09133039129149, average reward:-0.8552556348669077,success
Box_Position: [[1.29986444 0.76224391 0.57319434]]
actor_loss: tensor(0.9412, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0449, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9950, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-159.975864249638, average reward:-0.79987932124819,----
Box_Position: [[1.45330455 0.72538055 0.59462204]]
actor_loss: tensor(1.0005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9870, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-59.41221951510009, average reward:-0.8367918241563393,success
Box_Position: [[1.43317133 0.5682188  0.46773355]]
actor_loss: tensor(1.0390, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9721, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-190.13525458488562, average reward:-0.950676272924428,----
Box_Position: [[1.31251164 0.87726809 0.67664642]]
actor_loss: tensor(0.9506, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-44.88768395349758, average reward:-0.7739255854051307,success
Box_Position: [[1.33349246 0.61673541 0.50080039]]
Step:17, total reward:-7.022183001318158, average reward:-0.4130695883128328,success
Box_Position: [[1.40902367 1.10630643 0.50359614]]
actor_loss: tensor(0.9777, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0764, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0495, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-128.54293761860004, average reward:-0.6427146880930001,----
Box_Position: [[1.31194424 0.55240782 0.65266713]]
actor_loss: tensor(1.0118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0835, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0014, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-119.36988318378683, average reward:-0.8406329801675129,success
Box_Position: [[1.37219298 0.44548551 0.70608656]]
actor_loss: tensor(1.0449, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-32.22412405660636, average reward:-0.6318455697373796,success
Box_Position: [[1.34119693 0.88926851 0.61273133]]
actor_loss: tensor(0.9941, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0403, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0752, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-144.19508998104737, average reward:-0.7209754499052369,----
Box_Position: [[1.44580221 0.69160735 0.45953084]]
actor_loss: tensor(1.0463, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0011, device='cuda:0', grad_fn=<NegBackward>)
Step:152, total reward:-133.01775325439357, average reward:-0.8751167977262735,success
Box_Position: [[1.28388617 0.89965    0.56205327]]
actor_loss: tensor(0.9964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9942, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0651, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-155.9956119355438, average reward:-0.7799780596777189,----
Box_Position: [[1.53738269 0.85640024 0.50034886]]
actor_loss: tensor(0.9984, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1032, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0568, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-172.64887656123022, average reward:-0.8632443828061511,----
Box_Position: [[1.44983209 0.90118962 0.53520865]]
actor_loss: tensor(0.9853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0247, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0848, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-194.38577303025176, average reward:-0.9719288651512588,----
Box_Position: [[1.43261107 0.59767356 0.54467306]]
actor_loss: tensor(1.0958, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9233, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.73693984068507, average reward:-0.8586846992034254,----
Box_Position: [[1.54662639 1.16384476 0.5950411 ]]
actor_loss: tensor(1.0727, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1073, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-143.02596849563338, average reward:-0.7151298424781669,----
Box_Position: [[1.52418849 0.98498034 0.46844832]]
actor_loss: tensor(1.0745, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0425, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0708, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-175.98970987808676, average reward:-0.8799485493904338,----
Box_Position: [[1.39423206 0.65905008 0.55775645]]
actor_loss: tensor(1.1330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0891, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9722, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0385, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-164.677131684156, average reward:-0.8233856584207799,----
Box_Position: [[1.26239493 0.91777862 0.48139024]]
actor_loss: tensor(1.0399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0842, device='cuda:0', grad_fn=<NegBackward>)
Step:95, total reward:-70.35845103321962, average reward:-0.7406152740338908,success
Box_Position: [[1.52302881 0.50208262 0.5721804 ]]
actor_loss: tensor(1.0311, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0749, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0898, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-168.85331095665134, average reward:-0.8442665547832567,----
Box_Position: [[1.40078286 0.82420558 0.69211761]]
actor_loss: tensor(1.0889, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-21.05616277941668, average reward:-0.6016046508404767,success
Box_Position: [[1.47012352 0.50262303 0.47107055]]
actor_loss: tensor(1.0560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0569, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-183.70795879065503, average reward:-0.9185397939532751,----
Box_Position: [[1.38388302 1.02699073 0.49381713]]
actor_loss: tensor(1.0670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0553, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9978, device='cuda:0', grad_fn=<NegBackward>)
Step:176, total reward:-161.07809536735306, average reward:-0.9152164509508697,success
Box_Position: [[1.47993302 1.05541745 0.74897424]]
actor_loss: tensor(1.0542, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-21.371905507331523, average reward:-0.8219963656665971,success
Box_Position: [[1.50123459 0.97215282 0.71987301]]
actor_loss: tensor(1.0784, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0905, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0883, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-104.89089770529027, average reward:-0.7039657564113441,success
Box_Position: [[1.45241538 0.45469722 0.60230667]]
actor_loss: tensor(1.0433, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-69.09541130878138, average reward:-0.7851751285088793,success
Box_Position: [[1.50550575 0.84475563 0.61461421]]
actor_loss: tensor(1.1116, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0994, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0847, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-94.0559212639498, average reward:-0.8397850112852661,success
Box_Position: [[1.33238171 0.61288563 0.49297389]]
actor_loss: tensor(1.0547, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-54.62784635505572, average reward:-0.9932335700919223,success
Box_Position: [[1.44771742 1.04038965 0.65249738]]
actor_loss: tensor(1.0567, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-40.77576531371176, average reward:-0.7995248100727795,success
Box_Position: [[1.39810299 0.8934792  0.67801592]]
actor_loss: tensor(1.0772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0538, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1419, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-112.8244070992924, average reward:-0.7326260201252753,success
Box_Position: [[1.45735515 0.64234756 0.59361739]]

------------------Episode:950------------------
actor_loss: tensor(1.0572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0860, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0563, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1107, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-156.21988458558062, average reward:-0.7810994229279031,----
Box_Position: [[1.3444609  0.7053627  0.74038352]]
actor_loss: tensor(1.0490, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1355, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0892, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-145.49582369393758, average reward:-0.7274791184696879,----
Box_Position: [[1.27863724 0.66193937 0.71309466]]
actor_loss: tensor(1.1612, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0985, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1298, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0872, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-154.12826011885315, average reward:-0.7706413005942657,----
Box_Position: [[1.25867824 0.54501084 0.68264573]]
actor_loss: tensor(1.1107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1012, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-66.54157458517398, average reward:-0.7232779846214562,success
Box_Position: [[1.30648341 0.63506414 0.57900448]]
actor_loss: tensor(1.0659, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1175, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-99.41507529581637, average reward:-0.7203990963464953,success
Box_Position: [[1.30477847 0.60395017 0.45783811]]
actor_loss: tensor(1.1460, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1615, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-60.61254168626003, average reward:-0.8658934526608576,success
Box_Position: [[1.46464671 0.71041939 0.48075079]]
actor_loss: tensor(1.0805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1439, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0908, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1587, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-178.32928673394986, average reward:-0.8916464336697493,----
Box_Position: [[1.44306813 0.88087375 0.50708987]]
actor_loss: tensor(1.1993, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1985, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1954, device='cuda:0', grad_fn=<NegBackward>)
Step:140, total reward:-99.54311100467402, average reward:-0.7110222214619573,success
Box_Position: [[1.39399998 0.62132793 0.60520942]]
actor_loss: tensor(1.2355, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-47.616237434586694, average reward:-0.7936039572431116,success
Box_Position: [[1.38285288 0.69981413 0.68621846]]
actor_loss: tensor(1.1393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1065, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0804, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1448, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.2082530493484, average reward:-0.826041265246742,----
Box_Position: [[1.42598338 0.5257426  0.53484166]]
actor_loss: tensor(1.1328, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-67.96497958818088, average reward:-0.8826620725737777,success
Box_Position: [[1.45663243 1.11201665 0.67398397]]
Step:5, total reward:-0.885049823610164, average reward:-0.17700996472203281,success
Box_Position: [[1.39815894 1.11212198 0.6384392 ]]
actor_loss: tensor(1.1268, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0895, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0506, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1633, device='cuda:0', grad_fn=<NegBackward>)
Step:162, total reward:-108.50064698926231, average reward:-0.6697570801806315,success
Box_Position: [[1.47468494 1.14772523 0.66294744]]
actor_loss: tensor(1.1816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1942, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1508, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1536, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.46669414480567, average reward:-0.7673334707240284,----
Box_Position: [[1.43819563 0.53504712 0.56155942]]
actor_loss: tensor(1.1194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1126, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2148, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2064, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-184.4292549177292, average reward:-0.922146274588646,----
Box_Position: [[1.45650421 0.92217803 0.57363814]]
actor_loss: tensor(1.1912, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1732, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2368, device='cuda:0', grad_fn=<NegBackward>)
Step:166, total reward:-130.40675491424273, average reward:-0.7855828609291731,success
Box_Position: [[1.32525997 1.01398246 0.6693121 ]]
actor_loss: tensor(1.1164, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2477, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0616, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-163.34586005269367, average reward:-0.8167293002634683,----
Box_Position: [[1.33076271 0.90117679 0.63686302]]
actor_loss: tensor(1.1212, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1766, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1461, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-127.68155836854923, average reward:-0.7645602297517918,success
Box_Position: [[1.40410468 0.62416258 0.54466266]]
actor_loss: tensor(1.1842, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-15.556724344499761, average reward:-0.7407963973571314,success
Box_Position: [[1.34964143 1.04799229 0.54079649]]
actor_loss: tensor(1.2119, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-23.162409466291905, average reward:-0.5386606852626025,success
Box_Position: [[1.48169773 0.9797926  0.65776061]]
Step:40, total reward:-25.646495763160413, average reward:-0.6411623940790103,success
Box_Position: [[1.38450157 0.57278272 0.45526307]]
actor_loss: tensor(1.2257, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-15.96904824360427, average reward:-1.1406463031145908,success
Box_Position: [[1.5253653  0.94122648 0.57403685]]
actor_loss: tensor(1.0945, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2450, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1904, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.95146695943063, average reward:-0.8597573347971532,----
Box_Position: [[1.38488257 0.77666196 0.59255348]]
actor_loss: tensor(1.1833, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-55.93103000659044, average reward:-0.9812461404664989,success
Box_Position: [[1.33475451 1.00435397 0.74475119]]
actor_loss: tensor(1.2852, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2098, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-144.0259162923772, average reward:-0.720129581461886,----
Box_Position: [[1.33712124 0.78139597 0.65900292]]
actor_loss: tensor(1.2272, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2173, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2289, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2203, device='cuda:0', grad_fn=<NegBackward>)
Step:187, total reward:-142.11114256095595, average reward:-0.7599526340158073,success
Box_Position: [[1.29649311 0.58025171 0.65062336]]
Step:17, total reward:-12.929942369579878, average reward:-0.7605848452694046,success
Box_Position: [[1.33916647 0.92516912 0.63394229]]
Step:8, total reward:-3.926287979257272, average reward:-0.490785997407159,success
Box_Position: [[1.35110329 0.64123282 0.70786881]]
actor_loss: tensor(1.1802, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-16.67732768463675, average reward:-0.5053735662011136,success
Box_Position: [[1.44536713 0.93489155 0.58454448]]
actor_loss: tensor(1.2015, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1868, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2155, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-119.09852641709563, average reward:-0.753788141880352,success
Box_Position: [[1.3936228  0.48860368 0.74055578]]
Step:1, total reward:-0.039783313982738246, average reward:-0.039783313982738246,success
Box_Position: [[1.49163642 1.08662139 0.66171005]]
actor_loss: tensor(1.3100, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2383, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2408, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-122.22322042610804, average reward:-0.6111161021305402,----
Box_Position: [[1.25345815 0.89058606 0.4820985 ]]
actor_loss: tensor(1.1983, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2322, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2421, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-148.71333975740322, average reward:-0.7435666987870161,----
Box_Position: [[1.25761751 0.90514303 0.53846438]]
actor_loss: tensor(1.2197, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2131, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-60.43029448291834, average reward:-0.7553786810364793,success
Box_Position: [[1.44207436 1.04329055 0.55938705]]
actor_loss: tensor(1.2632, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-33.99788114617511, average reward:-0.6295903915958354,success
Box_Position: [[1.29598712 0.69729988 0.55884425]]
actor_loss: tensor(1.2846, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2231, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2479, device='cuda:0', grad_fn=<NegBackward>)
Step:166, total reward:-131.39181827702222, average reward:-0.791516977572423,success
Box_Position: [[1.52862991 1.08202072 0.52324413]]
actor_loss: tensor(1.2641, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1783, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2055, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1821, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-172.6961569603014, average reward:-0.863480784801507,----
Box_Position: [[1.29615114 1.09177662 0.6938482 ]]
actor_loss: tensor(1.2300, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2152, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2153, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-132.15397050668005, average reward:-0.6607698525334003,----
Box_Position: [[1.33640934 0.65757217 0.60929394]]
actor_loss: tensor(1.2638, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3100, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2528, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.0770419408863, average reward:-0.8253852097044314,----
Box_Position: [[1.34999583 0.63837383 0.61609188]]
Step:28, total reward:-13.979191478968417, average reward:-0.4992568385345863,success
Box_Position: [[1.53869642 0.97398639 0.72983448]]
actor_loss: tensor(1.1888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2170, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2788, device='cuda:0', grad_fn=<NegBackward>)
Step:133, total reward:-101.17068872578533, average reward:-0.7606818701186867,success
Box_Position: [[1.40933851 0.71194674 0.64642674]]
actor_loss: tensor(1.3027, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2062, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2141, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3013, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-148.21474725419276, average reward:-0.7410737362709638,----
Box_Position: [[1.51670277 0.89561152 0.48846376]]
actor_loss: tensor(1.2093, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2288, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2192, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-138.75760427833387, average reward:-0.9312590891163347,success
Box_Position: [[1.36539117 0.57560323 0.64571056]]
actor_loss: tensor(1.2611, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1975, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2565, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2689, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-192.96302577752093, average reward:-0.9648151288876047,----
Box_Position: [[1.2772586  0.89356183 0.68090277]]
Step:6, total reward:-7.378353442279251, average reward:-1.2297255737132085,success
Box_Position: [[1.53172259 0.73420497 0.66105383]]
actor_loss: tensor(1.0737, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-22.31517725908299, average reward:-0.8926070903633196,success
Box_Position: [[1.31790204 0.96381057 0.70498011]]
actor_loss: tensor(1.1782, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-21.11284176343128, average reward:-0.5556010990376653,success
Box_Position: [[1.52041273 0.62763236 0.47599859]]
actor_loss: tensor(1.2341, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2688, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2504, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3164, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-189.0999854990176, average reward:-0.945499927495088,----
Box_Position: [[1.27583846 0.64545456 0.64231909]]
actor_loss: tensor(1.2742, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2519, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2308, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-155.39625464137725, average reward:-0.7769812732068863,----
Box_Position: [[1.29780229 0.79376388 0.62533608]]
Step:30, total reward:-24.210034519419334, average reward:-0.8070011506473111,success
Box_Position: [[1.42032604 0.79219087 0.64948875]]

------------------Episode:1000------------------
actor_loss: tensor(1.2392, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-29.844528507455067, average reward:-0.7853823291435544,success
episode 1000, the accuracy is: 62%
Box_Position: [[1.40183046 0.96345776 0.48177829]]
actor_loss: tensor(1.2610, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-28.86153376229988, average reward:-0.8246152503514251,success
Box_Position: [[1.25588233 0.73122252 0.68814545]]
actor_loss: tensor(1.2647, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2145, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2753, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.6789104949407, average reward:-0.7133945524747035,----
Box_Position: [[1.42629209 0.71880738 0.53336388]]
Step:42, total reward:-29.96305062237878, average reward:-0.7134059671994948,success
Box_Position: [[1.33350652 0.58468517 0.51111178]]
actor_loss: tensor(1.2364, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2527, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2723, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2225, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-183.77136543967808, average reward:-0.9188568271983903,----
Box_Position: [[1.51410126 1.17007616 0.58536266]]
actor_loss: tensor(1.2298, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3224, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2950, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-156.278290783354, average reward:-0.78139145391677,----
Box_Position: [[1.26886257 0.89664153 0.51314057]]
actor_loss: tensor(1.2862, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2892, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2473, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2517, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-175.21340997578363, average reward:-0.8760670498789181,----
Box_Position: [[1.29260244 0.82442942 0.4876941 ]]
actor_loss: tensor(1.2467, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2920, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2669, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-174.84299489739763, average reward:-0.8742149744869882,----
Box_Position: [[1.28649548 0.90059379 0.64781142]]
actor_loss: tensor(1.2749, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2228, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2858, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2720, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-130.7278838820915, average reward:-0.6536394194104576,----
Box_Position: [[1.36508445 0.99846465 0.59441972]]
actor_loss: tensor(1.2876, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2866, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2925, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-75.79909844196351, average reward:-0.7084027891772291,success
Box_Position: [[1.53519788 1.06697622 0.5200765 ]]
actor_loss: tensor(1.2933, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3210, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2072, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2649, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-173.74952997055252, average reward:-0.8687476498527625,----
Box_Position: [[1.33049334 0.72107825 0.69108344]]
actor_loss: tensor(1.3063, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-48.828454052528784, average reward:-0.8276009161445557,success
Box_Position: [[1.48846733 0.8114132  0.6187697 ]]
actor_loss: tensor(1.2469, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-57.66835169320334, average reward:-0.8009493290722687,success
Box_Position: [[1.26535522 0.74025591 0.50523435]]
actor_loss: tensor(1.2847, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-31.066567526734726, average reward:-0.7577211591886519,success
Box_Position: [[1.47281199 0.86290481 0.54278566]]
actor_loss: tensor(1.3110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3039, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2998, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-156.99703722251587, average reward:-0.7849851861125794,----
Box_Position: [[1.46693308 0.98240884 0.587097  ]]
actor_loss: tensor(1.3044, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2470, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2778, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-128.73866547237293, average reward:-0.8878528653267098,success
Box_Position: [[1.47908659 0.54677605 0.74066816]]
actor_loss: tensor(1.2732, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2922, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2859, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2995, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-139.4827333748262, average reward:-0.6974136668741311,----
Box_Position: [[1.54361673 0.96568135 0.63057404]]
actor_loss: tensor(1.2390, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2768, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2543, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.1759045189063, average reward:-0.7358795225945315,----
Box_Position: [[1.42324819 0.64845351 0.4650219 ]]
Step:6, total reward:-7.3934535662524565, average reward:-1.232242261042076,success
Box_Position: [[1.33556214 1.06502138 0.66760458]]
actor_loss: tensor(1.3224, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3014, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2754, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2731, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-121.68671083795374, average reward:-0.6404563728313355,success
Box_Position: [[1.25016935 0.72141309 0.61798387]]
actor_loss: tensor(1.2551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2832, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2856, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2674, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-115.9325884595679, average reward:-0.5796629422978394,----
Box_Position: [[1.53359473 0.69433964 0.71739985]]
actor_loss: tensor(1.2897, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2815, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2940, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-141.23095126707906, average reward:-0.7061547563353954,----
Box_Position: [[1.2991213  0.85933948 0.58564978]]
actor_loss: tensor(1.2627, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-35.84138149685625, average reward:-0.6892573364780048,success
Box_Position: [[1.34408458 1.07436011 0.6294407 ]]
actor_loss: tensor(1.2769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2467, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3122, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-109.93207396470964, average reward:-0.5496603698235483,----
Box_Position: [[1.43199578 0.83472338 0.48812799]]
actor_loss: tensor(1.3123, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2694, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3012, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-135.12477373603718, average reward:-0.7856091496281231,success
Box_Position: [[1.43055725 1.11007968 0.58115285]]
actor_loss: tensor(1.2668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2869, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2734, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3022, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-146.6007675145638, average reward:-0.7330038375728191,----
Box_Position: [[1.30557398 0.53800305 0.70846839]]
actor_loss: tensor(1.3245, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-12.868192507233658, average reward:-0.6434096253616829,success
Box_Position: [[1.42532517 1.07734564 0.51188774]]
actor_loss: tensor(1.3423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2871, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2889, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3095, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-176.05512789239, average reward:-0.88027563946195,----
Box_Position: [[1.3512209  0.99161414 0.71494994]]
actor_loss: tensor(1.2836, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-19.927505179378812, average reward:-0.41515635790372524,success
Box_Position: [[1.35052228 0.72659085 0.69860223]]
Step:18, total reward:-14.992545158850598, average reward:-0.8329191754916999,success
Box_Position: [[1.42771392 0.47569135 0.62093785]]
actor_loss: tensor(1.2935, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3439, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2869, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-113.12025151879482, average reward:-0.5656012575939741,----
Box_Position: [[1.48390784 0.71580366 0.70966144]]
actor_loss: tensor(1.2841, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3206, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3159, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2506, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-115.102777831905, average reward:-0.5755138891595251,----
Box_Position: [[1.48425148 1.05051896 0.56319161]]
actor_loss: tensor(1.2988, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3295, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3363, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.16563735896275, average reward:-0.7108281867948137,----
Box_Position: [[1.44431559 0.8139453  0.50890182]]
Step:3, total reward:-2.5793625734422805, average reward:-0.8597875244807601,success
Box_Position: [[1.48490668 0.67932469 0.71281664]]
actor_loss: tensor(1.3289, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3553, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2791, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2719, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-116.16024763473108, average reward:-0.5808012381736554,----
Box_Position: [[1.40087837 0.9379392  0.56599296]]
actor_loss: tensor(1.2831, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3254, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2955, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.96526880734618, average reward:-0.8298263440367308,----
Box_Position: [[1.53685202 1.11373221 0.71989736]]
actor_loss: tensor(1.3297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3391, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2477, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2472, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-126.90673188573057, average reward:-0.6345336594286528,----
Box_Position: [[1.44764703 1.04292905 0.58833513]]
actor_loss: tensor(1.2735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3014, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3544, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-92.7696260178401, average reward:-0.6871824149469636,success
Box_Position: [[1.54026774 0.62313468 0.64665176]]
actor_loss: tensor(1.2354, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2963, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3075, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-140.96404138880624, average reward:-0.7048202069440311,----
Box_Position: [[1.53399016 0.87751369 0.5402346 ]]
actor_loss: tensor(1.2999, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-50.75841200928749, average reward:-0.6678738422274669,success
Box_Position: [[1.33584788 1.05317152 0.50247885]]
actor_loss: tensor(1.3076, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2522, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2975, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2820, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-158.36039054466974, average reward:-0.7918019527233487,----
Box_Position: [[1.32136722 0.91206947 0.7361212 ]]
actor_loss: tensor(1.3057, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2757, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3189, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2845, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-90.7085092788748, average reward:-0.453542546394374,----
Box_Position: [[1.42602142 0.83850878 0.49945601]]
actor_loss: tensor(1.3219, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2458, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2647, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-141.37584901825926, average reward:-0.7600852097755875,success
Box_Position: [[1.41331774 0.55411093 0.72193411]]
actor_loss: tensor(1.3014, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2589, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2179, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2551, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.27239721974385, average reward:-0.5313619860987192,----
Box_Position: [[1.3405778  0.6717959  0.65262224]]
actor_loss: tensor(1.2549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3384, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-67.39677729902382, average reward:-0.7169869925428066,success
Box_Position: [[1.43860536 0.72463035 0.46119992]]
actor_loss: tensor(1.2540, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2780, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-63.20834270062153, average reward:-0.7436275611837827,success
Box_Position: [[1.47486471 1.15947157 0.60125461]]
actor_loss: tensor(1.2212, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3243, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2993, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.3267, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-125.42238947639731, average reward:-0.6271119473819866,----
Box_Position: [[1.39349918 0.82347803 0.63708398]]
Step:8, total reward:-6.411514648102984, average reward:-0.801439331012873,success
Box_Position: [[1.53309946 0.76684287 0.4821273 ]]
actor_loss: tensor(1.2337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2495, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-174.280883718716, average reward:-0.8714044185935801,----
Box_Position: [[1.314864   1.00449843 0.64526941]]
actor_loss: tensor(1.2479, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-23.968881544006283, average reward:-0.5326418120890285,success
Box_Position: [[1.43594545 0.87430285 0.51934754]]

------------------Episode:1050------------------
Step:36, total reward:-27.368555281444404, average reward:-0.7602376467067891,success
Box_Position: [[1.26261844 0.89375145 0.49065131]]
actor_loss: tensor(1.2992, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2142, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2989, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-127.27338653766775, average reward:-0.6363669326883388,----
Box_Position: [[1.46180986 0.89058582 0.74122421]]
actor_loss: tensor(1.2994, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1953, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2175, device='cuda:0', grad_fn=<NegBackward>)
Step:127, total reward:-69.45337758720854, average reward:-0.5468769888756577,success
Box_Position: [[1.44668157 0.77351555 0.47204703]]
actor_loss: tensor(1.2606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2298, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2638, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1868, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.96405491143926, average reward:-0.7698202745571963,----
Box_Position: [[1.40211794 0.7216958  0.68293583]]
Step:15, total reward:-14.65241648587031, average reward:-0.9768277657246873,success
Box_Position: [[1.32651875 0.66763709 0.50349403]]
actor_loss: tensor(1.2474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2449, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2890, device='cuda:0', grad_fn=<NegBackward>)
Step:176, total reward:-112.96958689546216, average reward:-0.6418726528151258,success
Box_Position: [[1.47020257 0.80145537 0.51880223]]
actor_loss: tensor(1.2374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2535, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2395, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-157.26195917352533, average reward:-0.7863097958676266,----
Box_Position: [[1.40527545 0.6979429  0.56045409]]
actor_loss: tensor(1.2879, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2811, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2380, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-126.5092382108848, average reward:-0.632546191054424,----
Box_Position: [[1.34616478 1.05245925 0.63852892]]
actor_loss: tensor(1.2627, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2474, device='cuda:0', grad_fn=<NegBackward>)
Step:119, total reward:-57.6951931698382, average reward:-0.4848335560490605,success
Box_Position: [[1.44886907 0.79953901 0.53810065]]
actor_loss: tensor(1.2472, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2469, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1821, device='cuda:0', grad_fn=<NegBackward>)
Step:141, total reward:-92.20707831097648, average reward:-0.6539509100069254,success
Box_Position: [[1.27629396 0.99624256 0.57441202]]
actor_loss: tensor(1.2408, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.2308, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1914, device='cuda:0', grad_fn=<NegBackward>)
Step:152, total reward:-73.82436989707026, average reward:-0.4856866440596727,success
Box_Position: [[1.54659892 0.81131625 0.70408556]]
actor_loss: tensor(1.1790, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1839, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1678, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-112.75374134121043, average reward:-0.5637687067060522,----
Box_Position: [[1.54003377 0.81602354 0.56137606]]
actor_loss: tensor(1.1807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1396, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1692, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-145.3452070939483, average reward:-0.7267260354697415,----
Box_Position: [[1.2815054  0.6735636  0.64541206]]
actor_loss: tensor(1.1737, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-25.942546517138975, average reward:-0.41842816963127377,success
Box_Position: [[1.46127819 0.74872    0.45119364]]
actor_loss: tensor(1.1586, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1390, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-117.49459472316727, average reward:-0.8274267234025864,success
Box_Position: [[1.27281884 0.93183642 0.55077604]]
actor_loss: tensor(1.1145, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-16.355518231372013, average reward:-0.4673005208963432,success
Box_Position: [[1.25074403 0.57521403 0.74620168]]
Step:19, total reward:-9.013794324992295, average reward:-0.4744102276311734,success
Box_Position: [[1.31028126 0.71475409 0.65176725]]
actor_loss: tensor(1.1337, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-6.380867628321308, average reward:-0.3038508394438718,success
Box_Position: [[1.43589991 0.75349616 0.7066004 ]]
actor_loss: tensor(1.0929, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1011, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1419, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1255, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-83.07604423767661, average reward:-0.4153802211883831,----
Box_Position: [[1.36710536 0.82762557 0.53069672]]
actor_loss: tensor(1.1104, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1264, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-66.01640346042477, average reward:-0.5790912584247787,success
Box_Position: [[1.30846996 0.91957071 0.59715423]]
actor_loss: tensor(1.0958, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-26.605393245048433, average reward:-0.6489120303670349,success
Box_Position: [[1.36797644 0.55125145 0.55970165]]
actor_loss: tensor(1.1263, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1492, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1599, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-140.56478831530217, average reward:-0.7028239415765108,----
Box_Position: [[1.28082785 0.70994055 0.56272436]]
actor_loss: tensor(1.1522, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-27.161410189304107, average reward:-0.5223348113327713,success
Box_Position: [[1.28079117 0.86928762 0.65667955]]
actor_loss: tensor(1.1201, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-21.975658170568998, average reward:-0.34881997096141265,success
Box_Position: [[1.46162411 1.00039632 0.70460537]]
actor_loss: tensor(1.0822, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0587, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1366, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1422, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-103.19785531543715, average reward:-0.5159892765771857,----
Box_Position: [[1.33291257 0.93584886 0.52234798]]
actor_loss: tensor(1.1192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0954, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1066, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0945, device='cuda:0', grad_fn=<NegBackward>)
Step:194, total reward:-136.6931819776169, average reward:-0.7046040308124581,success
Box_Position: [[1.49537731 0.79009028 0.54807144]]
actor_loss: tensor(1.1494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1402, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1304, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1514, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-130.97095946753902, average reward:-0.6548547973376951,----
Box_Position: [[1.35057284 0.77199782 0.61269461]]
actor_loss: tensor(1.1020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0683, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-42.094923597509215, average reward:-0.472976669634935,success
Box_Position: [[1.5339434  0.93046523 0.66530107]]
actor_loss: tensor(1.1026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1203, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0615, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-124.308808330821, average reward:-0.6215440416541049,----
Box_Position: [[1.29334531 1.07737217 0.58617972]]
actor_loss: tensor(1.1115, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-37.93650222037075, average reward:-0.7025278188957546,success
Box_Position: [[1.28126284 0.58393879 0.65242351]]
actor_loss: tensor(1.0548, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-32.66453622974052, average reward:-0.41877610550949385,success
Box_Position: [[1.47565276 1.05482216 0.67231221]]
actor_loss: tensor(1.0761, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9922, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0786, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.31215349914181, average reward:-0.6015607674957091,----
Box_Position: [[1.31335823 0.83979367 0.51832858]]
actor_loss: tensor(1.0760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0757, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-116.11422466293438, average reward:-0.5805711233146719,----
Box_Position: [[1.36630132 0.95885316 0.64884346]]
actor_loss: tensor(1.0487, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-28.107209505633982, average reward:-0.585566864700708,success
Box_Position: [[1.29525233 0.60336272 0.66197743]]
actor_loss: tensor(1.0657, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0781, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1373, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-86.88545603265408, average reward:-0.43442728016327037,----
Box_Position: [[1.34032037 0.81217199 0.49124236]]
actor_loss: tensor(1.0703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.1117, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0617, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-135.77894440105086, average reward:-0.6788947220052544,----
Box_Position: [[1.51022216 1.111458   0.50209311]]
actor_loss: tensor(1.0592, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-35.94168021011194, average reward:-1.1594090390358691,success
Box_Position: [[1.50795685 0.89698162 0.73957092]]
actor_loss: tensor(1.1012, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0693, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-113.88720917331118, average reward:-0.5694360458665559,----
Box_Position: [[1.25988458 1.10754658 0.49822595]]
actor_loss: tensor(1.0792, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0865, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0758, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0816, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-124.4223746294948, average reward:-0.622111873147474,----
Box_Position: [[1.32850631 1.04819709 0.58013207]]
actor_loss: tensor(1.1241, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-14.266595443400833, average reward:-0.4196057483353186,success
Box_Position: [[1.52074944 0.68046323 0.73829572]]
actor_loss: tensor(1.0566, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0746, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0427, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0629, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-95.74704884502047, average reward:-0.4787352442251024,----
Box_Position: [[1.38260975 0.953194   0.65138201]]
actor_loss: tensor(1.0202, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-39.453910584409996, average reward:-0.5331609538433784,success
Box_Position: [[1.48983165 0.84387825 0.60551648]]
actor_loss: tensor(1.0121, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0629, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9612, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9652, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.0438563061117, average reward:-0.6002192815305585,----
Box_Position: [[1.41403003 0.93366757 0.50012901]]
actor_loss: tensor(1.0096, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-46.21592519713437, average reward:-0.6418878499601995,success
Box_Position: [[1.31881173 0.66809228 0.53300684]]
actor_loss: tensor(1.0118, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-27.88865550546885, average reward:-0.5262010472729972,success
Box_Position: [[1.43237387 0.98633764 0.53368193]]
actor_loss: tensor(1.0338, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0339, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0415, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-122.74114154241248, average reward:-0.6137057077120623,----
Box_Position: [[1.43137606 0.96463291 0.55460038]]
actor_loss: tensor(0.9921, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0284, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9894, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-121.14637203522821, average reward:-0.605731860176141,----
Box_Position: [[1.35590692 0.85007469 0.58240278]]
actor_loss: tensor(1.0165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9702, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9561, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0097, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-89.14832565700718, average reward:-0.4457416282850359,----
Box_Position: [[1.30743055 0.55251751 0.52054694]]
actor_loss: tensor(0.9766, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9910, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-49.233415438006304, average reward:-0.6564455391734174,success
Box_Position: [[1.33437453 1.00096182 0.48304568]]
actor_loss: tensor(0.9631, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9881, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0031, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.87604227286832, average reward:-0.7143802113643416,----
Box_Position: [[1.27014617 1.00012897 0.69247961]]

------------------Episode:1100------------------
Step:20, total reward:-5.260853467295922, average reward:-0.2630426733647961,success
episode 1100, the accuracy is: 50%
Box_Position: [[1.252393   0.89774164 0.73199989]]
actor_loss: tensor(1.0063, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-8.289833062681552, average reward:-0.2858563125062604,success
Box_Position: [[1.25593275 0.87642078 0.74853088]]
actor_loss: tensor(0.9693, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-9.251230732870242, average reward:-0.23721104443257032,success
Box_Position: [[1.40503737 0.87191399 0.59362926]]
actor_loss: tensor(0.9600, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0077, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9783, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9470, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-107.26250469700007, average reward:-0.5363125234850004,----
Box_Position: [[1.26804515 0.53120583 0.74702314]]
Step:6, total reward:-1.7631699420739437, average reward:-0.293861657012324,success
Box_Position: [[1.2844346  0.74332811 0.5723523 ]]
actor_loss: tensor(0.9751, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-30.123459903468035, average reward:-0.6024691980693607,success
Box_Position: [[1.39033512 0.80714376 0.71792705]]
actor_loss: tensor(1.0323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(1.0103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9731, device='cuda:0', grad_fn=<NegBackward>)
Step:156, total reward:-63.624219627090454, average reward:-0.4078475617121183,success
Box_Position: [[1.2606457  0.5854999  0.56030972]]
Step:20, total reward:-10.804420405964773, average reward:-0.5402210202982387,success
Box_Position: [[1.54271256 0.91686785 0.66695791]]
actor_loss: tensor(0.9379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8958, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9451, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8753, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.69401755679618, average reward:-0.5734700877839809,----
Box_Position: [[1.31132423 0.42667793 0.65114883]]
actor_loss: tensor(0.9188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8881, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.9487, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-94.1912591848689, average reward:-0.4709562959243445,----
Box_Position: [[1.51843282 0.51918669 0.74045795]]
actor_loss: tensor(0.9497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8594, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8613, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-105.61044339667976, average reward:-0.5280522169833988,----
Box_Position: [[1.28596668 0.66766231 0.64165724]]
actor_loss: tensor(0.8796, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-22.353166977509563, average reward:-0.40642121777290113,success
Box_Position: [[1.26191552 0.80452145 0.59044964]]
actor_loss: tensor(0.8221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8907, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-30.692054494122278, average reward:-0.3789142530138553,success
Box_Position: [[1.33407584 1.03251094 0.65002426]]
actor_loss: tensor(0.9735, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-27.282942759800132, average reward:-0.401219746467649,success
Box_Position: [[1.34967369 0.80413844 0.5536066 ]]
actor_loss: tensor(0.8765, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8720, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-51.003244758664216, average reward:-0.44739688384793175,success
Box_Position: [[1.2561089  0.78583571 0.66127612]]
actor_loss: tensor(0.8907, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-28.130938481490283, average reward:-0.36065305745500364,success
Box_Position: [[1.46558621 0.74303959 0.50657439]]
actor_loss: tensor(0.9051, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8354, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8902, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.79787216428622, average reward:-0.7389893608214311,----
Box_Position: [[1.38156968 0.83843241 0.5774627 ]]
actor_loss: tensor(0.8441, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-4.498356313122031, average reward:-0.3748630260935026,success
Box_Position: [[1.29702359 0.45834844 0.54562754]]
Step:3, total reward:-0.47204255082185953, average reward:-0.15734751694061985,success
Box_Position: [[1.31180383 0.64750839 0.74406795]]
actor_loss: tensor(0.8131, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8810, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.50492731156734, average reward:-0.3425246365578367,----
Box_Position: [[1.25567805 0.56111967 0.57206749]]
actor_loss: tensor(0.8491, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-25.45127051041097, average reward:-0.36885899290450685,success
Box_Position: [[1.39802888 0.74752193 0.48377618]]
actor_loss: tensor(0.8660, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8168, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8721, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8584, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-127.80264235990035, average reward:-0.6726454861047386,success
Box_Position: [[1.42401132 1.03452799 0.72336113]]
actor_loss: tensor(0.8712, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8476, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-45.66163426100246, average reward:-0.5309492355930518,success
Box_Position: [[1.36710768 0.80597479 0.69749854]]
actor_loss: tensor(0.8783, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-32.003586900493545, average reward:-0.4849028318256598,success
Box_Position: [[1.38139375 0.66658184 0.59125122]]
actor_loss: tensor(0.8891, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8569, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7955, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8317, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-103.19825145334724, average reward:-0.5159912572667362,----
Box_Position: [[1.49698827 0.62106615 0.71713204]]
actor_loss: tensor(0.8653, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8649, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-100.9503146843885, average reward:-0.5047515734219425,----
Box_Position: [[1.26686991 1.0566145  0.54823601]]
actor_loss: tensor(0.8544, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7914, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8107, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-140.7108389985208, average reward:-0.7035541949926041,----
Box_Position: [[1.34679261 0.65458511 0.6551745 ]]
actor_loss: tensor(0.8148, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8261, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7759, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-91.03132315841069, average reward:-0.4551566157920534,----
Box_Position: [[1.33686923 0.93709896 0.57213861]]
Step:7, total reward:-3.666630919066489, average reward:-0.5238044170094984,success
Box_Position: [[1.30851902 0.76751972 0.48129221]]
Step:14, total reward:-5.603441863291249, average reward:-0.4002458473779464,success
Box_Position: [[1.40117255 0.68133871 0.64302219]]
Step:8, total reward:-2.07651865929527, average reward:-0.25956483241190875,success
Box_Position: [[1.4582764  0.97451695 0.51057207]]
actor_loss: tensor(0.7976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8181, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7927, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-202.55833863015025, average reward:-1.0127916931507512,----
Box_Position: [[1.43747203 1.0298615  0.56976847]]
actor_loss: tensor(0.7964, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-28.096675380522036, average reward:-0.7804632050145011,success
Box_Position: [[1.32667795 0.6997424  0.65859774]]
actor_loss: tensor(0.7088, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-25.024371887389595, average reward:-0.36800546893219993,success
Box_Position: [[1.45288241 0.81282817 0.70188212]]
actor_loss: tensor(0.7624, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7712, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7295, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-91.4808246125708, average reward:-0.457404123062854,----
Box_Position: [[1.33573294 0.71034801 0.62051559]]
actor_loss: tensor(0.7569, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7374, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-15.538286214963634, average reward:-0.30467227872477715,success
Box_Position: [[1.31588559 0.75148087 0.6712341 ]]
Step:16, total reward:-4.117364959775635, average reward:-0.2573353099859772,success
Box_Position: [[1.29494707 0.59315909 0.67819749]]
actor_loss: tensor(0.8325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7840, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-57.40102592338958, average reward:-0.4555636978046792,success
Box_Position: [[1.43662599 1.01539259 0.71753457]]
actor_loss: tensor(0.7746, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7504, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7759, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7936, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-93.09030552501426, average reward:-0.4654515276250713,----
Box_Position: [[1.31572815 1.11789229 0.50233648]]
actor_loss: tensor(0.7502, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7381, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7561, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8131, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-164.37153044577215, average reward:-0.8218576522288608,----
Box_Position: [[1.52472869 0.97822904 0.48271767]]
actor_loss: tensor(0.7160, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7407, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6892, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7415, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-219.10011743024685, average reward:-1.0955005871512342,----
Box_Position: [[1.4133479  0.5887258  0.69380304]]
actor_loss: tensor(0.7114, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7679, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7167, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-49.074777710374626, average reward:-0.43816765812834485,success
Box_Position: [[1.31241904 0.52703587 0.47074758]]
actor_loss: tensor(0.7801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.8173, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.42174171939146, average reward:-0.7371087085969573,----
Box_Position: [[1.27439818 1.03738119 0.50838683]]
actor_loss: tensor(0.7019, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7411, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7192, device='cuda:0', grad_fn=<NegBackward>)
Step:159, total reward:-118.0837341549402, average reward:-0.7426649946851585,success
Box_Position: [[1.50906648 0.76844297 0.74445557]]
actor_loss: tensor(0.7378, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7277, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7298, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7214, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-77.49482243023225, average reward:-0.38747411215116123,----
Box_Position: [[1.3448567  0.79277187 0.73973568]]
Step:23, total reward:-7.947345954731876, average reward:-0.34553678064051635,success
Box_Position: [[1.33181027 0.79425311 0.68957505]]
actor_loss: tensor(0.7337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7733, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-24.697647067637043, average reward:-0.3859007354318288,success
Box_Position: [[1.35683874 0.91224631 0.72621317]]
Step:21, total reward:-7.708556309681194, average reward:-0.36707410998481876,success
Box_Position: [[1.37833571 0.90145657 0.68966401]]
Step:4, total reward:-0.7062251688485602, average reward:-0.17655629221214006,success
Box_Position: [[1.40681522 0.81365205 0.46964274]]
actor_loss: tensor(0.6735, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-31.69030197503221, average reward:-0.6338060395006442,success
Box_Position: [[1.44578671 1.02500018 0.73298518]]

------------------Episode:1150------------------
actor_loss: tensor(0.6708, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7715, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-69.84933722106723, average reward:-0.44208441279156474,success
Box_Position: [[1.33378492 1.03939261 0.59785106]]
actor_loss: tensor(0.7393, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-19.35084077725924, average reward:-0.5375233549238678,success
Box_Position: [[1.49280989 0.54818221 0.46114677]]
actor_loss: tensor(0.7122, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6706, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6602, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7216, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.8805818527488, average reward:-0.829402909263744,----
Box_Position: [[1.48927781 0.97347513 0.58957288]]
actor_loss: tensor(0.7064, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7602, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6828, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7572, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-145.1609000837876, average reward:-0.725804500418938,----
Box_Position: [[1.49366197 0.67431479 0.60341762]]
actor_loss: tensor(0.7318, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7586, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7007, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6748, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.21703789418468, average reward:-0.6010851894709234,----
Box_Position: [[1.51832282 0.74223044 0.63578329]]
actor_loss: tensor(0.7186, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7035, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7362, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7024, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-116.61065550155428, average reward:-0.5830532775077714,----
Box_Position: [[1.31352745 0.94297799 0.72343263]]
actor_loss: tensor(0.7031, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6774, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-42.924144532624744, average reward:-0.4566398354534547,success
Box_Position: [[1.38296564 0.92062189 0.60798348]]
actor_loss: tensor(0.7294, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6812, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-77.9923822805664, average reward:-0.5820327035863164,success
Box_Position: [[1.39358884 0.63348611 0.5490912 ]]
actor_loss: tensor(0.6977, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7316, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-33.62385607754881, average reward:-0.5898922118868212,success
Box_Position: [[1.46040215 0.51933692 0.53157792]]
actor_loss: tensor(0.6949, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6630, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6307, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7097, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-127.44901843323197, average reward:-0.6372450921661599,----
Box_Position: [[1.46025802 0.70195622 0.491601  ]]
actor_loss: tensor(0.7167, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7422, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7128, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-137.04667739213167, average reward:-0.6852333869606584,----
Box_Position: [[1.51979075 0.98970754 0.49319312]]
actor_loss: tensor(0.6669, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6627, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6953, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-404.43895568141636, average reward:-2.0221947784070817,----
Box_Position: [[1.29012561 0.75437629 0.63835334]]
Step:21, total reward:-8.487128498413828, average reward:-0.40414897611494416,success
Box_Position: [[1.46929723 0.64506947 0.72732879]]
actor_loss: tensor(0.6881, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6713, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6841, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-80.00867885051247, average reward:-0.40004339425256236,----
Box_Position: [[1.25780934 0.64665949 0.60976872]]
actor_loss: tensor(0.6633, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6934, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-55.937029011465135, average reward:-0.5039371983014878,success
Box_Position: [[1.29777227 0.99549395 0.51748458]]
actor_loss: tensor(0.6371, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6720, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-54.096905519909534, average reward:-0.5944714892297751,success
Box_Position: [[1.41157264 0.76743477 0.61649506]]
actor_loss: tensor(0.6618, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6276, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6678, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-65.19142950655758, average reward:-0.48650320527281776,success
Box_Position: [[1.3613264  0.7401597  0.58884531]]
actor_loss: tensor(0.7430, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-30.361116123434357, average reward:-0.4819224781497517,success
Box_Position: [[1.37927589 0.78342423 0.48972248]]
actor_loss: tensor(0.6468, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7150, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7034, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-124.96771504129909, average reward:-0.6248385752064954,----
Box_Position: [[1.3661533  0.93850688 0.61561564]]
actor_loss: tensor(0.7087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6349, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-39.11454813868625, average reward:-0.379752894550352,success
Box_Position: [[1.35820557 0.89722426 0.5335634 ]]
actor_loss: tensor(0.6952, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7172, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.53960665252079, average reward:-0.5326980332626039,----
Box_Position: [[1.29375914 0.74077112 0.53531244]]
actor_loss: tensor(0.7079, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-18.717520570668608, average reward:-0.4253981947879229,success
Box_Position: [[1.36854551 0.74685757 0.53086431]]
actor_loss: tensor(0.6750, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6935, device='cuda:0', grad_fn=<NegBackward>)
Step:161, total reward:-86.485795699217, average reward:-0.5371788552746397,success
Box_Position: [[1.31247299 0.55599644 0.59078256]]
Step:6, total reward:-3.071840041805228, average reward:-0.5119733403008714,success
Box_Position: [[1.34531065 0.75646159 0.74240605]]
actor_loss: tensor(0.6959, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7181, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7074, device='cuda:0', grad_fn=<NegBackward>)
Step:168, total reward:-59.208386254325376, average reward:-0.35243087056146055,success
Box_Position: [[1.42887263 0.54560194 0.5192611 ]]
actor_loss: tensor(0.6829, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7066, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-133.74155420522735, average reward:-0.6687077710261368,----
Box_Position: [[1.52910778 0.86081927 0.5758804 ]]
actor_loss: tensor(0.6491, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6899, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6241, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-125.39076060346959, average reward:-0.6269538030173479,----
Box_Position: [[1.40675795 0.71032751 0.71629836]]
actor_loss: tensor(0.6700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6477, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6925, device='cuda:0', grad_fn=<NegBackward>)
Step:150, total reward:-66.44900576087736, average reward:-0.44299337173918235,success
Box_Position: [[1.31873718 0.89501098 0.47881746]]
Step:23, total reward:-17.430880295470796, average reward:-0.7578643606726433,success
Box_Position: [[1.49750208 0.71883228 0.6525281 ]]
actor_loss: tensor(0.6471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6274, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-90.37394870617798, average reward:-0.45186974353088993,----
Box_Position: [[1.41661337 1.09828318 0.45921987]]
actor_loss: tensor(0.6328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6349, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6168, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6582, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-156.97110943202864, average reward:-0.7848555471601432,----
Box_Position: [[1.35112542 0.64058929 0.51660732]]
actor_loss: tensor(0.6533, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-11.908458359596768, average reward:-0.47633833438387074,success
Box_Position: [[1.2798472  0.71012818 0.65924993]]
Step:33, total reward:-15.988983988646698, average reward:-0.4845146663226272,success
Box_Position: [[1.2803857  0.98722519 0.65012249]]
actor_loss: tensor(0.6833, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-12.15011559250838, average reward:-0.3115414254489328,success
Box_Position: [[1.46580611 0.94022115 0.70525316]]
actor_loss: tensor(0.6138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.7077, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6863, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6419, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-83.50427694782047, average reward:-0.4175213847391024,----
Box_Position: [[1.31892737 0.72855924 0.53081162]]
actor_loss: tensor(0.6248, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5813, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6621, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-81.71361061283146, average reward:-0.5306078611222822,success
Box_Position: [[1.45639884 0.75689293 0.46908035]]
actor_loss: tensor(0.6261, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-41.004989744144275, average reward:-0.5942752136832503,success
Box_Position: [[1.36538304 0.88802416 0.50088809]]
actor_loss: tensor(0.5918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5894, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6286, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.8091285127719, average reward:-0.7140456425638595,----
Box_Position: [[1.54993113 0.76921771 0.66490841]]
actor_loss: tensor(0.6436, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6608, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6692, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5790, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-113.5008062660554, average reward:-0.567504031330277,----
Box_Position: [[1.54494859 0.94489884 0.60863588]]
actor_loss: tensor(0.6215, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6758, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6004, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-117.30634371837147, average reward:-0.5865317185918574,----
Box_Position: [[1.50382524 0.65272024 0.50759375]]
actor_loss: tensor(0.6403, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6205, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6384, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6071, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-168.07821304159532, average reward:-0.8403910652079766,----
Box_Position: [[1.3151659  0.74460405 0.45477803]]
actor_loss: tensor(0.6530, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-9.931596950037706, average reward:-0.5842115852963357,success
Box_Position: [[1.3149551  0.96996425 0.71272713]]
actor_loss: tensor(0.6268, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5999, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-35.13004125152036, average reward:-0.40848885176186467,success
Box_Position: [[1.41039866 0.70874453 0.46516865]]
Step:26, total reward:-16.800890137520778, average reward:-0.6461880822123376,success
Box_Position: [[1.32211449 0.83592255 0.5699421 ]]
actor_loss: tensor(0.6339, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6017, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6110, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-66.57504305876277, average reward:-0.5121157158366367,success
Box_Position: [[1.29810983 0.92070843 0.6051324 ]]
Step:28, total reward:-8.308930840101674, average reward:-0.2967475300036312,success
Box_Position: [[1.32661243 0.80567869 0.56084957]]
Step:5, total reward:-5.1100583093078855, average reward:-1.022011661861577,success
Box_Position: [[1.42292738 1.19291231 0.7420208 ]]
actor_loss: tensor(0.5961, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-8.07798408395333, average reward:-0.5048740052470831,success
Box_Position: [[1.33412728 0.57759419 0.69020259]]
Step:39, total reward:-21.196073206300067, average reward:-0.5434890565717966,success
Box_Position: [[1.34672303 0.49602939 0.66247081]]
actor_loss: tensor(0.6223, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6175, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-81.14040519060218, average reward:-0.5373536767589548,success
Box_Position: [[1.42072474 0.73893163 0.67954919]]

------------------Episode:1200------------------
actor_loss: tensor(0.6192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5340, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6741, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-70.0504001689869, average reward:-0.35025200084493446,----
episode 1200, the accuracy is: 63%
Box_Position: [[1.41619695 0.88183479 0.45390178]]
actor_loss: tensor(0.5679, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5915, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5460, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.60244064494998, average reward:-0.7380122032247499,----
Box_Position: [[1.38523626 1.02777306 0.59664605]]
actor_loss: tensor(0.5393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5823, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-38.4338577068492, average reward:-0.5413219395330874,success
Box_Position: [[1.42984505 0.96836957 0.60966582]]
actor_loss: tensor(0.5875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5769, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-42.28307388142663, average reward:-0.4646491635321608,success
Box_Position: [[1.27032698 0.51317167 0.54830071]]
Step:14, total reward:-9.195972394920114, average reward:-0.6568551710657224,success
Box_Position: [[1.43114736 0.87001485 0.66842075]]
actor_loss: tensor(0.5703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5658, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5477, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-87.05837889687199, average reward:-0.43529189448435995,----
Box_Position: [[1.42580642 0.79068261 0.5034986 ]]
actor_loss: tensor(0.5694, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5683, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5695, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6030, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-151.79557308740334, average reward:-0.7589778654370167,----
Box_Position: [[1.32202888 0.70389808 0.57405221]]
actor_loss: tensor(0.5622, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-20.72231320526102, average reward:-0.5920660915788863,success
Box_Position: [[1.44202452 0.79190747 0.7399668 ]]
actor_loss: tensor(0.5261, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5923, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5046, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-89.60379553704527, average reward:-0.44801897768522636,----
Box_Position: [[1.29113563 1.06265061 0.65370662]]
Step:15, total reward:-3.924751110894618, average reward:-0.2616500740596412,success
Box_Position: [[1.52318217 0.94417666 0.63343146]]
actor_loss: tensor(0.5576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.6020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5721, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5588, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-108.08620651926653, average reward:-0.5404310325963326,----
Box_Position: [[1.29908036 1.10855509 0.70401556]]
actor_loss: tensor(0.5404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5037, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5567, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-71.0970769971837, average reward:-0.35548538498591853,----
Box_Position: [[1.44307387 0.88056566 0.47897188]]
actor_loss: tensor(0.5295, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5509, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5361, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.5862328074847, average reward:-0.7679311640374235,----
Box_Position: [[1.42174303 0.85572605 0.50598056]]
actor_loss: tensor(0.5662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5517, device='cuda:0', grad_fn=<NegBackward>)
Step:168, total reward:-128.9136144447019, average reward:-0.7673429431232256,success
Box_Position: [[1.54580624 0.8364982  0.46229165]]
actor_loss: tensor(0.5096, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5618, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5116, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5296, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.58152545867915, average reward:-0.8579076272933958,----
Box_Position: [[1.54618133 0.91991284 0.74050128]]
actor_loss: tensor(0.5398, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5706, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5621, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5550, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-84.65485077904196, average reward:-0.42327425389520984,----
Box_Position: [[1.52421838 0.94651517 0.50851838]]
actor_loss: tensor(0.5351, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5312, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5477, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-188.02560232151868, average reward:-0.9401280116075934,----
Box_Position: [[1.29768369 0.49229753 0.50344894]]
actor_loss: tensor(0.5645, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5443, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4953, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5330, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-152.95247347379916, average reward:-0.7647623673689958,----
Box_Position: [[1.27165637 0.99537032 0.65621697]]
actor_loss: tensor(0.4982, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5310, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-20.390184494465007, average reward:-0.28319700686756955,success
Box_Position: [[1.31773227 0.60464288 0.46953437]]
actor_loss: tensor(0.5537, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5206, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5082, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-138.5154320855124, average reward:-0.744706624115658,success
Box_Position: [[1.50089806 0.69440919 0.54244693]]
actor_loss: tensor(0.5221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4957, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5449, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-124.50316647313632, average reward:-0.6225158323656816,----
Box_Position: [[1.52792707 0.90768861 0.61652499]]
actor_loss: tensor(0.4916, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5344, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5383, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-102.23560288309646, average reward:-0.5111780144154823,----
Box_Position: [[1.37457287 0.90479652 0.63144951]]
actor_loss: tensor(0.5141, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5147, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4954, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5320, device='cuda:0', grad_fn=<NegBackward>)
Step:189, total reward:-72.7137957761943, average reward:-0.3847290781809222,success
Box_Position: [[1.3400483  0.73448513 0.50133064]]
actor_loss: tensor(0.4752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4967, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4199, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-134.69070515869254, average reward:-0.6734535257934627,----
Box_Position: [[1.54444627 0.54929999 0.50852598]]
actor_loss: tensor(0.4355, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4859, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-174.16844261043224, average reward:-0.8708422130521611,----
Box_Position: [[1.3624838  1.02993074 0.65637894]]
actor_loss: tensor(0.4964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4276, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4131, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4768, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-88.14078939784352, average reward:-0.4407039469892176,----
Box_Position: [[1.30477957 0.85581289 0.64647306]]
Step:3, total reward:-0.6103618880684376, average reward:-0.2034539626894792,success
Box_Position: [[1.39527497 0.91556779 0.56657437]]
actor_loss: tensor(0.4657, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4417, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4270, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4010, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.8357623722901, average reward:-0.6041788118614505,----
Box_Position: [[1.34045882 0.67999698 0.71787832]]
actor_loss: tensor(0.4419, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-10.778378868272187, average reward:-0.32661754146279354,success
Box_Position: [[1.25725117 0.82188393 0.45801864]]
Step:1, total reward:-0.04831102201236303, average reward:-0.04831102201236303,success
Box_Position: [[1.42484831 0.69013367 0.62396601]]
actor_loss: tensor(0.4825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4305, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4294, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4559, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.19324235424521, average reward:-0.5559662117712261,----
Box_Position: [[1.42569541 0.92131714 0.74859674]]
actor_loss: tensor(0.4373, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4727, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4672, device='cuda:0', grad_fn=<NegBackward>)
Step:197, total reward:-77.16077798160352, average reward:-0.3916790760487488,success
Box_Position: [[1.33944551 0.7475447  0.67441712]]
actor_loss: tensor(0.4433, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-19.198330593874466, average reward:-0.5999478310585771,success
Box_Position: [[1.27981859 0.91481186 0.45265953]]
Step:12, total reward:-10.557658932756405, average reward:-0.8798049110630338,success
Box_Position: [[1.26608441 0.62217506 0.74604262]]
actor_loss: tensor(0.4700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4527, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-77.43203894188859, average reward:-0.38716019470944296,----
Box_Position: [[1.35678161 0.70215509 0.54755893]]
actor_loss: tensor(0.4337, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-29.96245314749544, average reward:-0.6513576771194661,success
Box_Position: [[1.52643312 0.86805607 0.71176206]]
Step:3, total reward:-0.3781206138086689, average reward:-0.12604020460288964,success
Box_Position: [[1.53052881 0.76430992 0.63234911]]
Step:7, total reward:-1.5657341853518811, average reward:-0.22367631219312586,success
Box_Position: [[1.51266757 1.18023952 0.60623503]]
actor_loss: tensor(0.4225, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4555, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4368, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4313, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.10677233005602, average reward:-0.5705338616502801,----
Box_Position: [[1.47080982 0.7904243  0.63926386]]
actor_loss: tensor(0.3807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5021, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4957, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-104.5086477552037, average reward:-0.5225432387760185,----
Box_Position: [[1.44986165 0.95592121 0.58729376]]
actor_loss: tensor(0.4559, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-18.609863267765785, average reward:-0.5815582271176808,success
Box_Position: [[1.40963423 1.00046073 0.5485097 ]]
actor_loss: tensor(0.5163, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-40.2179331233304, average reward:-0.7181773772023285,success
Box_Position: [[1.37482922 0.87787465 0.70351383]]
actor_loss: tensor(0.4558, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-37.12179970678845, average reward:-0.5540567120416187,success
Box_Position: [[1.25893818 0.93920439 0.45202437]]
actor_loss: tensor(0.4885, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-32.76499742337421, average reward:-0.6686734168035553,success
Box_Position: [[1.43354648 1.13264444 0.73434412]]
actor_loss: tensor(0.5138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4583, device='cuda:0', grad_fn=<NegBackward>)
Step:163, total reward:-73.10070058120978, average reward:-0.4484705557129434,success
Box_Position: [[1.3536874  0.60032693 0.58113331]]
actor_loss: tensor(0.4957, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4645, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4306, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5217, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.95600219113732, average reward:-0.5747800109556865,----
Box_Position: [[1.37578395 0.77842797 0.72599045]]
Step:8, total reward:-1.8496575075296608, average reward:-0.2312071884412076,success
Box_Position: [[1.50102537 0.74708044 0.64755705]]
actor_loss: tensor(0.5147, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4522, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5095, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5054, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-94.72021283723929, average reward:-0.47360106418619646,----
Box_Position: [[1.38951608 0.63254177 0.74416767]]
actor_loss: tensor(0.5122, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-5.702711983477719, average reward:-0.3801807988985146,success
Box_Position: [[1.43708578 0.77930894 0.58348465]]
Step:24, total reward:-8.181906444290506, average reward:-0.34091276851210445,success
Box_Position: [[1.30216721 0.83780283 0.5268497 ]]

------------------Episode:1250------------------
actor_loss: tensor(0.4800, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-26.59268240332945, average reward:-0.492457081543138,success
Box_Position: [[1.49937328 0.69947964 0.59974059]]
actor_loss: tensor(0.4233, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5102, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5235, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-115.1322204785739, average reward:-0.5756611023928695,----
Box_Position: [[1.42367036 0.70566636 0.56855076]]
actor_loss: tensor(0.4681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4850, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4532, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4714, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-107.23581024634575, average reward:-0.5361790512317287,----
Box_Position: [[1.45041438 1.14987982 0.56558483]]
actor_loss: tensor(0.5014, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-14.302715766357016, average reward:-0.7151357883178509,success
Box_Position: [[1.47223199 0.77344811 0.52523744]]
actor_loss: tensor(0.5144, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5019, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.79292634301258, average reward:-0.6039646317150629,----
Box_Position: [[1.53567714 0.49904106 0.48668995]]
actor_loss: tensor(0.4972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5027, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4765, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4782, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-166.2944157540838, average reward:-0.831472078770419,----
Box_Position: [[1.27539629 0.70136035 0.61152506]]
actor_loss: tensor(0.5037, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4976, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-31.487069725467666, average reward:-0.3422507578855181,success
Box_Position: [[1.45325845 0.92980424 0.59563139]]
actor_loss: tensor(0.4884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4754, device='cuda:0', grad_fn=<NegBackward>)
Step:160, total reward:-83.76873441736551, average reward:-0.5235545901085344,success
Box_Position: [[1.26554417 0.55235218 0.62512471]]
actor_loss: tensor(0.4410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4821, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5138, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-66.42862549878096, average reward:-0.4813668514404417,success
Box_Position: [[1.28852027 1.01783303 0.70042566]]
actor_loss: tensor(0.5043, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-15.850118221314583, average reward:-0.25983800362810794,success
Box_Position: [[1.49213912 0.95072601 0.64901813]]
actor_loss: tensor(0.5353, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-23.27341501009944, average reward:-0.5818353752524861,success
Box_Position: [[1.52955098 0.58100627 0.68021144]]
actor_loss: tensor(0.4617, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4944, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4902, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-95.25665029760728, average reward:-0.4762832514880364,----
Box_Position: [[1.3675193  0.63036157 0.68483069]]
actor_loss: tensor(0.4943, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5149, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-70.86209001323749, average reward:-0.35431045006618744,----
Box_Position: [[1.47502919 0.92408193 0.65561919]]
Step:23, total reward:-17.07590102611911, average reward:-0.742430479396483,success
Box_Position: [[1.29853539 0.59087396 0.74943381]]
actor_loss: tensor(0.5046, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-8.81147674522389, average reward:-0.2753586482882466,success
Box_Position: [[1.355466   0.83021711 0.64376173]]
actor_loss: tensor(0.5235, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-33.83533602888589, average reward:-0.4076546509504324,success
Box_Position: [[1.53870305 0.78355412 0.67793057]]
Step:8, total reward:-2.2666646355991453, average reward:-0.28333307944989317,success
Box_Position: [[1.30311071 0.9138219  0.52571566]]
actor_loss: tensor(0.4816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4864, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-65.16080234978617, average reward:-0.587034255403479,success
Box_Position: [[1.41611152 0.56595142 0.71749424]]
actor_loss: tensor(0.5345, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4823, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4835, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-91.50714233317481, average reward:-0.45753571166587403,----
Box_Position: [[1.40950251 0.72237862 0.49771976]]
actor_loss: tensor(0.4893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4942, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4787, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-123.09920722454108, average reward:-0.6154960361227054,----
Box_Position: [[1.33109356 1.08716842 0.53347742]]
Step:38, total reward:-21.47400154765079, average reward:-0.5651053038855471,success
Box_Position: [[1.2670812  0.54831829 0.48740956]]
actor_loss: tensor(0.5482, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-26.656075220346036, average reward:-0.5553349004238758,success
Box_Position: [[1.37133097 0.82313658 0.48384207]]
actor_loss: tensor(0.5458, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5201, device='cuda:0', grad_fn=<NegBackward>)
Step:95, total reward:-79.32046523606782, average reward:-0.8349522656428191,success
Box_Position: [[1.2872535  0.55767697 0.49690214]]
actor_loss: tensor(0.5469, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-30.258006732004212, average reward:-0.6724001496000936,success
Box_Position: [[1.38577461 1.03682672 0.72362468]]
actor_loss: tensor(0.4918, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-17.13894617463613, average reward:-0.30068326622168645,success
Box_Position: [[1.34841022 0.76523633 0.48309491]]
Step:1, total reward:-0.03408043843723348, average reward:-0.03408043843723348,success
Box_Position: [[1.48211788 0.84250883 0.74602719]]
actor_loss: tensor(0.5103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4523, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5189, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4914, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-78.34645256272051, average reward:-0.39173226281360257,----
Box_Position: [[1.43290108 0.75039461 0.57895419]]
actor_loss: tensor(0.5041, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4425, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4937, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4809, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.42451301021663, average reward:-0.5571225650510832,----
Box_Position: [[1.43146899 1.00733243 0.51218938]]
actor_loss: tensor(0.5071, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5164, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.5145, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-75.46733838686319, average reward:-0.6505805033350275,success
Box_Position: [[1.29459219 0.80380232 0.49603357]]
Step:6, total reward:-4.923793328501012, average reward:-0.8206322214168353,success
Box_Position: [[1.51687184 0.77935477 0.5804195 ]]
actor_loss: tensor(0.5173, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4629, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4968, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4733, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-126.9839296303854, average reward:-0.634919648151927,----
Box_Position: [[1.28788321 1.03083854 0.62305303]]
actor_loss: tensor(0.4796, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-26.891575677984605, average reward:-0.6253854808833629,success
Box_Position: [[1.44975868 0.89679028 0.61053333]]
actor_loss: tensor(0.4569, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4377, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4079, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-78.34033248101866, average reward:-0.3917016624050933,----
Box_Position: [[1.33978222 0.9484203  0.5597899 ]]
actor_loss: tensor(0.4272, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4472, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4229, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4438, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-82.5032816116981, average reward:-0.4125164080584905,----
Box_Position: [[1.40189876 1.06534812 0.54788042]]
actor_loss: tensor(0.4161, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3866, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4627, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-101.8614739136829, average reward:-0.5093073695684145,----
Box_Position: [[1.31428517 0.73322653 0.48195329]]
actor_loss: tensor(0.3981, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-56.16890952297173, average reward:-0.668677494321092,success
Box_Position: [[1.30645291 0.86136993 0.63863461]]
actor_loss: tensor(0.4102, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-3.0346792114915404, average reward:-0.2528899342909617,success
Box_Position: [[1.34972169 0.85448541 0.50186658]]
actor_loss: tensor(0.4471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4445, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-94.9647682598098, average reward:-0.6504436182178753,success
Box_Position: [[1.51036877 0.76783753 0.47494826]]
actor_loss: tensor(0.4183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4049, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3770, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4084, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-169.85041882908243, average reward:-0.8492520941454121,----
Box_Position: [[1.31519097 0.65987488 0.62588524]]
actor_loss: tensor(0.3978, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-10.347325936545882, average reward:-0.4927298065021849,success
Box_Position: [[1.41556813 0.50743281 0.50117184]]
actor_loss: tensor(0.3954, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3936, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4675, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-163.5185881730995, average reward:-0.8175929408654974,----
Box_Position: [[1.373027   0.69803865 0.72042541]]
Step:2, total reward:-0.17969816356027396, average reward:-0.08984908178013698,success
Box_Position: [[1.430605   0.55862195 0.6848181 ]]
actor_loss: tensor(0.4242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3257, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3573, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-91.49892799931665, average reward:-0.45749463999658324,----
Box_Position: [[1.45283746 0.60455995 0.67689864]]
actor_loss: tensor(0.3956, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4211, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3761, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-89.56787569260447, average reward:-0.44783937846302235,----
Box_Position: [[1.41330408 0.93040314 0.74256952]]
actor_loss: tensor(0.3639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4370, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-60.69208861774517, average reward:-0.30346044308872583,----
Box_Position: [[1.42918187 0.64543943 0.74035125]]
actor_loss: tensor(0.3680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3984, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.4119, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3370, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-71.66387399449741, average reward:-0.35831936997248703,----
Box_Position: [[1.36404269 0.97787825 0.56053593]]
actor_loss: tensor(0.3892, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3538, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-37.2635778053497, average reward:-0.4186918854533674,success
Box_Position: [[1.35424492 0.80438552 0.71584903]]
Step:2, total reward:-0.24928585641910758, average reward:-0.12464292820955379,success
Box_Position: [[1.51651349 0.48677102 0.58970371]]
actor_loss: tensor(0.3664, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3614, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3583, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3953, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-121.54459648931832, average reward:-0.6077229824465916,----
Box_Position: [[1.30927965 0.90925839 0.47198183]]
actor_loss: tensor(0.3241, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-33.46359041994331, average reward:-0.796752152855793,success
Box_Position: [[1.449566   0.49019142 0.65920975]]

------------------Episode:1300------------------
actor_loss: tensor(0.3350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3528, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3504, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-86.99642959291889, average reward:-0.43498214796459445,----
episode 1300, the accuracy is: 55%
Box_Position: [[1.54013025 0.63704188 0.73607125]]
actor_loss: tensor(0.2893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3311, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3335, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3315, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-77.53641069373215, average reward:-0.38768205346866075,----
Box_Position: [[1.33763368 1.03967719 0.48135457]]
Step:3, total reward:-0.48748189273756837, average reward:-0.16249396424585613,success
Box_Position: [[1.37933988 0.73075487 0.66089421]]
actor_loss: tensor(0.3329, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2906, device='cuda:0', grad_fn=<NegBackward>)
Step:97, total reward:-31.17246834732967, average reward:-0.32136565306525433,success
Box_Position: [[1.40449193 0.84869898 0.51254179]]
actor_loss: tensor(0.3337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3225, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3282, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-131.30761154224552, average reward:-0.6565380577112276,----
Box_Position: [[1.5411837  0.95465913 0.48081707]]
actor_loss: tensor(0.2751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2785, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3068, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2870, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-144.33358728669342, average reward:-0.721667936433467,----
Box_Position: [[1.31602319 0.8012215  0.53636632]]
actor_loss: tensor(0.2857, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-38.410122347861446, average reward:-0.4315744084029376,success
Box_Position: [[1.3401049  0.51454519 0.56274568]]
actor_loss: tensor(0.3458, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3563, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3025, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3038, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-131.84370407330698, average reward:-0.6592185203665349,----
Box_Position: [[1.35038747 0.57017451 0.65008634]]
actor_loss: tensor(0.2491, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-10.302746683715782, average reward:-0.34342488945719274,success
Box_Position: [[1.41610297 1.01891714 0.5826864 ]]
actor_loss: tensor(0.3172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2776, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-50.53794229366208, average reward:-0.6563369129047023,success
Box_Position: [[1.40743446 0.53611325 0.72349084]]
actor_loss: tensor(0.3180, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2981, device='cuda:0', grad_fn=<NegBackward>)
Step:132, total reward:-38.47058654851164, average reward:-0.29144383748872454,success
Box_Position: [[1.3151648  0.98593671 0.72541817]]
actor_loss: tensor(0.3189, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-10.005241645505555, average reward:-0.20844253428136572,success
Box_Position: [[1.25604248 0.8579805  0.71230909]]
Step:7, total reward:-0.901710144431745, average reward:-0.12881573491882073,success
Box_Position: [[1.28418917 0.59834133 0.66770316]]
actor_loss: tensor(0.2820, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2675, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3030, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2607, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-70.38381526599555, average reward:-0.35191907632997776,----
Box_Position: [[1.28045392 1.02995413 0.61126504]]
actor_loss: tensor(0.2597, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-8.853057599616054, average reward:-0.252944502846173,success
Box_Position: [[1.52768768 0.76495111 0.59691848]]
actor_loss: tensor(0.2774, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2764, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3147, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-102.44938842612545, average reward:-0.5122469421306273,----
Box_Position: [[1.31511237 0.87205372 0.48173359]]
actor_loss: tensor(0.3149, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3058, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2666, device='cuda:0', grad_fn=<NegBackward>)
Step:127, total reward:-73.92049599171213, average reward:-0.5820511495410404,success
Box_Position: [[1.30231365 0.88289658 0.60460514]]
Step:23, total reward:-8.63020604565752, average reward:-0.3752263498111965,success
Box_Position: [[1.3277088  0.97781606 0.56545544]]
actor_loss: tensor(0.2708, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-18.170641562328306, average reward:-0.5506255018887366,success
Box_Position: [[1.36622078 0.8824399  0.70472212]]
actor_loss: tensor(0.2501, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2654, device='cuda:0', grad_fn=<NegBackward>)
Step:117, total reward:-26.852906763933134, average reward:-0.22951202362336012,success
Box_Position: [[1.36264022 1.00842936 0.5188573 ]]
actor_loss: tensor(0.2807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2868, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-126.28347012024882, average reward:-0.6314173506012442,----
Box_Position: [[1.39579486 0.50935581 0.61377501]]
actor_loss: tensor(0.2560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2970, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2554, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-104.1695572135172, average reward:-0.520847786067586,----
Box_Position: [[1.36370393 0.79453213 0.49514909]]
actor_loss: tensor(0.2683, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2879, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2964, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.34175285760836, average reward:-0.5567087642880417,----
Box_Position: [[1.30452089 0.64600437 0.72272373]]
Step:14, total reward:-3.0393585643751497, average reward:-0.2170970403125107,success
Box_Position: [[1.50052876 0.90292887 0.68468401]]
actor_loss: tensor(0.2620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2932, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2769, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-64.38154796321456, average reward:-0.36169408968098066,success
Box_Position: [[1.41847592 1.08645852 0.69642718]]
actor_loss: tensor(0.2770, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2521, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-51.141599556004536, average reward:-0.46918898675233517,success
Box_Position: [[1.48598983 0.59607366 0.52650854]]
actor_loss: tensor(0.2028, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2500, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2029, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2211, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-142.31621875841603, average reward:-0.7115810937920801,----
Box_Position: [[1.49104358 0.65199139 0.48723312]]
actor_loss: tensor(0.2580, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2707, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-104.83732123514669, average reward:-0.723016008518253,success
Box_Position: [[1.30883014 0.89446799 0.5619847 ]]
actor_loss: tensor(0.2287, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-16.18425144810926, average reward:-0.4374122013002503,success
Box_Position: [[1.31447424 0.99122782 0.73820729]]
actor_loss: tensor(0.2305, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-22.306554081054028, average reward:-0.37177590135090044,success
Box_Position: [[1.25926742 0.75350458 0.60008606]]
actor_loss: tensor(0.2663, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2183, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-35.660991722409165, average reward:-0.40523854230010414,success
Box_Position: [[1.27129614 0.61228697 0.69466554]]
Step:17, total reward:-6.3451802448545465, average reward:-0.3732458967561498,success
Box_Position: [[1.29132882 0.80407356 0.73264943]]
Step:28, total reward:-6.181598083411576, average reward:-0.22077136012184198,success
Box_Position: [[1.48220272 0.83089337 0.70390651]]
actor_loss: tensor(0.2108, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-24.436111808123346, average reward:-0.49869615934945605,success
Box_Position: [[1.28713623 0.81290854 0.70159135]]
actor_loss: tensor(0.1984, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-4.487183912649812, average reward:-0.34516799328075476,success
Box_Position: [[1.27610771 0.74837368 0.71737119]]
Step:1, total reward:-0.03704909390278779, average reward:-0.03704909390278779,success
Box_Position: [[1.32719719 0.94712989 0.59732333]]
Step:6, total reward:-1.1872226473532057, average reward:-0.1978704412255343,success
Box_Position: [[1.50250305 0.85994137 0.5384943 ]]
actor_loss: tensor(0.2137, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1895, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2442, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2126, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-118.49761200396729, average reward:-0.5924880600198364,----
Box_Position: [[1.41670318 1.02088216 0.45907854]]
actor_loss: tensor(0.2151, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2169, device='cuda:0', grad_fn=<NegBackward>)
Step:175, total reward:-150.8031001775383, average reward:-0.8617320010145046,success
Box_Position: [[1.36738041 1.09283327 0.47565351]]
actor_loss: tensor(0.2231, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-52.18160981544397, average reward:-1.023168819910666,success
Box_Position: [[1.45440651 0.77798984 0.60022126]]
actor_loss: tensor(0.2224, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1911, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1405, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2098, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-101.6096843390887, average reward:-0.5080484216954435,----
Box_Position: [[1.30796537 0.81611296 0.62681041]]
actor_loss: tensor(0.2048, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-8.342979133558018, average reward:-0.39728472064561987,success
Box_Position: [[1.4907813  0.60835442 0.55036803]]
actor_loss: tensor(0.1646, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1811, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1957, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1858, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-112.73244129063822, average reward:-0.5636622064531911,----
Box_Position: [[1.42962183 0.62127468 0.53733766]]
actor_loss: tensor(0.1604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1761, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1690, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-116.12850750699009, average reward:-0.5806425375349504,----
Box_Position: [[1.30794322 0.89730851 0.52501658]]
actor_loss: tensor(0.1470, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1700, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-66.60541805848247, average reward:-0.7085682772178986,success
Box_Position: [[1.36184957 0.46574269 0.69089522]]
actor_loss: tensor(0.1657, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1362, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2255, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1563, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-85.11309998762978, average reward:-0.4255654999381489,----
Box_Position: [[1.27772357 0.76104565 0.60985298]]
Step:9, total reward:-5.461840734187324, average reward:-0.6068711926874805,success
Box_Position: [[1.47206798 0.81957495 0.64855119]]
actor_loss: tensor(0.1606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1898, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1458, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1450, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-80.54177618151567, average reward:-0.40270888090757834,----
Box_Position: [[1.49111832 0.75505979 0.68231084]]
actor_loss: tensor(0.1549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2031, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1451, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1585, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-88.71992949209391, average reward:-0.44359964746046954,----
Box_Position: [[1.42452105 0.79839705 0.64062159]]
actor_loss: tensor(0.1420, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1043, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2339, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1853, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-78.18310396346874, average reward:-0.3909155198173437,----
Box_Position: [[1.5104396  0.98811132 0.5966817 ]]

------------------Episode:1350------------------
actor_loss: tensor(0.1089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1260, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0927, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1097, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-127.25904323166272, average reward:-0.6362952161583135,----
Box_Position: [[1.50797503 0.71044821 0.56823964]]
actor_loss: tensor(0.1158, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1490, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1241, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-129.1028610345914, average reward:-0.645514305172957,----
Box_Position: [[1.39994034 1.07792659 0.69422817]]
actor_loss: tensor(0.1199, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0957, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0992, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1081, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-89.79531477179874, average reward:-0.4489765738589937,----
Box_Position: [[1.49485939 0.97414851 0.63364439]]
actor_loss: tensor(0.1551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1402, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1554, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-90.32462572070985, average reward:-0.49089470500385785,success
Box_Position: [[1.54037078 1.02960403 0.57185694]]
actor_loss: tensor(0.1166, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1229, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1463, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1153, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.94611264379074, average reward:-0.7397305632189537,----
Box_Position: [[1.45380399 1.01543958 0.65722671]]
actor_loss: tensor(0.1228, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-28.103341970694455, average reward:-0.4194528652342456,success
Box_Position: [[1.33386325 0.82006438 0.72897476]]
Step:19, total reward:-6.3411974602811005, average reward:-0.33374723475163687,success
Box_Position: [[1.27378417 0.76161569 0.6425155 ]]
Step:11, total reward:-4.801998366934662, average reward:-0.43654530608496933,success
Box_Position: [[1.30998869 0.87938247 0.72176289]]
actor_loss: tensor(0.1492, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-6.579869328372731, average reward:-0.23499533315616897,success
Box_Position: [[1.28671923 0.52943696 0.70393346]]
actor_loss: tensor(0.1259, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1321, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-44.59389034073204, average reward:-0.37791432492145793,success
Box_Position: [[1.47587793 0.77186362 0.55825481]]
actor_loss: tensor(0.1218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1561, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1109, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.1156498617068, average reward:-0.570578249308534,----
Box_Position: [[1.39125783 0.796036   0.72800693]]
actor_loss: tensor(0.0825, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-11.806079345261502, average reward:-0.30271998321183335,success
Box_Position: [[1.49674764 0.93372797 0.6029179 ]]
actor_loss: tensor(0.0794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1316, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1969, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1440, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-119.05016218576363, average reward:-0.5952508109288182,----
Box_Position: [[1.36202825 0.67641271 0.62724053]]
actor_loss: tensor(0.1480, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-13.192179558545822, average reward:-0.42555417930792977,success
Box_Position: [[1.39903793 0.80117027 0.55007655]]
actor_loss: tensor(0.1599, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1716, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1184, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-102.54686384150986, average reward:-0.5127343192075493,----
Box_Position: [[1.32875691 0.84131567 0.55835949]]
Step:22, total reward:-12.546165204340065, average reward:-0.5702802365609121,success
Box_Position: [[1.35559657 0.57154165 0.72266928]]
actor_loss: tensor(0.1747, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1950, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1615, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1316, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-73.82431137076371, average reward:-0.4147433223076613,success
Box_Position: [[1.29410374 0.82366685 0.73490088]]
actor_loss: tensor(0.1409, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-7.539350172867966, average reward:-0.18848375432169914,success
Box_Position: [[1.30984277 0.72819474 0.66998332]]
Step:19, total reward:-7.692836513110837, average reward:-0.40488613226899145,success
Box_Position: [[1.44905439 0.97898949 0.4521915 ]]
actor_loss: tensor(0.1869, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2230, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2254, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-146.521457921489, average reward:-0.9703407809370133,success
Box_Position: [[1.32263256 0.88810366 0.54591175]]
actor_loss: tensor(0.1377, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-19.99229886231796, average reward:-0.6664099620772653,success
Box_Position: [[1.3173886  0.95343137 0.55731322]]
Step:2, total reward:-0.23456488025461625, average reward:-0.11728244012730812,success
Box_Position: [[1.38561815 0.91420115 0.52058965]]
Step:5, total reward:-2.8916370101998186, average reward:-0.5783274020399637,success
Box_Position: [[1.40236789 1.00680587 0.72228915]]
actor_loss: tensor(0.1759, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1726, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-50.66309295725283, average reward:-0.25331546478626416,----
Box_Position: [[1.41957301 0.71229635 0.6391691 ]]
actor_loss: tensor(0.2062, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1921, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1930, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-91.1703358684681, average reward:-0.4558516793423405,----
Box_Position: [[1.36289032 0.55799392 0.69290144]]
Step:17, total reward:-6.338537298269077, average reward:-0.3728551351922986,success
Box_Position: [[1.3704257  0.45831709 0.59656042]]
actor_loss: tensor(0.1973, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1808, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1864, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2016, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-91.66053142293256, average reward:-0.45830265711466284,----
Box_Position: [[1.34950114 0.66231809 0.74302045]]
actor_loss: tensor(0.2050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2144, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-37.64269242197659, average reward:-0.495298584499692,success
Box_Position: [[1.39891706 0.93532616 0.62039809]]
actor_loss: tensor(0.2202, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1839, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1719, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2491, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-95.82122189969482, average reward:-0.4791061094984741,----
Box_Position: [[1.27817069 0.94078383 0.67497028]]
actor_loss: tensor(0.2283, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-18.119537422305523, average reward:-0.30199229037175873,success
Box_Position: [[1.50758855 0.57177607 0.45828802]]
Step:26, total reward:-18.594901815809916, average reward:-0.7151885313773044,success
Box_Position: [[1.48110306 0.6060582  0.51734432]]
actor_loss: tensor(0.2271, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1999, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2120, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2501, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-157.9074093333099, average reward:-0.7895370466665494,----
Box_Position: [[1.27657722 0.65964193 0.61133925]]
Step:5, total reward:-0.7848071480617438, average reward:-0.15696142961234877,success
Box_Position: [[1.3279112  0.97467014 0.49148318]]
actor_loss: tensor(0.2295, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2206, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-67.12332570267313, average reward:-0.9194976123653853,success
Box_Position: [[1.42360305 1.12167853 0.4769225 ]]
actor_loss: tensor(0.2012, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-50.79585645937306, average reward:-0.8911553764802291,success
Box_Position: [[1.26840437 0.73681871 0.66001684]]
actor_loss: tensor(0.2754, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-11.285663232865954, average reward:-0.43406397049484435,success
Box_Position: [[1.33047196 0.94067635 0.69111664]]
Step:8, total reward:-3.4914523000052307, average reward:-0.43643153750065383,success
Box_Position: [[1.27847755 1.03398988 0.69959456]]
actor_loss: tensor(0.2612, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-13.184723957667774, average reward:-0.32157863311384816,success
Box_Position: [[1.46424089 0.79502549 0.70495495]]
actor_loss: tensor(0.2374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2224, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2137, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2281, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-83.05722509552166, average reward:-0.4152861254776083,----
Box_Position: [[1.3153468  0.87709689 0.72274729]]
actor_loss: tensor(0.2234, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-21.966320692478845, average reward:-0.3379433952689053,success
Box_Position: [[1.3179026  0.70048626 0.47800423]]
actor_loss: tensor(0.2211, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2484, device='cuda:0', grad_fn=<NegBackward>)
Step:165, total reward:-123.69946996452379, average reward:-0.7496937573607502,success
Box_Position: [[1.30316297 0.81124648 0.57168027]]
actor_loss: tensor(0.2575, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-31.201203746057974, average reward:-0.6240240749211595,success
Box_Position: [[1.43273458 1.02890808 0.72148856]]
actor_loss: tensor(0.2426, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-11.541244010158621, average reward:-0.320590111393295,success
Box_Position: [[1.37835087 1.16837824 0.46191828]]
actor_loss: tensor(0.2057, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-31.681738493027208, average reward:-0.7727253290982246,success
Box_Position: [[1.38782448 0.70203732 0.59553693]]
actor_loss: tensor(0.2810, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-37.331342768439555, average reward:-0.4786069585697379,success
Box_Position: [[1.54850135 0.99771826 0.48822917]]
actor_loss: tensor(0.2595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2071, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2601, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-160.40887870323755, average reward:-0.8020443935161877,----
Box_Position: [[1.54665049 1.00407753 0.57108535]]
actor_loss: tensor(0.3130, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2015, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2647, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2193, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-118.4438290783551, average reward:-0.5922191453917754,----
Box_Position: [[1.34468372 0.77299372 0.71707851]]
actor_loss: tensor(0.2298, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-25.0234647779798, average reward:-0.56871510859045,success
Box_Position: [[1.26501979 0.88381729 0.62156163]]
actor_loss: tensor(0.2523, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-18.137463202558386, average reward:-0.6254297656054616,success
Box_Position: [[1.40407708 1.01159079 0.58716184]]
Step:7, total reward:-1.5155282617196795, average reward:-0.21650403738852564,success
Box_Position: [[1.25744168 0.9565847  0.45583822]]

------------------Episode:1400------------------
Step:16, total reward:-6.782013691933477, average reward:-0.4238758557458423,success
episode 1400, the accuracy is: 67%
Box_Position: [[1.25377773 0.64945233 0.59756315]]
actor_loss: tensor(0.2294, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2271, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-50.79908212027807, average reward:-0.4417311488719832,success
Box_Position: [[1.34732031 0.84715439 0.5735096 ]]
actor_loss: tensor(0.2541, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-5.222398028568334, average reward:-0.32639987678552085,success
Box_Position: [[1.28528948 0.62235858 0.58714988]]
Step:27, total reward:-13.736166733873823, average reward:-0.5087469160694008,success
Box_Position: [[1.28801544 0.59833503 0.52738617]]
actor_loss: tensor(0.2560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2209, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-138.6226665258457, average reward:-0.721993054822113,success
Box_Position: [[1.34390095 0.76217162 0.59686491]]
Step:7, total reward:-1.8639052029880785, average reward:-0.2662721718554398,success
Box_Position: [[1.34769284 0.54021437 0.70688779]]
actor_loss: tensor(0.2620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2276, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-27.14474047725005, average reward:-0.3668208172601358,success
Box_Position: [[1.34099566 0.82835364 0.56735774]]
actor_loss: tensor(0.2233, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-27.373881799823184, average reward:-0.5824230170175145,success
Box_Position: [[1.50611951 0.77952311 0.56885956]]
Step:12, total reward:-8.118067420365104, average reward:-0.6765056183637587,success
Box_Position: [[1.39940611 0.73612329 0.57344075]]
actor_loss: tensor(0.2452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2462, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-58.16626407669435, average reward:-0.6609802735987994,success
Box_Position: [[1.41503625 0.50988264 0.49260545]]
actor_loss: tensor(0.2834, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2866, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2336, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-153.01019073726354, average reward:-0.7650509536863177,----
Box_Position: [[1.51570745 0.67000977 0.66424691]]
Step:18, total reward:-9.53904327366474, average reward:-0.52994684853693,success
Box_Position: [[1.27714932 0.67914634 0.48097338]]
Step:20, total reward:-9.33865476190668, average reward:-0.466932738095334,success
Box_Position: [[1.28199273 0.67736971 0.58477483]]
actor_loss: tensor(0.2679, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2286, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2569, device='cuda:0', grad_fn=<NegBackward>)
Step:150, total reward:-89.15032016667674, average reward:-0.5943354677778449,success
Box_Position: [[1.52134269 0.58592373 0.49532354]]
actor_loss: tensor(0.2329, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2362, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2488, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-154.31817516160805, average reward:-0.8037404956333752,success
Box_Position: [[1.2918866  0.79072672 0.62079333]]
actor_loss: tensor(0.2552, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2527, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2153, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2584, device='cuda:0', grad_fn=<NegBackward>)
Step:180, total reward:-94.76940260741816, average reward:-0.5264966811523231,success
Box_Position: [[1.50001608 0.98683609 0.62019896]]
actor_loss: tensor(0.2411, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-18.405824576939374, average reward:-0.4489225506570579,success
Box_Position: [[1.53041755 0.98487912 0.50204102]]
actor_loss: tensor(0.2098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2186, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-109.20922189195996, average reward:-0.8149941932235818,success
Box_Position: [[1.348893   0.68729937 0.56536138]]
actor_loss: tensor(0.2464, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-14.456227243159043, average reward:-0.49849059459169115,success
Box_Position: [[1.25244572 0.87231568 0.74996123]]
Step:20, total reward:-4.245809896206063, average reward:-0.21229049481030313,success
Box_Position: [[1.36785516 0.64298903 0.58895273]]
actor_loss: tensor(0.2399, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-8.140713166833981, average reward:-0.9045236852037757,success
Box_Position: [[1.28013479 0.56296114 0.58162532]]
actor_loss: tensor(0.2652, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2364, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2086, device='cuda:0', grad_fn=<NegBackward>)
Step:160, total reward:-90.74306313932921, average reward:-0.5671441446208075,success
Box_Position: [[1.49633204 0.90298956 0.64203639]]
actor_loss: tensor(0.2295, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2397, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-53.261032274508366, average reward:-0.5326103227450837,success
Box_Position: [[1.34152098 0.70498494 0.62907433]]
Step:8, total reward:-3.602812128853639, average reward:-0.4503515161067049,success
Box_Position: [[1.35173549 1.03912628 0.52030688]]
Step:23, total reward:-26.271579425148314, average reward:-1.1422425837021006,success
Box_Position: [[1.41889532 0.64284169 0.62130943]]
actor_loss: tensor(0.2547, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-6.682871033919193, average reward:-0.5140670026091687,success
Box_Position: [[1.3777469  0.93798923 0.72746197]]
Step:36, total reward:-10.124462814427227, average reward:-0.2812350781785341,success
Box_Position: [[1.54559146 1.15029708 0.69279724]]
actor_loss: tensor(0.2641, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-9.806291041257387, average reward:-0.39225164165029547,success
Box_Position: [[1.52840135 0.52168217 0.67397304]]
Step:5, total reward:-1.3584359800305008, average reward:-0.27168719600610014,success
Box_Position: [[1.36220815 0.67147583 0.51794909]]
actor_loss: tensor(0.2495, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2590, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-48.1159014254836, average reward:-0.5594872258777163,success
Box_Position: [[1.26572815 0.50046685 0.50591525]]
actor_loss: tensor(0.2541, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2587, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-73.26607722071415, average reward:-0.5861286177657132,success
Box_Position: [[1.39995711 1.00593749 0.73564472]]
actor_loss: tensor(0.2672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2895, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2558, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-60.89632165968455, average reward:-0.3205069561036029,success
Box_Position: [[1.4911832  0.57131411 0.56613564]]
actor_loss: tensor(0.2650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2742, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2604, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-107.15915012900577, average reward:-0.5357957506450288,----
Box_Position: [[1.48044273 0.91908372 0.50848904]]
actor_loss: tensor(0.2690, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-14.012376034488295, average reward:-0.5389375397880113,success
Box_Position: [[1.31722166 0.82084216 0.55406983]]
actor_loss: tensor(0.2423, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-23.51100963270344, average reward:-0.41983945772684717,success
Box_Position: [[1.38503945 0.74150123 0.54609697]]
Step:40, total reward:-27.491658125383893, average reward:-0.6872914531345973,success
Box_Position: [[1.2883354  0.78911944 0.4645507 ]]
actor_loss: tensor(0.2684, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-31.624527079694456, average reward:-0.7529649304689157,success
Box_Position: [[1.49090843 0.7245585  0.46671677]]
actor_loss: tensor(0.2496, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-10.734227571978636, average reward:-0.6708892232486647,success
Box_Position: [[1.53586957 0.69042764 0.61650049]]
Step:26, total reward:-12.903096722420887, average reward:-0.4962729508623418,success
Box_Position: [[1.26208961 0.82063903 0.61999222]]
Step:9, total reward:-3.6160223014991253, average reward:-0.40178025572212506,success
Box_Position: [[1.47703524 0.99608108 0.74380718]]
actor_loss: tensor(0.2933, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2800, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-20.587649665625467, average reward:-0.3320588655746043,success
Box_Position: [[1.49938892 0.73230008 0.53814363]]
Step:17, total reward:-13.70779915560123, average reward:-0.8063411268000723,success
Box_Position: [[1.28650387 0.95573079 0.56627447]]
actor_loss: tensor(0.2885, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-51.91438830593715, average reward:-0.692191844079162,success
Box_Position: [[1.28718319 0.95314903 0.47242218]]
actor_loss: tensor(0.2694, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-17.088413566052996, average reward:-0.6835365426421198,success
Box_Position: [[1.25563268 0.56495787 0.46743916]]
actor_loss: tensor(0.2633, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2928, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-77.61939409657768, average reward:-0.616026937274426,success
Box_Position: [[1.31025894 0.9484757  0.50493033]]
actor_loss: tensor(0.2401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2287, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-61.24611360933978, average reward:-0.7752672608777187,success
Box_Position: [[1.47471866 0.99315647 0.62307358]]
Step:22, total reward:-4.527094853309312, average reward:-0.2057770387867869,success
Box_Position: [[1.37408309 0.68872823 0.535362  ]]
actor_loss: tensor(0.2760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2610, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2796, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2680, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-107.57161678626902, average reward:-0.537858083931345,----
Box_Position: [[1.50613251 0.82757778 0.66844314]]
actor_loss: tensor(0.2227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2848, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2848, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-75.40801738724618, average reward:-0.37704008693623087,----
Box_Position: [[1.50723261 0.84283743 0.6504037 ]]
actor_loss: tensor(0.2691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2365, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2827, device='cuda:0', grad_fn=<NegBackward>)
Step:148, total reward:-52.39367866898153, average reward:-0.3540113423579833,success
Box_Position: [[1.35935419 0.88127586 0.68947043]]

------------------Episode:1450------------------
actor_loss: tensor(0.2503, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2602, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-21.15644921030653, average reward:-0.37116577561941283,success
Box_Position: [[1.48224502 0.60416109 0.74171543]]
actor_loss: tensor(0.2407, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2723, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2327, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2727, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-61.29162496678349, average reward:-0.30645812483391743,----
Box_Position: [[1.49772961 0.73960418 0.71821406]]
actor_loss: tensor(0.2379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2980, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2266, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2416, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.11018109532678, average reward:-0.3405509054766339,----
Box_Position: [[1.49462391 0.74584709 0.56685504]]
actor_loss: tensor(0.2609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2941, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2573, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2827, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.63473506885187, average reward:-0.5331736753442593,----
Box_Position: [[1.52169101 0.60946159 0.45516455]]
actor_loss: tensor(0.2605, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2584, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2562, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2872, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-192.11346734137365, average reward:-0.9605673367068682,----
Box_Position: [[1.50576988 0.59829773 0.65562917]]
actor_loss: tensor(0.2428, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2631, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2895, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-63.64993608723305, average reward:-0.31824968043616525,----
Box_Position: [[1.42897575 0.9557267  0.59631731]]
Step:29, total reward:-6.885961869101754, average reward:-0.23744696100350876,success
Box_Position: [[1.44642985 0.93854806 0.45056325]]
Step:5, total reward:-3.2054194165468863, average reward:-0.6410838833093773,success
Box_Position: [[1.40293604 0.8272052  0.68298325]]
actor_loss: tensor(0.2566, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-5.617783425853252, average reward:-0.2247113370341301,success
Box_Position: [[1.3341406  0.90496699 0.63160581]]
actor_loss: tensor(0.2183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3175, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-34.343065022199944, average reward:-0.3150739910293573,success
Box_Position: [[1.46854444 0.60831503 0.46609075]]
actor_loss: tensor(0.2616, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-34.020774964828426, average reward:-0.7395820644527918,success
Box_Position: [[1.46686485 1.1083488  0.52124674]]
actor_loss: tensor(0.2255, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2452, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-100.33111483783522, average reward:-1.0451157795607835,success
Box_Position: [[1.54161673 0.97057632 0.57293944]]
Step:3, total reward:-0.5039888918068499, average reward:-0.16799629726894996,success
Box_Position: [[1.51638654 0.81011789 0.4525803 ]]
Step:17, total reward:-12.986514828205323, average reward:-0.7639126369532543,success
Box_Position: [[1.4976951  0.70557538 0.5309543 ]]
actor_loss: tensor(0.1966, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-38.17630509419648, average reward:-0.658212156796491,success
Box_Position: [[1.54738133 0.83836401 0.56023448]]
Step:11, total reward:-10.30225270807857, average reward:-0.9365684280071427,success
Box_Position: [[1.52863551 1.01270961 0.6135673 ]]
actor_loss: tensor(0.2381, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-16.813492280191763, average reward:-0.5604497426730588,success
Box_Position: [[1.29029033 0.85722992 0.46194112]]
Step:20, total reward:-18.135848473477175, average reward:-0.9067924236738587,success
Box_Position: [[1.53032949 0.72861063 0.5626774 ]]
actor_loss: tensor(0.2390, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2271, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2520, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2421, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-131.52247292194716, average reward:-0.6576123646097358,----
Box_Position: [[1.42045568 0.77803322 0.57912379]]
actor_loss: tensor(0.2826, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2766, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2487, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-96.33065637645342, average reward:-0.4816532818822671,----
Box_Position: [[1.31258024 0.61817021 0.49641839]]
actor_loss: tensor(0.2315, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2504, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1921, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2310, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-118.68643214077328, average reward:-0.6450349572868113,success
Box_Position: [[1.38747966 0.70231218 0.46088971]]
actor_loss: tensor(0.2149, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2409, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2314, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2262, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-145.47885638830408, average reward:-0.7273942819415204,----
Box_Position: [[1.48146164 0.51533989 0.56712335]]
actor_loss: tensor(0.2374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2521, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2714, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.57583704133611, average reward:-0.5728791852066806,----
Box_Position: [[1.51578593 0.58734383 0.58510799]]
actor_loss: tensor(0.2514, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2447, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2468, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2429, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-117.96229218281859, average reward:-0.589811460914093,----
Box_Position: [[1.4130063  0.55272323 0.62887949]]
actor_loss: tensor(0.2888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2371, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-92.58260071529843, average reward:-0.4629130035764921,----
Box_Position: [[1.27193338 0.64680224 0.69999066]]
Step:15, total reward:-7.264455837862052, average reward:-0.4842970558574701,success
Box_Position: [[1.43623181 0.62840825 0.54360783]]
actor_loss: tensor(0.2239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2116, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-119.56612885091512, average reward:-0.5978306442545755,----
Box_Position: [[1.41479215 0.71820328 0.70576495]]
actor_loss: tensor(0.1875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2013, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2131, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-61.49034312995244, average reward:-0.3074517156497622,----
Box_Position: [[1.41334949 0.80144677 0.74600485]]
actor_loss: tensor(0.2311, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2139, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2060, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-30.27755579837837, average reward:-0.2703353196283783,success
Box_Position: [[1.29954374 0.60665177 0.52991681]]
Step:8, total reward:-3.7596134126208525, average reward:-0.46995167657760656,success
Box_Position: [[1.49992383 1.00987941 0.58835962]]
Step:31, total reward:-17.056108761256148, average reward:-0.5501970568147144,success
Box_Position: [[1.47883093 0.65871326 0.52217148]]
actor_loss: tensor(0.2158, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2389, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2384, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-147.14515369436867, average reward:-0.7357257684718433,----
Box_Position: [[1.34496124 0.66052971 0.74186663]]
actor_loss: tensor(0.2344, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2325, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-19.63657289679115, average reward:-0.35065308744269913,success
Box_Position: [[1.40513706 0.85759514 0.64730772]]
Step:20, total reward:-4.737361198474531, average reward:-0.23686805992372656,success
Box_Position: [[1.28841092 1.0309425  0.58601526]]
Step:15, total reward:-6.746686728834985, average reward:-0.44977911525566566,success
Box_Position: [[1.40143105 0.86414234 0.68740536]]
actor_loss: tensor(0.2410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1874, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1913, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-71.75515952306056, average reward:-0.3899736930601117,success
Box_Position: [[1.48554289 0.70900577 0.49402345]]
actor_loss: tensor(0.2025, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2031, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2112, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-159.91366339347596, average reward:-0.7995683169673797,----
Box_Position: [[1.28221184 1.07274592 0.57520836]]
actor_loss: tensor(0.1917, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-17.05758867034357, average reward:-0.6560611027055219,success
Box_Position: [[1.45783001 0.6003716  0.66620097]]
actor_loss: tensor(0.1444, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1857, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1996, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2068, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-76.11874184479892, average reward:-0.3805937092239946,----
Box_Position: [[1.44252398 0.907217   0.53892565]]
actor_loss: tensor(0.1445, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-59.25538413294221, average reward:-0.6971221662699084,success
Box_Position: [[1.28535927 0.78257313 0.61141377]]
actor_loss: tensor(0.1883, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1383, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1405, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1415, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-112.7369400730433, average reward:-0.5636847003652165,----
Box_Position: [[1.50274092 1.0255162  0.53377596]]
actor_loss: tensor(0.1823, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1411, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1709, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-143.03899464362755, average reward:-0.7773858404544975,success
Box_Position: [[1.30485721 0.670876   0.64102384]]
actor_loss: tensor(0.1586, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1386, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-40.528070834834566, average reward:-0.47125663761435543,success
Box_Position: [[1.25765851 1.00475914 0.60897153]]
actor_loss: tensor(0.1401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0719, device='cuda:0', grad_fn=<NegBackward>)
Step:133, total reward:-78.95988512174809, average reward:-0.5936833467800608,success
Box_Position: [[1.46745851 0.73918747 0.63321818]]
actor_loss: tensor(0.0667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0808, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1142, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0956, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-139.1135194712998, average reward:-0.6955675973564991,----
Box_Position: [[1.3345544  0.62231307 0.63573168]]
actor_loss: tensor(0.1239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1317, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-154.07273728762556, average reward:-0.7703636864381278,----
Box_Position: [[1.37489274 0.65233569 0.61703589]]
actor_loss: tensor(0.1409, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0877, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1160, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-152.1025514734478, average reward:-0.760512757367239,----
Box_Position: [[1.45036814 0.6430936  0.49127566]]
actor_loss: tensor(0.1445, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1613, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1418, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-207.91655702710676, average reward:-1.0395827851355337,----
Box_Position: [[1.25987965 0.62111451 0.56468617]]
Step:5, total reward:-0.6132798903736746, average reward:-0.12265597807473491,success
Box_Position: [[1.2691959  0.50535144 0.53442097]]
actor_loss: tensor(0.1497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1548, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-69.80891444348835, average reward:-0.8726114305436043,success
Box_Position: [[1.31785931 0.51231922 0.64582947]]

------------------Episode:1500------------------
Step:5, total reward:-2.8870189396307295, average reward:-0.5774037879261459,success
episode 1500, the accuracy is: 75%
Box_Position: [[1.46430067 1.08858985 0.66274533]]
actor_loss: tensor(0.1757, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1795, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1919, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-73.62259628954958, average reward:-0.3681129814477479,----
Box_Position: [[1.31571817 0.5405674  0.67870909]]
actor_loss: tensor(0.1762, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1635, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-34.16647556265967, average reward:-0.46803391181725573,success
Box_Position: [[1.33750979 0.62901955 0.45939669]]
actor_loss: tensor(0.2139, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2198, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-96.66452014306265, average reward:-0.8868304600280976,success
Box_Position: [[1.37546497 0.92395017 0.72197866]]
actor_loss: tensor(0.2000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1584, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1664, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-107.23885911232122, average reward:-0.5361942955616061,----
Box_Position: [[1.41589505 0.99206535 0.58016015]]
actor_loss: tensor(0.2052, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2074, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-81.47575089053753, average reward:-0.7614556157994161,success
Box_Position: [[1.46890365 1.00710353 0.73897609]]
Step:5, total reward:-1.0930463649683917, average reward:-0.21860927299367833,success
Box_Position: [[1.40073324 0.67672298 0.62148763]]
actor_loss: tensor(0.2153, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-48.12812838016799, average reward:-0.6778609631009577,success
Box_Position: [[1.29991155 0.93037877 0.46834933]]
actor_loss: tensor(0.1769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1951, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-46.25737331620688, average reward:-0.6904085569583116,success
Box_Position: [[1.29316959 0.61048008 0.56914253]]
Step:15, total reward:-11.53064041534398, average reward:-0.768709361022932,success
Box_Position: [[1.31305306 0.49232404 0.67529128]]
actor_loss: tensor(0.1952, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2145, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-104.82263989755353, average reward:-0.9036434473927029,success
Box_Position: [[1.47717966 0.9720798  0.50810994]]
actor_loss: tensor(0.2375, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2268, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-85.58858795580626, average reward:-0.8915477912063152,success
Box_Position: [[1.48158331 0.60257772 0.56539967]]
actor_loss: tensor(0.2287, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2259, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2580, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-85.75111066915572, average reward:-0.6545886310622574,success
Box_Position: [[1.41054348 0.92897144 0.56765138]]
actor_loss: tensor(0.2594, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-29.199727047964906, average reward:-0.6790634197201141,success
Box_Position: [[1.31667371 0.70766808 0.64016686]]
actor_loss: tensor(0.2488, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-28.780577969674585, average reward:-0.5756115593934917,success
Box_Position: [[1.46032139 0.68229421 0.48605913]]
actor_loss: tensor(0.2296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1878, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2748, device='cuda:0', grad_fn=<NegBackward>)
Step:165, total reward:-135.7388269284499, average reward:-0.8226595571421206,success
Box_Position: [[1.32157582 0.85342766 0.48463271]]
Step:18, total reward:-15.379065087325253, average reward:-0.854392504851403,success
Box_Position: [[1.33285239 0.77574731 0.51426959]]
actor_loss: tensor(0.2251, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-14.441187802263642, average reward:-0.65641762737562,success
Box_Position: [[1.42384766 1.00956164 0.63119637]]
actor_loss: tensor(0.2501, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2259, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-53.296974219384104, average reward:-0.4934905020313343,success
Box_Position: [[1.26470366 1.09395707 0.67673537]]
actor_loss: tensor(0.2555, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2462, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-76.45370170275847, average reward:-0.38226850851379235,----
Box_Position: [[1.26217135 0.95249179 0.73094178]]
actor_loss: tensor(0.2726, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2738, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-32.72990124404457, average reward:-0.3991451371224948,success
Box_Position: [[1.39149908 0.9176718  0.57352976]]
actor_loss: tensor(0.2868, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-50.12935081861923, average reward:-0.7060471946284399,success
Box_Position: [[1.41530552 0.83335619 0.51986517]]
actor_loss: tensor(0.2901, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2708, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2962, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-103.77908267517219, average reward:-0.6965039105716254,success
Box_Position: [[1.47577267 0.62020964 0.6075476 ]]
actor_loss: tensor(0.2962, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-27.880079477821162, average reward:-0.633638169950481,success
Box_Position: [[1.4900819  0.70997383 0.54558068]]
actor_loss: tensor(0.3005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2833, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3129, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2648, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-125.81253888629679, average reward:-0.629062694431484,----
Box_Position: [[1.43464537 0.73406238 0.72267965]]
actor_loss: tensor(0.3090, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2961, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-62.047082766314105, average reward:-0.31023541383157055,----
Box_Position: [[1.48277963 0.81961768 0.58441561]]
actor_loss: tensor(0.3180, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-36.73082756391751, average reward:-0.7984962513895111,success
Box_Position: [[1.31009975 0.85209744 0.60023063]]
actor_loss: tensor(0.3112, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-15.396261723155275, average reward:-0.3421391494034506,success
Box_Position: [[1.42266543 0.91638717 0.66760464]]
Step:4, total reward:-0.8633225462797384, average reward:-0.2158306365699346,success
Box_Position: [[1.51700787 0.79594962 0.56562003]]
actor_loss: tensor(0.2976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3241, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3169, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3153, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.74308215379585, average reward:-0.5587154107689792,----
Box_Position: [[1.37785389 1.06076863 0.51400148]]
actor_loss: tensor(0.3097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3113, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-74.49536598098562, average reward:-0.5912330633411558,success
Box_Position: [[1.29343474 1.06999404 0.56798574]]
actor_loss: tensor(0.2937, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-11.013667020169796, average reward:-0.28240171846589224,success
Box_Position: [[1.36465388 0.86291878 0.56100751]]
actor_loss: tensor(0.3116, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-20.780630873672447, average reward:-0.9895538511272594,success
Box_Position: [[1.359835   1.05924891 0.52429376]]
actor_loss: tensor(0.3392, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-43.117112417192644, average reward:-0.6435389913013827,success
Box_Position: [[1.35973176 0.99066498 0.49505389]]
Step:4, total reward:-0.8459767700461083, average reward:-0.21149419251152707,success
Box_Position: [[1.45884306 0.6669623  0.65272727]]
Step:22, total reward:-9.244011251636836, average reward:-0.4201823296198562,success
Box_Position: [[1.468098   0.87693456 0.55413929]]
actor_loss: tensor(0.3202, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3046, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2881, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-129.01137608459092, average reward:-0.6450568804229546,----
Box_Position: [[1.40035861 0.78619002 0.52379975]]
actor_loss: tensor(0.3027, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2841, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2912, device='cuda:0', grad_fn=<NegBackward>)
Step:166, total reward:-111.81278495218741, average reward:-0.673570993687876,success
Box_Position: [[1.32993875 0.90848638 0.66934783]]
Step:7, total reward:-1.4445133600011055, average reward:-0.20635905142872937,success
Box_Position: [[1.48061708 0.93982864 0.58725155]]
Step:19, total reward:-7.997121356165279, average reward:-0.4209011240086989,success
Box_Position: [[1.28771281 0.6879101  0.62615155]]
actor_loss: tensor(0.3099, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3203, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2726, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.80666575635023, average reward:-0.5590333287817512,----
Box_Position: [[1.35777402 0.97008585 0.58322015]]
actor_loss: tensor(0.3222, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-10.778058109766524, average reward:-0.3170017091107801,success
Box_Position: [[1.42397716 0.41464396 0.71920843]]
actor_loss: tensor(0.3218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2802, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2577, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-82.08516775290508, average reward:-0.4104258387645254,----
Box_Position: [[1.54734754 0.93635153 0.56068505]]
actor_loss: tensor(0.2873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2842, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2813, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2689, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.47724286616224, average reward:-0.5573862143308113,----
Box_Position: [[1.26982578 0.93549168 0.60471892]]
Step:3, total reward:-0.5451026229932298, average reward:-0.1817008743310766,success
Box_Position: [[1.52941614 0.47459492 0.67439861]]
actor_loss: tensor(0.3257, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2422, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2761, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-79.92169123874922, average reward:-0.3996084561937461,----
Box_Position: [[1.38341403 0.70686823 0.58929048]]
actor_loss: tensor(0.2762, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3110, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-64.77824806194674, average reward:-0.5021569617205174,success
Box_Position: [[1.41688308 0.76319394 0.67023484]]
Step:22, total reward:-9.480058788940664, average reward:-0.4309117631336665,success
Box_Position: [[1.2519264  1.05578609 0.6295462 ]]
actor_loss: tensor(0.2700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3210, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-29.089206763242185, average reward:-0.3232134084804687,success
Box_Position: [[1.50049475 0.84663308 0.62614015]]
actor_loss: tensor(0.2984, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-21.054023604283444, average reward:-0.3568478576997194,success
Box_Position: [[1.30442583 0.66472283 0.74368204]]

------------------Episode:1550------------------
actor_loss: tensor(0.2782, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-7.565920540553926, average reward:-0.26089381174323883,success
Box_Position: [[1.54804512 0.74814318 0.7194637 ]]
actor_loss: tensor(0.2810, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2391, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2791, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3049, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-65.5481483031797, average reward:-0.3277407415158985,----
Box_Position: [[1.43774877 0.52393466 0.46330628]]
actor_loss: tensor(0.2722, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2931, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2904, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-172.36294720147743, average reward:-0.8618147360073871,----
Box_Position: [[1.48748655 1.16411851 0.64261384]]
Step:14, total reward:-8.81917402961281, average reward:-0.6299410021152008,success
Box_Position: [[1.25453822 0.84894438 0.73590119]]
actor_loss: tensor(0.2660, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2452, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-21.96959087844948, average reward:-0.2525240330856262,success
Box_Position: [[1.29124277 1.00929881 0.72243689]]
actor_loss: tensor(0.2637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2582, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-30.155975722553556, average reward:-0.23933314065518696,success
Box_Position: [[1.38561324 0.67130252 0.46470847]]
actor_loss: tensor(0.2487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2526, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-128.77688969793422, average reward:-0.7711190999876301,success
Box_Position: [[1.53257802 0.76844822 0.7167656 ]]
actor_loss: tensor(0.2572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2601, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2823, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2871, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-70.15197798597552, average reward:-0.3507598899298776,----
Box_Position: [[1.34738141 0.98014606 0.54968562]]
actor_loss: tensor(0.2420, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-15.322990038233716, average reward:-0.43779971537810614,success
Box_Position: [[1.37594967 0.76419792 0.54227722]]
actor_loss: tensor(0.2948, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-22.531818440812827, average reward:-0.5239957776933216,success
Box_Position: [[1.4851379  0.78061787 0.73115705]]
actor_loss: tensor(0.2786, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2481, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-54.610016576149086, average reward:-0.27305008288074545,----
Box_Position: [[1.49313476 0.49360142 0.65489044]]
actor_loss: tensor(0.2528, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2804, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3025, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-78.52828203559089, average reward:-0.39264141017795445,----
Box_Position: [[1.47862268 0.55683275 0.6166495 ]]
actor_loss: tensor(0.2717, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2750, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2793, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2840, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-89.9610539890121, average reward:-0.4498052699450605,----
Box_Position: [[1.25735784 0.8378022  0.53582374]]
Step:6, total reward:-1.1286635371385785, average reward:-0.18811058952309642,success
Box_Position: [[1.336199   1.02732195 0.59685167]]
Step:10, total reward:-4.060143250206293, average reward:-0.4060143250206293,success
Box_Position: [[1.33607075 0.97497527 0.6524669 ]]
actor_loss: tensor(0.2556, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-2.8362344624250535, average reward:-0.18908229749500358,success
Box_Position: [[1.30801994 0.83234561 0.48354345]]
actor_loss: tensor(0.2579, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2651, device='cuda:0', grad_fn=<NegBackward>)
Step:162, total reward:-122.70905537093212, average reward:-0.7574633047588403,success
Box_Position: [[1.46571397 0.5189576  0.66082783]]
Step:23, total reward:-7.52240534141294, average reward:-0.3270611018005626,success
Box_Position: [[1.51916598 0.92455027 0.47282242]]
actor_loss: tensor(0.2722, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-20.959051607074066, average reward:-0.7227259174853127,success
Box_Position: [[1.5057754  0.9064758  0.47931779]]
Step:20, total reward:-15.287405561040167, average reward:-0.7643702780520083,success
Box_Position: [[1.2632965  0.76152273 0.49045727]]
actor_loss: tensor(0.2560, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-17.571366979403724, average reward:-0.7321402908084885,success
Box_Position: [[1.4806012  0.46927143 0.74085065]]
Step:10, total reward:-4.747143373992475, average reward:-0.47471433739924745,success
Box_Position: [[1.29616648 1.08500218 0.48930714]]
actor_loss: tensor(0.2398, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-41.86624614066295, average reward:-0.7344955463274202,success
Box_Position: [[1.3509677  0.69903323 0.50232295]]
Step:15, total reward:-8.316659347643753, average reward:-0.5544439565095836,success
Box_Position: [[1.29159401 0.75050747 0.62562416]]
actor_loss: tensor(0.2673, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2678, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-30.378867533144614, average reward:-0.399721941225587,success
Box_Position: [[1.36027439 0.6051544  0.64644419]]
Step:15, total reward:-8.947118564636746, average reward:-0.596474570975783,success
Box_Position: [[1.37727636 0.94635196 0.63781615]]
actor_loss: tensor(0.2852, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2552, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-21.989294630125148, average reward:-0.3331711307594719,success
Box_Position: [[1.41526762 0.84585193 0.47557005]]
Step:21, total reward:-17.234708438441036, average reward:-0.8207004018305255,success
Box_Position: [[1.32070645 0.93711291 0.56732556]]
actor_loss: tensor(0.2685, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-37.6243566799821, average reward:-0.8360968151107133,success
Box_Position: [[1.35862899 0.62840081 0.63383995]]
Step:17, total reward:-7.521448590105481, average reward:-0.44243815235914596,success
Box_Position: [[1.4189949  0.86468129 0.53042826]]
actor_loss: tensor(0.2766, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2554, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2781, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-126.31596546912978, average reward:-0.6315798273456489,----
Box_Position: [[1.46894146 1.1184195  0.48214927]]
actor_loss: tensor(0.3286, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2649, device='cuda:0', grad_fn=<NegBackward>)
Step:137, total reward:-145.95403822897427, average reward:-1.0653579432771845,success
Box_Position: [[1.34724425 0.46172269 0.46803783]]
Step:23, total reward:-16.072551518216294, average reward:-0.6988065877485345,success
Box_Position: [[1.42026517 0.45776562 0.74349504]]
actor_loss: tensor(0.2772, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-5.920968533227859, average reward:-0.26913493332853905,success
Box_Position: [[1.52769812 0.93347011 0.65234048]]
actor_loss: tensor(0.2708, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2556, device='cuda:0', grad_fn=<NegBackward>)
Step:123, total reward:-49.70137501046945, average reward:-0.4040762195973126,success
Box_Position: [[1.54358424 0.51864224 0.66135168]]
actor_loss: tensor(0.2715, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2638, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2338, device='cuda:0', grad_fn=<NegBackward>)
Step:144, total reward:-67.88441751952949, average reward:-0.4714195661078437,success
Box_Position: [[1.31313938 1.08657552 0.73375561]]
actor_loss: tensor(0.3044, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2987, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2634, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-38.04374327409891, average reward:-0.29041025400075504,success
Box_Position: [[1.36340833 1.06782884 0.6749971 ]]
actor_loss: tensor(0.2609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2333, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.3001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2457, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-77.94923376093158, average reward:-0.3897461688046579,----
Box_Position: [[1.4716522  0.50333962 0.47636813]]
actor_loss: tensor(0.2582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2502, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2843, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-175.88712464871566, average reward:-0.8794356232435783,----
Box_Position: [[1.42387236 0.55341939 0.62042055]]
actor_loss: tensor(0.2824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2915, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2587, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2661, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-93.09876969771837, average reward:-0.4654938484885918,----
Box_Position: [[1.39462969 0.64889359 0.45544127]]
actor_loss: tensor(0.2862, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-66.92547126964239, average reward:-0.8471578641726885,success
Box_Position: [[1.3035049  0.84326831 0.49546763]]
actor_loss: tensor(0.2495, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-8.620238918507013, average reward:-0.6157313513219295,success
Box_Position: [[1.38592966 0.88442415 0.7442287 ]]
Step:14, total reward:-5.4112388700763345, average reward:-0.3865170621483096,success
Box_Position: [[1.47150841 0.688778   0.68182525]]
actor_loss: tensor(0.2363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2299, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-50.38816164227035, average reward:-0.41301771837926515,success
Box_Position: [[1.4214583  0.68710753 0.57874519]]
actor_loss: tensor(0.2599, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2763, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2251, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-113.01756814253389, average reward:-0.5650878407126695,----
Box_Position: [[1.39715627 0.91781674 0.57436607]]
actor_loss: tensor(0.2632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2526, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2592, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-78.47294228756405, average reward:-0.581281053981956,success
Box_Position: [[1.35032263 0.74382818 0.65194381]]
actor_loss: tensor(0.2364, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-5.552395943936638, average reward:-0.2643998068541256,success
Box_Position: [[1.42048289 0.89009401 0.70759987]]
Step:31, total reward:-7.163668721109043, average reward:-0.23108608777771106,success
Box_Position: [[1.39844935 0.88653523 0.66228558]]
actor_loss: tensor(0.2411, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-6.556270029394483, average reward:-0.19867484937559038,success
Box_Position: [[1.42347004 0.91891022 0.69348142]]
actor_loss: tensor(0.2818, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2388, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-59.302790853757486, average reward:-0.2965139542687874,----
Box_Position: [[1.26847294 0.51021558 0.72931809]]

------------------Episode:1600------------------
actor_loss: tensor(0.2218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2522, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-35.5750486980814, average reward:-0.37057342393834797,success
episode 1600, the accuracy is: 77%
Box_Position: [[1.47966427 0.67042923 0.66811841]]
actor_loss: tensor(0.2328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2927, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2782, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2378, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-78.75815159636544, average reward:-0.39379075798182717,----
Box_Position: [[1.45256146 1.0851658  0.69553168]]
actor_loss: tensor(0.2429, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2624, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2203, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-59.92782806099448, average reward:-0.402200188328822,success
Box_Position: [[1.49431287 0.74576666 0.48571589]]
actor_loss: tensor(0.2109, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2511, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2196, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2386, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-171.71641289341832, average reward:-0.8585820644670916,----
Box_Position: [[1.51555464 0.84973058 0.54996163]]
actor_loss: tensor(0.2820, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2307, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1974, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-129.054372345207, average reward:-0.6452718617260351,----
Box_Position: [[1.49375737 0.72205846 0.61173236]]
actor_loss: tensor(0.2111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1711, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2280, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2074, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-84.15566169595225, average reward:-0.4207783084797612,----
Box_Position: [[1.28231679 0.9519151  0.64007694]]
Step:9, total reward:-4.117818391722646, average reward:-0.4575353768580718,success
Box_Position: [[1.26289619 1.1260591  0.55688455]]
actor_loss: tensor(0.2167, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-20.340584691206683, average reward:-0.46228601570924277,success
Box_Position: [[1.35903054 0.55506216 0.56193459]]
actor_loss: tensor(0.2599, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2217, device='cuda:0', grad_fn=<NegBackward>)
Step:117, total reward:-72.34782281229118, average reward:-0.6183574599341127,success
Box_Position: [[1.39574277 0.53061698 0.66917936]]
actor_loss: tensor(0.2165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2757, device='cuda:0', grad_fn=<NegBackward>)
Step:185, total reward:-81.26430364366581, average reward:-0.4392665061819774,success
Box_Position: [[1.48542484 0.84299515 0.69899707]]
Step:6, total reward:-3.52169284811831, average reward:-0.5869488080197184,success
Box_Position: [[1.44423491 0.58191161 0.58473217]]
actor_loss: tensor(0.2378, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1954, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2439, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-60.80097724825363, average reward:-0.4641295973149132,success
Box_Position: [[1.29625998 0.71138565 0.55036861]]
Step:2, total reward:-2.305781796909628, average reward:-1.152890898454814,success
Box_Position: [[1.50742383 1.12809626 0.4865081 ]]
actor_loss: tensor(0.2353, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2256, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2307, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-185.79579302696192, average reward:-0.9289789651348096,----
Box_Position: [[1.48918006 0.76358744 0.62253101]]
actor_loss: tensor(0.2368, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2860, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-43.68304917186873, average reward:-0.37019533196498927,success
Box_Position: [[1.43309524 0.9796763  0.50790776]]
Step:24, total reward:-8.66901414637421, average reward:-0.3612089227655921,success
Box_Position: [[1.54737522 0.61407487 0.48097842]]
actor_loss: tensor(0.2468, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2122, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2341, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-112.09748636499845, average reward:-0.8365484057089436,success
Box_Position: [[1.36318132 0.91263588 0.62050142]]
actor_loss: tensor(0.2265, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-11.030116695191593, average reward:-0.42423525750736896,success
Box_Position: [[1.46876196 0.78051098 0.5575734 ]]
actor_loss: tensor(0.2478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2096, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2382, device='cuda:0', grad_fn=<NegBackward>)
Step:147, total reward:-96.1518136244009, average reward:-0.6540939702340197,success
Box_Position: [[1.37170203 0.80121693 0.52754093]]
actor_loss: tensor(0.2158, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-40.91976996501109, average reward:-0.5051823452470505,success
Box_Position: [[1.4714711  0.84266682 0.7266573 ]]
actor_loss: tensor(0.1812, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-14.893611333923852, average reward:-0.27079293334407006,success
Box_Position: [[1.48200251 0.66786287 0.60259742]]
actor_loss: tensor(0.2459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2201, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-48.280811095037244, average reward:-0.5424810235397444,success
Box_Position: [[1.42018828 0.54788204 0.57011632]]
actor_loss: tensor(0.1900, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2017, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2001, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-125.23136457791756, average reward:-0.6261568228895878,----
Box_Position: [[1.36304247 0.88658054 0.64701559]]
actor_loss: tensor(0.2030, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-7.492568174475533, average reward:-0.25836441980950114,success
Box_Position: [[1.44481215 0.89300674 0.47017105]]
Step:37, total reward:-26.97200135415391, average reward:-0.7289730095717273,success
Box_Position: [[1.3475096  0.93461988 0.48298489]]
actor_loss: tensor(0.2163, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1986, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2261, device='cuda:0', grad_fn=<NegBackward>)
Step:162, total reward:-117.74648989455845, average reward:-0.7268301845343115,success
Box_Position: [[1.33618267 0.90106824 0.53921684]]
Step:17, total reward:-7.203408889950512, average reward:-0.42372993470297127,success
Box_Position: [[1.41639739 0.77917239 0.7124496 ]]
actor_loss: tensor(0.2319, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2829, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2165, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-55.69030582318316, average reward:-0.2784515291159158,----
Box_Position: [[1.46805628 0.58255946 0.6144157 ]]
actor_loss: tensor(0.2085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2179, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2131, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2259, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-95.48261675289096, average reward:-0.4774130837644548,----
Box_Position: [[1.46036336 0.89108925 0.53120429]]
actor_loss: tensor(0.2303, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2724, device='cuda:0', grad_fn=<NegBackward>)
Step:194, total reward:-143.3851896542882, average reward:-0.7390989157437536,success
Box_Position: [[1.5060064  0.64943753 0.6132843 ]]
actor_loss: tensor(0.2292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2240, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2767, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-94.9662411400262, average reward:-0.474831205700131,----
Box_Position: [[1.33480013 0.91192274 0.4912811 ]]
Step:17, total reward:-11.017246354164838, average reward:-0.6480733149508728,success
Box_Position: [[1.51910105 0.69886185 0.74984367]]
actor_loss: tensor(0.2226, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-4.138863723000262, average reward:-0.2434625719411919,success
Box_Position: [[1.40038742 0.45685467 0.7447201 ]]
Step:10, total reward:-4.262071071156182, average reward:-0.4262071071156182,success
Box_Position: [[1.40304549 0.79856143 0.5480753 ]]
Step:18, total reward:-6.243010262711191, average reward:-0.3468339034839551,success
Box_Position: [[1.50394084 0.6009601  0.46778547]]
actor_loss: tensor(0.2315, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2318, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2145, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2316, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-184.35045040684534, average reward:-0.9217522520342267,----
Box_Position: [[1.39743487 1.03522015 0.46207898]]
Step:11, total reward:-9.931925424954425, average reward:-0.9029023113594932,success
Box_Position: [[1.27094013 0.97261876 0.68804601]]
actor_loss: tensor(0.2467, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2297, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-23.80390916641796, average reward:-0.28337987102878526,success
Box_Position: [[1.31330589 0.84650634 0.72016406]]
Step:13, total reward:-2.639377292933323, average reward:-0.20302902253333255,success
Box_Position: [[1.5000734  0.59052763 0.5698768 ]]
actor_loss: tensor(0.2203, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2433, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2390, device='cuda:0', grad_fn=<NegBackward>)
Step:164, total reward:-104.7979777300826, average reward:-0.6390120593297719,success
Box_Position: [[1.49910319 0.64389385 0.4998842 ]]
actor_loss: tensor(0.2512, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2452, device='cuda:0', grad_fn=<NegBackward>)
Step:153, total reward:-122.15000256149007, average reward:-0.7983660298136606,success
Box_Position: [[1.33321104 0.6845137  0.71441912]]
actor_loss: tensor(0.2776, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-22.68380965099383, average reward:-0.33856432314916163,success
Box_Position: [[1.32756831 0.48484731 0.57223999]]
Step:23, total reward:-18.533278553926486, average reward:-0.8057947197359342,success
Box_Position: [[1.54233965 0.749065   0.60001499]]
actor_loss: tensor(0.2317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2310, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2549, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-98.34842131818603, average reward:-0.5433614437468841,success
Box_Position: [[1.46472763 0.64207376 0.5043668 ]]
actor_loss: tensor(0.2316, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-33.30858217545543, average reward:-0.7746181901268704,success
Box_Position: [[1.29389028 0.97287448 0.68844225]]
actor_loss: tensor(0.2305, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2243, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2409, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2462, device='cuda:0', grad_fn=<NegBackward>)
Step:187, total reward:-64.33214988405305, average reward:-0.34402219189333183,success
Box_Position: [[1.46454499 0.97717723 0.56378206]]
Step:14, total reward:-4.253976304552236, average reward:-0.3038554503251597,success
Box_Position: [[1.25802715 0.92979646 0.50217862]]
actor_loss: tensor(0.2661, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2106, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-76.0695111387278, average reward:-0.7244715346545505,success
Box_Position: [[1.30545541 0.65103254 0.65104558]]
actor_loss: tensor(0.2415, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-35.14222829743044, average reward:-0.6275397910255436,success
Box_Position: [[1.4000213  0.76528528 0.72761503]]
actor_loss: tensor(0.2485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2264, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-22.812163876127475, average reward:-0.3001600510016773,success
Box_Position: [[1.31644617 0.57424911 0.55478911]]

------------------Episode:1650------------------
Step:34, total reward:-22.00659683436076, average reward:-0.6472528480694342,success
Box_Position: [[1.26372365 0.80310274 0.54450838]]
actor_loss: tensor(0.2245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2367, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2493, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2219, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-141.7223551528593, average reward:-0.7086117757642966,----
Box_Position: [[1.31614217 0.85190278 0.60955273]]
actor_loss: tensor(0.2129, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-1.9817532508472524, average reward:-0.18015938644065932,success
Box_Position: [[1.35566755 0.92517716 0.4722199 ]]
actor_loss: tensor(0.2138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2228, device='cuda:0', grad_fn=<NegBackward>)
Step:171, total reward:-140.4502784490628, average reward:-0.8213466575968585,success
Box_Position: [[1.3746892  0.729737   0.48142925]]
actor_loss: tensor(0.2435, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2096, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-95.66928267163242, average reward:-0.790655228691177,success
Box_Position: [[1.53505731 0.8028762  0.66573857]]
actor_loss: tensor(0.2142, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-8.720466821527408, average reward:-0.4360233410763704,success
Box_Position: [[1.33495989 0.71505676 0.66400942]]
Step:12, total reward:-2.353446677860119, average reward:-0.19612055648834326,success
Box_Position: [[1.50040051 0.99034752 0.56646308]]
actor_loss: tensor(0.2363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2515, device='cuda:0', grad_fn=<NegBackward>)
Step:93, total reward:-56.72611849938803, average reward:-0.6099582634342798,success
Box_Position: [[1.43403306 0.85243291 0.643103  ]]
Step:12, total reward:-4.016820142562482, average reward:-0.3347350118802068,success
Box_Position: [[1.48633879 0.78908471 0.58818389]]
actor_loss: tensor(0.2445, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2129, device='cuda:0', grad_fn=<NegBackward>)
Step:161, total reward:-97.12174291274673, average reward:-0.603240639209607,success
Box_Position: [[1.28469597 1.01149658 0.74960512]]
actor_loss: tensor(0.2237, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-11.393326258119052, average reward:-0.2649610757702105,success
Box_Position: [[1.46444394 0.92555014 0.52775416]]
actor_loss: tensor(0.2034, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-25.006945265467202, average reward:-0.7354983901608001,success
Box_Position: [[1.52593122 1.06925536 0.51870385]]
actor_loss: tensor(0.2163, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1982, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2438, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-130.52381757563637, average reward:-0.7093685737806324,success
Box_Position: [[1.54008214 0.69917307 0.4682955 ]]
actor_loss: tensor(0.2797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2028, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2493, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-192.38723575777152, average reward:-0.9619361787888576,----
Box_Position: [[1.43639218 0.95582045 0.70977666]]
Step:12, total reward:-1.9706724652330512, average reward:-0.1642227054360876,success
Box_Position: [[1.38720774 0.52463781 0.51548468]]
actor_loss: tensor(0.2089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2238, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2234, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-135.91017413961987, average reward:-0.6795508706980994,----
Box_Position: [[1.35093757 0.83645147 0.59746507]]
actor_loss: tensor(0.2242, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-29.68863290400106, average reward:-0.6316730405106609,success
Box_Position: [[1.33399783 0.6602785  0.69984999]]
Step:29, total reward:-12.577279396824643, average reward:-0.4336992895456774,success
Box_Position: [[1.52740822 0.68346475 0.56302314]]
actor_loss: tensor(0.2073, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-23.874115436683745, average reward:-0.582295498455701,success
Box_Position: [[1.41400236 0.90213219 0.53388833]]
actor_loss: tensor(0.2075, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1682, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-56.60665757795704, average reward:-0.7448244418152242,success
Box_Position: [[1.31764974 0.7392035  0.58279948]]
Step:21, total reward:-11.018544278234375, average reward:-0.5246925846778273,success
Box_Position: [[1.52725042 0.64228021 0.60584602]]
Step:9, total reward:-4.228595967945517, average reward:-0.46984399643839075,success
Box_Position: [[1.25824029 0.75866466 0.52804616]]
actor_loss: tensor(0.2151, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2090, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2122, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-149.1610650552988, average reward:-0.745805325276494,----
Box_Position: [[1.29924288 0.8363602  0.56545019]]
actor_loss: tensor(0.2568, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-5.902859586831353, average reward:-0.4216328276308109,success
Box_Position: [[1.335165   0.79074803 0.6705036 ]]
Step:32, total reward:-10.613085188170292, average reward:-0.3316589121303216,success
Box_Position: [[1.51639426 0.60910891 0.56405906]]
actor_loss: tensor(0.2138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1693, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1981, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1889, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-102.41207810544897, average reward:-0.5120603905272448,----
Box_Position: [[1.41306158 0.77786327 0.5008863 ]]
actor_loss: tensor(0.2002, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2174, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-73.40087661113274, average reward:-0.9061836618658363,success
Box_Position: [[1.39658072 0.96284267 0.45268753]]
Step:12, total reward:-4.6707315933863685, average reward:-0.38922763278219735,success
Box_Position: [[1.26311436 0.68176517 0.59373392]]
actor_loss: tensor(0.2117, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2054, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2260, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-101.62776265603235, average reward:-0.5081388132801617,----
Box_Position: [[1.45968705 0.8323571  0.73531254]]
actor_loss: tensor(0.2023, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-13.3150731947706, average reward:-0.2717361876483796,success
Box_Position: [[1.35642261 0.60201277 0.72171338]]
Step:9, total reward:-1.8139146305850027, average reward:-0.2015460700650003,success
Box_Position: [[1.42473164 0.60470376 0.62491918]]
actor_loss: tensor(0.1934, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2084, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1963, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-47.16087941279354, average reward:-0.36277599548302725,success
Box_Position: [[1.28234643 1.11192293 0.50110482]]
actor_loss: tensor(0.2102, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-58.37966083696602, average reward:-0.7783954778262135,success
Box_Position: [[1.53541721 0.73627724 0.62333283]]
actor_loss: tensor(0.2317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2036, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2068, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-51.739091594234885, average reward:-0.42759579829946187,success
Box_Position: [[1.43485991 1.0384998  0.56902471]]
Step:1, total reward:-0.028477468148521628, average reward:-0.028477468148521628,success
Box_Position: [[1.26256219 0.80604748 0.55139462]]
actor_loss: tensor(0.2081, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1935, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2173, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-137.03237704592857, average reward:-0.6851618852296428,----
Box_Position: [[1.27211442 0.89403653 0.49563626]]
actor_loss: tensor(0.2279, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-30.138875055849876, average reward:-0.6697527790188862,success
Box_Position: [[1.50976343 1.0174085  0.5245194 ]]
actor_loss: tensor(0.2042, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-44.867045522923455, average reward:-0.801197241480776,success
Box_Position: [[1.47449989 1.1362178  0.61642095]]
actor_loss: tensor(0.2018, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-17.0328820116482, average reward:-0.36240174492868515,success
Box_Position: [[1.44565299 0.99747602 0.7360117 ]]
Step:5, total reward:-0.8243390254406989, average reward:-0.16486780508813978,success
Box_Position: [[1.50803383 0.77306035 0.60198052]]
actor_loss: tensor(0.2231, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-38.09186466125407, average reward:-0.529053675850751,success
Box_Position: [[1.44672932 0.55214036 0.59058351]]
actor_loss: tensor(0.1890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2213, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1753, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-99.92666073547295, average reward:-0.49963330367736475,----
Box_Position: [[1.51257718 0.94370812 0.634878  ]]
actor_loss: tensor(0.1950, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-15.357853682216666, average reward:-0.3656631829099206,success
Box_Position: [[1.37754957 1.05232861 0.59487025]]
Step:21, total reward:-6.072358153255318, average reward:-0.28915991205977704,success
Box_Position: [[1.36243494 0.71709907 0.67911052]]
Step:1, total reward:-0.04486130904107666, average reward:-0.04486130904107666,success
Box_Position: [[1.39361248 0.75315799 0.63733425]]
actor_loss: tensor(0.1885, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-12.184311417011084, average reward:-0.3807597317815964,success
Box_Position: [[1.3878022  0.98450479 0.56629999]]
actor_loss: tensor(0.2324, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1931, device='cuda:0', grad_fn=<NegBackward>)
Step:147, total reward:-69.55280258905752, average reward:-0.4731483169323641,success
Box_Position: [[1.41380756 0.96669887 0.54216799]]
actor_loss: tensor(0.2080, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-39.09665001973299, average reward:-0.68590614069707,success
Box_Position: [[1.36377481 1.11610719 0.45394395]]
Step:8, total reward:-4.425224905273469, average reward:-0.5531531131591836,success
Box_Position: [[1.32114316 0.97819233 0.5357316 ]]
actor_loss: tensor(0.1767, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-15.039669155984594, average reward:-0.518609281240848,success
Box_Position: [[1.29126734 0.98671139 0.45039456]]

------------------Episode:1700------------------
Step:19, total reward:-22.584540688215068, average reward:-1.1886600362218456,success
episode 1700, the accuracy is: 82%
Box_Position: [[1.52586744 0.70791211 0.68321715]]
actor_loss: tensor(0.2159, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-3.0622610052488266, average reward:-0.23555853886529435,success
Box_Position: [[1.28141409 0.96962392 0.51286577]]
Step:11, total reward:-6.202600070679692, average reward:-0.5638727336981538,success
Box_Position: [[1.44200366 0.71019738 0.67013933]]
Step:8, total reward:-5.551977376288118, average reward:-0.6939971720360147,success
Box_Position: [[1.50052472 0.67269378 0.67587707]]
Step:26, total reward:-7.195339234773755, average reward:-0.2767438167220675,success
Box_Position: [[1.27297831 0.68753088 0.50342179]]
actor_loss: tensor(0.2297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2088, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2039, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-165.9257755774649, average reward:-0.8296288778873244,----
Box_Position: [[1.37943381 0.49312622 0.68850354]]
actor_loss: tensor(0.2123, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2025, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2281, device='cuda:0', grad_fn=<NegBackward>)
Step:137, total reward:-39.65984747757468, average reward:-0.2894879377925159,success
Box_Position: [[1.32992075 0.74092029 0.48821891]]
actor_loss: tensor(0.1840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2244, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-85.07792477929476, average reward:-1.1816378441568718,success
Box_Position: [[1.37985221 0.98120343 0.64684544]]
Step:7, total reward:-1.408531627309112, average reward:-0.2012188039013017,success
Box_Position: [[1.53303585 0.93890129 0.53734673]]
Step:24, total reward:-14.531745146639182, average reward:-0.6054893811099659,success
Box_Position: [[1.3072276  1.16850942 0.54628386]]
actor_loss: tensor(0.1780, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1779, device='cuda:0', grad_fn=<NegBackward>)
Step:147, total reward:-98.34064781507692, average reward:-0.6689839987420199,success
Box_Position: [[1.36134495 0.82390582 0.54080129]]
actor_loss: tensor(0.1937, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1815, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-88.78851283661082, average reward:-0.8145735122624846,success
Box_Position: [[1.36793344 0.858184   0.7070231 ]]
actor_loss: tensor(0.1672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1959, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-20.537544412233697, average reward:-0.24744029412329754,success
Box_Position: [[1.28261069 0.92262831 0.7027681 ]]
actor_loss: tensor(0.2050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1903, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1593, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-70.40138024252568, average reward:-0.3520069012126284,----
Box_Position: [[1.49721158 0.7655937  0.4623462 ]]
actor_loss: tensor(0.1844, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-19.543285824540035, average reward:-0.6739064077427599,success
Box_Position: [[1.49594264 1.07027055 0.60846939]]
actor_loss: tensor(0.1764, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-26.67756547967042, average reward:-0.5033502920692532,success
Box_Position: [[1.41179599 0.68974342 0.53555211]]
Step:5, total reward:-0.8852314357366283, average reward:-0.17704628714732568,success
Box_Position: [[1.37345604 0.73273921 0.51531298]]
Step:19, total reward:-7.274451799347907, average reward:-0.38286588417620565,success
Box_Position: [[1.31127904 0.62196381 0.57440814]]
Step:9, total reward:-7.254428241442286, average reward:-0.8060475823824762,success
Box_Position: [[1.28889837 0.7328271  0.58582653]]
Step:2, total reward:-0.2542035725096474, average reward:-0.1271017862548237,success
Box_Position: [[1.3297414  0.51628359 0.54399193]]
actor_loss: tensor(0.1826, device='cuda:0', grad_fn=<NegBackward>)
Step:7, total reward:-9.287182631646518, average reward:-1.3267403759495024,success
Box_Position: [[1.39944288 1.12550489 0.61030505]]
actor_loss: tensor(0.2117, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-31.033663612859527, average reward:-0.3608565536379015,success
Box_Position: [[1.38563766 0.99029751 0.49759099]]
Step:4, total reward:-2.580612717301844, average reward:-0.645153179325461,success
Box_Position: [[1.34117439 0.76290611 0.60530087]]
actor_loss: tensor(0.1931, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1898, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-33.27986557392534, average reward:-0.5367720253858926,success
Box_Position: [[1.36942874 0.76618822 0.69274814]]
Step:8, total reward:-1.573755745735877, average reward:-0.19671946821698463,success
Box_Position: [[1.45207285 0.89868556 0.68354745]]
Step:13, total reward:-11.343002400117454, average reward:-0.8725386461628811,success
Box_Position: [[1.46732951 0.56111971 0.48829476]]
actor_loss: tensor(0.1705, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-43.04280582323519, average reward:-0.8608561164647038,success
Box_Position: [[1.30312669 0.54478012 0.61465703]]
actor_loss: tensor(0.2052, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-21.335083548052104, average reward:-0.3333606804383141,success
Box_Position: [[1.38512703 0.87653635 0.59327162]]
Step:5, total reward:-2.8149512400368644, average reward:-0.5629902480073729,success
Box_Position: [[1.38609683 0.71284619 0.73456218]]
actor_loss: tensor(0.1702, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-3.9411911868087013, average reward:-0.2074311150951948,success
Box_Position: [[1.5471237  0.5512606  0.72531982]]
actor_loss: tensor(0.2352, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2203, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1863, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1928, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-69.82078846137841, average reward:-0.34910394230689207,----
Box_Position: [[1.41813778 0.48867846 0.49148889]]
actor_loss: tensor(0.2085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1896, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2034, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-172.84649348406526, average reward:-0.8642324674203263,----
Box_Position: [[1.2961626  0.7083098  0.72567541]]
actor_loss: tensor(0.1927, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1961, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-53.36331053206184, average reward:-0.2668165526603092,----
Box_Position: [[1.467373   0.61793246 0.72560462]]
actor_loss: tensor(0.2264, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-10.685745737987677, average reward:-0.24850571483692271,success
Box_Position: [[1.33721118 0.64909897 0.57984954]]
actor_loss: tensor(0.2233, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-51.34753349321541, average reward:-0.8023052108314908,success
Box_Position: [[1.31579835 0.49793675 0.63666381]]
actor_loss: tensor(0.2167, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-40.30809562441623, average reward:-0.5758299374916604,success
Box_Position: [[1.28959698 0.51024042 0.5868467 ]]
actor_loss: tensor(0.1967, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-6.173179087434428, average reward:-0.5611980988576752,success
Box_Position: [[1.37925528 0.91777064 0.4888657 ]]
Step:27, total reward:-29.995610671393322, average reward:-1.1109485433849378,success
Box_Position: [[1.50486336 0.9655491  0.5756902 ]]
actor_loss: tensor(0.1821, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2226, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2197, device='cuda:0', grad_fn=<NegBackward>)
Step:194, total reward:-101.62892548223074, average reward:-0.5238604406300553,success
Box_Position: [[1.41354656 0.92916713 0.47956925]]
actor_loss: tensor(0.1901, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-40.955389721686636, average reward:-0.6941591478251973,success
Box_Position: [[1.45978326 0.99113691 0.52567259]]
actor_loss: tensor(0.1926, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-12.752990579488461, average reward:-0.6712100304993927,success
Box_Position: [[1.53339346 1.00178401 0.61794365]]
actor_loss: tensor(0.1774, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-25.41158229944734, average reward:-0.5082316459889468,success
Box_Position: [[1.41484894 0.84289272 0.65250864]]
actor_loss: tensor(0.2106, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1779, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-43.23771961693691, average reward:-0.38952900555799014,success
Box_Position: [[1.34661494 0.7834191  0.65020301]]
actor_loss: tensor(0.2057, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-18.064095770269333, average reward:-0.23768547066143858,success
Box_Position: [[1.29178015 0.8364206  0.67817835]]
actor_loss: tensor(0.1877, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-7.7665070609073315, average reward:-0.2427033456533541,success
Box_Position: [[1.25938572 0.50228538 0.55291522]]
actor_loss: tensor(0.2028, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-21.244682050217783, average reward:-0.574180595951832,success
Box_Position: [[1.4025389  1.06948277 0.61945007]]
Step:36, total reward:-18.278419017809163, average reward:-0.5077338616058101,success
Box_Position: [[1.49337925 0.73829951 0.73388616]]
actor_loss: tensor(0.1999, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-5.5432471952663995, average reward:-0.34645294970414997,success
Box_Position: [[1.41377493 1.1293433  0.49583353]]
actor_loss: tensor(0.2063, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1838, device='cuda:0', grad_fn=<NegBackward>)
Step:106, total reward:-80.27799166980742, average reward:-0.757339544054787,success
Box_Position: [[1.29286999 0.91012115 0.55432823]]
Step:12, total reward:-2.3018873234883483, average reward:-0.19182394362402902,success
Box_Position: [[1.31940666 0.63062309 0.63513912]]

------------------Episode:1750------------------
actor_loss: tensor(0.1767, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-5.603885302278699, average reward:-0.20755130749180367,success
Box_Position: [[1.31557614 0.58563046 0.54418944]]
actor_loss: tensor(0.1711, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-24.67523884989343, average reward:-0.5140674760394465,success
Box_Position: [[1.30016678 0.89521178 0.51969898]]
Step:1, total reward:-0.047738683030789854, average reward:-0.047738683030789854,success
Box_Position: [[1.44238255 0.99840326 0.5574539 ]]
Step:32, total reward:-16.053667033467757, average reward:-0.5016770947958674,success
Box_Position: [[1.54057766 0.65459867 0.70404274]]
actor_loss: tensor(0.1798, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2034, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-23.029566120543976, average reward:-0.33867009000799964,success
Box_Position: [[1.46319729 0.91165008 0.63666557]]
actor_loss: tensor(0.1390, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1701, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-86.68158948611817, average reward:-0.5010496502087756,success
Box_Position: [[1.32996066 0.65399738 0.57223265]]
actor_loss: tensor(0.1562, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-27.125999927266076, average reward:-0.3665675665846767,success
Box_Position: [[1.29915642 0.62922256 0.61467489]]
actor_loss: tensor(0.1661, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-0.9774399772094342, average reward:-0.12217999715117928,success
Box_Position: [[1.26089565 0.7439639  0.67026558]]
actor_loss: tensor(0.1850, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2182, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2063, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-55.04491859364265, average reward:-0.29594042254646585,success
Box_Position: [[1.3297041  0.72021702 0.50581494]]
actor_loss: tensor(0.2021, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-13.958232846108512, average reward:-0.6344651293685687,success
Box_Position: [[1.50504612 0.6201432  0.54754522]]
Step:32, total reward:-19.722881201238827, average reward:-0.6163400375387134,success
Box_Position: [[1.26256581 0.78901943 0.69077411]]
actor_loss: tensor(0.1827, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-6.65576726471566, average reward:-0.22950921602467794,success
Box_Position: [[1.3069184  1.10740289 0.55088199]]
actor_loss: tensor(0.1724, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-17.15738390108485, average reward:-0.4637130784076986,success
Box_Position: [[1.25624478 0.84630678 0.47084162]]
Step:7, total reward:-3.104964670332277, average reward:-0.4435663814760396,success
Box_Position: [[1.44532075 0.90075888 0.69277272]]
Step:10, total reward:-1.928682398369054, average reward:-0.1928682398369054,success
Box_Position: [[1.29347386 0.76745978 0.61893152]]
actor_loss: tensor(0.1782, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1448, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-23.160044957669275, average reward:-0.3129735805090442,success
Box_Position: [[1.48248944 0.97927767 0.47127336]]
actor_loss: tensor(0.1953, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1796, device='cuda:0', grad_fn=<NegBackward>)
Step:120, total reward:-102.96110714478435, average reward:-0.8580092262065363,success
Box_Position: [[1.47917349 0.83669997 0.65546912]]
Step:21, total reward:-6.296628049477788, average reward:-0.29983943092751375,success
Box_Position: [[1.3517266  0.69025374 0.59427862]]
actor_loss: tensor(0.1772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1476, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-15.110383613949503, average reward:-0.2747342475263546,success
Box_Position: [[1.42975018 0.97322841 0.49674208]]
Step:10, total reward:-5.80351500574591, average reward:-0.5803515005745911,success
Box_Position: [[1.37363687 0.50274083 0.49562342]]
actor_loss: tensor(0.1598, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1358, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2170, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-127.1351623643727, average reward:-0.6356758118218635,----
Box_Position: [[1.43317024 0.73582466 0.47385097]]
actor_loss: tensor(0.1811, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-35.910802370667106, average reward:-0.6412643280476269,success
Box_Position: [[1.42411026 0.50429324 0.6111796 ]]
actor_loss: tensor(0.1676, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1960, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1796, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-81.93902789328757, average reward:-0.4096951394664379,----
Box_Position: [[1.35322128 0.96839854 0.45943215]]
Step:4, total reward:-2.743217062213111, average reward:-0.6858042655532778,success
Box_Position: [[1.44936564 0.81666817 0.65533001]]
actor_loss: tensor(0.1375, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1693, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-37.48306477296789, average reward:-0.3503090165697934,success
Box_Position: [[1.26348486 0.73701451 0.45448663]]
Step:22, total reward:-17.21366525830843, average reward:-0.7824393299231105,success
Box_Position: [[1.49921776 0.72177296 0.64726798]]
actor_loss: tensor(0.1420, device='cuda:0', grad_fn=<NegBackward>)
Step:3, total reward:-2.4467492737119683, average reward:-0.8155830912373228,success
Box_Position: [[1.35761082 0.71480483 0.60172986]]
Step:6, total reward:-0.784954966984558, average reward:-0.13082582783075966,success
Box_Position: [[1.48041154 0.5013741  0.58060636]]
actor_loss: tensor(0.1731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1431, device='cuda:0', grad_fn=<NegBackward>)
Step:137, total reward:-76.08942841034458, average reward:-0.5553972876667488,success
Box_Position: [[1.35963665 1.15142354 0.57671131]]
actor_loss: tensor(0.1821, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-5.593895955609572, average reward:-0.5593895955609571,success
Box_Position: [[1.54722851 0.93002956 0.59844012]]
actor_loss: tensor(0.1781, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-44.58450150937789, average reward:-0.49538335010419876,success
Box_Position: [[1.50196619 0.89029181 0.56447658]]
actor_loss: tensor(0.1340, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-11.108502431596735, average reward:-0.7405668287731156,success
Box_Position: [[1.30154578 0.56028204 0.69761423]]
actor_loss: tensor(0.1806, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-12.992295038234852, average reward:-0.28244119648336635,success
Box_Position: [[1.45950385 0.82186346 0.55341205]]
Step:5, total reward:-0.9733881356941995, average reward:-0.1946776271388399,success
Box_Position: [[1.47804986 0.5322801  0.63845923]]
actor_loss: tensor(0.1489, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1502, device='cuda:0', grad_fn=<NegBackward>)
Step:119, total reward:-63.34230762989203, average reward:-0.5322882994108573,success
Box_Position: [[1.54957312 0.90705673 0.48094218]]
actor_loss: tensor(0.1452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1622, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1909, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1295, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-160.70077751131225, average reward:-0.8035038875565612,----
Box_Position: [[1.41677182 1.01327744 0.67690756]]
actor_loss: tensor(0.1839, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-22.453342975290287, average reward:-0.38056513517441165,success
Box_Position: [[1.40487574 0.88823441 0.69865697]]
actor_loss: tensor(0.1546, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1738, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-51.92321548586129, average reward:-0.35563846223192663,success
Box_Position: [[1.36454962 1.00495633 0.61605384]]
actor_loss: tensor(0.1528, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1533, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-51.29394208268753, average reward:-0.4979994376959954,success
Box_Position: [[1.5036727  0.5798764  0.64839547]]
actor_loss: tensor(0.1742, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.2061, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-84.18001916922468, average reward:-0.431692405996024,success
Box_Position: [[1.40370984 0.90349057 0.57756937]]
actor_loss: tensor(0.1419, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1914, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-40.14692346193442, average reward:-0.5654496262244285,success
Box_Position: [[1.28049729 0.92929881 0.58914352]]
actor_loss: tensor(0.1843, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1586, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1539, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1428, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-120.72301185917752, average reward:-0.6036150592958875,----
Box_Position: [[1.43729602 0.90311618 0.46157696]]
Step:7, total reward:-5.756222271011965, average reward:-0.8223174672874236,success
Box_Position: [[1.35212387 0.68661801 0.48474667]]
Step:6, total reward:-2.936216448032706, average reward:-0.489369408005451,success
Box_Position: [[1.50608042 0.55054069 0.59576701]]
actor_loss: tensor(0.1598, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1214, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1506, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1415, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-123.9932360142162, average reward:-0.619966180071081,----
Box_Position: [[1.49081072 1.10239485 0.46579489]]
Step:15, total reward:-15.133742576162573, average reward:-1.0089161717441715,success
Box_Position: [[1.33935022 0.65839094 0.58674873]]
actor_loss: tensor(0.1627, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-35.189718618757745, average reward:-0.5331775548296628,success
Box_Position: [[1.42033855 0.86108285 0.67770943]]
actor_loss: tensor(0.1241, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1376, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-22.256988609522473, average reward:-0.2967598481269663,success
Box_Position: [[1.317632   0.77437888 0.49773469]]
actor_loss: tensor(0.1992, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1813, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-76.5118520642466, average reward:-0.7969984590025687,success
Box_Position: [[1.37463296 0.71982214 0.51755091]]
Step:6, total reward:-0.934220324678884, average reward:-0.15570338744648068,success
Box_Position: [[1.42221678 0.69495848 0.71268637]]

------------------Episode:1800------------------
actor_loss: tensor(0.1700, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-6.1299289502871925, average reward:-0.21137686035473077,success
episode 1800, the accuracy is: 90%
Box_Position: [[1.49830578 0.7785236  0.72417705]]
actor_loss: tensor(0.1673, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-17.79696616231541, average reward:-0.37077012838157103,success
Box_Position: [[1.31338314 0.99827583 0.67196388]]
actor_loss: tensor(0.2091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1705, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1583, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1729, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-71.63766412479463, average reward:-0.3581883206239731,----
Box_Position: [[1.54061057 1.06873548 0.68180163]]
actor_loss: tensor(0.1775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1779, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-36.78595724973524, average reward:-0.3406107152753263,success
Box_Position: [[1.35109552 0.79186059 0.61907191]]
actor_loss: tensor(0.1216, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1831, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-59.03603746352204, average reward:-0.5133568475088873,success
Box_Position: [[1.34686113 0.91820109 0.64303583]]
actor_loss: tensor(0.1677, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1978, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1563, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-64.82916673853238, average reward:-0.3241458336926619,----
Box_Position: [[1.31074225 0.69331015 0.63766232]]
actor_loss: tensor(0.1549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1509, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-97.9691632116624, average reward:-0.489845816058312,----
Box_Position: [[1.41080795 0.51861855 0.53168977]]
Step:22, total reward:-18.69874148130627, average reward:-0.8499427946048305,success
Box_Position: [[1.44582276 0.66306139 0.69138113]]
actor_loss: tensor(0.1670, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-15.664823354428641, average reward:-0.3481071856539698,success
Box_Position: [[1.37295743 0.97437878 0.69716353]]
actor_loss: tensor(0.1455, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1676, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-69.62280127894074, average reward:-0.3481140063947037,----
Box_Position: [[1.47693155 0.62152934 0.72302794]]
actor_loss: tensor(0.1796, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-6.484875764140581, average reward:-0.28195112018002527,success
Box_Position: [[1.52812038 0.76311567 0.49754705]]
Step:23, total reward:-14.290298793990367, average reward:-0.6213173388691464,success
Box_Position: [[1.50056484 0.93768883 0.61068064]]
Step:4, total reward:-0.4107621141260121, average reward:-0.10269052853150303,success
Box_Position: [[1.37414072 0.73428468 0.62397756]]
actor_loss: tensor(0.1702, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1888, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-34.652776394592856, average reward:-0.4950396627798979,success
Box_Position: [[1.41631143 1.06445856 0.67313935]]
actor_loss: tensor(0.1667, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-21.125140851605238, average reward:-0.3250021669477729,success
Box_Position: [[1.36646164 0.9948279  0.72339293]]
actor_loss: tensor(0.2054, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-12.38051742384083, average reward:-0.3346085790227251,success
Box_Position: [[1.43482283 1.10798662 0.63754905]]
actor_loss: tensor(0.1598, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1443, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-44.107812397879016, average reward:-0.4455334585644345,success
Box_Position: [[1.26852311 0.90303743 0.59112894]]
Step:2, total reward:-0.23401623325507617, average reward:-0.11700811662753809,success
Box_Position: [[1.37659335 0.89214241 0.73401506]]
Step:18, total reward:-5.963912678738959, average reward:-0.33132848215216437,success
Box_Position: [[1.53085017 1.11125945 0.48890436]]
actor_loss: tensor(0.1671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1718, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1540, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1448, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-185.86729202236953, average reward:-0.9293364601118477,----
Box_Position: [[1.276603   1.02307639 0.7299693 ]]
Step:16, total reward:-3.871773892373716, average reward:-0.24198586827335725,success
Box_Position: [[1.4207841  0.89084381 0.70156089]]
actor_loss: tensor(0.1728, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1717, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1734, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1555, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-64.57316928793728, average reward:-0.32286584643968635,----
Box_Position: [[1.34454599 0.80962108 0.5768771 ]]
actor_loss: tensor(0.1447, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-23.01798725419098, average reward:-0.8525180464515179,success
Box_Position: [[1.47489432 1.00366283 0.6965074 ]]
actor_loss: tensor(0.1569, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-17.805214210241807, average reward:-0.329726189078552,success
Box_Position: [[1.31513735 0.90955166 0.55602173]]
Step:12, total reward:-2.019581276334965, average reward:-0.16829843969458044,success
Box_Position: [[1.42037306 0.88193631 0.5584433 ]]
actor_loss: tensor(0.1297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1647, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1282, device='cuda:0', grad_fn=<NegBackward>)
Step:155, total reward:-109.6359267152746, average reward:-0.7073285594533846,success
Box_Position: [[1.30997836 1.11698636 0.57936376]]
actor_loss: tensor(0.1417, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1619, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1667, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.55736474028123, average reward:-0.5327868237014062,----
Box_Position: [[1.48125897 1.10413393 0.66246146]]
actor_loss: tensor(0.1344, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-14.47306653909593, average reward:-0.2837856184136457,success
Box_Position: [[1.49091824 0.82958861 0.62608457]]
actor_loss: tensor(0.2148, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-19.30100257561479, average reward:-0.4488605250142974,success
Box_Position: [[1.41661285 0.74302034 0.59313697]]
actor_loss: tensor(0.1352, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-30.88754195734097, average reward:-0.5719915177285365,success
Box_Position: [[1.42086906 0.79282266 0.53408881]]
actor_loss: tensor(0.1426, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-14.355423980108805, average reward:-0.5742169592043522,success
Box_Position: [[1.38007881 0.90646445 0.73634627]]
actor_loss: tensor(0.1482, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1620, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-56.69864219999165, average reward:-0.2834932109999583,----
Box_Position: [[1.25616196 0.74204928 0.5421552 ]]
actor_loss: tensor(0.1521, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-76.88953818103921, average reward:-1.2401538416296647,success
Box_Position: [[1.52633302 0.93145941 0.52169733]]
actor_loss: tensor(0.1200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1630, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1170, device='cuda:0', grad_fn=<NegBackward>)
Step:155, total reward:-121.73527260747747, average reward:-0.7853888555321127,success
Box_Position: [[1.27491823 1.03609597 0.72777115]]
actor_loss: tensor(0.1738, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1310, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1374, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-74.51581147063514, average reward:-0.3725790573531757,----
Box_Position: [[1.49810523 0.91247385 0.57122353]]
actor_loss: tensor(0.1388, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-25.853767356683427, average reward:-0.6463441839170857,success
Box_Position: [[1.34835316 1.00875389 0.58641099]]
actor_loss: tensor(0.1375, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-21.133299123880626, average reward:-0.5154463200946494,success
Box_Position: [[1.48764662 0.61174028 0.66349974]]
actor_loss: tensor(0.1412, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1544, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-45.42466319135304, average reward:-0.3984619578188863,success
Box_Position: [[1.32449743 0.52685992 0.630958  ]]
actor_loss: tensor(0.1084, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1509, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1499, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-90.76632025385743, average reward:-0.4538316012692871,----
Box_Position: [[1.26967542 0.520767   0.46622341]]
Step:7, total reward:-3.013105839554869, average reward:-0.4304436913649813,success
Box_Position: [[1.4517199  0.55892374 0.58667432]]
actor_loss: tensor(0.1207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1297, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-40.62719107329328, average reward:-0.564266542684629,success
Box_Position: [[1.50665557 1.00221028 0.71031811]]
actor_loss: tensor(0.1359, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-26.352535780174236, average reward:-0.32940669725217797,success
Box_Position: [[1.32876219 0.68323359 0.72578991]]
Step:1, total reward:-0.04530582328864626, average reward:-0.04530582328864626,success
Box_Position: [[1.38247498 1.03731136 0.50566591]]
actor_loss: tensor(0.1397, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-36.79280314143705, average reward:-0.8760191224151678,success
Box_Position: [[1.46035958 0.90015686 0.58757911]]
Step:13, total reward:-6.2791593955671905, average reward:-0.4830122611974762,success
Box_Position: [[1.44952041 0.78431536 0.46214636]]
actor_loss: tensor(0.1197, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1222, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-49.460696474548804, average reward:-0.82434494124248,success
Box_Position: [[1.27244782 0.87772476 0.45809462]]
Step:5, total reward:-8.595643643384395, average reward:-1.719128728676879,success
Box_Position: [[1.41725998 1.00393039 0.71899877]]
Step:37, total reward:-8.596539663869766, average reward:-0.232338909834318,success
Box_Position: [[1.39756855 0.77428409 0.51062235]]
actor_loss: tensor(0.1234, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-6.36274156488055, average reward:-0.5302284637400458,success
Box_Position: [[1.30685604 0.67903984 0.56438937]]
Step:12, total reward:-3.7724156746871738, average reward:-0.3143679728905978,success
Box_Position: [[1.51941757 0.95080274 0.52072326]]

------------------Episode:1850------------------
actor_loss: tensor(0.1245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1310, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-49.85653163683883, average reward:-0.6155127362572695,success
Box_Position: [[1.53565524 1.01796002 0.54683951]]
Step:39, total reward:-23.63253007199565, average reward:-0.60596230953835,success
Box_Position: [[1.31613109 0.62808409 0.70636647]]
actor_loss: tensor(0.1359, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1366, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-19.06018624302222, average reward:-0.2541358165736296,success
Box_Position: [[1.52038376 0.80450575 0.5505004 ]]
actor_loss: tensor(0.1448, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1353, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1270, device='cuda:0', grad_fn=<NegBackward>)
Step:153, total reward:-103.28182054675163, average reward:-0.6750445787369388,success
Box_Position: [[1.31050042 0.58615015 0.68250775]]
actor_loss: tensor(0.1367, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-9.87803507538855, average reward:-0.2669739209564473,success
Box_Position: [[1.26447298 0.83398067 0.70904888]]
actor_loss: tensor(0.1298, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-16.022152879893184, average reward:-0.2028120617707998,success
Box_Position: [[1.33093074 0.64485935 0.54279514]]
Step:7, total reward:-5.31013199624624, average reward:-0.7585902851780343,success
Box_Position: [[1.29001371 0.6015759  0.52594157]]
actor_loss: tensor(0.1124, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-14.949305982780828, average reward:-0.5749733070300318,success
Box_Position: [[1.48344956 0.95983375 0.64027477]]
actor_loss: tensor(0.1155, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0966, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-41.41011384803419, average reward:-0.45010993313080644,success
Box_Position: [[1.26811621 0.89896412 0.68754547]]
actor_loss: tensor(0.1360, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1369, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-29.886497429595174, average reward:-0.27931306008967455,success
Box_Position: [[1.52010777 0.72553198 0.6423033 ]]
actor_loss: tensor(0.1277, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1312, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1382, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0934, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-75.33765523823568, average reward:-0.3766882761911784,----
Box_Position: [[1.31140125 1.15726557 0.53206544]]
Step:21, total reward:-13.162374452763384, average reward:-0.6267797358458754,success
Box_Position: [[1.30402175 0.93416108 0.53838212]]
actor_loss: tensor(0.1179, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-32.35335216302292, average reward:-0.548361901068185,success
Box_Position: [[1.28491281 0.95537377 0.54044543]]
actor_loss: tensor(0.1365, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-14.223978569215625, average reward:-0.568959142768625,success
Box_Position: [[1.30925705 0.58610426 0.68014766]]
actor_loss: tensor(0.1107, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-10.771515292029294, average reward:-0.1958457325823508,success
Box_Position: [[1.51822543 0.75598585 0.6865491 ]]
actor_loss: tensor(0.1270, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-10.744968267044307, average reward:-0.3581656089014769,success
Box_Position: [[1.51150306 0.46350702 0.6431177 ]]
actor_loss: tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1166, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-50.022391162494195, average reward:-0.5496966061812549,success
Box_Position: [[1.41343528 0.75841549 0.60692769]]
actor_loss: tensor(0.1426, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-30.97721046810311, average reward:-0.5736520457056131,success
Box_Position: [[1.32259628 1.14026237 0.65222145]]
actor_loss: tensor(0.1185, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1190, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1045, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-71.23067430744854, average reward:-0.3561533715372427,----
Box_Position: [[1.42863862 1.14498874 0.48324701]]
actor_loss: tensor(0.1317, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-65.61938972313214, average reward:-0.9649910253401786,success
Box_Position: [[1.50049533 0.45920825 0.64792508]]
actor_loss: tensor(0.1317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1428, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1430, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-85.98520284620159, average reward:-0.42992601423100796,----
Box_Position: [[1.35622346 0.60847557 0.45707132]]
actor_loss: tensor(0.1183, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-34.80317299396292, average reward:-0.6692917883454407,success
Box_Position: [[1.53064857 0.72926397 0.68704785]]
Step:25, total reward:-6.613230757866423, average reward:-0.2645292303146569,success
Box_Position: [[1.42337157 0.89094568 0.63671705]]
actor_loss: tensor(0.1003, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-6.631811315216088, average reward:-0.552650942934674,success
Box_Position: [[1.31577239 0.69852754 0.53388254]]
Step:6, total reward:-1.193747314045931, average reward:-0.19895788567432182,success
Box_Position: [[1.48768243 1.06656151 0.56426496]]
actor_loss: tensor(0.0863, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-27.022725517815037, average reward:-0.7720778719375725,success
Box_Position: [[1.39016084 0.53986847 0.65192929]]
Step:26, total reward:-9.774360113429097, average reward:-0.3759369274395806,success
Box_Position: [[1.45076535 1.01626561 0.49632214]]
Step:6, total reward:-3.128966858818752, average reward:-0.521494476469792,success
Box_Position: [[1.42075935 0.61944017 0.49009984]]
actor_loss: tensor(0.1003, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-56.25513043251218, average reward:-1.0228205533184034,success
Box_Position: [[1.46840351 0.84692819 0.62206536]]
actor_loss: tensor(0.0964, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0935, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0987, device='cuda:0', grad_fn=<NegBackward>)
Step:159, total reward:-60.37355757649995, average reward:-0.3797079092861632,success
Box_Position: [[1.41731967 1.03026584 0.62889326]]
actor_loss: tensor(0.1270, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1224, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1017, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-50.761444596981484, average reward:-0.44527582979808317,success
Box_Position: [[1.38054339 0.65784641 0.46687618]]
Step:22, total reward:-17.130355783884948, average reward:-0.778652535631134,success
Box_Position: [[1.45347712 0.72690609 0.52722548]]
actor_loss: tensor(0.1194, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-25.98675218640296, average reward:-0.649668804660074,success
Box_Position: [[1.26716229 0.75182231 0.67326601]]
actor_loss: tensor(0.1116, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1024, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-43.21765609491057, average reward:-0.41159672471343406,success
Box_Position: [[1.43243647 0.96829657 0.71400983]]
actor_loss: tensor(0.1292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1066, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-29.765766365240243, average reward:-0.25660143418310555,success
Box_Position: [[1.4436658  0.72220622 0.72616734]]
actor_loss: tensor(0.1172, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-15.188868926412141, average reward:-0.2978209593414145,success
Box_Position: [[1.54157486 0.97980363 0.47390717]]
actor_loss: tensor(0.1117, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1004, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-47.44089365194423, average reward:-0.7298599023376036,success
Box_Position: [[1.39468902 0.72128656 0.48968635]]
actor_loss: tensor(0.1251, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-29.256911033304654, average reward:-0.6360198050718403,success
Box_Position: [[1.25580491 0.84837037 0.65296989]]
actor_loss: tensor(0.1283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1257, device='cuda:0', grad_fn=<NegBackward>)
Step:93, total reward:-40.13684704047938, average reward:-0.43157900043526215,success
Box_Position: [[1.2569712  0.95508974 0.72181194]]
actor_loss: tensor(0.1030, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-18.558962355040627, average reward:-0.23492357411443832,success
Box_Position: [[1.38626785 0.94107125 0.55958828]]
actor_loss: tensor(0.1002, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-7.489516916141483, average reward:-0.24965056387138276,success
Box_Position: [[1.53789308 0.43787885 0.60760978]]
Step:9, total reward:-1.852264355994016, average reward:-0.20580715066600178,success
Box_Position: [[1.42699177 0.7607662  0.5510522 ]]
Step:28, total reward:-10.676329225600742, average reward:-0.38129747234288364,success
Box_Position: [[1.4866174  0.71811636 0.64266777]]
actor_loss: tensor(0.1309, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1377, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1373, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-71.4729431063273, average reward:-0.3573647155316365,----
Box_Position: [[1.28111433 1.10611286 0.55485117]]
actor_loss: tensor(0.1167, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-9.1034743866992, average reward:-0.27586286020300604,success
Box_Position: [[1.32560067 1.02359397 0.65284472]]
actor_loss: tensor(0.1279, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0995, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-30.757950916779876, average reward:-0.2770986569079268,success
Box_Position: [[1.53815243 0.66045906 0.72249435]]
actor_loss: tensor(0.1050, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-9.24341859207232, average reward:-0.28885683100226,success
Box_Position: [[1.37564531 0.65388782 0.63479996]]
actor_loss: tensor(0.0996, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-26.871770969409713, average reward:-0.47985305302517345,success
Box_Position: [[1.47513832 0.45886606 0.72123602]]
actor_loss: tensor(0.1001, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-17.941536955086683, average reward:-0.3517948422566016,success
Box_Position: [[1.34163175 0.88809714 0.70415508]]
actor_loss: tensor(0.1006, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-10.222461655795657, average reward:-0.1965858010729934,success
Box_Position: [[1.26041009 0.77783442 0.60126915]]

------------------Episode:1900------------------
actor_loss: tensor(0.0990, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0982, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1116, device='cuda:0', grad_fn=<NegBackward>)
Step:164, total reward:-95.50175402191591, average reward:-0.5823277684263165,success
episode 1900, the accuracy is: 86%
Box_Position: [[1.42712456 0.8228851  0.58118899]]
actor_loss: tensor(0.1001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0964, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-14.736628919801834, average reward:-0.26315408785360417,success
Box_Position: [[1.34308605 0.73786787 0.69320152]]
Step:6, total reward:-0.9369605118205082, average reward:-0.15616008530341804,success
Box_Position: [[1.30351492 0.4789806  0.50116436]]
actor_loss: tensor(0.1091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0847, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-77.73557737711774, average reward:-0.8269742274161461,success
Box_Position: [[1.36085641 0.74021993 0.60434196]]
Step:11, total reward:-3.9044762139542333, average reward:-0.3549523830867485,success
Box_Position: [[1.34186041 0.71668451 0.57895442]]
Step:19, total reward:-19.151696193629668, average reward:-1.0079840101910351,success
Box_Position: [[1.42587221 0.66833988 0.56460715]]
actor_loss: tensor(0.1094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1031, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-31.693094039673834, average reward:-0.40117840556549156,success
Box_Position: [[1.52565954 0.88158841 0.70604548]]
actor_loss: tensor(0.1087, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-18.34358765380304, average reward:-0.29586431699682325,success
Box_Position: [[1.54437134 0.78346291 0.54774569]]
Step:17, total reward:-11.420006380001203, average reward:-0.6717650811765413,success
Box_Position: [[1.30664335 0.92899376 0.66165622]]
actor_loss: tensor(0.0860, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0896, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1247, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-78.37812489636094, average reward:-0.39189062448180473,----
Box_Position: [[1.52038785 1.01678442 0.54786512]]
actor_loss: tensor(0.1248, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1174, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1248, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1316, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-97.16019088065111, average reward:-0.48580095440325555,----
Box_Position: [[1.31094987 0.90463957 0.47613468]]
actor_loss: tensor(0.1361, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-19.047168328089256, average reward:-0.5147883331916016,success
Box_Position: [[1.46715073 0.88551909 0.68519502]]
actor_loss: tensor(0.1093, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-13.66989432111225, average reward:-0.30377542935805,success
Box_Position: [[1.40405618 0.46761597 0.45531865]]
actor_loss: tensor(0.1403, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-63.23776759058134, average reward:-0.8107406101356582,success
Box_Position: [[1.32849028 0.90943979 0.48407687]]
actor_loss: tensor(0.1214, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-19.60737573897534, average reward:-0.4084869945619862,success
Box_Position: [[1.51267492 0.67126683 0.62106981]]
actor_loss: tensor(0.1039, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-4.409270391442845, average reward:-0.3149478851030603,success
Box_Position: [[1.48478689 0.80679501 0.51401924]]
actor_loss: tensor(0.1160, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-35.844295807711156, average reward:-0.6637832556983547,success
Box_Position: [[1.30229802 0.97079048 0.48386124]]
Step:29, total reward:-18.835868760271794, average reward:-0.6495127158714411,success
Box_Position: [[1.51626956 0.53470717 0.6925336 ]]
actor_loss: tensor(0.1298, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-13.069926582246609, average reward:-0.30395178098247927,success
Box_Position: [[1.28854612 0.78444146 0.57598931]]
actor_loss: tensor(0.1188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1307, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1221, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-80.00853754257231, average reward:-0.610752194981468,success
Box_Position: [[1.28255245 0.68336999 0.65761633]]
actor_loss: tensor(0.1107, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-19.94523824659897, average reward:-0.2659365099546529,success
Box_Position: [[1.53268588 0.82582912 0.515736  ]]
actor_loss: tensor(0.0866, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-16.08752288607835, average reward:-1.0054701803798969,success
Box_Position: [[1.47102765 0.79038413 0.74873124]]
Step:3, total reward:-0.4286687251153344, average reward:-0.1428895750384448,success
Box_Position: [[1.2643863  1.12581897 0.71912913]]
actor_loss: tensor(0.1067, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-9.98865410713851, average reward:-0.24971635267846276,success
Box_Position: [[1.33418362 0.8350566  0.71152357]]
Step:24, total reward:-6.474083374316353, average reward:-0.26975347392984805,success
Box_Position: [[1.36624092 0.83649765 0.46553174]]
Step:4, total reward:-6.2866638435017865, average reward:-1.5716659608754466,success
Box_Position: [[1.30401692 0.87446345 0.59443825]]
actor_loss: tensor(0.1127, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1355, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-33.169659585217794, average reward:-0.4364428892791815,success
Box_Position: [[1.45178126 0.43898516 0.53514525]]
actor_loss: tensor(0.0969, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0982, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-64.28198218754648, average reward:-0.6493129513893583,success
Box_Position: [[1.31120473 1.1427106  0.55263629]]
actor_loss: tensor(0.1162, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1300, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1576, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-83.88343560175439, average reward:-0.41941717800877193,----
Box_Position: [[1.53407841 0.95742596 0.54406207]]
Step:6, total reward:-1.2577067068615007, average reward:-0.20961778447691679,success
Box_Position: [[1.41187348 0.48861537 0.55114747]]
Step:11, total reward:-10.066554049864735, average reward:-0.9151412772604304,success
Box_Position: [[1.54448304 1.13656551 0.5633768 ]]
actor_loss: tensor(0.1152, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1215, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1059, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1035, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-117.82089073781378, average reward:-0.5891044536890689,----
Box_Position: [[1.4005667  0.59944027 0.65603847]]
Step:17, total reward:-7.323671231038229, average reward:-0.4308041900610723,success
Box_Position: [[1.53289982 0.74923396 0.46810597]]
actor_loss: tensor(0.1091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0979, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-69.96709378575646, average reward:-0.8637912813056353,success
Box_Position: [[1.42252912 0.7256926  0.56317973]]
Step:2, total reward:-0.2249289507112252, average reward:-0.1124644753556126,success
Box_Position: [[1.43747132 0.67504574 0.72280412]]
Step:20, total reward:-6.135778501242907, average reward:-0.30678892506214533,success
Box_Position: [[1.33446041 0.7010336  0.71468022]]
actor_loss: tensor(0.1079, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-2.3147169596650774, average reward:-0.15431446397767182,success
Box_Position: [[1.46086059 0.67224921 0.60756091]]
Step:39, total reward:-18.143243701322575, average reward:-0.4652113769569891,success
Box_Position: [[1.30934379 0.67235362 0.62841022]]
actor_loss: tensor(0.1296, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-11.454167031410616, average reward:-0.2793699275953809,success
Box_Position: [[1.44773384 0.76756941 0.64630839]]
actor_loss: tensor(0.1252, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-13.551694067924396, average reward:-0.5019145951083109,success
Box_Position: [[1.43760416 1.02296397 0.60144353]]
Step:10, total reward:-4.029877408437149, average reward:-0.4029877408437149,success
Box_Position: [[1.53139197 0.80344385 0.68359527]]
actor_loss: tensor(0.1125, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1022, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1080, device='cuda:0', grad_fn=<NegBackward>)
Step:165, total reward:-56.11611692168286, average reward:-0.34009767831322946,success
Box_Position: [[1.25036955 0.68419555 0.71012303]]
actor_loss: tensor(0.1160, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0965, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-27.075363392340936, average reward:-0.28203503533688473,success
Box_Position: [[1.26910195 1.05081321 0.51915625]]
actor_loss: tensor(0.1187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0985, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0997, device='cuda:0', grad_fn=<NegBackward>)
Step:150, total reward:-96.1791356271937, average reward:-0.6411942375146247,success
Box_Position: [[1.45955403 0.87398652 0.72161995]]
actor_loss: tensor(0.1286, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1365, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-21.277202289417364, average reward:-0.26596502861771704,success
Box_Position: [[1.53453604 0.79875962 0.55040667]]
Step:8, total reward:-3.169022789883289, average reward:-0.3961278487354111,success
Box_Position: [[1.4593216  0.94632578 0.74302606]]
Step:25, total reward:-6.060789646225602, average reward:-0.24243158584902408,success
Box_Position: [[1.3507051  0.54382638 0.47516952]]
actor_loss: tensor(0.1251, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1402, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1327, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-210.73547260125184, average reward:-1.0536773630062592,----
Box_Position: [[1.5081946  0.86959789 0.66637868]]
actor_loss: tensor(0.1568, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-0.7850306184846353, average reward:-0.15700612369692707,success
Box_Position: [[1.36612143 0.55797109 0.74237945]]
actor_loss: tensor(0.1117, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-14.946211246340203, average reward:-0.22645774615666975,success
Box_Position: [[1.33092981 0.84325996 0.45402172]]

------------------Episode:1950------------------
actor_loss: tensor(0.1155, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1248, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1411, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-104.28565140223093, average reward:-0.778251129867395,success
Box_Position: [[1.39263341 1.05191408 0.62779939]]
actor_loss: tensor(0.1334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1285, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1502, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-73.7003270812698, average reward:-0.368501635406349,----
Box_Position: [[1.46713108 0.93766996 0.72198553]]
Step:11, total reward:-2.4541685195662044, average reward:-0.22310622905147312,success
Box_Position: [[1.27258195 0.69966085 0.53107593]]
Step:18, total reward:-8.824131194011676, average reward:-0.4902295107784264,success
Box_Position: [[1.33906898 0.7984194  0.51052865]]
actor_loss: tensor(0.1378, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-34.999242313100105, average reward:-0.5932074968322052,success
Box_Position: [[1.2748713  0.8917775  0.51572333]]
actor_loss: tensor(0.1111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1613, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1041, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1299, device='cuda:0', grad_fn=<NegBackward>)
Step:159, total reward:-117.72912593930121, average reward:-0.7404347543352278,success
Box_Position: [[1.52912386 0.92089691 0.61701894]]
Step:16, total reward:-5.000977899756188, average reward:-0.3125611187347617,success
Box_Position: [[1.51463288 0.48737531 0.60087868]]
Step:4, total reward:-0.918362412552071, average reward:-0.22959060313801774,success
Box_Position: [[1.31467748 0.82337379 0.47628747]]
actor_loss: tensor(0.1804, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-35.27198991899852, average reward:-0.7667823895434461,success
Box_Position: [[1.43051319 1.04534494 0.65769664]]
actor_loss: tensor(0.1487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1156, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1587, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-61.122835063518124, average reward:-0.3056141753175906,----
Box_Position: [[1.31943021 0.83770955 0.72413097]]
Step:14, total reward:-2.795829505499549, average reward:-0.19970210753568204,success
Box_Position: [[1.27530464 0.82703355 0.61076299]]
Step:14, total reward:-6.400656501940195, average reward:-0.45718975013858537,success
Box_Position: [[1.38832961 0.79556568 0.52468441]]
Step:1, total reward:-0.024764391849943973, average reward:-0.024764391849943973,success
Box_Position: [[1.43259528 0.61082277 0.7009875 ]]
actor_loss: tensor(0.1696, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1424, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1016, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1033, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-51.77336321936859, average reward:-0.258866816096843,----
Box_Position: [[1.51532219 0.87332473 0.70811733]]
actor_loss: tensor(0.1291, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1335, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-23.27962379577898, average reward:-0.332566054225414,success
Box_Position: [[1.46105096 0.6561271  0.58864119]]
actor_loss: tensor(0.1248, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-16.70270207427448, average reward:-0.3553766398781804,success
Box_Position: [[1.25911125 0.63429777 0.52759987]]
actor_loss: tensor(0.1503, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-26.45006293441421, average reward:-0.6451234862052246,success
Box_Position: [[1.51244482 0.64002289 0.5944932 ]]
actor_loss: tensor(0.1256, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-21.857564104427908, average reward:-0.34694546197504617,success
Box_Position: [[1.34910429 0.53392131 0.5718323 ]]
actor_loss: tensor(0.1501, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1432, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1548, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1422, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-87.91220626573883, average reward:-0.4395610313286942,----
Box_Position: [[1.4972048  1.03404406 0.55223155]]
Step:9, total reward:-1.5460308802939051, average reward:-0.17178120892154503,success
Box_Position: [[1.53653592 0.71640427 0.48793226]]
actor_loss: tensor(0.1275, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-28.120210016627198, average reward:-0.9696624143664551,success
Box_Position: [[1.30026308 0.64675624 0.53408242]]
Step:24, total reward:-22.054538595630344, average reward:-0.9189391081512643,success
Box_Position: [[1.46657179 0.93523659 0.74344601]]
actor_loss: tensor(0.1332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1302, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-16.917996246974827, average reward:-0.2255732832929977,success
Box_Position: [[1.26793924 1.00077197 0.64963867]]
Step:17, total reward:-2.744916619108213, average reward:-0.1614656834769537,success
Box_Position: [[1.29423526 0.96426781 0.50389655]]
actor_loss: tensor(0.1379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1211, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-133.54765241703987, average reward:-0.7764398396339527,success
Box_Position: [[1.28631561 0.47953883 0.65131238]]
actor_loss: tensor(0.1381, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-7.450894315712065, average reward:-0.3921523324058982,success
Box_Position: [[1.52113518 0.94125993 0.67916416]]
Step:37, total reward:-16.66353249349979, average reward:-0.4503657430675619,success
Box_Position: [[1.53120278 0.86018422 0.52302432]]
actor_loss: tensor(0.1376, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-28.40201884634784, average reward:-0.7282568934960985,success
Box_Position: [[1.39052047 0.59264319 0.50223751]]
actor_loss: tensor(0.1545, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1396, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1345, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1474, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-141.7031223074346, average reward:-0.708515611537173,----
Box_Position: [[1.41134489 0.83521714 0.50503553]]
actor_loss: tensor(0.1266, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-31.4706551102271, average reward:-0.8281751344796605,success
Box_Position: [[1.26893284 0.63045526 0.69911739]]
actor_loss: tensor(0.1120, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-4.450968433992864, average reward:-0.17803873735971457,success
Box_Position: [[1.39681255 0.77710029 0.69349768]]
Step:16, total reward:-5.102540097449991, average reward:-0.3189087560906244,success
Box_Position: [[1.3159157  0.5980874  0.70531766]]
Step:19, total reward:-3.4122757934975017, average reward:-0.179593462815658,success
Box_Position: [[1.5264891  0.78343731 0.73000008]]
Step:13, total reward:-2.3616049668012318, average reward:-0.18166192052317168,success
Box_Position: [[1.26584428 0.65715307 0.53550326]]
actor_loss: tensor(0.1242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1349, device='cuda:0', grad_fn=<NegBackward>)
Step:95, total reward:-42.19378070485021, average reward:-0.44414506005105486,success
Box_Position: [[1.25776933 1.02144304 0.6845847 ]]
actor_loss: tensor(0.1101, device='cuda:0', grad_fn=<NegBackward>)
Step:7, total reward:-1.5171819943837406, average reward:-0.21674028491196293,success
Box_Position: [[1.30002817 0.9747998  0.56410284]]
Step:9, total reward:-3.153680161402663, average reward:-0.3504089068225181,success
Box_Position: [[1.46249821 1.02598292 0.64053437]]
Step:27, total reward:-7.845895301158729, average reward:-0.2905887148577307,success
Box_Position: [[1.37672924 0.89510382 0.74174858]]
actor_loss: tensor(0.1111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1190, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-23.818834143119272, average reward:-0.2205447605844377,success
Box_Position: [[1.4951457  0.84498321 0.60454304]]
actor_loss: tensor(0.1331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1252, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-32.534304661493344, average reward:-0.38275652542933347,success
Box_Position: [[1.30053852 0.41132782 0.68263577]]
actor_loss: tensor(0.1057, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1758, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1157, device='cuda:0', grad_fn=<NegBackward>)
Step:174, total reward:-54.14357709299743, average reward:-0.3111699832930887,success
Box_Position: [[1.50044595 0.91451628 0.60164193]]
Step:33, total reward:-15.48217609277828, average reward:-0.4691568512963115,success
Box_Position: [[1.46290693 0.53253971 0.70005661]]
actor_loss: tensor(0.1386, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1593, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1156, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1568, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-57.666886339215964, average reward:-0.2883344316960798,----
Box_Position: [[1.42553287 1.05730486 0.46631684]]
actor_loss: tensor(0.0883, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-11.072061267798965, average reward:-0.5827400667262613,success
Box_Position: [[1.41627217 1.08199949 0.49045027]]
Step:12, total reward:-6.244514473047475, average reward:-0.5203762060872895,success
Box_Position: [[1.4772384  0.91408388 0.68379738]]
Step:4, total reward:-0.6234433438109819, average reward:-0.15586083595274547,success
Box_Position: [[1.44353354 0.79788731 0.48997075]]
Step:23, total reward:-17.96804587595329, average reward:-0.7812193859110126,success
Box_Position: [[1.32114112 0.94274178 0.46599642]]
actor_loss: tensor(0.1466, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-17.015438322736024, average reward:-0.7398016662059141,success
Box_Position: [[1.28336317 1.00451119 0.49472815]]
actor_loss: tensor(0.1212, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-30.076751114917528, average reward:-0.6538424155416854,success
Box_Position: [[1.52312555 0.82716322 0.52635984]]
actor_loss: tensor(0.1490, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-25.877646934229023, average reward:-0.663529408569975,success
Box_Position: [[1.33073155 0.71632443 0.46897491]]

------------------Episode:2000------------------
Step:8, total reward:-5.153401232066322, average reward:-0.6441751540082903,success
episode 2000, the accuracy is: 89%
Box_Position: [[1.45549095 0.66414937 0.57837679]]
Step:14, total reward:-4.65724626329094, average reward:-0.3326604473779243,success
Box_Position: [[1.30490039 0.91750104 0.64891281]]
Step:9, total reward:-3.5542577783334393, average reward:-0.3949175309259377,success
Box_Position: [[1.2747263  0.89964937 0.67240133]]
actor_loss: tensor(0.1509, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1432, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-22.8141891043214, average reward:-0.21936720292616732,success
Box_Position: [[1.48803249 1.01398819 0.58408266]]
actor_loss: tensor(0.1132, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1382, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1255, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-80.85711107638014, average reward:-0.5117538675720261,success
Box_Position: [[1.33514834 0.84940575 0.74479887]]
actor_loss: tensor(0.1351, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1543, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1354, device='cuda:0', grad_fn=<NegBackward>)
Step:127, total reward:-34.006739827754714, average reward:-0.2677696049429505,success
Box_Position: [[1.3873152  1.01274964 0.7147712 ]]
actor_loss: tensor(0.1508, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-7.504102555838174, average reward:-0.2587621570978681,success
Box_Position: [[1.44417499 1.02845137 0.58187179]]
actor_loss: tensor(0.1333, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-24.634773796375057, average reward:-0.40384875076024684,success
Box_Position: [[1.29266463 0.52976868 0.66557799]]
actor_loss: tensor(0.1398, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-24.642822489771465, average reward:-0.29336693440204126,success
Box_Position: [[1.48365287 0.8475854  0.47562396]]
actor_loss: tensor(0.1339, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-46.137933884081775, average reward:-1.048589406456404,success
Box_Position: [[1.52662001 0.98376426 0.50738149]]
actor_loss: tensor(0.1471, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-19.13110544067387, average reward:-0.546603012590682,success
Box_Position: [[1.28092106 0.75436304 0.50893991]]
actor_loss: tensor(0.1265, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-19.692962792248007, average reward:-0.504947763903795,success
Box_Position: [[1.49771269 0.96865627 0.71681551]]
actor_loss: tensor(0.1386, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-14.584252167906408, average reward:-0.19445669557208545,success
Box_Position: [[1.35550841 0.88383245 0.468276  ]]
Step:6, total reward:-2.827014206357052, average reward:-0.471169034392842,success
Box_Position: [[1.34663697 0.86592664 0.54719761]]
actor_loss: tensor(0.1562, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-32.07347962562145, average reward:-0.6051599929362538,success
Box_Position: [[1.27629757 0.69179326 0.72235348]]
actor_loss: tensor(0.1412, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1438, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1336, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-45.18134569472903, average reward:-0.32740105575890605,success
Box_Position: [[1.44228124 1.01115432 0.58203574]]
actor_loss: tensor(0.1012, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-10.570426614499237, average reward:-0.4228170645799695,success
Box_Position: [[1.27219225 0.60042659 0.71449267]]
Step:6, total reward:-1.1853895787088997, average reward:-0.19756492978481663,success
Box_Position: [[1.30773705 0.51650406 0.59045602]]
Step:20, total reward:-5.745454285741206, average reward:-0.2872727142870603,success
Box_Position: [[1.36583676 0.77613689 0.51353897]]
Step:12, total reward:-8.136647535378387, average reward:-0.6780539612815323,success
Box_Position: [[1.26844322 0.71957621 0.54476822]]
actor_loss: tensor(0.1328, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-1.6157112003551248, average reward:-0.14688283639592045,success
Box_Position: [[1.50902273 0.63494176 0.65103568]]
actor_loss: tensor(0.1531, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-30.99087750114323, average reward:-0.5436996052832146,success
Box_Position: [[1.30969427 0.65402366 0.66876788]]
actor_loss: tensor(0.1155, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1726, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1264, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-70.15585869287969, average reward:-0.35077929346439846,----
Box_Position: [[1.42242111 0.95290287 0.55843208]]
actor_loss: tensor(0.1192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1216, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-41.514293170129925, average reward:-0.4771757835647118,success
Box_Position: [[1.54471904 0.83308179 0.71467895]]
Step:13, total reward:-2.8005629920234205, average reward:-0.21542792246334003,success
Box_Position: [[1.44890538 0.83376451 0.55903915]]
actor_loss: tensor(0.1331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1326, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-77.5819256789175, average reward:-0.62065540543134,success
Box_Position: [[1.47484151 1.01361761 0.56452006]]
Step:5, total reward:-3.184396266632724, average reward:-0.6368792533265448,success
Box_Position: [[1.43065605 0.64533958 0.64023722]]
actor_loss: tensor(0.1283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1009, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-20.72979983280721, average reward:-0.3290444417905906,success
Box_Position: [[1.29697627 0.68792883 0.53337063]]
Step:9, total reward:-4.18524554410021, average reward:-0.46502728267780113,success
Box_Position: [[1.29517011 0.54849292 0.71263693]]
actor_loss: tensor(0.1137, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-13.705071516058887, average reward:-0.3045571448013086,success
Box_Position: [[1.4827938  0.80753363 0.68494774]]
Step:1, total reward:-0.03536413445777444, average reward:-0.03536413445777444,success
Box_Position: [[1.45263834 0.52444552 0.62957493]]
actor_loss: tensor(0.1309, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-11.33021566888017, average reward:-0.31472821302444914,success
Box_Position: [[1.46029817 0.71055237 0.72184581]]
Step:13, total reward:-4.273512596699629, average reward:-0.3287317382076637,success
Box_Position: [[1.50491686 0.62307935 0.64313692]]
actor_loss: tensor(0.1159, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-29.15335680823518, average reward:-0.5500633360044374,success
Box_Position: [[1.33534841 0.77306848 0.45288107]]
actor_loss: tensor(0.1028, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-35.410053624799225, average reward:-0.8636598445072982,success
Box_Position: [[1.49877473 0.99177106 0.60680623]]
Step:18, total reward:-7.8040271620861414, average reward:-0.4335570645603412,success
Box_Position: [[1.26303163 0.67367172 0.55125369]]
actor_loss: tensor(0.1091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1170, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0889, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1238, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-122.09828820898153, average reward:-0.6104914410449076,----
Box_Position: [[1.48040884 0.88662553 0.46463085]]
Step:5, total reward:-6.715235581116962, average reward:-1.3430471162233926,success
Box_Position: [[1.49803223 1.07753327 0.64745286]]
Step:17, total reward:-7.3557131669046125, average reward:-0.43268900981791836,success
Box_Position: [[1.35834023 0.85605623 0.49174308]]
actor_loss: tensor(0.1072, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-36.19520470698375, average reward:-0.738677647081301,success
Box_Position: [[1.34515981 0.69880712 0.55642704]]
Step:1, total reward:-0.02976776304179325, average reward:-0.02976776304179325,success
Box_Position: [[1.52759623 0.88539904 0.7046817 ]]
actor_loss: tensor(0.1049, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-1.874623068640332, average reward:-0.1874623068640332,success
Box_Position: [[1.52685052 0.92750357 0.53402703]]
Step:33, total reward:-22.286567896464472, average reward:-0.6753505423171052,success
Box_Position: [[1.45371369 0.77838496 0.53563746]]
actor_loss: tensor(0.1194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0946, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-30.721505508665263, average reward:-0.49550815336556875,success
Box_Position: [[1.53397485 0.82682182 0.53956202]]
actor_loss: tensor(0.1080, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-33.66178682833361, average reward:-0.601103336220243,success
Box_Position: [[1.4496479  0.98132254 0.50084222]]
actor_loss: tensor(0.1029, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0936, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1166, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-93.46210216311428, average reward:-0.6445662218145812,success
Box_Position: [[1.35966258 1.0631137  0.55934268]]
actor_loss: tensor(0.1210, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-21.98993452983346, average reward:-0.3331808262095979,success
Box_Position: [[1.44188204 0.65025083 0.64097866]]
Step:4, total reward:-0.6748014369420815, average reward:-0.16870035923552038,success
Box_Position: [[1.29797751 1.08291916 0.65070493]]
actor_loss: tensor(0.1122, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1370, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1110, device='cuda:0', grad_fn=<NegBackward>)
Step:188, total reward:-54.596809107261635, average reward:-0.2904085590811789,success
Box_Position: [[1.51541758 0.55798352 0.50406637]]
actor_loss: tensor(0.1414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1128, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1106, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-114.37902140172827, average reward:-0.783417954806358,success
Box_Position: [[1.48382318 0.7536246  0.49337248]]

------------------Episode:2050------------------
actor_loss: tensor(0.1296, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-52.3382404621998, average reward:-0.6015889708298827,success
Box_Position: [[1.40617958 1.06249826 0.57126156]]
actor_loss: tensor(0.1071, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-7.782675565369912, average reward:-0.6485562971141593,success
Box_Position: [[1.5471918  0.98899099 0.58225765]]
actor_loss: tensor(0.1124, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-36.61437182023917, average reward:-0.5156953777498475,success
Box_Position: [[1.25030367 0.68775836 0.69126606]]
actor_loss: tensor(0.1109, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1469, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1320, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-63.81897765062971, average reward:-0.3190948882531486,----
Box_Position: [[1.2928653  0.76625063 0.50219931]]
actor_loss: tensor(0.1328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1409, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1413, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-89.78267339491818, average reward:-0.6853639190451769,success
Box_Position: [[1.30008344 0.90473421 0.49778217]]
actor_loss: tensor(0.1206, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-48.88973126255672, average reward:-0.7189666362140694,success
Box_Position: [[1.34490306 0.95094838 0.68465187]]
Step:8, total reward:-1.576840782489845, average reward:-0.19710509781123062,success
Box_Position: [[1.50189381 0.98617268 0.56602969]]
actor_loss: tensor(0.1366, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-13.821464919125104, average reward:-0.6910732459562552,success
Box_Position: [[1.38274466 0.47129492 0.67374626]]
Step:7, total reward:-1.3412584030732482, average reward:-0.19160834329617832,success
Box_Position: [[1.32030549 0.92553926 0.70625275]]
actor_loss: tensor(0.1310, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1548, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1437, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0856, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-47.540159324877536, average reward:-0.23770079662438767,----
Box_Position: [[1.42782171 0.62152632 0.58260909]]
actor_loss: tensor(0.1324, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-31.69455310763685, average reward:-0.70432340239193,success
Box_Position: [[1.35171449 0.94704739 0.57417716]]
actor_loss: tensor(0.1354, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-33.932002841016654, average reward:-0.5472903684034944,success
Box_Position: [[1.44377161 0.62606292 0.56447055]]
Step:7, total reward:-1.0295217569433728, average reward:-0.1470745367061961,success
Box_Position: [[1.50063253 0.71946108 0.45025827]]
actor_loss: tensor(0.1445, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-19.05373377242759, average reward:-0.7939055738511497,success
Box_Position: [[1.36053182 1.12724063 0.57944508]]
actor_loss: tensor(0.1180, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-32.958336182435986, average reward:-0.37031838407231443,success
Box_Position: [[1.40813656 0.60240958 0.60697639]]
actor_loss: tensor(0.1226, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1309, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-35.99548416868173, average reward:-0.4090395928259287,success
Box_Position: [[1.32021782 0.82917823 0.7012542 ]]
actor_loss: tensor(0.1296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1256, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1296, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-60.83672973268323, average reward:-0.3041836486634162,----
Box_Position: [[1.47461072 0.703716   0.69772354]]
Step:16, total reward:-4.146348876520884, average reward:-0.25914680478255525,success
Box_Position: [[1.40173627 0.79690311 0.48291294]]
actor_loss: tensor(0.1201, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-33.810835043325774, average reward:-1.2522531497528064,success
Box_Position: [[1.46991723 0.70560878 0.71246792]]
actor_loss: tensor(0.1487, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-16.423853925689663, average reward:-0.32847707851379326,success
Box_Position: [[1.27667623 0.44596483 0.48630324]]
actor_loss: tensor(0.1357, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-21.610344844390745, average reward:-0.6753232763872108,success
Box_Position: [[1.54198002 1.01188366 0.71280186]]
Step:4, total reward:-0.7242464584106579, average reward:-0.18106161460266448,success
Box_Position: [[1.27314604 0.72615173 0.58203922]]
actor_loss: tensor(0.1452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1539, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-68.517645217188, average reward:-0.6228876837926183,success
Box_Position: [[1.29649924 0.80695078 0.68885523]]
actor_loss: tensor(0.1493, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1381, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1432, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1259, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-66.28286536976368, average reward:-0.33141432684881844,----
Box_Position: [[1.25405708 0.89596859 0.5853173 ]]
actor_loss: tensor(0.1508, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1326, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1461, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1495, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-92.39624871526111, average reward:-0.46198124357630554,----
Box_Position: [[1.2588645  0.87904404 0.56409057]]
actor_loss: tensor(0.1564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1570, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1388, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1396, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.87913939381856, average reward:-0.5343956969690928,----
Box_Position: [[1.34586739 0.86013409 0.59130292]]
actor_loss: tensor(0.1474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1115, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1236, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1305, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-87.69882653557312, average reward:-0.4384941326778656,----
Box_Position: [[1.42974241 0.75249848 0.57748631]]
actor_loss: tensor(0.1357, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-33.017176384499635, average reward:-0.402648492493898,success
Box_Position: [[1.26291108 1.04146985 0.58368387]]
actor_loss: tensor(0.0974, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1079, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0856, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-90.12127988480164, average reward:-0.4506063994240082,----
Box_Position: [[1.38107702 0.86904487 0.67523377]]
actor_loss: tensor(0.1284, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1357, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0845, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-57.43831428214608, average reward:-0.28719157141073043,----
Box_Position: [[1.53256204 0.92275579 0.69798156]]
actor_loss: tensor(0.1019, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-10.740955925896216, average reward:-0.29029610610530315,success
Box_Position: [[1.53717355 0.74767007 0.59321505]]
Step:2, total reward:-0.1274344450757773, average reward:-0.06371722253788865,success
Box_Position: [[1.39923848 1.10066241 0.51275905]]
actor_loss: tensor(0.0886, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-9.081366315092888, average reward:-0.3948420136996908,success
Box_Position: [[1.26255822 1.03534544 0.64046678]]
actor_loss: tensor(0.1128, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1255, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1177, device='cuda:0', grad_fn=<NegBackward>)
Step:144, total reward:-36.49781125883796, average reward:-0.2534570226308192,success
Box_Position: [[1.52779289 0.77847346 0.65678566]]
Step:7, total reward:-1.618008778473506, average reward:-0.23114411121050085,success
Box_Position: [[1.42152047 1.09437229 0.46631048]]
Step:3, total reward:-2.34566204923411, average reward:-0.7818873497447033,success
Box_Position: [[1.29206632 0.82919792 0.71157424]]
Step:25, total reward:-5.447053330192886, average reward:-0.21788213320771543,success
Box_Position: [[1.41074415 0.86002449 0.69195217]]
actor_loss: tensor(0.1316, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-15.859704785223869, average reward:-0.3236674445964055,success
Box_Position: [[1.40248291 0.55363528 0.60124155]]
actor_loss: tensor(0.0909, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1288, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1247, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.84890247295124, average reward:-0.34424451236475617,----
Box_Position: [[1.54258584 0.9121334  0.52095544]]
actor_loss: tensor(0.0865, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-16.190877855218783, average reward:-0.8095438927609392,success
Box_Position: [[1.36512834 0.70657847 0.4744497 ]]
Step:15, total reward:-12.42808632973004, average reward:-0.8285390886486693,success
Box_Position: [[1.50095984 0.95355344 0.72379109]]
Step:11, total reward:-1.7874807991058936, average reward:-0.16249825446417215,success
Box_Position: [[1.27672249 0.68017923 0.69535108]]
actor_loss: tensor(0.1304, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0893, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-24.42236108982305, average reward:-0.32134685644504013,success
Box_Position: [[1.53520298 0.60935333 0.5823145 ]]
Step:23, total reward:-8.204834721356152, average reward:-0.3567319444067892,success
Box_Position: [[1.47541393 0.75863982 0.46861903]]
Step:9, total reward:-5.348818784336599, average reward:-0.5943131982596221,success
Box_Position: [[1.31125748 0.71638904 0.57007583]]
actor_loss: tensor(0.1002, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-1.0802668326916394, average reward:-0.12002964807684882,success
Box_Position: [[1.44677919 0.72828802 0.63011118]]
Step:4, total reward:-0.6233816624538338, average reward:-0.15584541561345844,success
Box_Position: [[1.51104275 0.86019407 0.65895839]]
Step:26, total reward:-15.689355551030136, average reward:-0.6034367519626975,success
Box_Position: [[1.35016599 0.80727342 0.49940972]]
actor_loss: tensor(0.1234, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-22.455671481653532, average reward:-0.8316915363575382,success
Box_Position: [[1.43413228 0.62629602 0.56432118]]
Step:13, total reward:-6.069120633491772, average reward:-0.46685543334552093,success
Box_Position: [[1.47313376 0.8714124  0.60337405]]

------------------Episode:2100------------------
Step:28, total reward:-10.697443514591894, average reward:-0.38205155409256764,success
episode 2100, the accuracy is: 88%
Box_Position: [[1.38465422 0.82657794 0.63121267]]
actor_loss: tensor(0.1026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0885, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-17.835458386284273, average reward:-0.28766868364974635,success
Box_Position: [[1.39402744 0.78907069 0.47883568]]
Step:14, total reward:-12.288340200241446, average reward:-0.8777385857315319,success
Box_Position: [[1.30888867 0.83093664 0.65442927]]
actor_loss: tensor(0.1323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1186, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-29.689619483251953, average reward:-0.2968961948325195,success
Box_Position: [[1.45447556 0.54786056 0.74425277]]
Step:9, total reward:-2.1423473064498904, average reward:-0.23803858960554336,success
Box_Position: [[1.45831357 0.83353646 0.56349568]]
actor_loss: tensor(0.1081, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-11.775719111837427, average reward:-0.535259959628974,success
Box_Position: [[1.44257019 1.12878515 0.55727173]]
actor_loss: tensor(0.1033, device='cuda:0', grad_fn=<NegBackward>)
Step:93, total reward:-39.15977789264463, average reward:-0.42107288056607123,success
Box_Position: [[1.49927468 0.53083564 0.71802963]]
actor_loss: tensor(0.0854, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1485, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-19.43092178329919, average reward:-0.2428865222912399,success
Box_Position: [[1.48500918 0.68033658 0.48343344]]
actor_loss: tensor(0.1067, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-46.20579521487418, average reward:-0.7452547615302287,success
Box_Position: [[1.26532001 0.79458838 0.53907405]]
actor_loss: tensor(0.1216, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-7.786382154295075, average reward:-0.5561701538782197,success
Box_Position: [[1.45987086 0.72614536 0.69000999]]
Step:7, total reward:-3.5944209701466483, average reward:-0.5134887100209498,success
Box_Position: [[1.39042397 0.5361808  0.57030282]]
Step:33, total reward:-24.9326247291451, average reward:-0.7555340827013667,success
Box_Position: [[1.34948916 0.47148877 0.73918557]]
actor_loss: tensor(0.1100, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-6.65269195758268, average reward:-0.26610767830330717,success
Box_Position: [[1.29163778 0.70534911 0.48563826]]
Step:15, total reward:-13.813136113520839, average reward:-0.9208757409013892,success
Box_Position: [[1.33119976 0.92714968 0.66838216]]
Step:1, total reward:-0.013621688147276687, average reward:-0.013621688147276687,success
Box_Position: [[1.53266805 0.93382424 0.62761652]]
Step:5, total reward:-1.0489819371242037, average reward:-0.20979638742484075,success
Box_Position: [[1.32898128 0.84384768 0.67574356]]
actor_loss: tensor(0.0968, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-13.70022618775793, average reward:-0.23621079634065398,success
Box_Position: [[1.51688409 0.99885581 0.45856033]]
actor_loss: tensor(0.1025, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-36.19010319571449, average reward:-0.753960483244052,success
Box_Position: [[1.40066858 0.7541989  0.58976475]]
actor_loss: tensor(0.1029, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1174, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1054, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-64.95876429695495, average reward:-0.4301904920328143,success
Box_Position: [[1.53766589 0.49487349 0.45973931]]
actor_loss: tensor(0.0918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1147, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-76.96006347303458, average reward:-0.7329529854574722,success
Box_Position: [[1.3953557  0.81774795 0.48774319]]
Step:27, total reward:-25.819141675208513, average reward:-0.9562645064892042,success
Box_Position: [[1.37879007 0.80813057 0.66896364]]
Step:13, total reward:-2.3667744947524874, average reward:-0.18205957651942212,success
Box_Position: [[1.29166108 0.87937473 0.71403776]]
actor_loss: tensor(0.1431, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1146, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-17.466630349826264, average reward:-0.18985467771550288,success
Box_Position: [[1.44532762 0.89129562 0.55476437]]
actor_loss: tensor(0.1057, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-24.06607356559218, average reward:-0.46280910703061884,success
Box_Position: [[1.27124198 0.82304564 0.56879082]]
actor_loss: tensor(0.1092, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-20.96152453783673, average reward:-0.3811186279606678,success
Box_Position: [[1.42722608 0.71242061 0.51854076]]
Step:1, total reward:-0.03694947664225694, average reward:-0.03694947664225694,success
Box_Position: [[1.32749237 0.93224322 0.56286465]]
actor_loss: tensor(0.1419, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1258, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0904, device='cuda:0', grad_fn=<NegBackward>)
Step:174, total reward:-81.23211505299436, average reward:-0.4668512359367492,success
Box_Position: [[1.48169311 0.94142478 0.61826515]]
actor_loss: tensor(0.1245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1068, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1125, device='cuda:0', grad_fn=<NegBackward>)
Step:147, total reward:-48.58305258333181, average reward:-0.330496956349196,success
Box_Position: [[1.42109989 1.00828431 0.53463923]]
actor_loss: tensor(0.0974, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1075, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-60.60565534968254, average reward:-0.6587571233661146,success
Box_Position: [[1.29259757 1.05258451 0.5312317 ]]
actor_loss: tensor(0.1022, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1309, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-71.9656435358806, average reward:-0.533078841006523,success
Box_Position: [[1.53526402 1.11695825 0.70578067]]
actor_loss: tensor(0.1264, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-6.633268187462103, average reward:-0.201008126892791,success
Box_Position: [[1.44358406 0.75094244 0.52219386]]
Step:13, total reward:-6.074832455489404, average reward:-0.4672948042684157,success
Box_Position: [[1.34954255 0.73524303 0.51858636]]
actor_loss: tensor(0.1383, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1025, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-42.821162131834285, average reward:-0.5420400269852441,success
Box_Position: [[1.4661497  0.98425012 0.46445224]]
Step:10, total reward:-6.2192891778927075, average reward:-0.6219289177892707,success
Box_Position: [[1.3308458  0.66648662 0.68455877]]
Step:3, total reward:-0.5013111916493586, average reward:-0.1671037305497862,success
Box_Position: [[1.29412456 0.75903802 0.63334908]]
Step:2, total reward:-2.2584339284721673, average reward:-1.1292169642360836,success
Box_Position: [[1.45447989 0.86923289 0.60663887]]
actor_loss: tensor(0.1149, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1123, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-27.78054620707954, average reward:-0.356160848808712,success
Box_Position: [[1.47413537 0.93094794 0.6154872 ]]
Step:35, total reward:-15.469185439783226, average reward:-0.4419767268509493,success
Box_Position: [[1.48212884 0.56791114 0.54032206]]
actor_loss: tensor(0.1115, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1023, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-38.95135538805665, average reward:-0.5263696674061709,success
Box_Position: [[1.53907506 0.60288965 0.73570278]]
actor_loss: tensor(0.1179, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-21.42720005377255, average reward:-0.319808956026456,success
Box_Position: [[1.47325696 0.69482342 0.5520572 ]]
Step:5, total reward:-0.5317655121493585, average reward:-0.1063531024298717,success
Box_Position: [[1.48363845 0.81873474 0.62175242]]
actor_loss: tensor(0.1404, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-4.066138494151515, average reward:-0.36964895401377407,success
Box_Position: [[1.37065565 0.78896465 0.72278659]]
Step:14, total reward:-2.2611340191862856, average reward:-0.1615095727990204,success
Box_Position: [[1.39942024 1.04523295 0.67910544]]
actor_loss: tensor(0.1171, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-18.628506074470376, average reward:-0.3582405014321226,success
Box_Position: [[1.47829385 0.64028749 0.46332145]]
actor_loss: tensor(0.1139, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-36.70407266579682, average reward:-0.7340814533159364,success
Box_Position: [[1.49180528 0.84251354 0.63434354]]
actor_loss: tensor(0.1191, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-12.101175753781837, average reward:-0.25210782820378824,success
Box_Position: [[1.40332987 1.05349038 0.57808235]]
actor_loss: tensor(0.1064, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-14.483129033565941, average reward:-0.3368169542689754,success
Box_Position: [[1.47619004 0.82392738 0.56239474]]
actor_loss: tensor(0.1152, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-39.7927545284944, average reward:-0.7802500887940078,success
Box_Position: [[1.48314181 0.93841621 0.60542301]]
actor_loss: tensor(0.0914, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-25.263378865136982, average reward:-0.43557549767477555,success
Box_Position: [[1.28352454 1.00251208 0.53477227]]
Step:6, total reward:-0.7809569588704456, average reward:-0.13015949314507427,success
Box_Position: [[1.28400187 0.65747853 0.59830291]]

------------------Episode:2150------------------
Step:15, total reward:-8.668184311933949, average reward:-0.57787895412893,success
Box_Position: [[1.53595442 0.74488034 0.67592612]]
actor_loss: tensor(0.1052, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-4.856043129994258, average reward:-0.21113230999975033,success
Box_Position: [[1.51667553 0.64421654 0.58502015]]
actor_loss: tensor(0.1266, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1004, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-46.84993861524136, average reward:-0.5148344902773776,success
Box_Position: [[1.43814797 1.11459113 0.47889781]]
actor_loss: tensor(0.1001, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-34.92351719127371, average reward:-0.6021296067460985,success
Box_Position: [[1.39030736 0.66378047 0.72812879]]
actor_loss: tensor(0.0862, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0817, device='cuda:0', grad_fn=<NegBackward>)
Step:106, total reward:-24.271665617812737, average reward:-0.22897797752653526,success
Box_Position: [[1.30639524 1.12406289 0.63226012]]
Step:6, total reward:-3.02355970940156, average reward:-0.5039266182335933,success
Box_Position: [[1.32986393 0.97228956 0.70040811]]
Step:14, total reward:-2.3192509415183604, average reward:-0.16566078153702574,success
Box_Position: [[1.42369317 0.68587081 0.48172519]]
actor_loss: tensor(0.1157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1227, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-53.01332557420635, average reward:-0.6884847477169656,success
Box_Position: [[1.39723385 0.72029607 0.66987608]]
actor_loss: tensor(0.0418, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-8.795741914472332, average reward:-0.20942242653505552,success
Box_Position: [[1.494608   1.11070034 0.69973821]]
Step:32, total reward:-10.490014241838137, average reward:-0.3278129450574418,success
Box_Position: [[1.3220049  0.98883508 0.55397512]]
Step:12, total reward:-5.91964560142031, average reward:-0.49330380011835917,success
Box_Position: [[1.46685959 1.11096508 0.59653328]]
actor_loss: tensor(0.1112, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-26.389466806313393, average reward:-0.5997606092343953,success
Box_Position: [[1.25833967 0.8501401  0.50980537]]
actor_loss: tensor(0.1160, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-13.298617828764485, average reward:-1.2089652571604077,success
Box_Position: [[1.52300107 0.99081298 0.67808887]]
Step:37, total reward:-9.932420619625688, average reward:-0.268443800530424,success
Box_Position: [[1.33759667 0.62717889 0.46349091]]
actor_loss: tensor(0.0786, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1081, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0646, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0703, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-185.8988603947347, average reward:-0.9294943019736734,----
Box_Position: [[1.36487696 0.82490432 0.6971148 ]]
actor_loss: tensor(0.0686, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-4.16117334364468, average reward:-0.41611733436446796,success
Box_Position: [[1.42862528 0.62322006 0.66262823]]
Step:1, total reward:-0.047599323897617556, average reward:-0.047599323897617556,success
Box_Position: [[1.40122725 0.54899121 0.47646829]]
actor_loss: tensor(0.1059, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0299, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-157.64243874366937, average reward:-0.7882121937183468,----
Box_Position: [[1.32849974 0.72770947 0.73132106]]
Step:29, total reward:-4.930968697974227, average reward:-0.17003340337842163,success
Box_Position: [[1.40438915 0.84354126 0.70287087]]
Step:13, total reward:-2.3042648891781936, average reward:-0.17725114532139952,success
Box_Position: [[1.47398084 0.70255591 0.73166621]]
actor_loss: tensor(0.0684, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-1.6668053244397352, average reward:-0.18520059160441502,success
Box_Position: [[1.49931694 0.51446406 0.71929039]]
actor_loss: tensor(0.0738, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0427, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0543, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-55.868479515809426, average reward:-0.2793423975790471,----
Box_Position: [[1.36000241 0.48473475 0.6015005 ]]
actor_loss: tensor(0.0699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0342, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0591, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-84.26350575889103, average reward:-0.42131752879445517,----
Box_Position: [[1.32706555 0.57258994 0.60707683]]
Step:23, total reward:-3.6437665537002455, average reward:-0.15842463276957588,success
Box_Position: [[1.37830334 1.00092498 0.69450735]]
Step:5, total reward:-0.8003462656782733, average reward:-0.16006925313565465,success
Box_Position: [[1.2509379  0.84931482 0.61688185]]
Step:16, total reward:-8.865408769516208, average reward:-0.554088048094763,success
Box_Position: [[1.38486899 0.76382782 0.71646084]]
actor_loss: tensor(0.0777, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0612, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-12.617214106042505, average reward:-0.19116991069761372,success
Box_Position: [[1.43729824 0.62920742 0.59628306]]
actor_loss: tensor(0.0425, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0506, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)
Step:200, total reward:-74.13543568133571, average reward:-0.3706771784066785,----
Box_Position: [[1.31055293 0.80504946 0.55076538]]
Step:25, total reward:-20.235607484041, average reward:-0.8094242993616401,success
Box_Position: [[1.32086336 0.97414201 0.46702256]]
actor_loss: tensor(0.0329, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-9.662540074042845, average reward:-0.8052116728369038,success
Box_Position: [[1.52790441 0.63586722 0.47896026]]
Step:15, total reward:-5.060025115618532, average reward:-0.33733500770790215,success
Box_Position: [[1.53834558 0.85270119 0.70815471]]
actor_loss: tensor(0.0417, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-10.115106837837011, average reward:-0.280975189939917,success
Box_Position: [[1.302477   1.08351502 0.47990155]]
actor_loss: tensor(0.0234, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-84.87611158939994, average reward:-0.9869315301093017,success
Box_Position: [[1.51492611 0.73124442 0.66494271]]
actor_loss: tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Step:41, total reward:-9.813237665109646, average reward:-0.2393472601246255,success
Box_Position: [[1.45011545 0.57644815 0.65118072]]
actor_loss: tensor(0.0135, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0188, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-57.575535340814675, average reward:-0.2878776767040734,----
Box_Position: [[1.41450287 0.79987497 0.64977906]]
Step:17, total reward:-3.4055934739457108, average reward:-0.20032902787915946,success
Box_Position: [[1.42011162 0.81121305 0.48052408]]
actor_loss: tensor(0.0094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0411, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-55.34209610965419, average reward:-0.7581109056117012,success
Box_Position: [[1.31575295 0.99610938 0.45192841]]
Step:4, total reward:-4.5365868377265635, average reward:-1.1341467094316409,success
Box_Position: [[1.33624482 1.02662557 0.57115609]]
Step:14, total reward:-4.855556268277876, average reward:-0.34682544773413404,success
Box_Position: [[1.28249772 1.04294591 0.58084424]]
Step:3, total reward:-0.3722683203328574, average reward:-0.12408944011095246,success
Box_Position: [[1.45106263 0.90888009 0.50649346]]
Step:2, total reward:-0.3541901981383928, average reward:-0.1770950990691964,success
Box_Position: [[1.31836355 0.828051   0.57301145]]
actor_loss: tensor(0.0245, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-10.461138766671708, average reward:-0.6538211729169817,success
Box_Position: [[1.50764649 0.89361696 0.68646341]]
Step:21, total reward:-4.571554459087625, average reward:-0.21769306948036307,success
Box_Position: [[1.36393377 0.69839086 0.67430887]]
actor_loss: tensor(0.0136, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-4.70293174604918, average reward:-0.19595548941871585,success
Box_Position: [[1.40517904 1.07300066 0.71734749]]
Step:5, total reward:-3.0077950955027895, average reward:-0.6015590191005579,success
Box_Position: [[1.26126863 0.89681059 0.60605483]]
actor_loss: tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)
actor_loss: tensor(0.0085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0378, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-83.63645946230574, average reward:-0.4181822973115287,----
Box_Position: [[1.3994983  0.92128392 0.6626395 ]]
Step:1, total reward:-0.02622792259494155, average reward:-0.02622792259494155,success
Box_Position: [[1.29183342 0.61137903 0.53025929]]
Step:13, total reward:-16.164574167283256, average reward:-1.243428782098712,success
Box_Position: [[1.50475429 1.09720318 0.62319652]]
actor_loss: tensor(0.0002, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-17.50976202608639, average reward:-0.29677562756078624,success
Box_Position: [[1.36507665 0.97507238 0.61375855]]
Step:7, total reward:-3.1665348957853605, average reward:-0.4523621279693372,success
Box_Position: [[1.31057596 0.71501965 0.66736452]]

------------------Episode:2200------------------
actor_loss: tensor(0.0092, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-5.668372876266261, average reward:-0.31490960423701453,success
episode 2200, the accuracy is: 93%
Box_Position: [[1.52125151 0.55033733 0.58231729]]
actor_loss: tensor(0.0033, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2867e-05, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0016, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0094, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-74.37385297686836, average reward:-0.3718692648843418,----
Box_Position: [[1.40582497 0.68516393 0.53406693]]
actor_loss: tensor(0.0064, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>)
actor_loss: tensor(0.0182, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0348, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-101.7697537831022, average reward:-0.508848768915511,----
Box_Position: [[1.53362388 1.09360686 0.54211294]]
actor_loss: tensor(0.0213, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>)
Step:98, total reward:-72.29121896167457, average reward:-0.7376654996089242,success
Box_Position: [[1.41065824 0.57639798 0.72312607]]
Step:5, total reward:-0.8019932904027026, average reward:-0.16039865808054052,success
Box_Position: [[1.33863501 0.87045535 0.49533869]]
Step:3, total reward:-0.2687974197804986, average reward:-0.08959913992683287,success
Box_Position: [[1.38040541 0.94028114 0.67633512]]
actor_loss: tensor(0.0128, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-11.63717249512021, average reward:-0.2041609209670212,success
Box_Position: [[1.51501371 1.04004396 0.53237528]]
Step:15, total reward:-10.847636559535673, average reward:-0.7231757706357115,success
Box_Position: [[1.30923592 1.00105278 0.69217881]]
actor_loss: tensor(0.0055, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-2.7627179787299063, average reward:-0.16251282227822977,success
Box_Position: [[1.45465849 0.70673795 0.51666019]]
actor_loss: tensor(0.0040, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0276, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0071, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0061, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.40577533322758, average reward:-0.5320288766661379,----
Box_Position: [[1.32197821 0.55455197 0.63283863]]
Step:35, total reward:-10.235045401866817, average reward:-0.29242986862476616,success
Box_Position: [[1.26844706 0.95152567 0.68998269]]
actor_loss: tensor(0.0180, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0023, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-25.801078201069117, average reward:-0.3185318296428286,success
Box_Position: [[1.37811337 0.6249779  0.63480645]]
Step:18, total reward:-9.251429813568578, average reward:-0.5139683229760321,success
Box_Position: [[1.26415207 0.68703754 0.4952012 ]]
actor_loss: tensor(0.0175, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-46.37933626522965, average reward:-0.9867943886219074,success
Box_Position: [[1.54267724 1.0374866  0.67481187]]
actor_loss: tensor(0.0296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0142, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0316, device='cuda:0', grad_fn=<NegBackward>)
Step:128, total reward:-43.67182453388727, average reward:-0.3411861291709943,success
Box_Position: [[1.52817451 0.77870645 0.50012128]]
actor_loss: tensor(0.0003, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0082, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0238, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>)
Step:200, total reward:-125.77743875144068, average reward:-0.6288871937572034,----
Box_Position: [[1.54942126 0.81219079 0.5778729 ]]
actor_loss: tensor(0.0402, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)
Step:165, total reward:-78.17952583054948, average reward:-0.47381530806393624,success
Box_Position: [[1.30488094 0.69650218 0.48084629]]
Step:15, total reward:-16.11436916647858, average reward:-1.0742912777652385,success
Box_Position: [[1.28665055 0.79489758 0.52277577]]
Step:2, total reward:-0.2939845859540687, average reward:-0.14699229297703434,success
Box_Position: [[1.31700892 0.52991963 0.68318433]]
actor_loss: tensor(0.0187, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-5.282274861171793, average reward:-0.24010340278053602,success
Box_Position: [[1.33930058 1.09088844 0.58373171]]
actor_loss: tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>)
Step:63, total reward:-19.83915688042466, average reward:-0.3149072520702327,success
Box_Position: [[1.43060402 0.62292234 0.5233584 ]]
actor_loss: tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)
Step:59, total reward:-20.095993969904754, average reward:-0.34061006728652127,success
Box_Position: [[1.25173922 0.71682641 0.49360926]]
Step:4, total reward:-4.355127818461477, average reward:-1.0887819546153692,success
Box_Position: [[1.27850253 0.71455776 0.5655141 ]]
actor_loss: tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>)
Step:21, total reward:-15.038126374159845, average reward:-0.7161012559123735,success
Box_Position: [[1.33126393 0.69673588 0.51171004]]
Step:18, total reward:-4.656491779983592, average reward:-0.25869398777686625,success
Box_Position: [[1.47520477 0.81434587 0.7102906 ]]
actor_loss: tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>)
actor_loss: tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>)
Step:104, total reward:-21.481015896322045, average reward:-0.20654822977232737,success
Box_Position: [[1.25681065 0.89156798 0.70704745]]
actor_loss: tensor(0.0268, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0432, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0137, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0225, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-72.17293174653427, average reward:-0.3608646587326714,----
Box_Position: [[1.44097282 0.88410922 0.65142954]]
actor_loss: tensor(0.0275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0034, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0159, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>)
Step:168, total reward:-46.4432863299849, average reward:-0.27644813291657677,success
Box_Position: [[1.46880056 0.45976438 0.55532058]]
actor_loss: tensor(0.0191, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0139, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-59.63017454358191, average reward:-0.4551921720884115,success
Box_Position: [[1.5267497  0.8949903  0.48107787]]
actor_loss: tensor(0.0128, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-20.11515637552757, average reward:-0.5157732403981428,success
Box_Position: [[1.47928421 0.86375416 0.61105214]]
actor_loss: tensor(0.0107, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-7.576156724458465, average reward:-0.2525385574819488,success
Box_Position: [[1.40057047 0.99996936 0.66680745]]
actor_loss: tensor(0.0179, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-31.200510729295573, average reward:-0.3627966363871578,success
Box_Position: [[1.25552607 1.00851652 0.71784582]]
actor_loss: tensor(0.0118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0142, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-69.51725296110808, average reward:-0.34758626480554045,----
Box_Position: [[1.39984606 0.82755069 0.64250558]]
actor_loss: tensor(0.0179, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-11.642860867443689, average reward:-0.38809536224812297,success
Box_Position: [[1.36978087 0.57155776 0.6708051 ]]
Step:18, total reward:-4.65123327531655, average reward:-0.25840184862869725,success
Box_Position: [[1.50324036 0.77832645 0.51230603]]
Step:14, total reward:-9.1298469700838, average reward:-0.6521319264345572,success
Box_Position: [[1.31082847 1.01307315 0.64102466]]
actor_loss: tensor(0.0053, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-7.480282289684677, average reward:-0.37401411448423383,success
Box_Position: [[1.3482009  0.62534254 0.51390611]]
Step:16, total reward:-4.21773784997886, average reward:-0.26360861562367877,success
Box_Position: [[1.44474187 0.91105972 0.47112214]]
actor_loss: tensor(0.0129, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-31.305150858816063, average reward:-0.7280267641585131,success
Box_Position: [[1.28301424 0.51121962 0.55163525]]
actor_loss: tensor(0.0195, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-22.78923863460334, average reward:-0.785835814986322,success
Box_Position: [[1.35578779 0.69431738 0.52345847]]
Step:19, total reward:-9.186045771699579, average reward:-0.48347609324734625,success
Box_Position: [[1.48173611 0.94226997 0.6999756 ]]
Step:11, total reward:-4.487129824447163, average reward:-0.4079208931315603,success
Box_Position: [[1.54370343 0.68792084 0.47098469]]
actor_loss: tensor(0.0387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0308, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0148, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-151.0935443675144, average reward:-0.7554677218375719,----
Box_Position: [[1.25427982 0.93114578 0.68472373]]
actor_loss: tensor(0.0449, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0359, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0079, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0675, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-87.82971889513922, average reward:-0.4391485944756961,----
Box_Position: [[1.37943399 0.7119095  0.72335735]]
actor_loss: tensor(0.0077, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-9.266933886131625, average reward:-0.3088977962043875,success
Box_Position: [[1.48093226 0.54216118 0.67764466]]
Step:8, total reward:-3.734656995266534, average reward:-0.46683212440831673,success
Box_Position: [[1.46518697 1.06332394 0.64566792]]
actor_loss: tensor(0.0429, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-15.722693631437902, average reward:-0.29665459681958306,success
Box_Position: [[1.37731742 0.96266465 0.50463219]]
Step:7, total reward:-5.091090608025777, average reward:-0.7272986582893967,success
Box_Position: [[1.44242395 0.53615322 0.54470709]]
actor_loss: tensor(0.0136, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-18.67308241939104, average reward:-0.7469232967756416,success
Box_Position: [[1.33724993 0.92045644 0.62186601]]
Step:13, total reward:-4.0233762832025874, average reward:-0.30949048332327594,success
Box_Position: [[1.37739412 0.59901234 0.61370975]]

------------------Episode:2250------------------
Step:25, total reward:-12.486124882199569, average reward:-0.49944499528798275,success
Box_Position: [[1.37990572 0.93601631 0.52409628]]
actor_loss: tensor(0.0186, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0213, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-57.72864476007243, average reward:-0.7126993180255855,success
Box_Position: [[1.43004441 0.76386244 0.58902291]]
actor_loss: tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)
Step:47, total reward:-24.172467039087405, average reward:-0.5143078093422851,success
Box_Position: [[1.46760435 0.7648505  0.60806176]]
actor_loss: tensor(0.0270, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-19.3333233278541, average reward:-0.5523806665101171,success
Box_Position: [[1.40281768 0.79646869 0.64088801]]
Step:14, total reward:-4.365645324369721, average reward:-0.3118318088835515,success
Box_Position: [[1.49422364 0.86607504 0.73840313]]
Step:3, total reward:-0.6106884446767193, average reward:-0.2035628148922398,success
Box_Position: [[1.53640945 0.84557221 0.60701265]]
Step:20, total reward:-6.008871936814048, average reward:-0.3004435968407024,success
Box_Position: [[1.52317467 0.56313266 0.49889251]]
actor_loss: tensor(0.0182, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0075, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-52.30230408590974, average reward:-0.6537788010738718,success
Box_Position: [[1.3106743  1.07949792 0.749616  ]]
actor_loss: tensor(0.0467, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-6.172520244238366, average reward:-0.2571883435099319,success
Box_Position: [[1.38908799 1.07040422 0.66612776]]
actor_loss: tensor(0.0184, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-24.44124770769727, average reward:-0.2656657359532312,success
Box_Position: [[1.41216183 0.69988545 0.59741222]]
actor_loss: tensor(0.0268, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0437, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0377, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-48.999097671369434, average reward:-0.40163194812597897,success
Box_Position: [[1.41192818 1.0710363  0.69196102]]
Step:13, total reward:-4.595068808263515, average reward:-0.3534668314048858,success
Box_Position: [[1.43167548 0.509361   0.59180238]]
actor_loss: tensor(0.0227, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-16.29561900876367, average reward:-0.38799092878008734,success
Box_Position: [[1.43672889 0.53492404 0.67404605]]
actor_loss: tensor(0.0301, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-25.452267609532612, average reward:-0.3263111231991361,success
Box_Position: [[1.25894896 1.13715055 0.59069566]]
actor_loss: tensor(0.0286, device='cuda:0', grad_fn=<NegBackward>)
Step:3, total reward:-0.37539090856073104, average reward:-0.125130302853577,success
Box_Position: [[1.44065747 0.82491833 0.58968198]]
actor_loss: tensor(0.0338, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-34.56244954046673, average reward:-0.5400382740697927,success
Box_Position: [[1.32541859 1.02923178 0.53347658]]
Step:4, total reward:-4.512767609571669, average reward:-1.1281919023929172,success
Box_Position: [[1.43313771 1.00794489 0.69188653]]
actor_loss: tensor(0.0437, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0357, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-20.683071376823577, average reward:-0.24919363104606718,success
Box_Position: [[1.45062591 0.53690481 0.51696712]]
Step:44, total reward:-26.221255038380985, average reward:-0.5959376145086588,success
Box_Position: [[1.34423753 1.09386103 0.54062518]]
actor_loss: tensor(0.0429, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0554, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-34.8788450293599, average reward:-0.4777923976624644,success
Box_Position: [[1.32636827 0.87312872 0.68606297]]
Step:18, total reward:-3.1585720385657523, average reward:-0.175476224364764,success
Box_Position: [[1.33882034 0.71459548 0.68897261]]
actor_loss: tensor(0.0378, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-2.878010651196707, average reward:-0.15988948062203928,success
Box_Position: [[1.27525716 0.76827305 0.73544144]]
actor_loss: tensor(0.0401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0372, device='cuda:0', grad_fn=<NegBackward>)
Step:117, total reward:-32.64099876143782, average reward:-0.27898289539690446,success
Box_Position: [[1.32357599 0.5790643  0.45069409]]
actor_loss: tensor(0.0426, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-110.37640809168158, average reward:-1.0315552158101082,success
Box_Position: [[1.36722349 0.79887194 0.65483443]]
actor_loss: tensor(0.0503, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-8.722971341572268, average reward:-0.2127553985749334,success
Box_Position: [[1.53228764 0.55281921 0.47421967]]
actor_loss: tensor(0.0234, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0593, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0481, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0718, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-162.00287598396088, average reward:-0.8100143799198044,----
Box_Position: [[1.44127824 1.0312979  0.49762752]]
Step:17, total reward:-9.241832914779744, average reward:-0.5436372302811614,success
Box_Position: [[1.36695255 0.78454069 0.6964551 ]]
actor_loss: tensor(0.0308, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-2.7510172996307762, average reward:-0.17193858122692351,success
Box_Position: [[1.46114327 1.03014643 0.73141738]]
Step:25, total reward:-4.644808652181263, average reward:-0.1857923460872505,success
Box_Position: [[1.36570167 0.8064296  0.57539406]]
Step:3, total reward:-2.461844136827098, average reward:-0.8206147122756993,success
Box_Position: [[1.51066816 0.99301532 0.65822643]]
actor_loss: tensor(0.0178, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-9.644773913765713, average reward:-0.32149246379219043,success
Box_Position: [[1.38181628 0.54465302 0.62226737]]
Step:25, total reward:-8.35596111954777, average reward:-0.3342384447819108,success
Box_Position: [[1.51040189 0.8355674  0.53216084]]
actor_loss: tensor(0.0333, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0459, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-35.94908397739046, average reward:-0.5135583425341494,success
Box_Position: [[1.41507645 1.11891782 0.61416931]]
Step:21, total reward:-7.20413841454449, average reward:-0.34305421021640425,success
Box_Position: [[1.46612609 0.93288287 0.56939062]]
actor_loss: tensor(0.0471, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-12.347661519138379, average reward:-0.3527903291182394,success
Box_Position: [[1.47042556 0.83525849 0.46643855]]
Step:10, total reward:-1.7129731289518113, average reward:-0.17129731289518113,success
Box_Position: [[1.46635619 0.8651657  0.58039669]]
Step:22, total reward:-3.6766027669542964, average reward:-0.16711830758883164,success
Box_Position: [[1.27910611 0.53642896 0.4770222 ]]
actor_loss: tensor(0.0565, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-11.416495633040936, average reward:-0.9513746360867447,success
Box_Position: [[1.28878809 0.98673102 0.4595606 ]]
Step:23, total reward:-14.672269534974639, average reward:-0.6379247623902017,success
Box_Position: [[1.26178427 1.01502694 0.60704336]]
Step:15, total reward:-6.057643191472006, average reward:-0.40384287943146707,success
Box_Position: [[1.37496254 1.01565115 0.53208877]]
actor_loss: tensor(0.0639, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-6.219386098030776, average reward:-0.565398736184616,success
Box_Position: [[1.25417381 0.62792971 0.61098336]]
actor_loss: tensor(0.0595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0478, device='cuda:0', grad_fn=<NegBackward>)
Step:113, total reward:-46.478952977792716, average reward:-0.41131816794506826,success
Box_Position: [[1.33946257 0.63987809 0.47941537]]
Step:11, total reward:-7.474024756809175, average reward:-0.6794567960735614,success
Box_Position: [[1.33702511 0.87178835 0.64078847]]
Step:6, total reward:-0.6213960643467201, average reward:-0.10356601072445336,success
Box_Position: [[1.3833655  0.57507636 0.57210914]]
actor_loss: tensor(0.0528, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-18.11475443187396, average reward:-0.8233979287215436,success
Box_Position: [[1.36782662 0.55872806 0.59588314]]
Step:9, total reward:-3.2640676534184174, average reward:-0.3626741837131575,success
Box_Position: [[1.50166644 0.47277621 0.67333924]]
actor_loss: tensor(0.0404, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-19.477292254383627, average reward:-0.3301235975319259,success
Box_Position: [[1.35464551 0.62345735 0.68102847]]
actor_loss: tensor(0.0465, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-16.31743707078664, average reward:-0.2913828048354757,success
Box_Position: [[1.39975104 0.46702526 0.51180495]]
actor_loss: tensor(0.0578, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-34.175939275671624, average reward:-0.7119987349098255,success
Box_Position: [[1.45855587 0.8566696  0.65726328]]
Step:13, total reward:-4.167073322915615, average reward:-0.3205441017627396,success
Box_Position: [[1.46117803 0.61138401 0.54896908]]

------------------Episode:2300------------------
actor_loss: tensor(0.0499, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0448, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-22.442854580696714, average reward:-0.3400432512226775,success
episode 2300, the accuracy is: 91%
Box_Position: [[1.27585754 0.76160253 0.74429476]]
Step:41, total reward:-9.695649483205267, average reward:-0.23647925568793335,success
Box_Position: [[1.54299921 0.56401479 0.64684736]]
actor_loss: tensor(0.0453, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0455, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0520, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-35.38089109229011, average reward:-0.2830471287383209,success
Box_Position: [[1.34198466 0.74803414 0.47789271]]
actor_loss: tensor(0.0579, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-56.69345443868758, average reward:-1.1116363615428937,success
Box_Position: [[1.29786661 1.10227025 0.48343965]]
actor_loss: tensor(0.0531, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-51.895912457954594, average reward:-0.8370308460960418,success
Box_Position: [[1.38414956 0.78688108 0.45756386]]
actor_loss: tensor(0.0492, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-34.588790372119476, average reward:-0.6917758074423895,success
Box_Position: [[1.31258046 0.88013975 0.50357435]]
Step:10, total reward:-5.317727775786071, average reward:-0.5317727775786071,success
Box_Position: [[1.27234431 0.81966449 0.59290331]]
actor_loss: tensor(0.0470, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-5.306686748451698, average reward:-0.5896318609390776,success
Box_Position: [[1.29407935 0.62382968 0.50063987]]
Step:18, total reward:-26.954739272669467, average reward:-1.4974855151483037,success
Box_Position: [[1.38008232 0.94836032 0.55361602]]
actor_loss: tensor(0.0329, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-16.100584979820017, average reward:-0.44723847166166714,success
Box_Position: [[1.40367733 0.55581717 0.4772568 ]]
actor_loss: tensor(0.0444, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-64.74773416773702, average reward:-0.7896065142406954,success
Box_Position: [[1.47887749 0.87699546 0.61024104]]
Step:4, total reward:-2.674488669518474, average reward:-0.6686221673796185,success
Box_Position: [[1.45795123 0.79280212 0.45476066]]
actor_loss: tensor(0.0534, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-9.009818381422557, average reward:-1.1262272976778196,success
Box_Position: [[1.420121   1.02169453 0.73714442]]
Step:24, total reward:-6.482989475100921, average reward:-0.2701245614625384,success
Box_Position: [[1.26738658 1.14615657 0.57148283]]
actor_loss: tensor(0.0873, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-22.981835878448457, average reward:-0.3482096345219463,success
Box_Position: [[1.27748985 0.75788425 0.56916973]]
actor_loss: tensor(0.0568, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-11.208977440774722, average reward:-0.533760830513082,success
Box_Position: [[1.45023152 1.17154643 0.4606747 ]]
Step:11, total reward:-10.19549866582375, average reward:-0.9268635150748864,success
Box_Position: [[1.54098189 0.87018108 0.64991783]]
actor_loss: tensor(0.0640, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-15.180031686259424, average reward:-0.3373340374724316,success
Box_Position: [[1.53122457 0.84452409 0.47270501]]
actor_loss: tensor(0.0697, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-30.388042413365287, average reward:-0.7411717661796412,success
Box_Position: [[1.33042705 0.79127434 0.73146161]]
actor_loss: tensor(0.0691, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-9.181797144169858, average reward:-0.22954492860424644,success
Box_Position: [[1.38053293 0.85635512 0.57606735]]
actor_loss: tensor(0.0576, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-29.396827405841687, average reward:-0.5546571208649375,success
Box_Position: [[1.2905653  0.55821133 0.58871627]]
Step:8, total reward:-2.911495766979798, average reward:-0.36393697087247473,success
Box_Position: [[1.45931446 0.82312084 0.61318346]]
actor_loss: tensor(0.0576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0513, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-32.29812144491411, average reward:-0.32624365095872837,success
Box_Position: [[1.32306977 0.82690463 0.60865538]]
Step:25, total reward:-7.9028050373270595, average reward:-0.3161122014930824,success
Box_Position: [[1.52617881 0.68760066 0.53174591]]
actor_loss: tensor(0.0559, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-18.109157046336925, average reward:-0.6036385682112309,success
Box_Position: [[1.34705058 0.48651129 0.49374427]]
actor_loss: tensor(0.0587, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0722, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0605, device='cuda:0', grad_fn=<NegBackward>)
Step:199, total reward:-183.8215438487067, average reward:-0.9237263509985262,success
Box_Position: [[1.29071911 1.02796142 0.54197736]]
actor_loss: tensor(0.0699, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-40.150459538482124, average reward:-0.7435270284904097,success
Box_Position: [[1.34482051 0.81038681 0.47286111]]
Step:8, total reward:-3.130533259255808, average reward:-0.391316657406976,success
Box_Position: [[1.3203259  0.60481274 0.69533378]]
actor_loss: tensor(0.0651, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-10.937788600840975, average reward:-0.37716512416693015,success
Box_Position: [[1.3426866  0.65032804 0.53888684]]
Step:4, total reward:-0.6482699478347937, average reward:-0.16206748695869844,success
Box_Position: [[1.42933667 0.5814389  0.48349018]]
Step:28, total reward:-18.467915538084018, average reward:-0.6595684120744292,success
Box_Position: [[1.32639027 0.74282793 0.72886399]]
actor_loss: tensor(0.0316, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-11.934361413774937, average reward:-0.221006692847684,success
Box_Position: [[1.48473162 0.80017022 0.51105178]]
actor_loss: tensor(0.0746, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-23.565638641659643, average reward:-0.44463469135206873,success
Box_Position: [[1.42862183 0.62254799 0.67561069]]
actor_loss: tensor(0.0635, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-22.752002513232537, average reward:-0.4643265819027048,success
Box_Position: [[1.33045209 0.97063861 0.68480936]]
actor_loss: tensor(0.0754, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-10.320101524524523, average reward:-0.20235493185342202,success
Box_Position: [[1.34043781 1.04451279 0.66076752]]
actor_loss: tensor(0.0682, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-1.281185783432576, average reward:-0.14235397593695287,success
Box_Position: [[1.38134357 0.65454115 0.52732443]]
Step:10, total reward:-3.938833578225055, average reward:-0.3938833578225055,success
Box_Position: [[1.36102845 0.7131259  0.57247315]]
Step:12, total reward:-8.447305145398863, average reward:-0.7039420954499053,success
Box_Position: [[1.3691221  0.44625055 0.69315693]]
Step:3, total reward:-2.457112644533273, average reward:-0.8190375481777576,success
Box_Position: [[1.39178428 0.67873184 0.74411415]]
actor_loss: tensor(0.0962, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-4.209505883317246, average reward:-0.20045266111034504,success
Box_Position: [[1.44031745 0.92007593 0.53741342]]
Step:11, total reward:-1.778495703676822, average reward:-0.1616814276069838,success
Box_Position: [[1.3213399  1.01966477 0.60689755]]
Step:16, total reward:-4.759732963024869, average reward:-0.29748331018905433,success
Box_Position: [[1.46083524 0.82058939 0.614893  ]]
actor_loss: tensor(0.0499, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0845, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-37.27419947423202, average reward:-0.42357044857081844,success
Box_Position: [[1.44099505 0.48825817 0.51576024]]
actor_loss: tensor(0.0924, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-43.62825775372424, average reward:-0.7932410500677135,success
Box_Position: [[1.40886578 0.93477037 0.70078208]]
actor_loss: tensor(0.0754, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-9.143708401428183, average reward:-0.2126443814285624,success
Box_Position: [[1.39217481 0.82185347 0.67985873]]
Step:10, total reward:-3.779683039934815, average reward:-0.37796830399348147,success
Box_Position: [[1.31141226 1.10416488 0.71406591]]
actor_loss: tensor(0.0484, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-8.050516893273771, average reward:-0.2683505631091257,success
Box_Position: [[1.30643551 0.78362826 0.54125399]]
Step:7, total reward:-2.93937260026665, average reward:-0.41991037146666427,success
Box_Position: [[1.35729639 1.14766818 0.51073119]]
Step:15, total reward:-10.516698566439295, average reward:-0.7011132377626197,success
Box_Position: [[1.47943368 1.05986521 0.65622643]]
actor_loss: tensor(0.0714, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-11.296467770773724, average reward:-0.3227562220221064,success
Box_Position: [[1.53312573 1.01408816 0.65922002]]

------------------Episode:2350------------------
Step:16, total reward:-3.8505286392656446, average reward:-0.2406580399541028,success
Box_Position: [[1.52916405 0.64844573 0.54241115]]
actor_loss: tensor(0.0605, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-10.57734894713655, average reward:-0.423093957885462,success
Box_Position: [[1.40742632 0.91537379 0.6336963 ]]
actor_loss: tensor(0.0804, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0566, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-32.47903112988762, average reward:-0.3314186849988533,success
Box_Position: [[1.52364082 0.62231726 0.72439724]]
actor_loss: tensor(0.0461, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-12.275136193355646, average reward:-0.211640279195787,success
Box_Position: [[1.37075173 0.80537464 0.64267126]]
Step:30, total reward:-10.915908679197814, average reward:-0.36386362263992716,success
Box_Position: [[1.38543986 0.78663303 0.5511081 ]]
actor_loss: tensor(0.0600, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-9.150549504505035, average reward:-0.5382676179120609,success
Box_Position: [[1.28264355 0.97578572 0.59339703]]
Step:35, total reward:-13.688943530928363, average reward:-0.39111267231223895,success
Box_Position: [[1.45527024 0.77710011 0.72731618]]
actor_loss: tensor(0.0566, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-3.7261070971894865, average reward:-0.17743367129473744,success
Box_Position: [[1.49453153 1.09639401 0.71917499]]
Step:27, total reward:-5.175462467476026, average reward:-0.1916837950917047,success
Box_Position: [[1.51576127 0.749063   0.74550371]]
actor_loss: tensor(0.0692, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-12.222243757409974, average reward:-0.2396518383805877,success
Box_Position: [[1.47744946 0.57460162 0.59757925]]
Step:9, total reward:-1.4832502653553041, average reward:-0.16480558503947823,success
Box_Position: [[1.3482018  0.75438913 0.62676513]]
actor_loss: tensor(0.0881, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-15.01682258230248, average reward:-0.31950686345324425,success
Box_Position: [[1.27384439 0.86165908 0.66426846]]
actor_loss: tensor(0.0642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0661, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0662, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-72.3936061064687, average reward:-0.3619680305323435,----
Box_Position: [[1.37569656 0.67071147 0.68474651]]
actor_loss: tensor(0.0524, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-21.364139249613363, average reward:-0.41890469116888945,success
Box_Position: [[1.37264285 0.48032776 0.72900348]]
actor_loss: tensor(0.0656, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-6.79698983126899, average reward:-0.205969388826333,success
Box_Position: [[1.53653843 0.99688613 0.49136289]]
actor_loss: tensor(0.0835, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0582, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-62.79447564295659, average reward:-0.5708588694814235,success
Box_Position: [[1.29990928 0.91245549 0.72062842]]
Step:8, total reward:-1.1668485162681788, average reward:-0.14585606453352234,success
Box_Position: [[1.37425152 0.82303194 0.71372601]]
actor_loss: tensor(0.0711, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-4.460589367373242, average reward:-0.2787868354608276,success
Box_Position: [[1.53057005 0.98641058 0.62821648]]
Step:30, total reward:-12.165398641302042, average reward:-0.4055132880434014,success
Box_Position: [[1.44347463 0.71028967 0.45148287]]
actor_loss: tensor(0.0580, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-28.958068900191314, average reward:-1.206586204174638,success
Box_Position: [[1.31965891 0.70158512 0.46144784]]
actor_loss: tensor(0.0641, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-62.68052171770417, average reward:-1.139645849412803,success
Box_Position: [[1.47028807 0.72617812 0.5303627 ]]
Step:9, total reward:-3.4979580121654155, average reward:-0.3886620013517128,success
Box_Position: [[1.36259777 0.88776682 0.714311  ]]
actor_loss: tensor(0.0705, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0603, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-16.298481584701484, average reward:-0.23620987803915194,success
Box_Position: [[1.45019847 1.04284523 0.69345263]]
Step:25, total reward:-6.95287342834025, average reward:-0.27811493713361,success
Box_Position: [[1.49144233 0.53712939 0.50621372]]
actor_loss: tensor(0.0688, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-25.117798895340766, average reward:-0.8372599631780255,success
Box_Position: [[1.25716471 1.10259482 0.62998697]]
Step:30, total reward:-8.947274108933827, average reward:-0.29824247029779427,success
Box_Position: [[1.29027639 0.49871225 0.48447536]]
Step:4, total reward:-0.5931188032252293, average reward:-0.1482797008063073,success
Box_Position: [[1.35965628 0.44361024 0.49385023]]
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-22.26572854262099, average reward:-1.1132864271310496,success
Box_Position: [[1.32140893 1.00097923 0.73624744]]
Step:39, total reward:-11.203602129468468, average reward:-0.28727184947355044,success
Box_Position: [[1.43963605 1.03403958 0.53008023]]
actor_loss: tensor(0.0689, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-3.770700432607982, average reward:-0.4189667147342202,success
Box_Position: [[1.33310155 0.88222544 0.62761671]]
actor_loss: tensor(0.0622, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-17.46963664133602, average reward:-0.2130443492845856,success
Box_Position: [[1.31715629 0.74297832 0.58265441]]
actor_loss: tensor(0.0586, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-27.639469520878638, average reward:-0.5419503827623262,success
Box_Position: [[1.3022343 0.9765655 0.7268688]]
actor_loss: tensor(0.0706, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0526, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-40.42500072379646, average reward:-0.25585443496073706,success
Box_Position: [[1.51295426 0.7474276  0.66513459]]
actor_loss: tensor(0.0567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0894, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-24.513243430114393, average reward:-0.47140852750219986,success
Box_Position: [[1.46166893 0.51795142 0.74904288]]
actor_loss: tensor(0.0634, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-16.065932367791373, average reward:-0.22313794955265795,success
Box_Position: [[1.3641835  0.62350263 0.60771031]]
actor_loss: tensor(0.0743, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-13.124508348509048, average reward:-0.33652585508997557,success
Box_Position: [[1.46922931 0.76393132 0.72011436]]
actor_loss: tensor(0.0578, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-10.300112723076191, average reward:-0.2239154939799172,success
Box_Position: [[1.43702246 0.84847138 0.51769844]]
Step:36, total reward:-24.55188872061256, average reward:-0.6819969089059045,success
Box_Position: [[1.40167485 0.723442   0.6360631 ]]
Step:5, total reward:-0.7748893325328575, average reward:-0.1549778665065715,success
Box_Position: [[1.33099096 1.12850532 0.66817545]]
actor_loss: tensor(0.0485, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-6.099852451263501, average reward:-0.24399409805054004,success
Box_Position: [[1.51245098 1.12616204 0.45448931]]
actor_loss: tensor(0.0494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0672, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-151.89800493631063, average reward:-0.7594900246815531,----
Box_Position: [[1.3534027  1.05601996 0.68359348]]
actor_loss: tensor(0.0530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0528, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0698, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-54.87896484562808, average reward:-0.27439482422814043,----
Box_Position: [[1.43672392 1.04618212 0.70311653]]
Step:8, total reward:-1.407085863043951, average reward:-0.17588573288049386,success
Box_Position: [[1.39159094 0.64861433 0.60686825]]
actor_loss: tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0778, device='cuda:0', grad_fn=<NegBackward>)
Step:106, total reward:-38.56223949033981, average reward:-0.3637947121730171,success
Box_Position: [[1.34083154 0.63950235 0.6501449 ]]
actor_loss: tensor(0.0725, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-13.123270525415457, average reward:-0.3280817631353864,success
Box_Position: [[1.30194303 0.76921596 0.647685  ]]
actor_loss: tensor(0.0604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0513, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-34.64856815908761, average reward:-0.30936221570613937,success
Box_Position: [[1.53660455 0.8511795  0.46097968]]
actor_loss: tensor(0.0604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0778, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-47.105604955298816, average reward:-0.7477080151634733,success
Box_Position: [[1.32416046 0.72898542 0.70024306]]
Step:43, total reward:-7.598520311225908, average reward:-0.17670977467967228,success
Box_Position: [[1.52899498 0.823429   0.52876127]]
actor_loss: tensor(0.0416, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-11.677734200988729, average reward:-0.6869255412346311,success
Box_Position: [[1.46185982 0.96165871 0.61837592]]
Step:2, total reward:-0.34441875221807966, average reward:-0.17220937610903983,success
Box_Position: [[1.34406447 0.9759458  0.46384164]]

------------------Episode:2400------------------
Step:5, total reward:-2.8438464718779866, average reward:-0.5687692943755973,success
episode 2400, the accuracy is: 97%
Box_Position: [[1.35964508 1.02129148 0.72276193]]
Step:13, total reward:-1.88767473950222, average reward:-0.14520574919247847,success
Box_Position: [[1.50048122 0.75639495 0.45096359]]
actor_loss: tensor(0.0724, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0594, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-64.2599199158582, average reward:-0.9313031871863509,success
Box_Position: [[1.39789084 0.88224301 0.74790514]]
actor_loss: tensor(0.0655, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-14.860258010384836, average reward:-0.23219153141226306,success
Box_Position: [[1.26863663 0.61621169 0.54934972]]
Step:23, total reward:-9.366152090654284, average reward:-0.4072240039414906,success
Box_Position: [[1.52976859 0.65998393 0.55186166]]
actor_loss: tensor(0.0806, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-32.59730307344982, average reward:-0.6268712129509582,success
Box_Position: [[1.36341043 0.45085301 0.67416589]]
Step:3, total reward:-0.5448665933168365, average reward:-0.18162219777227884,success
Box_Position: [[1.54922564 1.09655575 0.55824953]]
actor_loss: tensor(0.0634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0719, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-103.43738009561372, average reward:-0.5843919779413205,success
Box_Position: [[1.40675588 0.94736381 0.59286842]]
actor_loss: tensor(0.0705, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-30.65452396502427, average reward:-0.41425032385167937,success
Box_Position: [[1.5214805  0.77712045 0.56499107]]
actor_loss: tensor(0.0725, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0697, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-33.120472844406564, average reward:-0.5018253461273722,success
Box_Position: [[1.44529506 0.74157222 0.48390287]]
actor_loss: tensor(0.0760, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-58.03495941617343, average reward:-0.9513927773143185,success
Box_Position: [[1.28632395 0.85445311 0.6528431 ]]
actor_loss: tensor(0.0577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0711, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-59.43685806868788, average reward:-0.2971842903434394,----
Box_Position: [[1.37403518 0.68343022 0.61095245]]
actor_loss: tensor(0.0378, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0486, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-31.3259902689159, average reward:-0.38674062060389996,success
Box_Position: [[1.39783178 0.72844111 0.49292954]]
Step:31, total reward:-20.54046327104704, average reward:-0.6625955893886143,success
Box_Position: [[1.32683481 0.94463872 0.71092067]]
actor_loss: tensor(0.0563, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0646, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-52.06883220477524, average reward:-0.2603441610238762,----
Box_Position: [[1.54363445 0.60543513 0.74551267]]
actor_loss: tensor(0.0487, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-14.470163568419775, average reward:-0.24525700963423347,success
Box_Position: [[1.5271755 1.0844712 0.7226274]]
actor_loss: tensor(0.0506, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0612, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0612, device='cuda:0', grad_fn=<NegBackward>)
Step:168, total reward:-38.95675500089103, average reward:-0.23188544643387518,success
Box_Position: [[1.43037145 0.89361805 0.63683302]]
Step:6, total reward:-2.986609636544216, average reward:-0.49776827275736935,success
Box_Position: [[1.25710748 0.9484166  0.63074231]]
actor_loss: tensor(0.0559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0660, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0658, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0545, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-62.73192561366697, average reward:-0.3136596280683348,----
Box_Position: [[1.34045374 1.04666873 0.55702057]]
Step:26, total reward:-18.861868882040948, average reward:-0.7254564954631134,success
Box_Position: [[1.36468898 0.98695282 0.57672705]]
actor_loss: tensor(0.0572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0612, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-27.873663383213092, average reward:-0.40396613598859554,success
Box_Position: [[1.33051035 0.56899294 0.60673266]]
Step:31, total reward:-21.79271346033735, average reward:-0.7029907567850758,success
Box_Position: [[1.41318706 0.84470258 0.72641793]]
actor_loss: tensor(0.0644, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-2.4341500722617306, average reward:-0.17386786230440934,success
Box_Position: [[1.4615464  0.85738978 0.591799  ]]
Step:14, total reward:-10.82115377020658, average reward:-0.7729395550147558,success
Box_Position: [[1.43880822 0.88573832 0.60503043]]
Step:9, total reward:-1.7860660424151016, average reward:-0.19845178249056683,success
Box_Position: [[1.41264617 0.49585259 0.46111942]]
actor_loss: tensor(0.0531, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-28.142995397864446, average reward:-0.7817498721629013,success
Box_Position: [[1.41236736 0.79829491 0.46966556]]
Step:12, total reward:-12.22566842646078, average reward:-1.018805702205065,success
Box_Position: [[1.27576087 0.86481155 0.69704608]]
actor_loss: tensor(0.0481, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0366, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0786, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-58.317717072134926, average reward:-0.2915885853606746,----
Box_Position: [[1.25920889 0.60272466 0.51663542]]
Step:7, total reward:-5.049574752747148, average reward:-0.7213678218210211,success
Box_Position: [[1.54615821 1.10248885 0.6529185 ]]
actor_loss: tensor(0.0629, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-7.99693778656801, average reward:-0.2665645928856003,success
Box_Position: [[1.50954857 0.80490403 0.49437687]]
Step:4, total reward:-4.79935754749672, average reward:-1.19983938687418,success
Box_Position: [[1.45518747 0.62016893 0.53446349]]
actor_loss: tensor(0.0344, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-21.41555372495895, average reward:-0.5635672032883935,success
Box_Position: [[1.37641401 0.52597281 0.54625485]]
actor_loss: tensor(0.0499, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-41.832779273215806, average reward:-0.7605959867857419,success
Box_Position: [[1.53799202 0.81534231 0.69341752]]
Step:10, total reward:-1.746716089765715, average reward:-0.1746716089765715,success
Box_Position: [[1.50667873 1.04915218 0.7387499 ]]
actor_loss: tensor(0.0535, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0575, device='cuda:0', grad_fn=<NegBackward>)
Step:97, total reward:-31.511595181190483, average reward:-0.3248618059916545,success
Box_Position: [[1.44827367 0.78194139 0.63809736]]
actor_loss: tensor(0.0506, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-8.741666632766359, average reward:-0.24976190379332452,success
Box_Position: [[1.39186753 0.6417665  0.55973909]]
Step:11, total reward:-3.916145145793481, average reward:-0.35601319507213464,success
Box_Position: [[1.38553842 0.65966239 0.70892174]]
actor_loss: tensor(0.0624, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0445, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-29.525508428644233, average reward:-0.28665542163732266,success
Box_Position: [[1.50118886 0.99645156 0.58114384]]
actor_loss: tensor(0.0606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0684, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-61.13205306923825, average reward:-0.5180682463494767,success
Box_Position: [[1.53789554 0.62865776 0.61764258]]
actor_loss: tensor(0.0337, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-25.089828093293775, average reward:-0.5017965618658755,success
Box_Position: [[1.37908444 0.84033742 0.48727003]]
actor_loss: tensor(0.0535, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0596, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-89.87633923959739, average reward:-0.8898647449465088,success
Box_Position: [[1.28298025 0.75941103 0.50716438]]
actor_loss: tensor(0.0589, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0322, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-58.76513671434752, average reward:-0.734564208929344,success
Box_Position: [[1.29121711 0.4756685  0.63756621]]
actor_loss: tensor(0.0334, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-14.97305492089496, average reward:-0.3185756366147864,success
Box_Position: [[1.3440128  1.12582637 0.4787657 ]]
actor_loss: tensor(0.0109, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0386, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0293, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0386, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-56.16700287503831, average reward:-0.28083501437519154,----
Box_Position: [[1.46613351 0.45446108 0.73929344]]
Step:33, total reward:-8.550603585692409, average reward:-0.25910919956643663,success
Box_Position: [[1.49544833 0.6497232  0.57155163]]
actor_loss: tensor(0.0246, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0395, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-33.64519557927205, average reward:-0.5426644448269685,success
Box_Position: [[1.48095294 0.88562051 0.54931144]]
Step:3, total reward:-0.36122427027569937, average reward:-0.12040809009189979,success
Box_Position: [[1.52943969 0.89739508 0.47643907]]
Step:7, total reward:-5.095955750906333, average reward:-0.7279936787009047,success
Box_Position: [[1.43388147 0.71025573 0.46112429]]
actor_loss: tensor(0.0457, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-23.20856777086362, average reward:-0.7252677428394881,success
Box_Position: [[1.38604723 0.61564919 0.56157447]]
actor_loss: tensor(0.0533, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-40.42598677098053, average reward:-0.6219382580150851,success
Box_Position: [[1.45097919 1.16037831 0.7260703 ]]

------------------Episode:2450------------------
Step:9, total reward:-1.3684656503970107, average reward:-0.1520517389330012,success
Box_Position: [[1.40802688 0.87644945 0.60118427]]
actor_loss: tensor(0.0275, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-14.615664131774366, average reward:-0.42987247446395194,success
Box_Position: [[1.49614933 0.99623712 0.68189665]]
actor_loss: tensor(0.0447, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0446, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-39.30540606557252, average reward:-0.38160588413177204,success
Box_Position: [[1.50522395 1.1358005  0.67137649]]
actor_loss: tensor(0.0458, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0516, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0668, device='cuda:0', grad_fn=<NegBackward>)
Step:155, total reward:-62.24618543820422, average reward:-0.4015882931497047,success
Box_Position: [[1.43068237 0.61302163 0.6989409 ]]
Step:8, total reward:-3.7136675727960986, average reward:-0.4642084465995123,success
Box_Position: [[1.44065068 0.7296563  0.45900961]]
actor_loss: tensor(0.0449, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-31.568321746613723, average reward:-0.6716664201407175,success
Box_Position: [[1.54759861 0.81317414 0.59468453]]
actor_loss: tensor(0.0176, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0196, device='cuda:0', grad_fn=<NegBackward>)
Step:175, total reward:-140.55246587208865, average reward:-0.8031569478405065,success
Box_Position: [[1.36664953 0.75331788 0.60320027]]
actor_loss: tensor(0.0427, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-7.796117688326501, average reward:-0.33896163862289136,success
Box_Position: [[1.40563397 0.99209481 0.68327668]]
Step:13, total reward:-2.2577350787222352, average reward:-0.17367192913247964,success
Box_Position: [[1.43211973 0.73273894 0.56618089]]
actor_loss: tensor(0.0183, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-16.971783910531926, average reward:-0.4586968624468088,success
Box_Position: [[1.27355259 0.67937294 0.46018442]]
actor_loss: tensor(0.0286, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0254, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0331, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-150.54130327894396, average reward:-0.7527065163947197,----
Box_Position: [[1.53786062 0.77697939 0.70298027]]
actor_loss: tensor(0.0145, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-17.0598779158107, average reward:-0.27079171294937615,success
Box_Position: [[1.32999641 0.92022203 0.51345435]]
Step:5, total reward:-6.558397515249007, average reward:-1.3116795030498014,success
Box_Position: [[1.25351284 1.04200186 0.64953741]]
actor_loss: tensor(0.0356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0251, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0465, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0447, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.60421263437527, average reward:-0.34302106317187636,----
Box_Position: [[1.36829204 0.66151305 0.6468205 ]]
actor_loss: tensor(0.0444, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0614, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0370, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0366, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-82.81045044375271, average reward:-0.4140522522187636,----
Box_Position: [[1.31469417 0.75069272 0.62404486]]
Step:1, total reward:-0.049681599002450616, average reward:-0.049681599002450616,success
Box_Position: [[1.38047029 0.61219578 0.47930155]]
Step:6, total reward:-1.0620855641874278, average reward:-0.17701426069790463,success
Box_Position: [[1.53875853 0.48682039 0.72449896]]
actor_loss: tensor(0.0490, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-2.154269163055755, average reward:-0.15387636878969677,success
Box_Position: [[1.25630198 1.0144695  0.66611319]]
actor_loss: tensor(0.0254, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0382, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0240, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.85802916947421, average reward:-0.34429014584737105,----
Box_Position: [[1.28599057 0.71797537 0.68277659]]
actor_loss: tensor(0.0536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0390, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0289, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0513, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-66.97012070600276, average reward:-0.3348506035300138,----
Box_Position: [[1.36624088 0.92172801 0.70046039]]
actor_loss: tensor(0.0279, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0351, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-19.157203106784454, average reward:-0.1954816643549434,success
Box_Position: [[1.30532837 0.86239647 0.66510333]]
actor_loss: tensor(0.0141, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0219, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0413, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-46.95198025626704, average reward:-0.2594032058357295,success
Box_Position: [[1.50917086 0.99678859 0.52442234]]
actor_loss: tensor(0.0360, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0235, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-39.099614745361336, average reward:-0.5749943344906079,success
Box_Position: [[1.39409158 0.6865542  0.64464148]]
actor_loss: tensor(0.0603, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-19.653913940412064, average reward:-0.32219531049855843,success
Box_Position: [[1.3711891  0.72141185 0.68665651]]
Step:11, total reward:-1.7701616271517053, average reward:-0.16092378428651866,success
Box_Position: [[1.42740214 0.80632326 0.68787403]]
actor_loss: tensor(0.0432, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0300, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-18.262675587064216, average reward:-0.24029836298768706,success
Box_Position: [[1.48202135 0.7588831  0.64725888]]
Step:33, total reward:-8.878393827670525, average reward:-0.2690422372021371,success
Box_Position: [[1.44784635 0.82878555 0.69302432]]
actor_loss: tensor(0.0406, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-11.068814626468846, average reward:-0.23550669418018821,success
Box_Position: [[1.4804062  0.75770864 0.68354581]]
Step:6, total reward:-0.8800163549986637, average reward:-0.14666939249977728,success
Box_Position: [[1.37593326 1.09363338 0.51730195]]
actor_loss: tensor(0.0436, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-7.754983300543689, average reward:-0.6462486083786407,success
Box_Position: [[1.5449084  1.09054016 0.61454208]]
Step:29, total reward:-11.704037556488295, average reward:-0.40358750194787224,success
Box_Position: [[1.28570588 0.72209905 0.73251406]]
actor_loss: tensor(0.0201, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0386, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0355, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0457, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-61.427472871883104, average reward:-0.3071373643594155,----
Box_Position: [[1.43050558 1.08365058 0.53981863]]
actor_loss: tensor(0.0478, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-21.737984325288828, average reward:-0.45287467344351723,success
Box_Position: [[1.29101824 0.94655008 0.70810404]]
actor_loss: tensor(0.0442, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-8.122269708664515, average reward:-0.2538209283957661,success
Box_Position: [[1.31951382 1.04552541 0.47784054]]
actor_loss: tensor(0.0284, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-38.07546518096866, average reward:-0.7322204842493973,success
Box_Position: [[1.40075594 0.80932329 0.71726817]]
actor_loss: tensor(0.0394, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-19.560730961932304, average reward:-0.23012624661096828,success
Box_Position: [[1.40502967 0.97167455 0.65841424]]
actor_loss: tensor(0.0470, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-11.799183426943953, average reward:-0.25650398754225984,success
Box_Position: [[1.46789579 0.85128311 0.54491478]]
actor_loss: tensor(0.0579, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-19.45560846163137, average reward:-0.6276002729558506,success
Box_Position: [[1.47773485 1.02703175 0.69204191]]
actor_loss: tensor(0.0282, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-18.148844934004202, average reward:-0.26689477844123827,success
Box_Position: [[1.29389406 0.77276015 0.63255869]]
actor_loss: tensor(0.0743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0466, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-76.85978751972971, average reward:-0.3842989375986485,----
Box_Position: [[1.46420132 0.61897704 0.53202958]]
actor_loss: tensor(0.0432, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-5.923024531069468, average reward:-0.6581138367854965,success
Box_Position: [[1.30217185 1.02266743 0.46645791]]
Step:6, total reward:-9.069861586873659, average reward:-1.5116435978122764,success
Box_Position: [[1.51561475 0.41124854 0.55995608]]
actor_loss: tensor(0.0616, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-39.39393310366076, average reward:-0.667693781417979,success
Box_Position: [[1.49782145 0.66101722 0.69782875]]
Step:15, total reward:-5.233527971444874, average reward:-0.3489018647629916,success
Box_Position: [[1.49338698 0.81869326 0.65118244]]
actor_loss: tensor(0.0600, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-17.348181071536285, average reward:-0.27536795351644894,success
Box_Position: [[1.45971406 1.03423632 0.47696809]]
actor_loss: tensor(0.0402, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-5.6367353045290685, average reward:-0.7045919130661336,success
Box_Position: [[1.40949307 0.80182988 0.57530901]]
actor_loss: tensor(0.0456, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-34.43695208615192, average reward:-0.4359107859006572,success
Box_Position: [[1.33779577 0.65436337 0.49908695]]
actor_loss: tensor(0.0388, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-8.688922957644825, average reward:-0.347556918305793,success
Box_Position: [[1.30272965 0.83045546 0.47148118]]
Step:17, total reward:-14.490105755289811, average reward:-0.8523591620758713,success
Box_Position: [[1.25855094 1.06551916 0.54417934]]
Step:21, total reward:-7.0838641661628365, average reward:-0.3373268650553732,success
Box_Position: [[1.44541855 1.01698331 0.53136264]]

------------------Episode:2500------------------
actor_loss: tensor(0.0310, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-15.710016552691256, average reward:-0.8727786973717364,success
episode 2500, the accuracy is: 88%
Box_Position: [[1.25824295 0.84695894 0.70118731]]
actor_loss: tensor(0.0567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0499, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-58.834920217527745, average reward:-0.2941746010876387,----
Box_Position: [[1.31361703 0.63834314 0.58317304]]
actor_loss: tensor(0.0626, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-23.874865024327868, average reward:-0.47749730048655736,success
Box_Position: [[1.51416447 1.15277299 0.62888858]]
Step:4, total reward:-0.44132632268311156, average reward:-0.11033158067077789,success
Box_Position: [[1.44181094 1.10074405 0.55655941]]
Step:10, total reward:-1.5775675739696957, average reward:-0.15775675739696957,success
Box_Position: [[1.25706915 1.08099014 0.47648639]]
Step:1, total reward:-0.04780324819042505, average reward:-0.04780324819042505,success
Box_Position: [[1.45971599 0.96018978 0.68194591]]
Step:3, total reward:-0.3147641733183127, average reward:-0.10492139110610423,success
Box_Position: [[1.35212059 0.82370213 0.45723884]]
Step:5, total reward:-2.853617654077584, average reward:-0.5707235308155167,success
Box_Position: [[1.43937116 0.83075148 0.52141781]]
actor_loss: tensor(0.0452, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-28.028534267373953, average reward:-0.539010274372576,success
Box_Position: [[1.25749568 0.66790193 0.61249941]]
actor_loss: tensor(0.0547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0759, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-84.32481922499717, average reward:-0.42162409612498586,----
Box_Position: [[1.3590255  0.7041219  0.46491063]]
actor_loss: tensor(0.0719, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-27.80242993081388, average reward:-0.7316428929161547,success
Box_Position: [[1.39078629 0.53093722 0.58994563]]
Step:3, total reward:-0.31542153501245146, average reward:-0.10514051167081716,success
Box_Position: [[1.29455757 0.9942889  0.57346423]]
Step:14, total reward:-6.275731029491856, average reward:-0.4482665021065611,success
Box_Position: [[1.38654013 0.99181453 0.6237388 ]]
actor_loss: tensor(0.0628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0907, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-30.952143617779864, average reward:-0.3557717657216076,success
Box_Position: [[1.53494529 0.97938341 0.70323212]]
Step:4, total reward:-0.6258450715268491, average reward:-0.15646126788171227,success
Box_Position: [[1.44766575 0.99851219 0.6412602 ]]
actor_loss: tensor(0.0763, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-10.516111509226894, average reward:-0.28421922997910526,success
Box_Position: [[1.47131313 0.75250143 0.62412816]]
Step:14, total reward:-4.864765512434898, average reward:-0.34748325088820703,success
Box_Position: [[1.41506858 0.69513841 0.61055621]]
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-3.0103415198120342, average reward:-0.1584390273585281,success
Box_Position: [[1.32753574 0.4437804  0.47884546]]
actor_loss: tensor(0.0659, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-64.07834532447758, average reward:-0.8009793165559698,success
Box_Position: [[1.30046068 1.04307292 0.46331241]]
Step:5, total reward:-2.9040928557232517, average reward:-0.5808185711446503,success
Box_Position: [[1.36870222 1.11818531 0.69466194]]
Step:6, total reward:-0.7621063511435079, average reward:-0.12701772519058466,success
Box_Position: [[1.49628843 0.92224058 0.5600182 ]]
actor_loss: tensor(0.0633, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0561, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-25.23979642306989, average reward:-0.44280344601877003,success
Box_Position: [[1.48427805 0.97271665 0.51161575]]
Step:27, total reward:-16.278946213307247, average reward:-0.6029239338261944,success
Box_Position: [[1.41891811 0.8197293  0.58988904]]
actor_loss: tensor(0.0739, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0704, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-43.4375267471215, average reward:-0.4524742369491823,success
Box_Position: [[1.53542454 0.50407204 0.69904384]]
actor_loss: tensor(0.0688, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-8.848977300932237, average reward:-0.22689685387005737,success
Box_Position: [[1.34251232 0.82704443 0.51231756]]
actor_loss: tensor(0.0582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0544, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0664, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0726, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.4696862176133, average reward:-0.5573484310880665,----
Box_Position: [[1.54153446 0.72223992 0.50216606]]
Step:5, total reward:-0.7204967251157679, average reward:-0.14409934502315358,success
Box_Position: [[1.40071794 0.7503914  0.55233998]]
Step:27, total reward:-17.22547043198767, average reward:-0.6379803863699137,success
Box_Position: [[1.53043912 0.96196597 0.46260122]]
actor_loss: tensor(0.0441, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0521, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-78.04625562485917, average reward:-1.0546791300656644,success
Box_Position: [[1.54149152 0.87982535 0.5688939 ]]
Step:27, total reward:-20.306327334257887, average reward:-0.7520861975651069,success
Box_Position: [[1.48282758 0.90978987 0.70021707]]
actor_loss: tensor(0.0655, device='cuda:0', grad_fn=<NegBackward>)
Step:7, total reward:-3.4918257492940787, average reward:-0.4988322498991541,success
Box_Position: [[1.29153894 1.05064554 0.58775855]]
Step:8, total reward:-1.2518741839762626, average reward:-0.15648427299703283,success
Box_Position: [[1.38804528 0.98570674 0.58994396]]
Step:20, total reward:-7.89636626213041, average reward:-0.3948183131065205,success
Box_Position: [[1.43194235 0.60982035 0.50193633]]
Step:6, total reward:-4.787885094745907, average reward:-0.7979808491243179,success
Box_Position: [[1.36525117 0.89023611 0.53669126]]
actor_loss: tensor(0.0658, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0619, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0441, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-110.70772394094253, average reward:-0.5535386197047126,----
Box_Position: [[1.25172881 0.78077965 0.57161778]]
actor_loss: tensor(0.0886, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0622, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0574, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-104.65612772464442, average reward:-0.523280638623222,----
Box_Position: [[1.28569391 0.58706195 0.56802431]]
actor_loss: tensor(0.0650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0798, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-102.1916310540063, average reward:-0.5109581552700315,----
Box_Position: [[1.46250648 0.85269752 0.45049169]]
Step:9, total reward:-6.192394756989405, average reward:-0.6880438618877116,success
Box_Position: [[1.3394531  0.54962636 0.5250194 ]]
actor_loss: tensor(0.0602, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0574, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-121.16184487499962, average reward:-0.6058092243749981,----
Box_Position: [[1.40433319 1.01336978 0.61953053]]
actor_loss: tensor(0.0386, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0604, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-30.505187193162367, average reward:-0.34664985446775415,success
Box_Position: [[1.54163902 0.94281508 0.67607642]]
actor_loss: tensor(0.0662, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-7.621979127944022, average reward:-0.2540659709314674,success
Box_Position: [[1.41064419 0.77252353 0.59415833]]
actor_loss: tensor(0.0483, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-35.090226993339016, average reward:-0.4332126789301113,success
Box_Position: [[1.43941598 0.77254647 0.74338852]]
actor_loss: tensor(0.0678, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0476, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-15.473436080027097, average reward:-0.26678338069012236,success
Box_Position: [[1.29457545 1.01630378 0.60155711]]
Step:16, total reward:-2.2837637319705655, average reward:-0.14273523324816034,success
Box_Position: [[1.31827581 0.77080352 0.59892663]]
actor_loss: tensor(0.0633, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-12.317781620621309, average reward:-0.34216060057281417,success
Box_Position: [[1.3894331  0.74910367 0.67640126]]
Step:18, total reward:-5.480787737051963, average reward:-0.3044882076139979,success
Box_Position: [[1.25503842 0.78016767 0.60127832]]
actor_loss: tensor(0.0513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0606, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.7593534396855, average reward:-0.3437967671984275,----
Box_Position: [[1.53662394 0.82533494 0.61435234]]
Step:4, total reward:-0.6006921978172928, average reward:-0.1501730494543232,success
Box_Position: [[1.25535108 0.67522205 0.67659724]]
actor_loss: tensor(0.0691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0641, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0494, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-74.51712013728617, average reward:-0.3725856006864309,----
Box_Position: [[1.49301211 0.63479545 0.72555026]]
actor_loss: tensor(0.0524, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0646, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-24.221985189719817, average reward:-0.23068557323542682,success
Box_Position: [[1.51588144 0.67962826 0.62899276]]

------------------Episode:2550------------------
actor_loss: tensor(0.0582, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-7.5300552304881085, average reward:-0.35857405859467184,success
Box_Position: [[1.54550163 1.08021712 0.57991704]]
actor_loss: tensor(0.0577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0449, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0648, device='cuda:0', grad_fn=<NegBackward>)
Step:153, total reward:-79.98065641531828, average reward:-0.5227493883354136,success
Box_Position: [[1.37728693 0.68799114 0.5775232 ]]
actor_loss: tensor(0.0619, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0649, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0718, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-118.30539259545385, average reward:-0.5915269629772693,----
Box_Position: [[1.52566552 0.62726175 0.66100414]]
actor_loss: tensor(0.0597, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-14.761976240962321, average reward:-0.3140846008715387,success
Box_Position: [[1.30780557 0.63216353 0.72961765]]
actor_loss: tensor(0.0580, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0630, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0514, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-61.91856323579759, average reward:-0.309592816178988,----
Box_Position: [[1.40091893 0.62722332 0.54639151]]
actor_loss: tensor(0.0387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0641, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0771, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-117.5344183286711, average reward:-0.7037989121477312,success
Box_Position: [[1.41350267 0.77912203 0.66861413]]
Step:4, total reward:-0.7641951534899065, average reward:-0.19104878837247663,success
Box_Position: [[1.36053042 0.69320362 0.56745057]]
Step:5, total reward:-2.523867214163073, average reward:-0.5047734428326146,success
Box_Position: [[1.38496415 0.54498508 0.70346226]]
actor_loss: tensor(0.0669, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-14.169328491112704, average reward:-0.2623949720576427,success
Box_Position: [[1.31692868 1.15303657 0.54568871]]
Step:2, total reward:-0.20667959565307428, average reward:-0.10333979782653714,success
Box_Position: [[1.52594629 0.86794856 0.63820379]]
Step:11, total reward:-1.8641398812541112, average reward:-0.16946726193219194,success
Box_Position: [[1.28955017 0.85532829 0.53274997]]
actor_loss: tensor(0.0488, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0600, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-137.95226062878817, average reward:-0.6897613031439408,----
Box_Position: [[1.54345942 0.67507812 0.49797811]]
actor_loss: tensor(0.0826, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-9.44981867418879, average reward:-0.5906136671367994,success
Box_Position: [[1.36307846 0.77156923 0.70900418]]
actor_loss: tensor(0.0693, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0596, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0814, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-54.29288056689949, average reward:-0.27146440283449746,----
Box_Position: [[1.50269139 0.79002263 0.52852909]]
actor_loss: tensor(0.0615, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-50.1890629722881, average reward:-0.6875214105792891,success
Box_Position: [[1.36988277 0.69736428 0.65790285]]
actor_loss: tensor(0.0749, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0730, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0719, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0574, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-69.66979635174387, average reward:-0.34834898175871937,----
Box_Position: [[1.52198617 0.96630969 0.47205089]]
actor_loss: tensor(0.0770, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-39.756243957316, average reward:-0.9465772370789525,success
Box_Position: [[1.35495515 1.0337223  0.66832201]]
Step:21, total reward:-3.378566475414367, average reward:-0.16088411787687462,success
Box_Position: [[1.48981283 0.75577274 0.49004768]]
actor_loss: tensor(0.0727, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-20.701222233677477, average reward:-0.6469131948024212,success
Box_Position: [[1.43529485 0.83025251 0.66988274]]
actor_loss: tensor(0.0805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0912, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0634, device='cuda:0', grad_fn=<NegBackward>)
Step:171, total reward:-45.38888357919945, average reward:-0.2654320677146167,success
Box_Position: [[1.40618565 0.90163253 0.52680744]]
Step:26, total reward:-16.190343047729414, average reward:-0.6227055018357467,success
Box_Position: [[1.54533174 0.58164005 0.6927358 ]]
Step:7, total reward:-0.9976260414577447, average reward:-0.14251800592253497,success
Box_Position: [[1.54176903 0.68614345 0.58785864]]
Step:11, total reward:-1.6255271036079546, average reward:-0.1477751912370868,success
Box_Position: [[1.26207045 0.78004133 0.53961793]]
actor_loss: tensor(0.0769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0631, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0750, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-95.50249898197356, average reward:-0.4775124949098678,----
Box_Position: [[1.36715331 0.75242488 0.72462003]]
actor_loss: tensor(0.0885, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-1.584956970789427, average reward:-0.1584956970789427,success
Box_Position: [[1.5457358  0.52564932 0.72830888]]
Step:23, total reward:-4.495966846514553, average reward:-0.1954768194136762,success
Box_Position: [[1.4973602  0.79291088 0.49753539]]
Step:19, total reward:-15.183230498798585, average reward:-0.7991173946736098,success
Box_Position: [[1.49702278 0.95100535 0.60247303]]
Step:2, total reward:-0.334845777369142, average reward:-0.167422888684571,success
Box_Position: [[1.27471717 0.48587933 0.47717176]]
actor_loss: tensor(0.0761, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-21.91589970325133, average reward:-0.6087749917569814,success
Box_Position: [[1.53937504 0.82569982 0.59282676]]
Step:9, total reward:-5.464709132125864, average reward:-0.6071899035695405,success
Box_Position: [[1.36590721 0.83500759 0.64293622]]
actor_loss: tensor(0.0596, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-6.16985601457607, average reward:-0.2127536556750369,success
Box_Position: [[1.30210787 0.90249071 0.5584761 ]]
Step:26, total reward:-14.056287800525832, average reward:-0.5406264538663781,success
Box_Position: [[1.34682687 0.78783004 0.59147777]]
actor_loss: tensor(0.0487, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-0.4934910062954272, average reward:-0.1233727515738568,success
Box_Position: [[1.43454347 1.02393941 0.68207376]]
Step:26, total reward:-6.6907083861528065, average reward:-0.2573349379289541,success
Box_Position: [[1.32021575 0.73882664 0.66325705]]
Step:11, total reward:-1.9245129542139963, average reward:-0.1749557231103633,success
Box_Position: [[1.29566578 0.78230407 0.48620975]]
actor_loss: tensor(0.0526, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0631, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-46.129014060313104, average reward:-0.7440163558115017,success
Box_Position: [[1.53992767 0.87150222 0.64258803]]
Step:32, total reward:-6.11613663576343, average reward:-0.1911292698676072,success
Box_Position: [[1.28122735 0.74568394 0.7286827 ]]
actor_loss: tensor(0.0597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0524, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0617, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0778, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-54.16690844147451, average reward:-0.2708345422073726,----
Box_Position: [[1.27309012 0.6273788  0.72333952]]
actor_loss: tensor(0.0631, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0490, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0592, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-43.32179451897655, average reward:-0.22563434645300287,success
Box_Position: [[1.4942777  0.88312548 0.74059603]]
Step:11, total reward:-4.593672933472078, average reward:-0.41760663031564343,success
Box_Position: [[1.51870784 0.65842054 0.56038194]]
actor_loss: tensor(0.0614, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-5.503580384068973, average reward:-0.30575446578160964,success
Box_Position: [[1.33441264 1.10108701 0.66479723]]
actor_loss: tensor(0.0797, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-19.47977454612203, average reward:-0.2465794246344561,success
Box_Position: [[1.2652703  0.91905428 0.66682219]]
actor_loss: tensor(0.0454, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-3.5063820586344514, average reward:-0.16697057422068817,success
Box_Position: [[1.25931487 0.74993636 0.66258921]]
actor_loss: tensor(0.0629, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-11.768325572874316, average reward:-0.2451734494348816,success
Box_Position: [[1.378969   0.89496487 0.72504717]]
Step:4, total reward:-0.7686905877138139, average reward:-0.19217264692845348,success
Box_Position: [[1.28342031 0.89774652 0.52269511]]
actor_loss: tensor(0.0676, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-32.24283480804345, average reward:-0.620054515539297,success
Box_Position: [[1.27902042 0.63414879 0.48932261]]
actor_loss: tensor(0.0582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0502, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0539, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0856, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-138.2997709668681, average reward:-0.6914988548343405,----
Box_Position: [[1.31689498 1.07390348 0.54235986]]
Step:3, total reward:-0.23845037199888944, average reward:-0.07948345733296315,success
Box_Position: [[1.43540748 0.65225538 0.45866878]]
Step:31, total reward:-26.38863340905457, average reward:-0.8512462390017603,success
Box_Position: [[1.34106554 0.92292752 0.70105667]]
actor_loss: tensor(0.0499, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-2.8199616494493696, average reward:-0.18799744329662463,success
Box_Position: [[1.50157947 0.87185905 0.58476883]]

------------------Episode:2600------------------
Step:3, total reward:-0.2430636823142018, average reward:-0.08102122743806726,success
episode 2600, the accuracy is: 83%
Box_Position: [[1.49072692 1.04720822 0.49517367]]
actor_loss: tensor(0.0638, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0557, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-63.59484536360663, average reward:-0.7145488243101868,success
Box_Position: [[1.35431442 1.12844295 0.48979317]]
actor_loss: tensor(0.0644, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-55.74030672933878, average reward:-0.7850747426667434,success
Box_Position: [[1.29755388 0.9571005  0.50906818]]
actor_loss: tensor(0.0649, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-17.75857731239215, average reward:-0.5223110974232985,success
Box_Position: [[1.50308325 0.6156777  0.5253416 ]]
Step:4, total reward:-0.8977001002204088, average reward:-0.2244250250551022,success
Box_Position: [[1.44952066 0.85993189 0.53493709]]
Step:11, total reward:-3.3680110327811255, average reward:-0.30618282116192047,success
Box_Position: [[1.51389714 0.96144135 0.50864992]]
actor_loss: tensor(0.0663, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0717, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-64.40892840553973, average reward:-0.7156547600615525,success
Box_Position: [[1.31115587 0.79219407 0.52779771]]
Step:1, total reward:-0.03514073502646013, average reward:-0.03514073502646013,success
Box_Position: [[1.34934116 0.74407255 0.63288543]]
Step:14, total reward:-4.643917481879278, average reward:-0.33170839156280557,success
Box_Position: [[1.32112469 0.77205668 0.65342708]]
Step:9, total reward:-1.24802528258481, average reward:-0.13866947584275666,success
Box_Position: [[1.26483766 0.76844918 0.64303529]]
actor_loss: tensor(0.0669, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-4.898543299036027, average reward:-0.15307947809487585,success
Box_Position: [[1.45542514 0.82052713 0.58921727]]
Step:30, total reward:-13.023371908660868, average reward:-0.4341123969553623,success
Box_Position: [[1.36025539 0.49942634 0.48799409]]
actor_loss: tensor(0.0635, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0578, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-36.926998645433784, average reward:-0.6713999753715233,success
Box_Position: [[1.45541021 0.42355226 0.5607427 ]]
actor_loss: tensor(0.0728, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-23.23449960228482, average reward:-0.35203787276189125,success
Box_Position: [[1.4316348  0.81135589 0.68818327]]
Step:3, total reward:-0.4744846357443049, average reward:-0.15816154524810164,success
Box_Position: [[1.46657591 0.7880872  0.63035503]]
actor_loss: tensor(0.0644, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-20.443348544032347, average reward:-0.3145130545235746,success
Box_Position: [[1.46699149 0.60175378 0.47159163]]
Step:14, total reward:-10.097094875369807, average reward:-0.7212210625264148,success
Box_Position: [[1.38030674 0.59200402 0.64406326]]
actor_loss: tensor(0.0682, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0685, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0635, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0582, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-68.57146952641706, average reward:-0.3428573476320853,----
Box_Position: [[1.35046479 0.95000924 0.54864592]]
actor_loss: tensor(0.0930, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0671, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-54.132199460632926, average reward:-0.47071477791854716,success
Box_Position: [[1.37684671 0.86829543 0.64358309]]
actor_loss: tensor(0.0645, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0619, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-20.675927804930662, average reward:-0.22973253116589626,success
Box_Position: [[1.34915007 1.00613126 0.4691132 ]]
Step:21, total reward:-8.979274190441975, average reward:-0.42758448525914167,success
Box_Position: [[1.41334938 0.64581263 0.5804767 ]]
Step:20, total reward:-12.996116843478044, average reward:-0.6498058421739021,success
Box_Position: [[1.30010756 0.62140709 0.68261125]]
actor_loss: tensor(0.0606, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-13.0214490035717, average reward:-0.3028243954319,success
Box_Position: [[1.27256786 1.04171083 0.50726981]]
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-20.460647817841995, average reward:-0.705539579925586,success
Box_Position: [[1.44572576 0.76601271 0.73628733]]
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-14.568051716938612, average reward:-0.3387919003939212,success
Box_Position: [[1.5337605  0.76957296 0.70536092]]
Step:13, total reward:-4.160735941933298, average reward:-0.320056610917946,success
Box_Position: [[1.29625522 0.57356856 0.67518554]]
actor_loss: tensor(0.0743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0761, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-35.52216910844971, average reward:-0.26312717858110896,success
Box_Position: [[1.53979167 0.48411152 0.71483595]]
actor_loss: tensor(0.0473, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-17.251045179116666, average reward:-0.25369184086936275,success
Box_Position: [[1.51486039 0.97611118 0.71548783]]
actor_loss: tensor(0.0813, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-8.132190172663984, average reward:-0.1891207016898601,success
Box_Position: [[1.3354611  0.74649929 0.64413089]]
actor_loss: tensor(0.0610, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-8.946955016653904, average reward:-0.28861145215012596,success
Box_Position: [[1.5251721  0.61429822 0.552769  ]]
actor_loss: tensor(0.0797, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-42.04991512545449, average reward:-0.7249985366457671,success
Box_Position: [[1.51731018 0.71849355 0.49819768]]
Step:17, total reward:-10.385817974890347, average reward:-0.6109304691111969,success
Box_Position: [[1.33370547 0.91359351 0.69946628]]
Step:4, total reward:-0.3824978480389869, average reward:-0.09562446200974672,success
Box_Position: [[1.4213734  0.6682578  0.63389587]]
actor_loss: tensor(0.0837, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0742, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0803, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-45.81428834321894, average reward:-0.33198759668999234,success
Box_Position: [[1.27819397 0.73587203 0.50892912]]
actor_loss: tensor(0.0789, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-34.86359331644105, average reward:-0.4910365255836767,success
Box_Position: [[1.27648188 0.71295424 0.60118944]]
actor_loss: tensor(0.0547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0750, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0713, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0789, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-59.12246742941352, average reward:-0.2956123371470676,----
Box_Position: [[1.51645293 0.70650084 0.5300593 ]]
Step:2, total reward:-0.18165754609226395, average reward:-0.09082877304613197,success
Box_Position: [[1.4265781  0.63776497 0.49917969]]
actor_loss: tensor(0.0833, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-14.056865753463095, average reward:-0.8785541095914434,success
Box_Position: [[1.3248477  0.62546556 0.61804493]]
actor_loss: tensor(0.0747, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0738, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0641, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-90.7500858935414, average reward:-0.453750429467707,----
Box_Position: [[1.39770309 0.60893179 0.60677885]]
Step:31, total reward:-10.225275033649565, average reward:-0.3298475817306311,success
Box_Position: [[1.49882452 0.99081753 0.70861128]]
Step:12, total reward:-1.9350829502358846, average reward:-0.16125691251965704,success
Box_Position: [[1.27346146 0.95976861 0.56297613]]
actor_loss: tensor(0.0812, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0700, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-23.638671480844586, average reward:-0.40756330139387215,success
Box_Position: [[1.39050811 0.61453109 0.45811761]]
actor_loss: tensor(0.0932, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-32.75384663568985, average reward:-0.6065527154757379,success
Box_Position: [[1.51664573 1.07274555 0.60244353]]
actor_loss: tensor(0.0749, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-12.991981292882793, average reward:-0.2706662769350582,success
Box_Position: [[1.34842146 0.88437528 0.59590288]]
Step:2, total reward:-0.11535201281567133, average reward:-0.05767600640783566,success
Box_Position: [[1.52285495 0.65149842 0.70831911]]
Step:36, total reward:-8.017884510634863, average reward:-0.22271901418430173,success
Box_Position: [[1.44025993 0.79844661 0.71169139]]
Step:1, total reward:-0.04091150174450901, average reward:-0.04091150174450901,success
Box_Position: [[1.39895122 0.76849751 0.53834381]]
actor_loss: tensor(0.0861, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0856, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0711, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-61.07716422002633, average reward:-0.5929821768934596,success
Box_Position: [[1.38354011 0.6057371  0.54553624]]
Step:27, total reward:-12.54422503614666, average reward:-0.4646009272646911,success
Box_Position: [[1.50882007 0.49007311 0.68815568]]
actor_loss: tensor(0.0714, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-10.729863758394359, average reward:-0.3974023614220133,success
Box_Position: [[1.26975343 0.68362763 0.51288191]]

------------------Episode:2650------------------
actor_loss: tensor(0.0595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0771, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0649, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-125.7532956173298, average reward:-0.628766478086649,----
Box_Position: [[1.53140917 1.02652574 0.6134357 ]]
actor_loss: tensor(0.0670, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-22.6309234374482, average reward:-0.41909117476755925,success
Box_Position: [[1.45227909 0.87664513 0.59396964]]
actor_loss: tensor(0.0755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0614, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-40.6396863606912, average reward:-0.36612330054676756,success
Box_Position: [[1.2911239  0.68940344 0.65668186]]
actor_loss: tensor(0.0717, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-11.371812201386172, average reward:-0.3553691312933179,success
Box_Position: [[1.40131857 0.92933387 0.74711841]]
Step:3, total reward:-0.35948029224250017, average reward:-0.11982676408083338,success
Box_Position: [[1.33452362 0.96638658 0.59960813]]
Step:16, total reward:-10.64922498411579, average reward:-0.6655765615072369,success
Box_Position: [[1.47482536 0.95926472 0.48148461]]
Step:4, total reward:-2.57881786374785, average reward:-0.6447044659369625,success
Box_Position: [[1.38938497 0.57946964 0.60003909]]
actor_loss: tensor(0.0637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0695, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-44.0964881721392, average reward:-0.3290782699413373,success
Box_Position: [[1.50343798 0.58840444 0.6483016 ]]
Step:12, total reward:-6.213989721278839, average reward:-0.5178324767732366,success
Box_Position: [[1.46288227 1.07104999 0.60005257]]
Step:1, total reward:-0.02737383639660071, average reward:-0.02737383639660071,success
Box_Position: [[1.48357223 0.83987056 0.70260884]]
Step:4, total reward:-0.7924037373920576, average reward:-0.1981009343480144,success
Box_Position: [[1.53592117 0.77596883 0.45747904]]
Step:18, total reward:-10.69050409976237, average reward:-0.5939168944312427,success
Box_Position: [[1.45838395 0.84868511 0.67426648]]
actor_loss: tensor(0.0737, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-8.619774916861475, average reward:-0.25352279167239633,success
Box_Position: [[1.38147002 0.44123398 0.68111411]]
Step:18, total reward:-3.480546874315457, average reward:-0.1933637152397476,success
Box_Position: [[1.43246194 0.95698135 0.4612729 ]]
actor_loss: tensor(0.0893, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-29.152535406716318, average reward:-0.9110167314598849,success
Box_Position: [[1.44689842 0.62362232 0.64913424]]
actor_loss: tensor(0.0703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0623, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-36.29359591135146, average reward:-0.3703428154219537,success
Box_Position: [[1.51842675 0.93164871 0.70466716]]
Step:9, total reward:-1.4401666623228657, average reward:-0.16001851803587397,success
Box_Position: [[1.51366836 0.59995691 0.65677641]]
actor_loss: tensor(0.0656, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-3.6545938620385066, average reward:-0.1740282791446908,success
Box_Position: [[1.2824193  0.62657666 0.61287655]]
Step:11, total reward:-1.951742015030248, average reward:-0.1774310922754771,success
Box_Position: [[1.41481572 0.54220463 0.71175198]]
Step:4, total reward:-0.5296404842453286, average reward:-0.13241012106133215,success
Box_Position: [[1.42747417 0.69786279 0.48413004]]
actor_loss: tensor(0.0877, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-53.23155028337364, average reward:-0.8065386406571764,success
Box_Position: [[1.48736135 1.0950742  0.5124018 ]]
actor_loss: tensor(0.0735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0843, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-52.16227492793141, average reward:-0.6863457227359396,success
Box_Position: [[1.51953215 0.98727606 0.53528361]]
Step:5, total reward:-1.0434535307002015, average reward:-0.20869070614004032,success
Box_Position: [[1.3534453  0.91716811 0.6590519 ]]
Step:16, total reward:-4.703864452321438, average reward:-0.2939915282700899,success
Box_Position: [[1.45016808 0.81497098 0.63284519]]
actor_loss: tensor(0.0832, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0612, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-33.26512008729348, average reward:-0.289261913802552,success
Box_Position: [[1.34747334 0.92008683 0.73855976]]
actor_loss: tensor(0.0700, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-4.556230809942859, average reward:-0.15711140723940892,success
Box_Position: [[1.39505143 0.54242793 0.60024918]]
actor_loss: tensor(0.0725, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0686, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0566, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0541, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-66.32014251662322, average reward:-0.3833534249515793,success
Box_Position: [[1.49290959 0.53757749 0.59758962]]
Step:4, total reward:-0.4826992997818439, average reward:-0.12067482494546097,success
Box_Position: [[1.3365655  0.89993547 0.66008434]]
actor_loss: tensor(0.0731, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-9.181660468459963, average reward:-0.20403689929911029,success
Box_Position: [[1.43515512 0.72805155 0.62958174]]
Step:21, total reward:-3.4599789990775904, average reward:-0.1647609047179805,success
Box_Position: [[1.25590044 0.54492404 0.71947998]]
actor_loss: tensor(0.0695, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0539, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0833, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0654, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-45.51140497239435, average reward:-0.22755702486197177,----
Box_Position: [[1.3500996  0.72030277 0.5748858 ]]
actor_loss: tensor(0.0621, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0683, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0712, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-82.90448286197488, average reward:-0.4145224143098744,----
Box_Position: [[1.32833469 0.90496881 0.73205229]]
actor_loss: tensor(0.0679, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-10.33569921941341, average reward:-0.18132805648093703,success
Box_Position: [[1.50731058 0.73283764 0.62505211]]
Step:3, total reward:-0.4230712762603037, average reward:-0.14102375875343456,success
Box_Position: [[1.4722533  0.98572339 0.56575625]]
actor_loss: tensor(0.0587, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-23.07055718937217, average reward:-0.4614111437874434,success
Box_Position: [[1.40918423 0.98428013 0.57243866]]
actor_loss: tensor(0.0671, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-5.143414296310524, average reward:-0.24492449030050112,success
Box_Position: [[1.42423221 0.8377978  0.70218944]]
actor_loss: tensor(0.0791, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0659, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-25.178927960240987, average reward:-0.22086778912492094,success
Box_Position: [[1.34291316 0.76599602 0.4984961 ]]
actor_loss: tensor(0.0623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0729, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0717, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0820, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-150.33040102429152, average reward:-0.7516520051214576,----
Box_Position: [[1.37824049 0.94920024 0.68232737]]
Step:7, total reward:-0.8877252197559404, average reward:-0.12681788853656292,success
Box_Position: [[1.32721753 0.79312304 0.50810659]]
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0804, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-139.6525608396688, average reward:-0.6982628041983441,----
Box_Position: [[1.26841105 0.76315877 0.57261335]]
actor_loss: tensor(0.0705, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0737, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0589, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0676, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-104.35652020944421, average reward:-0.5217826010472211,----
Box_Position: [[1.4783956  0.71555316 0.45904178]]
actor_loss: tensor(0.0682, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-29.93112446150174, average reward:-0.7876611700395194,success
Box_Position: [[1.46326551 0.98702881 0.5366459 ]]
Step:35, total reward:-18.29781893866277, average reward:-0.5227948268189362,success
Box_Position: [[1.37421747 0.98546854 0.62822324]]
actor_loss: tensor(0.0689, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-7.857055612859542, average reward:-0.31428222451438165,success
Box_Position: [[1.29481021 0.62074404 0.54109392]]
actor_loss: tensor(0.0853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1056, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0868, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0726, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-114.10797068522598, average reward:-0.5705398534261299,----
Box_Position: [[1.49230903 0.73948335 0.70513584]]
actor_loss: tensor(0.0841, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0891, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-26.92255336220311, average reward:-0.2692255336220311,success
Box_Position: [[1.54622193 0.63522491 0.67258662]]
Step:18, total reward:-5.859940964291192, average reward:-0.32555227579395507,success
Box_Position: [[1.36864203 0.97613273 0.70775729]]
actor_loss: tensor(0.0772, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-3.697165650553518, average reward:-0.17605550716921514,success
Box_Position: [[1.37640288 0.54955199 0.54359944]]
Step:9, total reward:-3.2427985433412503, average reward:-0.3603109492601389,success
Box_Position: [[1.39542291 0.85844354 0.66478299]]
actor_loss: tensor(0.0736, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0667, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-25.82033651974102, average reward:-0.24590796685467636,success
Box_Position: [[1.39528275 0.91888636 0.60701989]]

------------------Episode:2700------------------
actor_loss: tensor(0.0717, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-25.49638507909761, average reward:-0.37494683939849427,success
episode 2700, the accuracy is: 90%
Box_Position: [[1.5449119  0.68193018 0.47206293]]
actor_loss: tensor(0.0833, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-21.423457506138956, average reward:-1.020164643149474,success
Box_Position: [[1.37452948 0.80412472 0.60678777]]
Step:12, total reward:-7.850151412265525, average reward:-0.6541792843554605,success
Box_Position: [[1.2693276  0.94588054 0.55394422]]
actor_loss: tensor(0.0693, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-24.57024699116076, average reward:-0.6640607294908314,success
Box_Position: [[1.31222849 0.87197402 0.66709173]]
Step:27, total reward:-4.46827504217337, average reward:-0.16549166822864333,success
Box_Position: [[1.33117233 0.90844343 0.68354858]]
actor_loss: tensor(0.0652, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-13.910352662188885, average reward:-0.25759912337386826,success
Box_Position: [[1.43362801 1.02875144 0.52342679]]
actor_loss: tensor(0.0743, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-19.992704400583534, average reward:-0.8330293500243139,success
Box_Position: [[1.5497214  0.93481806 0.48497661]]
actor_loss: tensor(0.0776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0687, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1035, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-116.25935099120701, average reward:-0.8017886275255656,success
Box_Position: [[1.36160157 0.6668387  0.58404569]]
actor_loss: tensor(0.0819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1008, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0607, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-90.20394565518286, average reward:-0.4510197282759143,----
Box_Position: [[1.31940185 0.61833877 0.69111679]]
actor_loss: tensor(0.0644, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0814, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0766, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0898, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-58.10191212679767, average reward:-0.29050956063398836,----
Box_Position: [[1.32206467 0.97206013 0.45334224]]
Step:5, total reward:-6.559836326211399, average reward:-1.3119672652422798,success
Box_Position: [[1.43305662 0.9159576  0.57009615]]
Step:21, total reward:-15.84505541566207, average reward:-0.7545264483648605,success
Box_Position: [[1.5326783  0.99769654 0.63597121]]
actor_loss: tensor(0.0938, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-11.232484492460848, average reward:-0.34037831795335904,success
Box_Position: [[1.35145333 0.88004515 0.46756246]]
Step:12, total reward:-9.900490133662743, average reward:-0.8250408444718952,success
Box_Position: [[1.47726288 1.10173645 0.54854748]]
Step:12, total reward:-3.734522375339261, average reward:-0.3112101979449384,success
Box_Position: [[1.29972818 0.50536543 0.72038741]]
actor_loss: tensor(0.0960, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-2.905722882648334, average reward:-0.17092487544990198,success
Box_Position: [[1.44813255 0.74593124 0.45581334]]
Step:5, total reward:-2.750428109303759, average reward:-0.5500856218607517,success
Box_Position: [[1.53718792 0.59896715 0.65055404]]
Step:21, total reward:-12.222487835510323, average reward:-0.5820232302623963,success
Box_Position: [[1.26104125 1.06226428 0.70266397]]
actor_loss: tensor(0.0790, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0723, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-13.1564739043106, average reward:-0.1686727423629564,success
Box_Position: [[1.28568947 0.82694435 0.67142043]]
actor_loss: tensor(0.0893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0834, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-21.522669664461027, average reward:-0.19566063331328207,success
Box_Position: [[1.41137691 1.04397546 0.53330519]]
actor_loss: tensor(0.0757, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-20.575759213695694, average reward:-0.6858586404565231,success
Box_Position: [[1.48732786 0.99717457 0.69491622]]
Step:20, total reward:-3.698508396509621, average reward:-0.18492541982548105,success
Box_Position: [[1.50025949 0.98053938 0.73617168]]
Step:7, total reward:-1.0633819673638853, average reward:-0.1519117096234122,success
Box_Position: [[1.453475   0.66556731 0.47609529]]
actor_loss: tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-33.26974518643704, average reward:-0.7393276708097121,success
Box_Position: [[1.43600628 0.79849155 0.49695438]]
Step:21, total reward:-17.194420211223107, average reward:-0.818781914820148,success
Box_Position: [[1.29843793 0.9607808  0.51182631]]
actor_loss: tensor(0.0609, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-4.490469210336583, average reward:-1.1226173025841457,success
Box_Position: [[1.49398053 0.72899518 0.53798885]]
Step:26, total reward:-18.409976075447947, average reward:-0.7080760029018441,success
Box_Position: [[1.45589802 0.45216666 0.63445013]]
actor_loss: tensor(0.0772, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-6.74692082233765, average reward:-0.23265244214957412,success
Box_Position: [[1.51425434 0.68469854 0.65704538]]
Step:9, total reward:-1.7239812958475402, average reward:-0.19155347731639336,success
Box_Position: [[1.50965543 0.90485367 0.67803243]]
Step:11, total reward:-1.5516527799225144, average reward:-0.1410593436293195,success
Box_Position: [[1.3366246  0.84427972 0.49675124]]
actor_loss: tensor(0.0781, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0876, device='cuda:0', grad_fn=<NegBackward>)
Step:120, total reward:-71.95310017270357, average reward:-0.5996091681058631,success
Box_Position: [[1.51085937 0.9825944  0.49507362]]
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0780, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0649, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-75.7995403771807, average reward:-0.7018475960850066,success
Box_Position: [[1.41643835 0.93769758 0.53310535]]
actor_loss: tensor(0.0703, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-29.050459953270504, average reward:-0.5008699991943191,success
Box_Position: [[1.3778988  0.67924169 0.45179002]]
Step:26, total reward:-27.899126063087436, average reward:-1.0730433101187475,success
Box_Position: [[1.36607216 0.80807631 0.50629268]]
actor_loss: tensor(0.0783, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-30.919016869970996, average reward:-0.8136583386834473,success
Box_Position: [[1.53831597 0.88321528 0.60461846]]
Step:16, total reward:-4.618888873090843, average reward:-0.2886805545681777,success
Box_Position: [[1.32622066 0.84033933 0.63933623]]
actor_loss: tensor(0.0825, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-3.70422527966951, average reward:-0.37042252796695097,success
Box_Position: [[1.43023657 1.01244968 0.70374112]]
Step:2, total reward:-0.16310113982698013, average reward:-0.08155056991349006,success
Box_Position: [[1.40552063 1.07274759 0.64743682]]
Step:29, total reward:-6.517805530316409, average reward:-0.22475191483849685,success
Box_Position: [[1.42309608 0.91942776 0.46730338]]
Step:10, total reward:-9.298437351648564, average reward:-0.9298437351648564,success
Box_Position: [[1.411475   0.71327328 0.53902024]]
actor_loss: tensor(0.0704, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-22.227649972219822, average reward:-0.6350757134919949,success
Box_Position: [[1.30141699 0.62884946 0.55424397]]
actor_loss: tensor(0.0741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0906, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-47.795117615206976, average reward:-0.5310568623911887,success
Box_Position: [[1.35834758 0.64591684 0.73902476]]
Step:12, total reward:-1.626750950911715, average reward:-0.13556257924264292,success
Box_Position: [[1.51072292 0.62796101 0.52839881]]
actor_loss: tensor(0.0788, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-28.015453770859978, average reward:-0.6367148584286358,success
Box_Position: [[1.25751019 0.54208572 0.72362785]]
actor_loss: tensor(0.0773, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-15.2427044297003, average reward:-0.220908759850729,success
Box_Position: [[1.35759922 0.75390165 0.71162219]]
actor_loss: tensor(0.0768, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-4.596887033753848, average reward:-0.158513345991512,success
Box_Position: [[1.41161604 0.73167999 0.58836881]]
Step:18, total reward:-7.0551973626535815, average reward:-0.3919554090363101,success
Box_Position: [[1.41538737 0.61849781 0.69981495]]
actor_loss: tensor(0.0799, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-7.303024960644764, average reward:-0.2608223200230273,success
Box_Position: [[1.43078972 1.03437032 0.72427593]]
Step:18, total reward:-3.301831650558993, average reward:-0.18343509169772182,success
Box_Position: [[1.54692345 0.98595287 0.54662084]]
actor_loss: tensor(0.0791, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-11.098850625073617, average reward:-0.38271898707150404,success
Box_Position: [[1.35558876 1.15246572 0.54921246]]

------------------Episode:2750------------------
Step:2, total reward:-0.08686737332223046, average reward:-0.04343368666111523,success
Box_Position: [[1.50253338 0.80917443 0.47998773]]
Step:2, total reward:-0.16668669953668847, average reward:-0.08334334976834423,success
Box_Position: [[1.45551286 0.67899401 0.62305909]]
Step:16, total reward:-5.353644523721691, average reward:-0.3346027827326057,success
Box_Position: [[1.42814519 0.64797714 0.47695236]]
Step:6, total reward:-1.0388476800451918, average reward:-0.17314128000753196,success
Box_Position: [[1.5374033  1.12223019 0.70357552]]
actor_loss: tensor(0.0775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0870, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0789, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-51.62535009367137, average reward:-0.25812675046835687,----
Box_Position: [[1.54191225 0.81675336 0.4651641 ]]
actor_loss: tensor(0.0653, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-42.837069708553344, average reward:-0.996210923454729,success
Box_Position: [[1.51108306 1.08596774 0.55740907]]
actor_loss: tensor(0.0777, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-27.6152256657178, average reward:-0.6575053729932809,success
Box_Position: [[1.46865244 0.98288131 0.55604548]]
actor_loss: tensor(0.0810, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-11.709540306250776, average reward:-0.40377725193968195,success
Box_Position: [[1.4374811  0.69907889 0.68381998]]
Step:8, total reward:-0.8480544245713478, average reward:-0.10600680307141848,success
Box_Position: [[1.54350772 0.82001706 0.62607247]]
actor_loss: tensor(0.0607, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-14.873318454825867, average reward:-0.4131477348562741,success
Box_Position: [[1.32483598 1.07299021 0.66853607]]
Step:6, total reward:-0.8934996687099532, average reward:-0.14891661145165888,success
Box_Position: [[1.52467128 0.87561503 0.65170383]]
Step:23, total reward:-10.57031282680409, average reward:-0.4595788185566995,success
Box_Position: [[1.52519024 0.92603974 0.62805973]]
Step:7, total reward:-1.0159007968602685, average reward:-0.14512868526575265,success
Box_Position: [[1.29556817 0.70326356 0.58891672]]
actor_loss: tensor(0.0760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0856, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0655, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0611, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-81.24359373692796, average reward:-0.40621796868463983,----
Box_Position: [[1.33787015 0.57628679 0.57128876]]
actor_loss: tensor(0.0794, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-19.820921635121447, average reward:-0.3603803933658445,success
Box_Position: [[1.3851602  0.72353737 0.52737282]]
actor_loss: tensor(0.0723, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-23.649116455551223, average reward:-0.503172690543643,success
Box_Position: [[1.35903573 0.48709216 0.52725488]]
actor_loss: tensor(0.0698, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0763, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0792, device='cuda:0', grad_fn=<NegBackward>)
Step:119, total reward:-62.37866545840169, average reward:-0.524190466036989,success
Box_Position: [[1.45148938 0.56711638 0.56563572]]
Step:10, total reward:-5.647025281629168, average reward:-0.5647025281629168,success
Box_Position: [[1.37699609 1.03470928 0.63170825]]
Step:11, total reward:-1.4253072907547406, average reward:-0.1295733900686128,success
Box_Position: [[1.51560976 0.88891045 0.48690873]]
Step:3, total reward:-0.41459877991402144, average reward:-0.13819959330467382,success
Box_Position: [[1.42978521 0.91041027 0.65861394]]
actor_loss: tensor(0.0901, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0875, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-31.38526395428423, average reward:-0.3566507267532299,success
Box_Position: [[1.49855407 0.86131445 0.7243924 ]]
actor_loss: tensor(0.0822, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0798, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-25.02204120989295, average reward:-0.22956001109993532,success
Box_Position: [[1.30994936 0.88834698 0.70283402]]
Step:8, total reward:-1.9736763962408064, average reward:-0.2467095495301008,success
Box_Position: [[1.28461882 0.84114512 0.45963315]]
actor_loss: tensor(0.0677, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0821, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-42.75709984143771, average reward:-0.6786841244672652,success
Box_Position: [[1.46929337 0.86672369 0.7257992 ]]
Step:6, total reward:-0.918363382694705, average reward:-0.15306056378245084,success
Box_Position: [[1.34020969 0.9928603  0.50075195]]
Step:23, total reward:-17.70379091445958, average reward:-0.7697300397591123,success
Box_Position: [[1.51815696 0.6267263  0.46606899]]
actor_loss: tensor(0.0642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0751, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-82.67521914791955, average reward:-0.939491126680904,success
Box_Position: [[1.40682649 0.63798914 0.48456632]]
Step:13, total reward:-8.131038546908249, average reward:-0.6254645036083268,success
Box_Position: [[1.44344432 0.98732365 0.49850314]]
actor_loss: tensor(0.0610, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-41.50919152843468, average reward:-0.6918198588072446,success
Box_Position: [[1.52575387 0.54001921 0.63556211]]
actor_loss: tensor(0.0722, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-18.482751351663133, average reward:-0.3300491312796988,success
Box_Position: [[1.30494872 0.68578087 0.66358387]]
Step:2, total reward:-0.2094119412385661, average reward:-0.10470597061928305,success
Box_Position: [[1.34164165 0.82722897 0.70426561]]
actor_loss: tensor(0.0792, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-7.1874767490734275, average reward:-0.39930426383741263,success
Box_Position: [[1.3104596  0.56197545 0.69901273]]
Step:25, total reward:-10.709883475716827, average reward:-0.4283953390286731,success
Box_Position: [[1.51416322 0.75740203 0.63744001]]
actor_loss: tensor(0.0618, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-5.461298672939272, average reward:-0.606810963659919,success
Box_Position: [[1.48719546 0.5837788  0.72549363]]
Step:5, total reward:-0.9190004469650822, average reward:-0.18380008939301645,success
Box_Position: [[1.28500477 0.60072513 0.46175266]]
Step:11, total reward:-5.659198470117981, average reward:-0.5144725881925437,success
Box_Position: [[1.52280141 0.60280521 0.53767472]]
Step:10, total reward:-3.611837957476837, average reward:-0.36118379574768367,success
Box_Position: [[1.46426302 0.82387885 0.60783149]]
Step:4, total reward:-0.821719762076989, average reward:-0.20542994051924726,success
Box_Position: [[1.3768121  0.83877684 0.59424942]]
actor_loss: tensor(0.0679, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-13.60137552183128, average reward:-0.6476845486586323,success
Box_Position: [[1.2599874  0.68159433 0.70054143]]
actor_loss: tensor(0.0758, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-9.332076354340062, average reward:-0.17946300681423197,success
Box_Position: [[1.53987373 0.69484537 0.51306636]]
Step:44, total reward:-29.92466295057971, average reward:-0.6801059761495388,success
Box_Position: [[1.53757608 0.61727374 0.66527358]]
actor_loss: tensor(0.0797, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-12.06344621111106, average reward:-0.33509572808641835,success
Box_Position: [[1.44047822 0.79784372 0.45435373]]
Step:12, total reward:-14.003866603655878, average reward:-1.1669888836379898,success
Box_Position: [[1.53260682 0.98589032 0.6045664 ]]
actor_loss: tensor(0.0705, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-3.9909949065912276, average reward:-0.3325829088826023,success
Box_Position: [[1.2737994  0.81340258 0.56847226]]
Step:19, total reward:-11.056672635352017, average reward:-0.5819301387027377,success
Box_Position: [[1.42533358 0.74309429 0.49702695]]
actor_loss: tensor(0.0802, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-19.854858155589476, average reward:-0.7353651168736843,success
Box_Position: [[1.4380272  0.93146363 0.67820187]]
Step:1, total reward:-0.04411227214555872, average reward:-0.04411227214555872,success
Box_Position: [[1.3496172  0.53173903 0.74244348]]
Step:18, total reward:-5.493510349903772, average reward:-0.30519501943909844,success
Box_Position: [[1.47573179 0.93364251 0.56354724]]
Step:5, total reward:-0.5654355372068453, average reward:-0.11308710744136904,success
Box_Position: [[1.48535557 0.9425128  0.69966612]]
Step:5, total reward:-2.9864382620378014, average reward:-0.5972876524075603,success
Box_Position: [[1.42542244 0.91839729 0.52334456]]

------------------Episode:2800------------------
actor_loss: tensor(0.0872, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-32.742970774890495, average reward:-0.6821452244768853,success
episode 2800, the accuracy is: 96%
Box_Position: [[1.44697976 0.63431796 0.61697398]]
Step:15, total reward:-4.883260956175283, average reward:-0.32555073041168553,success
Box_Position: [[1.28831264 0.56316118 0.62696087]]
actor_loss: tensor(0.0874, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-3.2372318844277714, average reward:-0.3596924316030857,success
Box_Position: [[1.30325378 0.84535973 0.47248141]]
Step:36, total reward:-36.37408233791222, average reward:-1.0103911760531172,success
Box_Position: [[1.47038469 0.69686634 0.73684733]]
actor_loss: tensor(0.0884, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-3.8771088067485415, average reward:-0.19385544033742708,success
Box_Position: [[1.32353922 1.02618459 0.74801319]]
actor_loss: tensor(0.0692, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-13.664617072333712, average reward:-0.2440110191488163,success
Box_Position: [[1.45661479 0.86339789 0.74628824]]
actor_loss: tensor(0.0654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0780, device='cuda:0', grad_fn=<NegBackward>)
Step:163, total reward:-36.518523608857436, average reward:-0.22404002214022967,success
Box_Position: [[1.54504614 0.62304366 0.67175541]]
actor_loss: tensor(0.0670, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-12.067209950618091, average reward:-0.3549179397240615,success
Box_Position: [[1.52393026 0.60276474 0.67764827]]
Step:9, total reward:-1.4094808307073805, average reward:-0.15660898118970895,success
Box_Position: [[1.50116842 1.10106296 0.65585659]]
actor_loss: tensor(0.0743, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-16.58925912123499, average reward:-0.3606360678529345,success
Box_Position: [[1.31827929 0.92971167 0.48633081]]
Step:1, total reward:-0.040252719171077464, average reward:-0.040252719171077464,success
Box_Position: [[1.27117108 0.91937529 0.64212969]]
actor_loss: tensor(0.0526, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-10.81746168472705, average reward:-0.2638405288957817,success
Box_Position: [[1.26195855 1.12361056 0.69226527]]
Step:6, total reward:-0.7479509590499263, average reward:-0.12465849317498771,success
Box_Position: [[1.41786207 0.44901373 0.49195213]]
Step:5, total reward:-2.431408245960589, average reward:-0.4862816491921178,success
Box_Position: [[1.31116801 0.91479783 0.59524645]]
Step:27, total reward:-8.266461897910103, average reward:-0.306165255478152,success
Box_Position: [[1.43554154 0.80994044 0.59779702]]
actor_loss: tensor(0.0809, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-2.6170537915701373, average reward:-0.6542634478925343,success
Box_Position: [[1.4948767 0.9460321 0.6288523]]
Step:14, total reward:-3.9618778211105155, average reward:-0.28299127293646537,success
Box_Position: [[1.49602805 0.85636311 0.47395471]]
Step:13, total reward:-7.908795539811366, average reward:-0.6083688876777974,success
Box_Position: [[1.2791678  0.64531591 0.48051853]]
actor_loss: tensor(0.0876, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0578, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-158.61921960126293, average reward:-0.7930960980063146,----
Box_Position: [[1.48733243 0.99142249 0.53211832]]
Step:16, total reward:-6.198090148403021, average reward:-0.3873806342751888,success
Box_Position: [[1.54703416 1.08205482 0.73912639]]
actor_loss: tensor(0.0671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0566, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-42.30307715825693, average reward:-0.23765773684414007,success
Box_Position: [[1.37280289 0.81440881 0.47975819]]
Step:6, total reward:-6.512903861729299, average reward:-1.0854839769548832,success
Box_Position: [[1.46579539 1.04687154 0.50579884]]
actor_loss: tensor(0.0739, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-23.067540553019924, average reward:-1.002936545783475,success
Box_Position: [[1.48846263 0.59929082 0.55886789]]
Step:25, total reward:-17.693676962190075, average reward:-0.707747078487603,success
Box_Position: [[1.25553522 0.8074745  0.70439528]]
actor_loss: tensor(0.0775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0842, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-22.17449821489645, average reward:-0.29565997619861933,success
Box_Position: [[1.39270532 0.86545061 0.69047405]]
actor_loss: tensor(0.0662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0685, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-26.64968323996199, average reward:-0.21319746591969593,success
Box_Position: [[1.29223045 0.87623914 0.7420203 ]]
Step:16, total reward:-2.776454810773572, average reward:-0.17352842567334825,success
Box_Position: [[1.37172171 0.91850913 0.45446984]]
actor_loss: tensor(0.0595, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-7.2935608993531424, average reward:-0.7293560899353142,success
Box_Position: [[1.44223955 0.88121896 0.65146036]]
actor_loss: tensor(0.0795, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-18.710771252220372, average reward:-0.2792652425704533,success
Box_Position: [[1.50431566 0.87986615 0.5087102 ]]
Step:20, total reward:-13.418788531924166, average reward:-0.6709394265962083,success
Box_Position: [[1.46200267 0.82750075 0.58767413]]
actor_loss: tensor(0.0705, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-9.222437596274712, average reward:-0.4391636950607006,success
Box_Position: [[1.45809447 0.65046063 0.73378302]]
Step:5, total reward:-0.642349020375441, average reward:-0.12846980407508818,success
Box_Position: [[1.41020541 0.56333821 0.46806675]]
actor_loss: tensor(0.0834, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-27.807539527834194, average reward:-0.5793237401632124,success
Box_Position: [[1.51018492 1.01100859 0.70233799]]
actor_loss: tensor(0.0648, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-21.324761204359582, average reward:-0.30905451020810987,success
Box_Position: [[1.25913581 1.05589439 0.485971  ]]
Step:11, total reward:-7.347909213558035, average reward:-0.667991746687094,success
Box_Position: [[1.42651808 1.01082652 0.46921008]]
Step:3, total reward:-0.3246635200038519, average reward:-0.1082211733346173,success
Box_Position: [[1.42364729 0.64206256 0.62411922]]
actor_loss: tensor(0.0571, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-5.195387307215955, average reward:-0.6494234134019944,success
Box_Position: [[1.27031282 0.68338356 0.67271932]]
Step:5, total reward:-0.8792241190784842, average reward:-0.17584482381569683,success
Box_Position: [[1.4984973  0.80851777 0.46698567]]
Step:16, total reward:-16.159646083367516, average reward:-1.0099778802104697,success
Box_Position: [[1.34778897 0.74846348 0.52888657]]
Step:5, total reward:-2.5528087486689617, average reward:-0.5105617497337923,success
Box_Position: [[1.38706046 0.46052362 0.64952323]]
Step:16, total reward:-6.876208318885452, average reward:-0.4297630199303408,success
Box_Position: [[1.34480377 0.80633489 0.57547516]]
actor_loss: tensor(0.0629, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0728, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0737, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-94.82033955951061, average reward:-0.47410169779755307,----
Box_Position: [[1.35225814 0.92441693 0.48588727]]
actor_loss: tensor(0.0592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0706, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0699, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-99.13763384148669, average reward:-0.9532464792450643,success
Box_Position: [[1.44998506 1.05123448 0.69241395]]
Step:17, total reward:-4.68972174087064, average reward:-0.27586598475709645,success
Box_Position: [[1.3288051  0.7735195  0.46672127]]
Step:16, total reward:-10.338205033752594, average reward:-0.6461378146095371,success
Box_Position: [[1.5432376  0.86565589 0.72083072]]
Step:6, total reward:-0.6827035025492901, average reward:-0.11378391709154835,success
Box_Position: [[1.27064909 1.16588418 0.48839036]]
actor_loss: tensor(0.0423, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-7.7632130633534855, average reward:-0.6469344219461238,success
Box_Position: [[1.29656237 0.8018972  0.58499842]]
actor_loss: tensor(0.0456, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0355, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0223, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-98.87915936468794, average reward:-0.4943957968234397,----
Box_Position: [[1.33143516 0.86246053 0.73196164]]
actor_loss: tensor(0.0428, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-10.10664064113375, average reward:-0.18375710256606817,success
Box_Position: [[1.50269486 0.76060613 0.72325401]]
actor_loss: tensor(0.0287, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-10.047108790499014, average reward:-0.20931476646872946,success
Box_Position: [[1.37110258 0.94425105 0.61533194]]

------------------Episode:2850------------------
Step:1, total reward:-0.04817312138893101, average reward:-0.04817312138893101,success
Box_Position: [[1.51309925 0.40831377 0.62943906]]
actor_loss: tensor(0.0333, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0584, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0265, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-72.72483828220365, average reward:-0.4017946866420091,success
Box_Position: [[1.33750359 0.46148005 0.48463286]]
Step:5, total reward:-2.5667220505234756, average reward:-0.5133444101046951,success
Box_Position: [[1.48793749 0.83733548 0.57457856]]
actor_loss: tensor(0.0398, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-6.606034043008226, average reward:-0.36700189127823474,success
Box_Position: [[1.5103057  0.75400671 0.7348329 ]]
Step:28, total reward:-6.947997444568622, average reward:-0.2481427658774508,success
Box_Position: [[1.49177953 0.72716392 0.63854725]]
actor_loss: tensor(0.0238, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-6.060204789513803, average reward:-0.28858118045303827,success
Box_Position: [[1.49966778 0.96830529 0.67433828]]
Step:21, total reward:-3.6646492837092275, average reward:-0.17450710874805844,success
Box_Position: [[1.32069195 0.77621651 0.62212496]]
actor_loss: tensor(0.0251, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-9.018808945948152, average reward:-0.19606106404235113,success
Box_Position: [[1.31327529 0.78823585 0.51463125]]
Step:8, total reward:-6.9163777650063825, average reward:-0.8645472206257978,success
Box_Position: [[1.3051763  0.61423395 0.58884781]]
actor_loss: tensor(0.0387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0399, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-29.92715426856882, average reward:-0.3439902789490669,success
Box_Position: [[1.44570261 0.94521451 0.59904756]]
actor_loss: tensor(0.0493, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-19.655129748990404, average reward:-0.33313779235576957,success
Box_Position: [[1.25542884 0.78381391 0.47180522]]
actor_loss: tensor(0.0353, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-27.22562311197132, average reward:-0.605013846932696,success
Box_Position: [[1.53245184 0.72072329 0.51621476]]
actor_loss: tensor(0.0437, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-30.254152426681205, average reward:-0.7563538106670301,success
Box_Position: [[1.48157411 0.97081278 0.6056815 ]]
Step:7, total reward:-1.0253251195905049, average reward:-0.14647501708435784,success
Box_Position: [[1.34495643 0.96862245 0.48544401]]
Step:24, total reward:-15.80911037864099, average reward:-0.6587129324433746,success
Box_Position: [[1.54277841 0.54336596 0.69853287]]
actor_loss: tensor(0.0467, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0506, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-23.55939106367045, average reward:-0.2647122591423646,success
Box_Position: [[1.38901972 0.93751017 0.57924269]]
actor_loss: tensor(0.0417, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-5.476240689274344, average reward:-0.2738120344637172,success
Box_Position: [[1.36007499 0.98940403 0.65822211]]
actor_loss: tensor(0.0207, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-23.34440734788853, average reward:-0.5074871162584463,success
Box_Position: [[1.52035692 0.61309739 0.5511358 ]]
Step:12, total reward:-4.036793736947928, average reward:-0.336399478078994,success
Box_Position: [[1.42900203 0.97385455 0.59479245]]
Step:2, total reward:-0.20067276796612568, average reward:-0.10033638398306284,success
Box_Position: [[1.46172083 0.84063578 0.62248396]]
Step:5, total reward:-2.750651868068201, average reward:-0.5501303736136401,success
Box_Position: [[1.32522871 0.89495386 0.5954808 ]]
actor_loss: tensor(0.0244, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-20.62666131784088, average reward:-0.4687877572236564,success
Box_Position: [[1.53634971 0.85341988 0.59011306]]
actor_loss: tensor(0.0476, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0168, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-44.75488131911916, average reward:-0.5204055967339437,success
Box_Position: [[1.30039097 0.90584248 0.49925813]]
Step:31, total reward:-25.803440958383433, average reward:-0.8323690631736591,success
Box_Position: [[1.34977968 0.67380933 0.60894968]]
actor_loss: tensor(0.0033, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0306, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0078, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>)
Step:200, total reward:-178.6305677107733, average reward:-0.8931528385538665,----
Box_Position: [[1.47373845 0.46618341 0.69806168]]
actor_loss: tensor(0.0178, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0047, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-75.05580130960509, average reward:-0.6583842220140798,success
Box_Position: [[1.51472552 0.54695724 0.49093334]]
actor_loss: tensor(0.0104, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-39.0860889786601, average reward:-1.2608415799567774,success
Box_Position: [[1.40776315 0.74887388 0.50590232]]
actor_loss: tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>)
Step:60, total reward:-34.320133641262416, average reward:-0.5720022273543736,success
Box_Position: [[1.45859571 0.75240834 0.49201869]]
Step:7, total reward:-5.050925129648389, average reward:-0.7215607328069128,success
Box_Position: [[1.49436255 0.7398099  0.66580411]]
actor_loss: tensor(0.0178, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0101, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0041, device='cuda:0', grad_fn=<NegBackward>)
Step:128, total reward:-63.57681439145143, average reward:-0.4966938624332143,success
Box_Position: [[1.45233417 0.60876786 0.74629613]]
Step:3, total reward:-0.4768149005866552, average reward:-0.15893830019555175,success
Box_Position: [[1.28165667 0.96976783 0.65210845]]
actor_loss: tensor(0.0055, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0116, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0265, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0069, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-122.25098445715032, average reward:-0.6112549222857516,----
Box_Position: [[1.34500816 0.76736874 0.68896833]]
actor_loss: tensor(0.0096, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0468, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-111.91441023356705, average reward:-0.5595720511678353,----
Box_Position: [[1.50805026 1.10283823 0.62342178]]
Step:12, total reward:-1.9883583216945837, average reward:-0.16569652680788197,success
Box_Position: [[1.390001   0.46715702 0.56543095]]
actor_loss: tensor(0.0208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0342, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0240, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0264, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-170.53931220282385, average reward:-0.8526965610141193,----
Box_Position: [[1.25465616 0.60735469 0.65772677]]
actor_loss: tensor(0.0266, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0076, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0076, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0123, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-124.13403776488006, average reward:-0.6206701888244003,----
Box_Position: [[1.40437494 0.68982119 0.5353708 ]]
actor_loss: tensor(0.0292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0329, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0404, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-199.04028683413034, average reward:-0.9952014341706517,----
Box_Position: [[1.29225806 1.08306492 0.70454354]]
Step:5, total reward:-0.3827018835938755, average reward:-0.0765403767187751,success
Box_Position: [[1.28828776 0.84021409 0.50201737]]
Step:4, total reward:-4.382049526894851, average reward:-1.0955123817237127,success
Box_Position: [[1.37400478 1.0658656  0.659911  ]]
actor_loss: tensor(0.0326, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-2.553664844639712, average reward:-0.15021557909645364,success
Box_Position: [[1.37244812 1.03444256 0.47035682]]
Step:25, total reward:-20.574366924135713, average reward:-0.8229746769654285,success
Box_Position: [[1.34066122 0.68260933 0.50680778]]
Step:4, total reward:-0.4461545496765057, average reward:-0.11153863741912642,success
Box_Position: [[1.38335921 0.92795746 0.60816   ]]
actor_loss: tensor(0.0517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0569, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0402, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-108.05764947388947, average reward:-0.5402882473694474,----
Box_Position: [[1.52594286 1.04100602 0.45756709]]
actor_loss: tensor(0.0263, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-32.85703582410752, average reward:-1.02678236950336,success
Box_Position: [[1.43695569 1.01036203 0.73048946]]
actor_loss: tensor(0.0388, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0403, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-13.714051488712247, average reward:-0.17142564360890308,success
Box_Position: [[1.35026863 0.78585575 0.53948022]]
Step:37, total reward:-28.29270657531337, average reward:-0.7646677452787397,success
Box_Position: [[1.39266731 0.7024859  0.64914147]]
actor_loss: tensor(0.0454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0417, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0394, device='cuda:0', grad_fn=<NegBackward>)
Step:164, total reward:-66.95601420249271, average reward:-0.40826837928349213,success
Box_Position: [[1.47428568 1.0878037  0.68639522]]
Step:17, total reward:-5.14808469746175, average reward:-0.30282851161539703,success
Box_Position: [[1.54479993 0.90570632 0.46632675]]
actor_loss: tensor(0.0363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0501, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-86.19883661542525, average reward:-1.0385402001858464,success
Box_Position: [[1.31348635 0.52346482 0.72134278]]
actor_loss: tensor(0.0459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0338, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0486, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-94.65479537678891, average reward:-0.47327397688394457,----
Box_Position: [[1.46088241 0.69577363 0.51324927]]

------------------Episode:2900------------------
Step:1, total reward:-0.031267441011689955, average reward:-0.031267441011689955,success
episode 2900, the accuracy is: 89%
Box_Position: [[1.31305261 0.64481632 0.52178589]]
Step:2, total reward:-0.09623061198872002, average reward:-0.04811530599436001,success
Box_Position: [[1.37657011 0.62822044 0.4734778 ]]
Step:23, total reward:-19.833250964707297, average reward:-0.8623152593350999,success
Box_Position: [[1.47626038 0.67617738 0.4816627 ]]
actor_loss: tensor(0.0127, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-16.94510801019751, average reward:-0.7702321822817051,success
Box_Position: [[1.3614801  0.88210969 0.46136244]]
Step:14, total reward:-13.391530082469437, average reward:-0.9565378630335312,success
Box_Position: [[1.33613171 0.80771057 0.71633499]]
Step:9, total reward:-1.7400917012689274, average reward:-0.19334352236321417,success
Box_Position: [[1.48326049 0.7226659  0.64914843]]
Step:1, total reward:-0.030278423530617167, average reward:-0.030278423530617167,success
Box_Position: [[1.33098153 0.56795667 0.55356853]]
actor_loss: tensor(0.0353, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-47.539596943694605, average reward:-0.7202969233893122,success
Box_Position: [[1.4966091  0.62669831 0.62070426]]
actor_loss: tensor(0.0295, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-7.069108638928186, average reward:-0.3366242209013422,success
Box_Position: [[1.39038432 0.58637411 0.54320678]]
actor_loss: tensor(0.0334, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-30.293611861696196, average reward:-0.7573402965424049,success
Box_Position: [[1.34372252 0.75179827 0.67574027]]
actor_loss: tensor(0.0347, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-21.16669487473166, average reward:-0.2785091430885745,success
Box_Position: [[1.48569749 1.04179387 0.53340644]]
Step:4, total reward:-2.41630837246408, average reward:-0.60407709311602,success
Box_Position: [[1.34165566 0.56218279 0.67355872]]
actor_loss: tensor(0.0472, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0260, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0682, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0387, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-73.36484354761431, average reward:-0.36682421773807156,----
Box_Position: [[1.30050841 1.05427806 0.52871942]]
actor_loss: tensor(0.0362, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0333, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-94.69134944550898, average reward:-0.7761586020123686,success
Box_Position: [[1.41636598 0.44042419 0.7086893 ]]
Step:4, total reward:-0.6467173472873776, average reward:-0.1616793368218444,success
Box_Position: [[1.50174585 1.17086795 0.68377284]]
Step:11, total reward:-1.6242040870767667, average reward:-0.14765491700697878,success
Box_Position: [[1.48225704 0.87047738 0.67094357]]
Step:2, total reward:-0.24186473675869533, average reward:-0.12093236837934766,success
Box_Position: [[1.38911156 0.99637352 0.64554449]]
Step:3, total reward:-0.442125472771705, average reward:-0.14737515759056832,success
Box_Position: [[1.46586192 1.11354118 0.73840318]]
actor_loss: tensor(0.0350, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-3.756159934703966, average reward:-0.1391170346186654,success
Box_Position: [[1.37403472 0.68302997 0.45741678]]
Step:34, total reward:-27.086147641991648, average reward:-0.7966514012350485,success
Box_Position: [[1.49991475 0.82553391 0.64077943]]
Step:11, total reward:-1.7557095368064422, average reward:-0.15960995789149474,success
Box_Position: [[1.28024345 0.75938739 0.46461137]]
actor_loss: tensor(0.0665, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-13.142147937743085, average reward:-1.4602386597492316,success
Box_Position: [[1.41622478 0.68745128 0.61868708]]
actor_loss: tensor(0.0648, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0413, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0516, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0496, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-71.38635303186527, average reward:-0.35693176515932634,----
Box_Position: [[1.52065655 0.64075464 0.59564852]]
Step:22, total reward:-7.76736230868152, average reward:-0.3530619231218873,success
Box_Position: [[1.34119299 0.84606094 0.73762597]]
actor_loss: tensor(0.0518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0583, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0604, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-27.243818195605375, average reward:-0.19185787461693926,success
Box_Position: [[1.3340391  0.81636377 0.51592984]]
Step:10, total reward:-7.224244330856969, average reward:-0.7224244330856969,success
Box_Position: [[1.26593631 0.92502582 0.58291446]]
actor_loss: tensor(0.0436, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-10.298850755283667, average reward:-0.42911878147015275,success
Box_Position: [[1.30348816 1.07641856 0.73853828]]
Step:29, total reward:-6.365420642804351, average reward:-0.21949726354497764,success
Box_Position: [[1.27651018 0.76440643 0.56055344]]
actor_loss: tensor(0.0563, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-12.159979769937296, average reward:-0.48639919079749183,success
Box_Position: [[1.38888562 0.55095627 0.68585901]]
Step:10, total reward:-1.8480127704578164, average reward:-0.18480127704578164,success
Box_Position: [[1.31976318 1.15514968 0.65022211]]
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-4.984788360772989, average reward:-0.15105419275069665,success
Box_Position: [[1.49068965 0.672544   0.56383501]]
Step:7, total reward:-1.0164217340131783, average reward:-0.14520310485902546,success
Box_Position: [[1.29819079 1.01830265 0.67610922]]
actor_loss: tensor(0.0515, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0484, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-20.1215391658686, average reward:-0.17496990579016175,success
Box_Position: [[1.38415744 0.85058631 0.48164293]]
Step:13, total reward:-11.813632490486974, average reward:-0.9087409608066903,success
Box_Position: [[1.28210443 0.73649441 0.5717239 ]]
actor_loss: tensor(0.0518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0456, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0565, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0676, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.22746670266301, average reward:-0.531137333513315,----
Box_Position: [[1.4526378  0.92781486 0.4680548 ]]
Step:8, total reward:-11.08204715718168, average reward:-1.38525589464771,success
Box_Position: [[1.44028043 1.05530457 0.74147334]]
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-3.9539548191561837, average reward:-0.17191107909374712,success
Box_Position: [[1.52420578 0.88001479 0.69762615]]
Step:5, total reward:-0.657515162132295, average reward:-0.131503032426459,success
Box_Position: [[1.4075503  0.96658132 0.53381063]]
actor_loss: tensor(0.0660, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0738, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0484, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0593, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-104.40557454787512, average reward:-0.5220278727393756,----
Box_Position: [[1.42477241 0.91214686 0.58400037]]
actor_loss: tensor(0.0502, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-21.336928535008465, average reward:-0.40258355726431067,success
Box_Position: [[1.26767226 0.86169473 0.60619854]]
actor_loss: tensor(0.0501, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-22.642346937401474, average reward:-0.4043276238821692,success
Box_Position: [[1.52438788 0.83001978 0.50267501]]
actor_loss: tensor(0.0397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0520, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-53.434645629252344, average reward:-0.7220898058007074,success
Box_Position: [[1.33498612 1.08658443 0.69528492]]
actor_loss: tensor(0.0406, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-21.3732313254513, average reward:-0.2968504350757125,success
Box_Position: [[1.39206306 1.03297451 0.58863889]]
Step:6, total reward:-2.8691537928109914, average reward:-0.4781922988018319,success
Box_Position: [[1.35159502 0.54109327 0.52638709]]
actor_loss: tensor(0.0570, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0716, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0437, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-109.5868766759832, average reward:-0.5479343833799161,----
Box_Position: [[1.43560161 1.03728237 0.45753228]]
Step:5, total reward:-2.4876329362885845, average reward:-0.4975265872577169,success
Box_Position: [[1.31139577 0.96261588 0.6110063 ]]
actor_loss: tensor(0.0732, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-2.696647211294495, average reward:-0.13483236056472475,success
Box_Position: [[1.45747458 0.73046502 0.57616668]]
Step:1, total reward:-0.044393778239921466, average reward:-0.044393778239921466,success
Box_Position: [[1.47115583 0.71341816 0.65423778]]
Step:39, total reward:-6.297513456199981, average reward:-0.16147470400512773,success
Box_Position: [[1.5455654  1.12430437 0.53319457]]
actor_loss: tensor(0.0805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0785, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0661, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-123.99572266704914, average reward:-0.6199786133352457,----
Box_Position: [[1.35807373 0.93564812 0.55393416]]

------------------Episode:2950------------------
actor_loss: tensor(0.0700, device='cuda:0', grad_fn=<NegBackward>)
Step:2, total reward:-2.2992937631035772, average reward:-1.1496468815517886,success
Box_Position: [[1.36857832 0.86971095 0.7286151 ]]
Step:30, total reward:-5.569503491898738, average reward:-0.1856501163966246,success
Box_Position: [[1.47570451 0.78299195 0.56913257]]
Step:6, total reward:-2.8774638999905267, average reward:-0.4795773166650878,success
Box_Position: [[1.50865028 0.67816408 0.53142018]]
Step:12, total reward:-10.104601603033636, average reward:-0.8420501335861363,success
Box_Position: [[1.47976826 1.09812957 0.49567261]]
actor_loss: tensor(0.0617, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0733, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-41.120551995228, average reward:-0.6632347096004516,success
Box_Position: [[1.45384992 0.73628364 0.7434756 ]]
Step:8, total reward:-1.3140001219003876, average reward:-0.16425001523754845,success
Box_Position: [[1.29171099 0.7583294  0.71385172]]
actor_loss: tensor(0.0675, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0489, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0719, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-50.98783278635042, average reward:-0.2549391639317521,----
Box_Position: [[1.461985   0.9835299  0.69549278]]
Step:11, total reward:-3.800158153035523, average reward:-0.34546892300322934,success
Box_Position: [[1.29366376 1.03564718 0.4903291 ]]
actor_loss: tensor(0.0702, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-22.780008449429445, average reward:-0.7118752640446702,success
Box_Position: [[1.52432642 0.79765152 0.72402313]]
Step:19, total reward:-3.2116830246132677, average reward:-0.16903594866385618,success
Box_Position: [[1.44043307 0.78907426 0.57437868]]
actor_loss: tensor(0.0665, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-6.067437540960112, average reward:-0.2757926154981869,success
Box_Position: [[1.35456268 0.68506763 0.45499767]]
actor_loss: tensor(0.0622, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-76.80730345742903, average reward:-0.9036153347932827,success
Box_Position: [[1.32071644 0.80689043 0.53697099]]
actor_loss: tensor(0.0632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0457, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0771, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-99.99364340693681, average reward:-0.4999682170346841,----
Box_Position: [[1.50396719 0.440473   0.65709552]]
actor_loss: tensor(0.0678, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-4.559666844168051, average reward:-0.16887654978400188,success
Box_Position: [[1.45691016 0.60458417 0.64781646]]
Step:5, total reward:-0.7760784460884136, average reward:-0.15521568921768272,success
Box_Position: [[1.34092387 0.97278604 0.69586614]]
Step:7, total reward:-0.9003129273162327, average reward:-0.12861613247374754,success
Box_Position: [[1.54450043 1.00012532 0.52044046]]
Step:10, total reward:-3.904325587172699, average reward:-0.3904325587172699,success
Box_Position: [[1.44410016 0.92847745 0.70233406]]
Step:7, total reward:-3.222507859665336, average reward:-0.4603582656664766,success
Box_Position: [[1.37754711 0.78170162 0.56777286]]
actor_loss: tensor(0.0652, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0568, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0449, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-106.7722602194026, average reward:-0.533861301097013,----
Box_Position: [[1.43886215 1.1089302  0.49732275]]
actor_loss: tensor(0.0533, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-7.824676635374262, average reward:-0.6520563862811884,success
Box_Position: [[1.45342912 0.54860664 0.61001568]]
Step:41, total reward:-12.613381467354689, average reward:-0.3076434504232851,success
Box_Position: [[1.32446281 1.04585966 0.47053083]]
actor_loss: tensor(0.0672, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-33.4426650394936, average reward:-0.7270144573802956,success
Box_Position: [[1.28234949 0.79185656 0.51178757]]
actor_loss: tensor(0.0621, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0531, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0522, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-135.40580972780887, average reward:-0.6770290486390443,----
Box_Position: [[1.40218396 0.773331   0.57621489]]
actor_loss: tensor(0.0658, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-11.730393820444158, average reward:-0.3007793287293374,success
Box_Position: [[1.50153386 0.9951894  0.71284446]]
Step:7, total reward:-1.2114236527908886, average reward:-0.1730605218272698,success
Box_Position: [[1.51214806 0.61031356 0.5180662 ]]
Step:3, total reward:-2.321202693781284, average reward:-0.773734231260428,success
Box_Position: [[1.52681237 0.70634502 0.49251398]]
actor_loss: tensor(0.0603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0816, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-53.51713567844024, average reward:-0.7537624743442287,success
Box_Position: [[1.39888343 0.87896535 0.64094072]]
Step:2, total reward:-0.2517598803710132, average reward:-0.1258799401855066,success
Box_Position: [[1.33567259 0.56631927 0.49734661]]
Step:20, total reward:-16.832333027118498, average reward:-0.8416166513559249,success
Box_Position: [[1.25165322 0.93565457 0.50142793]]
actor_loss: tensor(0.0715, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0659, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-47.61462225222027, average reward:-0.6027167373698769,success
Box_Position: [[1.33843854 0.85330061 0.68146885]]
Step:8, total reward:-3.329896154526463, average reward:-0.41623701931580787,success
Box_Position: [[1.51829934 0.70769677 0.50808634]]
Step:12, total reward:-11.893321213355026, average reward:-0.9911101011129189,success
Box_Position: [[1.34322681 1.00591969 0.58987216]]
Step:8, total reward:-1.0498216813495793, average reward:-0.13122771016869741,success
Box_Position: [[1.47999537 1.00934884 0.45623103]]
actor_loss: tensor(0.0633, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-32.5215802791297, average reward:-0.9291880079751343,success
Box_Position: [[1.25798072 0.88984113 0.55434184]]
actor_loss: tensor(0.0739, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0817, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.1092, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-100.45554241672794, average reward:-0.5022777120836397,----
Box_Position: [[1.40628921 1.02901219 0.47623345]]
Step:5, total reward:-2.790347241204959, average reward:-0.5580694482409918,success
Box_Position: [[1.48183971 0.790974   0.46895053]]
Step:4, total reward:-2.721558104335581, average reward:-0.6803895260838952,success
Box_Position: [[1.43962022 1.07449673 0.66927974]]
actor_loss: tensor(0.0560, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-2.5785305371594505, average reward:-0.1516782668917324,success
Box_Position: [[1.32653738 1.10916827 0.72028759]]
Step:4, total reward:-0.406922531362288, average reward:-0.101730632840572,success
Box_Position: [[1.53726904 0.77983849 0.58286345]]
Step:24, total reward:-9.682626474460706, average reward:-0.4034427697691961,success
Box_Position: [[1.26450631 0.93677112 0.50750497]]
actor_loss: tensor(0.0707, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-31.051509309294627, average reward:-0.4928811001475338,success
Box_Position: [[1.3814022  0.73403477 0.69586912]]
Step:5, total reward:-2.760658402262784, average reward:-0.5521316804525568,success
Box_Position: [[1.40424801 0.66914468 0.6964606 ]]
actor_loss: tensor(0.0714, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-10.946511728824472, average reward:-0.23290450486860578,success
Box_Position: [[1.44973797 0.88021019 0.63727665]]
actor_loss: tensor(0.0738, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-12.880922184466161, average reward:-0.2995563298713061,success
Box_Position: [[1.49509955 0.49645047 0.65478228]]
Step:3, total reward:-0.521195116632341, average reward:-0.17373170554411366,success
Box_Position: [[1.47978138 0.48839118 0.61735248]]
actor_loss: tensor(0.0585, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-22.65993912558662, average reward:-0.41962850232567817,success
Box_Position: [[1.49971957 1.00387708 0.676244  ]]
actor_loss: tensor(0.0788, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-8.23614414889634, average reward:-0.22878178191378723,success
Box_Position: [[1.42823483 0.85807248 0.72264192]]
actor_loss: tensor(0.0805, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0787, device='cuda:0', grad_fn=<NegBackward>)
Step:123, total reward:-27.012768948440357, average reward:-0.2196160077108972,success
Box_Position: [[1.30183581 0.97141827 0.53713497]]
Step:20, total reward:-14.448981589892638, average reward:-0.7224490794946319,success
Box_Position: [[1.45753842 1.03874945 0.74484819]]
actor_loss: tensor(0.0744, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(0.0715, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-26.039115908784886, average reward:-0.21519930503128004,success

Process finished with exit code 0

Step:200, total reward:-3015.079051695055, average reward:-15.075395258475275,----
Box_Position: [[1.43006842 0.54657454 0.70751082]]
Step:200, total reward:-3059.5361232494975, average reward:-15.297680616247487,----
Box_Position: [[1.46029453 0.75965631 0.74880721]]
Step:200, total reward:-2712.480724759018, average reward:-13.56240362379509,----
Box_Position: [[1.27626009 0.981722   0.50565434]]
Step:200, total reward:-3033.696157911805, average reward:-15.168480789559025,----
Box_Position: [[1.3810425  0.85993085 0.54979849]]
Step:200, total reward:-2765.637535526668, average reward:-13.828187677633341,----
Box_Position: [[1.46273006 0.70645653 0.69591656]]
Step:200, total reward:-2792.747614767688, average reward:-13.96373807383844,----
Box_Position: [[1.52678174 0.75670532 0.74636569]]
Step:200, total reward:-2598.5183757105146, average reward:-12.992591878552574,----
Box_Position: [[1.36802777 0.73766217 0.56895357]]
Step:200, total reward:-2603.6385829172686, average reward:-13.018192914586344,----
Box_Position: [[1.2529607  0.80639749 0.63669183]]
Step:200, total reward:-2446.1436794169986, average reward:-12.230718397084992,----
Box_Position: [[1.37761525 0.68921607 0.52115087]]
Step:41, total reward:-542.6662115405346, average reward:-13.23576125708621,success
Box_Position: [[1.31209174 0.88324824 0.46188936]]
Step:165, total reward:-2043.4567926103102, average reward:-12.384586621880668,success
Box_Position: [[1.35874751 0.88139756 0.57411949]]
Step:200, total reward:-2738.8486924656268, average reward:-13.694243462328133,----
Box_Position: [[1.46664306 0.59237241 0.67679092]]
Step:200, total reward:-2594.1061657373107, average reward:-12.970530828686554,----
Box_Position: [[1.54214618 0.99535308 0.73949892]]
Step:200, total reward:-2834.304860013988, average reward:-14.17152430006994,----
Box_Position: [[1.49609468 0.82903044 0.46936909]]
Step:200, total reward:-3031.9201586299414, average reward:-15.159600793149707,----
Box_Position: [[1.40854356 0.71271403 0.73505939]]
Step:24, total reward:-246.55610233822352, average reward:-10.273170930759314,success
Box_Position: [[1.30175283 0.69853328 0.54329748]]
Step:200, total reward:-2700.4578929333425, average reward:-13.502289464666712,----
Box_Position: [[1.26668474 0.81007644 0.734738  ]]
Step:80, total reward:-1031.3498736628908, average reward:-12.891873420786135,success
Box_Position: [[1.33220759 0.61933798 0.58609538]]
Step:200, total reward:-2458.647674142991, average reward:-12.293238370714954,----
Box_Position: [[1.48809478 0.90884029 0.48532257]]
Step:200, total reward:-3010.192321571865, average reward:-15.050961607859325,----
Box_Position: [[1.47059684 0.48843688 0.6153276 ]]
Step:200, total reward:-2848.8441272954537, average reward:-14.24422063647727,----
Box_Position: [[1.46267566 0.91268875 0.58359462]]
Step:200, total reward:-2993.694199352645, average reward:-14.968470996763223,----
Box_Position: [[1.37948678 0.70454988 0.5928655 ]]
Step:200, total reward:-2712.916264668474, average reward:-13.56458132334237,----
Box_Position: [[1.5206682  0.88788261 0.5061546 ]]
Step:200, total reward:-3163.410247775824, average reward:-15.817051238879118,----
Box_Position: [[1.54233037 0.61046189 0.74657424]]
Step:200, total reward:-2814.362265886764, average reward:-14.07181132943382,----
Box_Position: [[1.36286087 0.48043036 0.73590785]]
Step:200, total reward:-2781.6145218259644, average reward:-13.908072609129823,----
Box_Position: [[1.38354051 0.96612713 0.74345074]]
Step:200, total reward:-2510.5381384670504, average reward:-12.552690692335252,----
Box_Position: [[1.25718615 0.73874567 0.68449513]]
Step:153, total reward:-1820.1505329112783, average reward:-11.89640871183842,success
Box_Position: [[1.32348709 0.93720515 0.46498116]]
Step:200, total reward:-3032.4660872305653, average reward:-15.162330436152827,----
Box_Position: [[1.29660777 0.66770309 0.60106712]]
Step:200, total reward:-2598.9525693033215, average reward:-12.994762846516608,----
Box_Position: [[1.38745608 1.13306181 0.5433986 ]]
Step:200, total reward:-3050.754179479837, average reward:-15.253770897399185,----
Box_Position: [[1.2638739  0.52269762 0.64177915]]
Step:200, total reward:-2590.7852737725584, average reward:-12.953926368862792,----
Box_Position: [[1.44264797 0.88259398 0.52077176]]
Step:200, total reward:-2735.986494685879, average reward:-13.679932473429394,----
Box_Position: [[1.47759557 0.71607531 0.71620318]]
Step:200, total reward:-2679.8682995569084, average reward:-13.399341497784542,----
Box_Position: [[1.40488038 0.8937877  0.60109267]]
Step:200, total reward:-2713.433149656656, average reward:-13.56716574828328,----
Box_Position: [[1.50898867 0.94728575 0.72488232]]
Step:200, total reward:-2549.5731657275855, average reward:-12.747865828637927,----
Box_Position: [[1.34643278 0.67925486 0.67625737]]
Step:161, total reward:-2261.437660230344, average reward:-14.046196647393442,success
Box_Position: [[1.52052325 0.81304908 0.72455451]]
Step:200, total reward:-2745.78517517763, average reward:-13.728925875888152,----
Box_Position: [[1.49632874 0.55754474 0.5015994 ]]
Step:200, total reward:-3037.357425538199, average reward:-15.186787127690996,----
Box_Position: [[1.44801214 0.97433223 0.46865813]]
Step:200, total reward:-2998.9108751793524, average reward:-14.994554375896762,----
Box_Position: [[1.3017798  0.42213468 0.46312185]]
Step:200, total reward:-2971.817532069982, average reward:-14.85908766034991,----
Box_Position: [[1.44668223 0.67815227 0.53252058]]
Step:200, total reward:-2789.690420624672, average reward:-13.948452103123358,----
Box_Position: [[1.54274445 0.88636638 0.60530427]]
Step:200, total reward:-2999.6622256353035, average reward:-14.998311128176518,----
Box_Position: [[1.4079576  0.78154709 0.58323962]]
Step:200, total reward:-2615.0825335759005, average reward:-13.075412667879503,----
Box_Position: [[1.29376028 0.69637489 0.74935211]]
Step:67, total reward:-858.455271119681, average reward:-12.812765240592254,success
Box_Position: [[1.32327582 0.81879128 0.55159331]]
Step:22, total reward:-270.036861553535, average reward:-12.274402797887955,success
Box_Position: [[1.29687193 0.58950037 0.53735036]]
Step:200, total reward:-2805.6904915015675, average reward:-14.028452457507838,----
Box_Position: [[1.31357971 0.8332995  0.64892444]]
Step:200, total reward:-2760.2898513475047, average reward:-13.801449256737524,----
Box_Position: [[1.44557734 0.56108362 0.67002627]]
Step:200, total reward:-2783.0499332698355, average reward:-13.915249666349178,----
Box_Position: [[1.33778844 0.952849   0.55751625]]

------------------Episode:50------------------
Step:190, total reward:-2632.5026935118094, average reward:-13.855277334272682,success
Box_Position: [[1.51035828 1.04043799 0.65275816]]
Step:200, total reward:-3111.648317973409, average reward:-15.558241589867045,----
Box_Position: [[1.44652752 1.06570547 0.73147917]]
Step:200, total reward:-2593.9892161446155, average reward:-12.969946080723078,----
Box_Position: [[1.44954914 0.80037151 0.68619779]]
Step:200, total reward:-2613.5218611997775, average reward:-13.067609305998888,----
Box_Position: [[1.36176642 0.67317618 0.53649849]]
Step:200, total reward:-2740.9634687168545, average reward:-13.704817343584272,----
Box_Position: [[1.2773329  0.54533662 0.56292378]]
Step:200, total reward:-2705.5739148371163, average reward:-13.527869574185582,----
Box_Position: [[1.43800083 0.84644851 0.56929993]]
Step:200, total reward:-3038.2165784725075, average reward:-15.191082892362537,----
Box_Position: [[1.35062392 0.8673013  0.58535896]]
Step:200, total reward:-2550.0461727487213, average reward:-12.750230863743607,----
Box_Position: [[1.4080604  0.93838096 0.56532713]]
Step:200, total reward:-2653.845759964406, average reward:-13.26922879982203,----
Box_Position: [[1.45281675 0.8020295  0.54001083]]
Step:200, total reward:-2803.693106875419, average reward:-14.018465534377095,----
Box_Position: [[1.49658377 0.6979399  0.57053076]]
Step:200, total reward:-2816.925103907952, average reward:-14.08462551953976,----
Box_Position: [[1.3933653  1.02488151 0.74547082]]
Step:200, total reward:-3061.9868785401427, average reward:-15.309934392700713,----
Box_Position: [[1.3042659  1.04742698 0.72277319]]
Step:200, total reward:-2503.636909179008, average reward:-12.51818454589504,----
Box_Position: [[1.44881023 0.73240874 0.54939021]]
Step:200, total reward:-2716.6846945765765, average reward:-13.583423472882883,----
Box_Position: [[1.26250885 0.57794561 0.71100878]]
Step:200, total reward:-2361.608326839176, average reward:-11.80804163419588,----
Box_Position: [[1.35091135 0.86080423 0.51756837]]
Step:200, total reward:-2845.4613282474443, average reward:-14.227306641237222,----
Box_Position: [[1.36887053 0.94815357 0.52356765]]
Step:200, total reward:-2455.7591718701706, average reward:-12.278795859350852,----
Box_Position: [[1.30406326 0.89948209 0.65222132]]
Step:200, total reward:-2495.6254388582956, average reward:-12.478127194291478,----
Box_Position: [[1.40640512 0.51648003 0.66118241]]
Step:200, total reward:-2829.461305486482, average reward:-14.147306527432411,----
Box_Position: [[1.46575082 1.03847019 0.57697936]]
Step:200, total reward:-2674.645476551541, average reward:-13.373227382757705,----
Box_Position: [[1.28128055 0.83485587 0.48013646]]
Step:200, total reward:-2575.0297036609336, average reward:-12.875148518304668,----
Box_Position: [[1.4150398  0.62414438 0.45671516]]
Step:200, total reward:-2805.085443406291, average reward:-14.025427217031455,----
Box_Position: [[1.47914174 0.87895368 0.66431696]]
Step:200, total reward:-2769.1367478793163, average reward:-13.845683739396582,----
Box_Position: [[1.25175312 0.44046327 0.62330192]]
Step:200, total reward:-2502.85619278848, average reward:-12.514280963942399,----
Box_Position: [[1.28542889 0.59442386 0.73965359]]
Step:200, total reward:-2392.624433534167, average reward:-11.963122167670836,----
Box_Position: [[1.50497427 0.88720677 0.54792718]]
Step:200, total reward:-2991.740169940347, average reward:-14.958700849701735,----
Box_Position: [[1.27333689 0.94131094 0.48972317]]
Step:200, total reward:-2687.0530146159153, average reward:-13.435265073079577,----
Box_Position: [[1.49958012 0.69942786 0.57631966]]
Step:200, total reward:-2711.9597261344884, average reward:-13.559798630672441,----
Box_Position: [[1.52357919 0.60691705 0.54612143]]
Step:200, total reward:-2816.7227908043037, average reward:-14.08361395402152,----
Box_Position: [[1.30752323 0.913891   0.47787647]]
Step:200, total reward:-2641.4611072180032, average reward:-13.207305536090017,----
Box_Position: [[1.36101555 0.81040265 0.46185799]]
Step:200, total reward:-2864.915995171774, average reward:-14.32457997585887,----
Box_Position: [[1.4064218  0.59378403 0.60668876]]
Step:200, total reward:-2848.6005220552706, average reward:-14.243002610276353,----
Box_Position: [[1.38448098 1.00932171 0.62052841]]
Step:200, total reward:-2889.0425276755027, average reward:-14.445212638377514,----
Box_Position: [[1.49926541 0.89920631 0.5223008 ]]
Step:200, total reward:-2953.3671925156923, average reward:-14.766835962578462,----
Box_Position: [[1.43219832 0.88331628 0.52862271]]
Step:200, total reward:-2722.0505308555485, average reward:-13.610252654277742,----
Box_Position: [[1.25844477 1.1830351  0.50954261]]
Step:158, total reward:-2448.997978856861, average reward:-15.499987207954819,success
Box_Position: [[1.3307478  0.83527475 0.64245582]]
Step:200, total reward:-2772.361154303183, average reward:-13.861805771515915,----
Box_Position: [[1.29062553 0.80026294 0.45026246]]
Step:200, total reward:-2826.9369833143305, average reward:-14.134684916571652,----
Box_Position: [[1.41197156 0.99922057 0.68326623]]
Step:200, total reward:-2852.142911708731, average reward:-14.260714558543654,----
Box_Position: [[1.26227972 0.71387772 0.66842844]]
Step:200, total reward:-2555.1199776130716, average reward:-12.775599888065358,----
Box_Position: [[1.29995276 0.46996336 0.71469324]]
Step:200, total reward:-3090.1797717046534, average reward:-15.450898858523267,----
Box_Position: [[1.54185556 0.614935   0.52054191]]
Step:200, total reward:-2900.9213633269364, average reward:-14.504606816634682,----
Box_Position: [[1.30623701 0.7749979  0.65054166]]
Step:200, total reward:-2534.6422706374597, average reward:-12.673211353187298,----
Box_Position: [[1.44838009 0.72864725 0.58805237]]
Step:200, total reward:-2768.0141781911266, average reward:-13.840070890955634,----
Box_Position: [[1.47826478 0.44180757 0.51433898]]
Step:200, total reward:-2793.6784413476807, average reward:-13.968392206738404,----
Box_Position: [[1.35098786 1.0577415  0.55084212]]
Step:200, total reward:-2998.79510083553, average reward:-14.99397550417765,----
Box_Position: [[1.38460415 0.99288085 0.56852005]]
Step:200, total reward:-2668.1856399868093, average reward:-13.340928199934046,----
Box_Position: [[1.33707623 0.58068013 0.51431113]]
Step:200, total reward:-2693.5115358627363, average reward:-13.467557679313682,----
Box_Position: [[1.29496823 0.79943165 0.58649371]]
Step:200, total reward:-2635.6834220264536, average reward:-13.178417110132267,----
Box_Position: [[1.26594289 1.03206324 0.68657057]]
Step:200, total reward:-2646.1870803589277, average reward:-13.230935401794639,----
Box_Position: [[1.34838328 0.76552043 0.62337764]]

------------------Episode:100------------------
Step:200, total reward:-2512.2284633200275, average reward:-12.561142316600137,----
episode 100, the accuracy is: 10%
Box_Position: [[1.36171591 0.86546418 0.65565212]]
Step:196, total reward:-2497.4384774886344, average reward:-12.7420330484114,success
Box_Position: [[1.45731345 0.84466911 0.55411287]]
Step:200, total reward:-2809.661865247974, average reward:-14.04830932623987,----
Box_Position: [[1.32455286 0.99168873 0.69655633]]
Step:32, total reward:-382.7462462844358, average reward:-11.96082019638862,success
Box_Position: [[1.47716833 0.77409285 0.73720079]]
Step:200, total reward:-2752.6174910686254, average reward:-13.763087455343127,----
Box_Position: [[1.47582003 0.90385113 0.49583457]]
Step:200, total reward:-2676.3012587367602, average reward:-13.3815062936838,----
Box_Position: [[1.39917909 0.68842018 0.52960512]]
Step:200, total reward:-2792.56469987956, average reward:-13.9628234993978,----
Box_Position: [[1.38815381 0.75819615 0.64723607]]
Step:200, total reward:-2783.702065025873, average reward:-13.918510325129365,----
Box_Position: [[1.28855118 0.68046533 0.62090726]]
Step:200, total reward:-2385.7791755455864, average reward:-11.928895877727932,----
Box_Position: [[1.28058232 0.5221194  0.59191689]]
Step:49, total reward:-737.2976223136076, average reward:-15.046890251298114,success
Box_Position: [[1.44116495 0.78792387 0.49066429]]
Step:200, total reward:-2712.0491811406255, average reward:-13.560245905703127,----
Box_Position: [[1.2565229  0.89588685 0.69401004]]
Step:200, total reward:-2482.7482958277005, average reward:-12.413741479138503,----
Box_Position: [[1.48591324 0.57993786 0.73816351]]
Step:200, total reward:-2773.553551857475, average reward:-13.867767759287377,----
Box_Position: [[1.48216615 0.98385389 0.55636562]]
Step:200, total reward:-2822.6665399146505, average reward:-14.113332699573252,----
Box_Position: [[1.35934389 0.96532248 0.74249718]]
Step:200, total reward:-2968.5591476262043, average reward:-14.842795738131022,----
Box_Position: [[1.5291355  0.94835437 0.52895626]]
Step:200, total reward:-2886.520169653448, average reward:-14.43260084826724,----
Box_Position: [[1.36862385 0.88044283 0.62650064]]
Step:200, total reward:-2546.641582665102, average reward:-12.73320791332551,----
Box_Position: [[1.26910561 1.10865241 0.63185283]]
Step:200, total reward:-2772.984334626607, average reward:-13.864921673133034,----
Box_Position: [[1.45602775 0.72525801 0.66597208]]
Step:200, total reward:-2736.8966667554137, average reward:-13.684483333777068,----
Box_Position: [[1.28511882 0.45430538 0.74298819]]
Step:200, total reward:-2765.2178679267136, average reward:-13.826089339633567,----
Box_Position: [[1.43754909 0.61198823 0.66123575]]
Step:200, total reward:-2649.3811133562313, average reward:-13.246905566781157,----
Box_Position: [[1.42748328 0.5494071  0.66499877]]
Step:200, total reward:-2750.3666594599536, average reward:-13.751833297299768,----
Box_Position: [[1.28586717 0.59330611 0.65866408]]
Step:200, total reward:-2648.7721806963445, average reward:-13.243860903481723,----
Box_Position: [[1.42006111 0.8866745  0.48342635]]
Step:200, total reward:-2964.1692670706616, average reward:-14.820846335353307,----
Box_Position: [[1.32018565 0.8226087  0.71921655]]
Step:200, total reward:-2555.7521368317466, average reward:-12.778760684158733,----
Box_Position: [[1.41241994 0.73018734 0.74757336]]
Step:200, total reward:-2778.7024965798123, average reward:-13.893512482899062,----
Box_Position: [[1.52393841 0.72371483 0.71380771]]
Step:200, total reward:-3676.1531445125465, average reward:-18.38076572256273,----
Box_Position: [[1.2908191  0.94030771 0.71160362]]
Step:197, total reward:-2488.4133570245936, average reward:-12.631539883373572,success
Box_Position: [[1.26527881 0.82676141 0.59434914]]
Step:200, total reward:-2626.3900600775987, average reward:-13.131950300387993,----
Box_Position: [[1.50892154 0.83520461 0.69609269]]
Step:200, total reward:-2729.9945221291605, average reward:-13.649972610645802,----
Box_Position: [[1.30118349 0.7753925  0.58050778]]
Step:200, total reward:-2634.587606713172, average reward:-13.172938033565861,----
Box_Position: [[1.31170234 0.73572851 0.56212908]]
Step:200, total reward:-2611.271527235755, average reward:-13.056357636178776,----
Box_Position: [[1.34864114 0.61612285 0.70266025]]
Step:200, total reward:-2733.7678619194307, average reward:-13.668839309597153,----
Box_Position: [[1.4264415  1.12780692 0.49875044]]
Step:200, total reward:-3029.7132979866115, average reward:-15.148566489933057,----
Box_Position: [[1.27634127 0.97391501 0.74975816]]
Step:200, total reward:-2565.4564298636383, average reward:-12.827282149318192,----
Box_Position: [[1.38706818 0.65328578 0.53049809]]
Step:200, total reward:-2829.499910947816, average reward:-14.14749955473908,----
Box_Position: [[1.45014379 0.51204166 0.70202857]]
Step:200, total reward:-2963.437489511314, average reward:-14.81718744755657,----
Box_Position: [[1.49274104 0.87241332 0.50810842]]
Step:200, total reward:-3061.167603882132, average reward:-15.30583801941066,----
Box_Position: [[1.31762503 0.52541314 0.64856486]]
Step:200, total reward:-2577.4548679852855, average reward:-12.887274339926428,----
Box_Position: [[1.41337351 0.69535273 0.53761385]]
Step:200, total reward:-2696.0616291963383, average reward:-13.480308145981692,----
Box_Position: [[1.25049327 1.05265089 0.63352661]]
Step:175, total reward:-2360.157933247616, average reward:-13.486616761414947,success
Box_Position: [[1.49907061 0.89571635 0.46310923]]
Step:200, total reward:-2779.683917881957, average reward:-13.898419589409784,----
Box_Position: [[1.34214372 0.82047079 0.48805073]]
Step:200, total reward:-2981.883522588735, average reward:-14.909417612943676,----
Box_Position: [[1.52929564 0.478468   0.7366018 ]]
Step:200, total reward:-2922.6045161579596, average reward:-14.613022580789798,----
Box_Position: [[1.52104931 0.71019975 0.58487931]]
Step:200, total reward:-2696.4682279054787, average reward:-13.482341139527394,----
Box_Position: [[1.49048961 0.55013185 0.69951647]]
Step:200, total reward:-2846.3682186459687, average reward:-14.231841093229843,----
Box_Position: [[1.3718237  0.73912092 0.69006453]]
Step:200, total reward:-2692.461416303576, average reward:-13.46230708151788,----
Box_Position: [[1.34711734 1.06459547 0.52420717]]
Step:200, total reward:-2836.396736231751, average reward:-14.181983681158757,----
Box_Position: [[1.49819161 0.89700366 0.64225309]]
Step:200, total reward:-2636.6618236076133, average reward:-13.183309118038066,----
Box_Position: [[1.40659608 1.02102873 0.6569896 ]]
Step:200, total reward:-2641.261699046102, average reward:-13.206308495230509,----
Box_Position: [[1.35628916 0.91018711 0.48916805]]

------------------Episode:150------------------
Step:200, total reward:-2667.1283255021076, average reward:-13.335641627510538,----
Box_Position: [[1.3632323  0.40326911 0.54418334]]
Step:200, total reward:-2853.312712003196, average reward:-14.26656356001598,----
Box_Position: [[1.54906747 0.91722882 0.61250682]]
Step:200, total reward:-3083.497992985794, average reward:-15.41748996492897,----
Box_Position: [[1.26149164 0.75668995 0.66426465]]
Step:200, total reward:-2654.400749787531, average reward:-13.272003748937655,----
Box_Position: [[1.30181314 0.81303435 0.53615998]]
Step:200, total reward:-2931.5316300089858, average reward:-14.657658150044929,----
Box_Position: [[1.38708186 0.88804319 0.70563679]]
Step:200, total reward:-2658.852407568633, average reward:-13.294262037843167,----
Box_Position: [[1.40435179 0.8341045  0.57235016]]
Step:200, total reward:-2802.901243131429, average reward:-14.014506215657144,----
Box_Position: [[1.27927353 0.91412815 0.66415671]]
Step:200, total reward:-2485.83578066191, average reward:-12.42917890330955,----
Box_Position: [[1.54952708 0.49005577 0.48631617]]
Step:200, total reward:-3218.049426266052, average reward:-16.09024713133026,----
Box_Position: [[1.50461439 1.06200569 0.60953814]]
Step:200, total reward:-2995.9278657268633, average reward:-14.979639328634317,----
Box_Position: [[1.54874273 0.90255394 0.7347463 ]]
Step:200, total reward:-3199.265975017677, average reward:-15.996329875088385,----
Box_Position: [[1.33382105 0.77662033 0.53917073]]
Step:200, total reward:-2791.8424281883927, average reward:-13.959212140941963,----
Box_Position: [[1.35313178 0.79333528 0.74516066]]
Step:200, total reward:-2591.178950883964, average reward:-12.95589475441982,----
Box_Position: [[1.52775084 0.65007274 0.67585619]]
Step:200, total reward:-2886.0113293251948, average reward:-14.430056646625975,----
Box_Position: [[1.39583964 0.88582793 0.74785049]]
Step:200, total reward:-2542.06079588186, average reward:-12.7103039794093,----
Box_Position: [[1.2641353  0.98685917 0.59419963]]
Step:175, total reward:-2530.075988379213, average reward:-14.457577076452646,success
Box_Position: [[1.28726422 0.59350512 0.65816224]]
Step:200, total reward:-2508.7640460769385, average reward:-12.543820230384693,----
Box_Position: [[1.42217418 0.93053487 0.60749011]]
Step:200, total reward:-2791.4360758567514, average reward:-13.957180379283757,----
Box_Position: [[1.28439929 0.72892549 0.74835516]]
Step:200, total reward:-2384.5181157893085, average reward:-11.922590578946542,----
Box_Position: [[1.38310306 0.57529056 0.5013802 ]]
Step:200, total reward:-2789.6474406439484, average reward:-13.948237203219742,----
Box_Position: [[1.38580467 0.66042753 0.58834472]]
Step:200, total reward:-2614.3464364692372, average reward:-13.071732182346187,----
Box_Position: [[1.38580743 0.82654641 0.49898249]]
Step:200, total reward:-2820.1700634798503, average reward:-14.100850317399251,----
Box_Position: [[1.31162593 0.76349583 0.64467471]]
Step:200, total reward:-2497.009921991814, average reward:-12.48504960995907,----
Box_Position: [[1.30221867 0.55518883 0.73815543]]
Step:200, total reward:-2783.0122445355055, average reward:-13.915061222677528,----
Box_Position: [[1.48949794 1.06195286 0.5260766 ]]
Step:200, total reward:-3143.475202632244, average reward:-15.71737601316122,----
Box_Position: [[1.4454943  0.71274942 0.73319703]]
Step:161, total reward:-2064.0723188284796, average reward:-12.820324961667575,success
Box_Position: [[1.45356582 0.87298596 0.52363238]]
Step:200, total reward:-3012.925465419685, average reward:-15.064627327098426,----
Box_Position: [[1.45289201 1.17942522 0.49598475]]
Step:200, total reward:-3007.6714630799124, average reward:-15.038357315399562,----
Box_Position: [[1.30955488 0.99400704 0.56263374]]
Step:200, total reward:-2667.569901553773, average reward:-13.337849507768865,----
Box_Position: [[1.3953132  0.64951141 0.65443829]]
Step:200, total reward:-2541.089135900772, average reward:-12.70544567950386,----
Box_Position: [[1.42050973 0.58808524 0.58614391]]
Step:200, total reward:-2669.8830102234156, average reward:-13.349415051117077,----
Box_Position: [[1.40193663 1.0931464  0.70022445]]
Step:200, total reward:-3013.4496013634803, average reward:-15.067248006817401,----
Box_Position: [[1.47888811 1.04359608 0.63456172]]
Step:200, total reward:-2931.7694715244006, average reward:-14.658847357622003,----
Box_Position: [[1.33637187 0.90163302 0.64748781]]
Step:200, total reward:-2601.581595589153, average reward:-13.007907977945765,----
Box_Position: [[1.35823907 0.83419833 0.60554041]]
Step:200, total reward:-2723.771825325455, average reward:-13.618859126627276,----
Box_Position: [[1.46524718 0.83997994 0.69691226]]
Step:200, total reward:-2781.212167472099, average reward:-13.906060837360494,----
Box_Position: [[1.45843476 1.03944362 0.63160712]]
Step:200, total reward:-2830.3038732366686, average reward:-14.151519366183344,----
Box_Position: [[1.30361413 0.84142747 0.4742009 ]]
Step:200, total reward:-2699.134108936018, average reward:-13.49567054468009,----
Box_Position: [[1.38107556 1.13535956 0.5727501 ]]
Step:200, total reward:-2905.4619328962794, average reward:-14.527309664481397,----
Box_Position: [[1.28408908 0.62597652 0.52409464]]
Step:200, total reward:-2805.410155371455, average reward:-14.027050776857275,----
Box_Position: [[1.49550713 0.859678   0.70023777]]
Step:200, total reward:-2828.84682136135, average reward:-14.144234106806751,----
Box_Position: [[1.50732099 0.87681658 0.66770861]]
Step:200, total reward:-2783.5814626596834, average reward:-13.917907313298418,----
Box_Position: [[1.53275224 0.58491452 0.59873613]]
Step:200, total reward:-2786.1430468813896, average reward:-13.930715234406948,----
Box_Position: [[1.5403968  0.75032138 0.69381386]]
Step:200, total reward:-2792.657750250648, average reward:-13.96328875125324,----
Box_Position: [[1.52549224 0.9310396  0.66432935]]
Step:200, total reward:-2902.308201003207, average reward:-14.511541005016035,----
Box_Position: [[1.45894893 0.89927536 0.74090843]]
Step:200, total reward:-2857.0676613360806, average reward:-14.285338306680403,----
Box_Position: [[1.26987196 1.10008159 0.50875547]]
Step:200, total reward:-2674.2533740685503, average reward:-13.371266870342751,----
Box_Position: [[1.40249304 0.44636175 0.53745074]]
Step:200, total reward:-3060.1951996215444, average reward:-15.300975998107722,----
Box_Position: [[1.26279615 0.46166739 0.61101378]]
Step:200, total reward:-2710.0940662762596, average reward:-13.550470331381298,----
Box_Position: [[1.46973991 0.89268214 0.51835193]]
Step:200, total reward:-2919.462897778549, average reward:-14.597314488892746,----
Box_Position: [[1.28052967 0.87698842 0.7104379 ]]

------------------Episode:200------------------
Step:200, total reward:-2571.631207155426, average reward:-12.858156035777132,----
episode 200, the accuracy is: 7%
Box_Position: [[1.26319332 0.60662988 0.63480042]]
Step:200, total reward:-2337.1267898008045, average reward:-11.685633949004023,----
Box_Position: [[1.2934159  1.18085741 0.48953085]]
Step:200, total reward:-3107.7300677400412, average reward:-15.538650338700206,----
Box_Position: [[1.26048234 0.56635897 0.54321008]]
Step:200, total reward:-2756.8401892140328, average reward:-13.784200946070165,----
Box_Position: [[1.50954691 0.7055341  0.6862811 ]]
Step:200, total reward:-2735.9693946498805, average reward:-13.679846973249402,----
Box_Position: [[1.28145523 0.61560227 0.66726637]]
Step:200, total reward:-2431.6523382135197, average reward:-12.1582616910676,----
Box_Position: [[1.50771886 0.50133811 0.54553759]]
Step:200, total reward:-2942.27520134879, average reward:-14.711376006743949,----
Box_Position: [[1.34776698 0.57428582 0.57433443]]
Step:200, total reward:-2687.422790744161, average reward:-13.437113953720804,----
Box_Position: [[1.40851292 0.79190135 0.6673259 ]]
Step:200, total reward:-2537.8240097739094, average reward:-12.689120048869547,----
Box_Position: [[1.25538037 0.84746417 0.52670237]]
Step:200, total reward:-2678.348867981432, average reward:-13.39174433990716,----
Box_Position: [[1.44497338 0.9118333  0.739979  ]]
Step:200, total reward:-2926.2922765073886, average reward:-14.631461382536942,----
Box_Position: [[1.33248887 0.93266037 0.46637681]]
Step:200, total reward:-2902.521294015062, average reward:-14.512606470075308,----
Box_Position: [[1.47098418 0.67916859 0.46466234]]
Step:200, total reward:-2863.5463359186133, average reward:-14.317731679593066,----
Box_Position: [[1.36784094 0.62892595 0.60418679]]
Step:200, total reward:-2708.8971272794047, average reward:-13.544485636397024,----
Box_Position: [[1.50729115 1.02159287 0.62805437]]
Step:200, total reward:-2942.78272087059, average reward:-14.71391360435295,----
Box_Position: [[1.38289166 0.82135659 0.70801129]]
Step:200, total reward:-2694.3661744528467, average reward:-13.471830872264233,----
Box_Position: [[1.3107031  0.7444072  0.54561527]]
Step:200, total reward:-2424.926949312646, average reward:-12.12463474656323,----
Box_Position: [[1.41192842 0.73248446 0.52760651]]
Step:200, total reward:-2709.7783101817413, average reward:-13.548891550908706,----
Box_Position: [[1.53346457 0.73752058 0.50450784]]
Step:200, total reward:-2814.210180561609, average reward:-14.071050902808045,----
Box_Position: [[1.4045614  0.70776204 0.59512168]]
Step:200, total reward:-2703.534132344952, average reward:-13.51767066172476,----
Box_Position: [[1.42641928 0.67788163 0.46371657]]
Step:200, total reward:-2976.1392539704543, average reward:-14.880696269852272,----
Box_Position: [[1.29580857 0.74200211 0.68518608]]
Step:88, total reward:-1073.9125668660747, average reward:-12.203551896205395,success
Box_Position: [[1.48609127 0.83653562 0.67865452]]
Step:200, total reward:-3013.712330157402, average reward:-15.06856165078701,----
Box_Position: [[1.39225594 0.86690908 0.48704589]]
Step:200, total reward:-2617.307265078271, average reward:-13.086536325391355,----
Box_Position: [[1.26831467 0.52442047 0.67356144]]
Step:200, total reward:-2554.734037580758, average reward:-12.77367018790379,----
Box_Position: [[1.26707216 0.46034745 0.55071501]]
Step:200, total reward:-2690.418533575687, average reward:-13.452092667878436,----
Box_Position: [[1.46177934 0.95359214 0.61648722]]
Step:200, total reward:-2737.240517384501, average reward:-13.686202586922505,----
Box_Position: [[1.40127234 1.00538707 0.55506695]]
Step:200, total reward:-2683.5570630293814, average reward:-13.417785315146908,----
Box_Position: [[1.29976627 0.94120829 0.68211329]]
Step:200, total reward:-2758.1974169181963, average reward:-13.79098708459098,----
Box_Position: [[1.54303667 0.61967457 0.74748546]]
Step:200, total reward:-2839.5131198589684, average reward:-14.197565599294842,----
Box_Position: [[1.28992449 0.6128889  0.69199943]]
Step:200, total reward:-2704.152643158314, average reward:-13.520763215791568,----
Box_Position: [[1.29501191 0.64821059 0.56840508]]
Step:200, total reward:-2480.859965073825, average reward:-12.404299825369126,----
Box_Position: [[1.33776281 0.7170353  0.64946685]]
Step:200, total reward:-2783.5778384524297, average reward:-13.917889192262148,----
Box_Position: [[1.25266707 0.58854492 0.50222971]]
Step:200, total reward:-2744.607489095175, average reward:-13.723037445475875,----
Box_Position: [[1.4457016  0.80321291 0.46315658]]
Step:200, total reward:-3040.937522145038, average reward:-15.204687610725191,----
Box_Position: [[1.34707554 0.82730037 0.63818505]]
Step:200, total reward:-2584.172936999818, average reward:-12.92086468499909,----
Box_Position: [[1.31945994 0.98885502 0.64654479]]
Step:200, total reward:-2862.9763019940456, average reward:-14.314881509970228,----
Box_Position: [[1.51755828 0.92293714 0.66391401]]
Step:200, total reward:-2784.6612326090594, average reward:-13.923306163045297,----
Box_Position: [[1.3814719  0.6617817  0.45963798]]
Step:200, total reward:-2915.7174261341047, average reward:-14.578587130670524,----
Box_Position: [[1.50583032 1.05980622 0.60636623]]
Step:200, total reward:-2645.563916470863, average reward:-13.227819582354316,----
Box_Position: [[1.297719   0.96020839 0.45657024]]
Step:200, total reward:-2734.1701940315916, average reward:-13.670850970157957,----
Box_Position: [[1.40377915 0.66869823 0.61279369]]
Step:200, total reward:-2629.6326202253954, average reward:-13.148163101126977,----
Box_Position: [[1.4552355  0.9667033  0.74788911]]
Step:200, total reward:-2569.2691903804807, average reward:-12.846345951902403,----
Box_Position: [[1.36978107 0.78814287 0.62915844]]
Step:200, total reward:-2748.8306659989025, average reward:-13.744153329994512,----
Box_Position: [[1.30997132 0.53523768 0.53502771]]
Step:200, total reward:-2849.6923746694792, average reward:-14.248461873347397,----
Box_Position: [[1.38283971 0.53084248 0.4686011 ]]
Step:200, total reward:-3084.0221954416625, average reward:-15.420110977208312,----
Box_Position: [[1.4821751  0.48132753 0.62058447]]
Step:200, total reward:-2690.231721614464, average reward:-13.451158608072319,----
Box_Position: [[1.5272877  0.51799093 0.71991508]]
Step:200, total reward:-2832.753646920002, average reward:-14.163768234600012,----
Box_Position: [[1.4100316  0.79879442 0.74638505]]
Step:13, total reward:-159.7126070464398, average reward:-12.285585157418447,success
Box_Position: [[1.40504313 0.76662956 0.46672686]]
Step:200, total reward:-2801.927123381626, average reward:-14.009635616908131,----
Box_Position: [[1.28047083 0.60104479 0.70456507]]

------------------Episode:250------------------
Step:200, total reward:-2676.5114977163776, average reward:-13.382557488581888,----
Box_Position: [[1.3530885  1.0827479  0.53301771]]
Step:200, total reward:-2550.9170038294637, average reward:-12.754585019147319,----
Box_Position: [[1.30438944 0.80382234 0.74307277]]
Step:48, total reward:-730.5824421890028, average reward:-15.220467545604224,success
Box_Position: [[1.33286149 1.02197005 0.53323734]]
Step:200, total reward:-2987.1877394811568, average reward:-14.935938697405783,----
Box_Position: [[1.46385384 0.83438419 0.48570621]]
Step:200, total reward:-2927.236760537167, average reward:-14.636183802685835,----
Box_Position: [[1.25372204 0.69068635 0.52519172]]
Step:200, total reward:-2644.773654851635, average reward:-13.223868274258175,----
Box_Position: [[1.42929041 0.84625289 0.70987251]]
Step:200, total reward:-2694.5230911231565, average reward:-13.472615455615783,----
Box_Position: [[1.37358599 0.74190836 0.58333958]]
Step:200, total reward:-2672.591193070807, average reward:-13.362955965354036,----
Box_Position: [[1.52767742 0.93172812 0.50267289]]
Step:200, total reward:-3165.5903102463535, average reward:-15.827951551231768,----
Box_Position: [[1.34882664 0.82382013 0.57676134]]
Step:200, total reward:-2602.1564784086204, average reward:-13.010782392043103,----
Box_Position: [[1.26145786 0.90447082 0.64856273]]
Step:200, total reward:-2740.822619047617, average reward:-13.704113095238085,----
Box_Position: [[1.29083769 0.79985462 0.59620722]]
Step:200, total reward:-2566.492024607677, average reward:-12.832460123038386,----
Box_Position: [[1.44477279 0.50480559 0.55908834]]
Step:200, total reward:-3199.9199518434793, average reward:-15.999599759217396,----
Box_Position: [[1.48309942 0.75923975 0.51070018]]
Step:200, total reward:-2803.684663581306, average reward:-14.01842331790653,----
Box_Position: [[1.53393358 1.08144748 0.71827465]]
Step:200, total reward:-2890.1556802751948, average reward:-14.450778401375974,----
Box_Position: [[1.25984185 1.07073586 0.74371961]]
Step:200, total reward:-2745.5205538688983, average reward:-13.727602769344491,----
Box_Position: [[1.310186   0.65011407 0.51256222]]
Step:130, total reward:-1866.3537658232124, average reward:-14.356567429409326,success
Box_Position: [[1.43104379 0.83628466 0.5606332 ]]
Step:200, total reward:-2778.747953553649, average reward:-13.893739767768245,----
Box_Position: [[1.31115829 0.62615695 0.68616555]]
Step:200, total reward:-2644.334119667084, average reward:-13.22167059833542,----
Box_Position: [[1.31786611 1.06734528 0.66865154]]
Step:200, total reward:-3088.8143225041795, average reward:-15.444071612520897,----
Box_Position: [[1.4665257  0.99400813 0.73830846]]
Step:200, total reward:-2811.5178597114277, average reward:-14.057589298557138,----
Box_Position: [[1.28414514 0.71306645 0.49611936]]
Step:200, total reward:-2858.8595271580857, average reward:-14.294297635790429,----
Box_Position: [[1.50839592 0.71400584 0.54779672]]
Step:200, total reward:-2961.9051725778063, average reward:-14.809525862889032,----
Box_Position: [[1.47689533 0.96129529 0.55203715]]
Step:200, total reward:-2784.5269378052853, average reward:-13.922634689026427,----
Box_Position: [[1.4745146  0.86672981 0.67596303]]
Step:200, total reward:-2863.6309815470245, average reward:-14.318154907735122,----
Box_Position: [[1.3182639  0.60023499 0.50625509]]
Step:200, total reward:-2773.1207313155733, average reward:-13.865603656577866,----
Box_Position: [[1.53742629 0.49857941 0.66062879]]
Step:200, total reward:-2753.9808422451943, average reward:-13.76990421122597,----
Box_Position: [[1.29485453 0.82867271 0.56402833]]
Step:200, total reward:-2548.545454116902, average reward:-12.74272727058451,----
Box_Position: [[1.52569014 0.60191316 0.694366  ]]
Step:200, total reward:-2841.9996500838874, average reward:-14.209998250419437,----
Box_Position: [[1.46303445 0.50675852 0.64811954]]
Step:200, total reward:-2880.55049549395, average reward:-14.40275247746975,----
Box_Position: [[1.4908112  1.01094947 0.72025605]]
Step:200, total reward:-2685.0764204144407, average reward:-13.425382102072204,----
Box_Position: [[1.51328269 0.55376861 0.6808876 ]]
Step:200, total reward:-2658.939403657323, average reward:-13.294697018286616,----
Box_Position: [[1.2988437  0.52050007 0.51034   ]]
Step:36, total reward:-461.88229412233954, average reward:-12.830063725620542,success
Box_Position: [[1.39022502 0.64364391 0.47896289]]
Step:200, total reward:-2784.861797141382, average reward:-13.92430898570691,----
Box_Position: [[1.35999838 0.85820268 0.67362823]]
Step:200, total reward:-2632.386119750552, average reward:-13.161930598752761,----
Box_Position: [[1.36542616 0.62812593 0.62556813]]
Step:200, total reward:-2766.769429322482, average reward:-13.833847146612412,----
Box_Position: [[1.46295515 0.73095744 0.50560127]]
Step:200, total reward:-2732.585247938674, average reward:-13.66292623969337,----
Box_Position: [[1.29023768 0.53813641 0.72210562]]
Step:200, total reward:-2540.1836141790286, average reward:-12.700918070895144,----
Box_Position: [[1.421194   1.05842839 0.53375649]]
Step:200, total reward:-2787.607327787381, average reward:-13.938036638936905,----
Box_Position: [[1.5211175  0.73967725 0.48776872]]
Step:200, total reward:-2563.9110623839383, average reward:-12.819555311919691,----
Box_Position: [[1.27745935 0.65671    0.72459568]]
Step:200, total reward:-2468.855469883906, average reward:-12.344277349419531,----
Box_Position: [[1.3527656  1.01120679 0.59096209]]
Step:50, total reward:-813.8926324394301, average reward:-16.277852648788603,success
Box_Position: [[1.45892769 0.67999815 0.57506135]]
Step:200, total reward:-2685.304759645856, average reward:-13.42652379822928,----
Box_Position: [[1.54777286 0.61372361 0.66998751]]
Step:200, total reward:-2736.788587897853, average reward:-13.683942939489265,----
Box_Position: [[1.51580356 0.67816443 0.50284363]]
Step:200, total reward:-3163.3365546889027, average reward:-15.816682773444514,----
Box_Position: [[1.31710465 0.5971022  0.61423127]]
Step:200, total reward:-2702.061435279566, average reward:-13.51030717639783,----
Box_Position: [[1.40565508 0.76756079 0.69064013]]
Step:200, total reward:-2523.1027685738272, average reward:-12.615513842869136,----
Box_Position: [[1.53368586 0.86660014 0.45717827]]
Step:200, total reward:-2595.428417384046, average reward:-12.97714208692023,----
Box_Position: [[1.53400662 0.94004507 0.6165158 ]]
Step:200, total reward:-2905.4782818657372, average reward:-14.527391409328686,----
Box_Position: [[1.41734476 0.69300068 0.71246288]]
Step:200, total reward:-2567.129878279353, average reward:-12.835649391396764,----
Box_Position: [[1.50173156 0.83086427 0.49279543]]

------------------Episode:300------------------
Step:200, total reward:-2854.3825102406804, average reward:-14.271912551203402,----
episode 300, the accuracy is: 6%
Box_Position: [[1.44405893 1.14106379 0.66368154]]
Step:200, total reward:-2782.655670625879, average reward:-13.913278353129394,----
Box_Position: [[1.42787866 0.54964343 0.49340296]]
Step:200, total reward:-2616.9482373711744, average reward:-13.084741186855872,----
Box_Position: [[1.29604961 0.6715997  0.69192788]]
Step:200, total reward:-2655.3256782217964, average reward:-13.276628391108982,----
Box_Position: [[1.47252971 0.67714237 0.55386755]]
Step:200, total reward:-2722.5563831357204, average reward:-13.612781915678601,----
Box_Position: [[1.52826006 0.66624564 0.51255756]]
Step:200, total reward:-2984.7018635962077, average reward:-14.923509317981038,----
Box_Position: [[1.31696483 0.97123406 0.68020915]]
Step:200, total reward:-2829.6831716781226, average reward:-14.148415858390614,----
Box_Position: [[1.48837451 0.58329746 0.70240346]]
Step:200, total reward:-2762.908048278835, average reward:-13.814540241394175,----
Box_Position: [[1.35232879 0.69377238 0.70486866]]
Step:155, total reward:-1967.0974160392411, average reward:-12.69095107122091,success
Box_Position: [[1.32892817 0.56962857 0.64260455]]
Step:200, total reward:-2844.138962779938, average reward:-14.22069481389969,----
Box_Position: [[1.43594688 0.85162038 0.53216395]]
Step:195, total reward:-2689.9577281037755, average reward:-13.794655015916797,success
Box_Position: [[1.2740127  0.81857647 0.55835232]]
Step:200, total reward:-2699.7097889719644, average reward:-13.498548944859822,----
Box_Position: [[1.41560534 0.7345519  0.57807048]]
Step:200, total reward:-2689.82151405553, average reward:-13.449107570277649,----
Box_Position: [[1.53456328 0.88562529 0.66829552]]
Step:200, total reward:-2675.667450409785, average reward:-13.378337252048926,----
Box_Position: [[1.4873522  0.56885092 0.45106879]]
Step:200, total reward:-3074.320175739935, average reward:-15.371600878699676,----
Box_Position: [[1.49742165 0.83029869 0.63393647]]
Step:200, total reward:-2647.38464869467, average reward:-13.236923243473349,----
Box_Position: [[1.4757879  0.92121078 0.73269514]]
Step:200, total reward:-2642.3094213630357, average reward:-13.211547106815178,----
Box_Position: [[1.43001104 1.03556415 0.62119688]]
Step:200, total reward:-3106.9590635016007, average reward:-15.534795317508003,----
Box_Position: [[1.36009791 0.78136808 0.74658354]]
Step:200, total reward:-2561.684234758896, average reward:-12.808421173794478,----
Box_Position: [[1.50131674 0.84631235 0.61279304]]
Step:200, total reward:-2928.8355525072325, average reward:-14.644177762536163,----
Box_Position: [[1.3552736  0.71845296 0.52960622]]
Step:200, total reward:-2771.436166841951, average reward:-13.857180834209755,----
Box_Position: [[1.28846237 1.04283437 0.50642201]]
Step:200, total reward:-2860.211848849971, average reward:-14.301059244249855,----
Box_Position: [[1.52551963 0.81685484 0.49081174]]
Step:200, total reward:-3010.111688814673, average reward:-15.050558444073365,----
Box_Position: [[1.44879037 1.08301912 0.55894855]]
Step:200, total reward:-2933.9731154859774, average reward:-14.669865577429887,----
Box_Position: [[1.32111673 0.61193824 0.66751469]]
Step:200, total reward:-2617.518395246947, average reward:-13.087591976234735,----
Box_Position: [[1.4656247  0.76518559 0.72228694]]
Step:200, total reward:-2715.7962687427785, average reward:-13.578981343713892,----
Box_Position: [[1.49488873 0.73230566 0.62344969]]
Step:200, total reward:-2877.432675463968, average reward:-14.387163377319839,----
Box_Position: [[1.47433576 0.93633664 0.49161325]]
Step:200, total reward:-3029.8047005798926, average reward:-15.149023502899462,----
Box_Position: [[1.41993146 0.61222263 0.70049331]]
Step:123, total reward:-1678.7033203295462, average reward:-13.647994474223953,success
Box_Position: [[1.37802914 0.95679025 0.73947814]]
Step:200, total reward:-2592.065038075556, average reward:-12.96032519037778,----
Box_Position: [[1.5226676  0.75743922 0.54796667]]
Step:200, total reward:-2738.275078304753, average reward:-13.691375391523765,----
Box_Position: [[1.52813704 0.85203124 0.56400323]]
Step:200, total reward:-2874.519460988407, average reward:-14.372597304942035,----
Box_Position: [[1.38981997 0.90870729 0.55319746]]
Step:200, total reward:-2823.4632048743424, average reward:-14.117316024371712,----
Box_Position: [[1.54294859 0.91103442 0.46987677]]
Step:200, total reward:-3203.7325305372583, average reward:-16.01866265268629,----
Box_Position: [[1.50427663 0.71714387 0.68333144]]
Step:200, total reward:-2846.4096694705686, average reward:-14.232048347352842,----
Box_Position: [[1.53596914 0.7426857  0.61656153]]
Step:200, total reward:-3020.232796968486, average reward:-15.101163984842431,----
Box_Position: [[1.29915466 1.14056084 0.70662676]]
Step:200, total reward:-2698.7930509061234, average reward:-13.493965254530616,----
Box_Position: [[1.51428073 1.03997652 0.55325304]]
Step:200, total reward:-2791.0722998603505, average reward:-13.955361499301752,----
Box_Position: [[1.44833613 0.94225528 0.48945683]]
Step:200, total reward:-2875.5814941530075, average reward:-14.377907470765038,----
Box_Position: [[1.42185577 0.74119622 0.47936509]]
Step:200, total reward:-2893.5557288473633, average reward:-14.467778644236816,----
Box_Position: [[1.28304969 0.85631726 0.74790509]]
Step:20, total reward:-221.7161293167763, average reward:-11.085806465838814,success
Box_Position: [[1.36176934 0.72595077 0.617977  ]]
Step:120, total reward:-1554.9718108542102, average reward:-12.958098423785085,success
Box_Position: [[1.51292163 1.16190026 0.51418699]]
Step:200, total reward:-3086.161544840279, average reward:-15.430807724201395,----
Box_Position: [[1.27025019 0.92593934 0.66383521]]
Step:106, total reward:-1295.4631871435188, average reward:-12.221350822108668,success
Box_Position: [[1.29748865 0.72664684 0.71484272]]
Step:200, total reward:-2667.7943502693406, average reward:-13.338971751346703,----
Box_Position: [[1.50346096 0.88089649 0.48443232]]
Step:200, total reward:-2729.824414292528, average reward:-13.64912207146264,----
Box_Position: [[1.41811266 0.58518981 0.73451046]]
Step:200, total reward:-2696.705395317653, average reward:-13.483526976588264,----
Box_Position: [[1.29039939 0.70542826 0.7080569 ]]
Step:200, total reward:-2694.621312583292, average reward:-13.47310656291646,----
Box_Position: [[1.47043873 0.54814398 0.65904959]]
Step:200, total reward:-2703.030143592972, average reward:-13.51515071796486,----
Box_Position: [[1.2727593  0.63064464 0.65600411]]
Step:200, total reward:-2541.6883538719467, average reward:-12.708441769359734,----
Box_Position: [[1.4959643  0.89267363 0.5616589 ]]

------------------Episode:350------------------
Step:200, total reward:-2793.281557653777, average reward:-13.966407788268885,----
Box_Position: [[1.54874774 0.59618122 0.48093331]]
Step:200, total reward:-2818.9942916509017, average reward:-14.09497145825451,----
Box_Position: [[1.44490907 0.46533633 0.7138001 ]]
Step:200, total reward:-2878.5194723466416, average reward:-14.392597361733207,----
Box_Position: [[1.4013267  1.07559015 0.63800796]]
Step:200, total reward:-2888.1572475944486, average reward:-14.440786237972242,----
Box_Position: [[1.40786178 0.98663605 0.54710766]]
Step:200, total reward:-2942.138393731582, average reward:-14.710691968657908,----
Box_Position: [[1.31388774 0.75674314 0.72720942]]
Step:200, total reward:-2441.6139624034386, average reward:-12.208069812017193,----
Box_Position: [[1.40271459 0.79636713 0.5398993 ]]
Step:200, total reward:-2911.2266356679306, average reward:-14.556133178339653,----
Box_Position: [[1.34905918 0.67073059 0.5038084 ]]
Step:200, total reward:-2605.69911919757, average reward:-13.028495595987849,----
Box_Position: [[1.33959084 0.89003486 0.70106527]]
Step:200, total reward:-2912.3602542593753, average reward:-14.561801271296877,----
Box_Position: [[1.54817889 0.73302205 0.58266503]]
Step:200, total reward:-2880.42187711949, average reward:-14.40210938559745,----
Box_Position: [[1.32876233 0.72057426 0.47256297]]
Step:200, total reward:-2708.5439187774546, average reward:-13.542719593887274,----
Box_Position: [[1.43467415 0.69876782 0.53352121]]
Step:200, total reward:-2846.3523720566727, average reward:-14.231761860283363,----
Box_Position: [[1.47360964 0.81213127 0.63234124]]
Step:200, total reward:-2554.4996880319745, average reward:-12.772498440159872,----
Box_Position: [[1.53486814 0.66249138 0.61139502]]
Step:200, total reward:-2814.3973658370696, average reward:-14.071986829185349,----
Box_Position: [[1.27600486 0.99191734 0.58474309]]
Step:200, total reward:-2924.456472955057, average reward:-14.622282364775286,----
Box_Position: [[1.54910637 0.85026673 0.58751457]]
Step:200, total reward:-2940.421618611193, average reward:-14.702108093055966,----
Box_Position: [[1.39940457 0.90165753 0.59898687]]
Step:200, total reward:-2664.7947258010763, average reward:-13.323973629005382,----
Box_Position: [[1.39251915 0.73564896 0.62812857]]
Step:200, total reward:-2767.2680082358556, average reward:-13.836340041179279,----
Box_Position: [[1.37972574 0.97596505 0.57178964]]
Step:200, total reward:-2813.8751541104266, average reward:-14.069375770552133,----
Box_Position: [[1.26565021 0.85599159 0.58394271]]
Step:200, total reward:-2609.343918759158, average reward:-13.04671959379579,----
Box_Position: [[1.38312362 0.86033557 0.57830236]]
Step:200, total reward:-2600.226807297348, average reward:-13.00113403648674,----
Box_Position: [[1.51628068 1.01926729 0.71708244]]
Step:200, total reward:-2651.2038383252407, average reward:-13.256019191626203,----
Box_Position: [[1.25532262 1.02825692 0.55983687]]
Step:200, total reward:-2980.715810411509, average reward:-14.903579052057546,----
Box_Position: [[1.41118605 0.8294028  0.48981471]]
Step:200, total reward:-2709.554667593872, average reward:-13.54777333796936,----
Box_Position: [[1.35716195 0.5484581  0.50220423]]
Step:200, total reward:-2699.8026014651487, average reward:-13.499013007325743,----
Box_Position: [[1.54009267 1.09518824 0.4979788 ]]
Step:200, total reward:-3121.9687025820754, average reward:-15.609843512910377,----
Box_Position: [[1.41000867 0.71663935 0.46474756]]
Step:200, total reward:-2740.6658533219666, average reward:-13.703329266609833,----
Box_Position: [[1.26782552 1.05202933 0.46943328]]
Step:200, total reward:-2894.048183860775, average reward:-14.470240919303876,----
Box_Position: [[1.37748049 0.73770997 0.57609385]]
Step:200, total reward:-2737.4739544544154, average reward:-13.687369772272078,----
Box_Position: [[1.53182313 0.98799661 0.60301142]]
Step:200, total reward:-3068.743962501, average reward:-15.343719812505,----
Box_Position: [[1.31328022 0.91762833 0.68911308]]
Step:200, total reward:-2560.2364035247842, average reward:-12.80118201762392,----
Box_Position: [[1.32927036 0.62296882 0.59875994]]
Step:200, total reward:-2466.1750477064043, average reward:-12.330875238532021,----
Box_Position: [[1.35783203 0.76663245 0.63543896]]
Step:200, total reward:-2654.587540283544, average reward:-13.272937701417721,----
Box_Position: [[1.27003505 0.69859967 0.47618709]]
Step:200, total reward:-2674.9093076072827, average reward:-13.374546538036414,----
Box_Position: [[1.48938511 0.81925731 0.65056862]]
Step:200, total reward:-2642.653012937609, average reward:-13.213265064688047,----
Box_Position: [[1.4363552  1.11366597 0.56055585]]
Step:200, total reward:-3052.846686464092, average reward:-15.26423343232046,----
Box_Position: [[1.5419279 0.5454325 0.5067671]]
Step:200, total reward:-3015.7855850212795, average reward:-15.078927925106397,----
Box_Position: [[1.41182085 1.09291967 0.60844134]]
Step:200, total reward:-2965.9354884539234, average reward:-14.829677442269617,----
Box_Position: [[1.50913185 0.65971742 0.57803671]]
Step:200, total reward:-2885.230816032871, average reward:-14.426154080164356,----
Box_Position: [[1.42175802 0.84730109 0.74317264]]
Step:200, total reward:-2788.6579104094867, average reward:-13.943289552047434,----
Box_Position: [[1.40638388 0.80322489 0.69612803]]
Step:200, total reward:-2629.3069290402823, average reward:-13.146534645201411,----
Box_Position: [[1.33140472 0.79911035 0.67550056]]
Step:200, total reward:-2441.866370600975, average reward:-12.209331853004876,----
Box_Position: [[1.28968453 1.07413829 0.62474919]]
Step:200, total reward:-2922.911199752518, average reward:-14.61455599876259,----
Box_Position: [[1.4795029  0.62949508 0.48239609]]
Step:200, total reward:-3025.3151629433974, average reward:-15.126575814716986,----
Box_Position: [[1.25621729 0.81223301 0.53103322]]
Step:200, total reward:-2566.9438494712, average reward:-12.834719247355999,----
Box_Position: [[1.31130462 1.14269876 0.56574491]]
Step:200, total reward:-3196.986502906092, average reward:-15.98493251453046,----
Box_Position: [[1.28372216 0.6401799  0.63741105]]
Step:200, total reward:-2576.449294315616, average reward:-12.88224647157808,----
Box_Position: [[1.33818383 0.67305585 0.49898573]]
Step:200, total reward:-2742.2759023660096, average reward:-13.711379511830048,----
Box_Position: [[1.40819152 0.870324   0.50725441]]
Step:200, total reward:-2957.646221566558, average reward:-14.78823110783279,----
Box_Position: [[1.41353676 0.77811017 0.58310849]]
Step:6, total reward:-61.357287568875975, average reward:-10.226214594812662,success
Box_Position: [[1.26756902 0.55960656 0.70746867]]

------------------Episode:400------------------
Step:200, total reward:-2728.3791277265677, average reward:-13.641895638632839,----
episode 400, the accuracy is: 7%
Box_Position: [[1.46885144 0.68258051 0.63609554]]
Step:200, total reward:-2633.9186470873774, average reward:-13.169593235436887,----
Box_Position: [[1.53892623 0.95471174 0.72978241]]
Step:200, total reward:-2971.255895919742, average reward:-14.856279479598712,----
Box_Position: [[1.34660707 0.63129732 0.54672783]]
Step:200, total reward:-2812.1639288017386, average reward:-14.060819644008694,----
Box_Position: [[1.45858846 0.68407111 0.54298038]]
Step:200, total reward:-2873.3308688757625, average reward:-14.366654344378812,----
Box_Position: [[1.28730216 1.02218853 0.47499434]]
Step:200, total reward:-2875.4982546814517, average reward:-14.377491273407259,----
Box_Position: [[1.44389507 0.77513245 0.60402418]]
Step:200, total reward:-2639.4619027770473, average reward:-13.197309513885237,----
Box_Position: [[1.31490871 0.86082467 0.60476855]]
Step:200, total reward:-2749.7116532815694, average reward:-13.748558266407848,----
Box_Position: [[1.52232267 0.99092697 0.52101828]]
Step:200, total reward:-2993.8577524323928, average reward:-14.969288762161964,----
Box_Position: [[1.43351231 0.91555126 0.67411435]]
Step:200, total reward:-2663.31586261406, average reward:-13.3165793130703,----
Box_Position: [[1.3165096  1.01698917 0.54084795]]
Step:200, total reward:-2618.931191357001, average reward:-13.094655956785004,----
Box_Position: [[1.49905521 0.70710425 0.5561291 ]]
Step:200, total reward:-2652.6400512259215, average reward:-13.263200256129608,----
Box_Position: [[1.43546963 0.92043251 0.58820988]]
Step:200, total reward:-2641.357122327346, average reward:-13.20678561163673,----
Box_Position: [[1.54941381 0.74440342 0.49999637]]
Step:200, total reward:-3036.4163978953875, average reward:-15.182081989476938,----
Box_Position: [[1.2919799  0.79886895 0.51953462]]
Step:200, total reward:-2652.7389031355588, average reward:-13.263694515677793,----
Box_Position: [[1.35200056 0.89030944 0.50282574]]
Step:200, total reward:-2651.7585326956873, average reward:-13.258792663478436,----
Box_Position: [[1.51901056 1.12712379 0.50853992]]
Step:200, total reward:-3076.049233933918, average reward:-15.38024616966959,----
Box_Position: [[1.27625732 0.6250433  0.53975737]]
Step:200, total reward:-2747.3262582639954, average reward:-13.736631291319977,----
Box_Position: [[1.41763801 0.49957941 0.691927  ]]
Step:200, total reward:-2698.063957124477, average reward:-13.490319785622384,----
Box_Position: [[1.25577091 0.62788981 0.67247622]]
Step:200, total reward:-2431.1842683584096, average reward:-12.155921341792048,----
Box_Position: [[1.43120516 0.7275401  0.59955073]]
Step:200, total reward:-2723.480738849893, average reward:-13.617403694249465,----
Box_Position: [[1.35765568 0.71669869 0.73442028]]
Step:200, total reward:-2522.7119283201655, average reward:-12.613559641600828,----
Box_Position: [[1.50492781 0.80910636 0.64287603]]
Step:200, total reward:-2748.853220372719, average reward:-13.744266101863595,----
Box_Position: [[1.50197746 0.82456992 0.74234988]]
Step:200, total reward:-2764.7405497986656, average reward:-13.823702748993329,----
Box_Position: [[1.49798014 0.61758782 0.73784192]]
Step:200, total reward:-2725.9172061806457, average reward:-13.629586030903228,----
Box_Position: [[1.46177125 0.67964124 0.52929152]]
Step:200, total reward:-2738.65027055185, average reward:-13.693251352759251,----
Box_Position: [[1.49831294 0.61489101 0.50145345]]
Step:200, total reward:-2961.0699126933064, average reward:-14.805349563466532,----
Box_Position: [[1.39081553 0.71512584 0.73868344]]
Step:200, total reward:-2698.5743723801884, average reward:-13.492871861900943,----
Box_Position: [[1.26507393 0.51964771 0.69220886]]
Step:200, total reward:-2933.5004592825408, average reward:-14.667502296412703,----
Box_Position: [[1.37706758 0.85472118 0.68769394]]
Step:200, total reward:-2796.48485356866, average reward:-13.982424267843301,----
Box_Position: [[1.41720998 0.49946357 0.59671889]]
Step:200, total reward:-2960.321089748892, average reward:-14.80160544874446,----
Box_Position: [[1.34921904 0.8485406  0.70098495]]
Step:200, total reward:-2788.833400090332, average reward:-13.94416700045166,----
Box_Position: [[1.27903827 0.89043384 0.56872231]]
Step:200, total reward:-2628.4083326358914, average reward:-13.142041663179457,----
Box_Position: [[1.28501634 0.65885828 0.60447537]]
Step:200, total reward:-2559.326338365621, average reward:-12.796631691828104,----
Box_Position: [[1.25660252 0.61778705 0.47382671]]
Step:200, total reward:-2663.648790779049, average reward:-13.318243953895244,----
Box_Position: [[1.25427392 0.85101874 0.52193082]]
Step:200, total reward:-2755.2912809469126, average reward:-13.776456404734564,----
Box_Position: [[1.48358315 0.73067235 0.50396244]]
Step:200, total reward:-2807.547659589533, average reward:-14.037738297947664,----
Box_Position: [[1.30387716 0.68621117 0.52033458]]
Step:91, total reward:-1074.5962616016666, average reward:-11.80875012749084,success
Box_Position: [[1.48696734 0.77375469 0.58106151]]
Step:200, total reward:-2825.6120229587946, average reward:-14.128060114793973,----
Box_Position: [[1.25074785 1.12063747 0.62919896]]
Step:200, total reward:-2741.178415012917, average reward:-13.705892075064584,----
Box_Position: [[1.48594113 0.65001859 0.46068174]]
Step:200, total reward:-2872.988048900613, average reward:-14.364940244503066,----
Box_Position: [[1.42093698 1.02560123 0.70097461]]
Step:200, total reward:-2890.2819367995503, average reward:-14.45140968399775,----
Box_Position: [[1.42717884 0.77678825 0.70467557]]
Step:200, total reward:-2825.787258820963, average reward:-14.128936294104815,----
Box_Position: [[1.42021435 0.91055466 0.55614052]]
Step:200, total reward:-2674.129322978685, average reward:-13.370646614893426,----
Box_Position: [[1.28747284 1.03360292 0.46219879]]
Step:200, total reward:-2838.47221489673, average reward:-14.19236107448365,----
Box_Position: [[1.38837198 0.75111272 0.69099115]]
Step:200, total reward:-2568.5015363134166, average reward:-12.842507681567083,----
Box_Position: [[1.43028905 0.91818995 0.61879326]]
Step:200, total reward:-2784.483714487078, average reward:-13.92241857243539,----
Box_Position: [[1.41356873 1.14044213 0.52166254]]
Step:200, total reward:-3069.4377892490666, average reward:-15.347188946245332,----
Box_Position: [[1.44938967 0.73302274 0.61372068]]
Step:200, total reward:-2539.819877831329, average reward:-12.699099389156645,----
Box_Position: [[1.30398294 0.92300746 0.50565793]]
Step:200, total reward:-2928.84938942167, average reward:-14.64424694710835,----
Box_Position: [[1.44226709 0.96115296 0.47270762]]

------------------Episode:450------------------
Step:200, total reward:-2945.1455091682856, average reward:-14.725727545841428,----
Box_Position: [[1.49321042 0.56151492 0.68292263]]
Step:200, total reward:-2792.566549480152, average reward:-13.96283274740076,----
Box_Position: [[1.30219504 1.06270258 0.53462408]]
Step:200, total reward:-2716.9950177992496, average reward:-13.584975088996249,----
Box_Position: [[1.2953854  1.19206575 0.63448217]]
Step:200, total reward:-2900.704056492708, average reward:-14.503520282463539,----
Box_Position: [[1.32803456 1.08213928 0.64052657]]
Step:200, total reward:-2505.433206897535, average reward:-12.527166034487674,----
Box_Position: [[1.51293192 0.91069747 0.6002981 ]]
Step:200, total reward:-2903.0441845333626, average reward:-14.515220922666813,----
Box_Position: [[1.4964204  0.83535841 0.68499102]]
Step:200, total reward:-2997.4393470559403, average reward:-14.987196735279701,----
Box_Position: [[1.46313861 0.95815093 0.65887908]]
Step:200, total reward:-2761.98330691349, average reward:-13.809916534567451,----
Box_Position: [[1.46046846 0.44133702 0.54594406]]
Step:200, total reward:-3166.8632325551143, average reward:-15.834316162775572,----
Box_Position: [[1.5215237  0.64369809 0.45036529]]
Step:200, total reward:-2951.6264162578436, average reward:-14.758132081289219,----
Box_Position: [[1.29868635 0.56938532 0.67862192]]
Step:200, total reward:-2624.9472069834974, average reward:-13.124736034917486,----
Box_Position: [[1.39127416 0.87675391 0.55844398]]
Step:200, total reward:-2674.9008428898205, average reward:-13.374504214449102,----
Box_Position: [[1.27053889 0.86016334 0.61166237]]
Step:200, total reward:-2656.0030863389825, average reward:-13.280015431694913,----
Box_Position: [[1.43975855 0.96371839 0.55243799]]
Step:200, total reward:-2623.154489305153, average reward:-13.115772446525765,----
Box_Position: [[1.34844916 0.88454548 0.64821198]]
Step:200, total reward:-2621.8288109270675, average reward:-13.109144054635337,----
Box_Position: [[1.44340927 0.96847877 0.60348542]]
Step:200, total reward:-2813.7761691547057, average reward:-14.068880845773528,----
Box_Position: [[1.26500226 0.56342467 0.58275397]]
Step:200, total reward:-2591.926294697253, average reward:-12.959631473486265,----
Box_Position: [[1.50737541 0.99285082 0.47945666]]
Step:200, total reward:-3088.375641582867, average reward:-15.441878207914336,----
Box_Position: [[1.37901047 0.54674212 0.68578168]]
Step:200, total reward:-2655.6457079234115, average reward:-13.278228539617057,----
Box_Position: [[1.41055286 1.09378038 0.62407528]]
Step:200, total reward:-2810.100452861971, average reward:-14.050502264309856,----
Box_Position: [[1.547407   0.83989911 0.58181525]]
Step:200, total reward:-2911.8752764754477, average reward:-14.559376382377238,----
Box_Position: [[1.45388054 0.74705125 0.68021918]]
Step:200, total reward:-2871.6076510033668, average reward:-14.358038255016833,----
Box_Position: [[1.4867362  0.77333358 0.64309663]]
Step:200, total reward:-2730.175151419116, average reward:-13.65087575709558,----
Box_Position: [[1.49658277 0.62443741 0.72636915]]
Step:200, total reward:-2672.3390372384733, average reward:-13.361695186192367,----
Box_Position: [[1.4666942  0.69263623 0.66199075]]
Step:200, total reward:-2713.758204373607, average reward:-13.568791021868035,----
Box_Position: [[1.26817318 1.11751107 0.55761395]]
Step:200, total reward:-2816.2848939655482, average reward:-14.081424469827741,----
Box_Position: [[1.36745069 1.09974873 0.47582756]]
Step:200, total reward:-2807.8626039303444, average reward:-14.039313019651722,----
Box_Position: [[1.34473733 0.92917772 0.65569784]]
Step:200, total reward:-2866.784397486748, average reward:-14.333921987433738,----
Box_Position: [[1.39702251 0.68905013 0.54303979]]
Step:200, total reward:-2781.1358001492968, average reward:-13.905679000746483,----
Box_Position: [[1.36788321 1.04460407 0.53799626]]
Step:158, total reward:-2071.869909695383, average reward:-13.113100694274575,success
Box_Position: [[1.25959214 0.83954387 0.73290113]]
Step:200, total reward:-2634.262576875725, average reward:-13.171312884378624,----
Box_Position: [[1.40878666 0.65754194 0.59947798]]
Step:200, total reward:-2596.0426111867237, average reward:-12.980213055933618,----
Box_Position: [[1.52641008 0.86065389 0.72282475]]
Step:200, total reward:-2718.7712455446576, average reward:-13.593856227723288,----
Box_Position: [[1.37327128 0.74875471 0.7103023 ]]
Step:200, total reward:-2509.3585912675712, average reward:-12.546792956337857,----
Box_Position: [[1.40259863 1.10788691 0.55336655]]
Step:200, total reward:-2961.4334779151927, average reward:-14.807167389575964,----
Box_Position: [[1.46808605 0.82486123 0.72971106]]
Step:200, total reward:-2685.3913509552604, average reward:-13.426956754776302,----
Box_Position: [[1.5454476  0.77997414 0.62424577]]
Step:200, total reward:-2995.5579876071624, average reward:-14.977789938035812,----
Box_Position: [[1.30510277 0.64682851 0.71870772]]
Step:200, total reward:-2631.689448336135, average reward:-13.158447241680674,----
Box_Position: [[1.50117318 0.6566191  0.70171973]]
Step:200, total reward:-2707.357345062568, average reward:-13.53678672531284,----
Box_Position: [[1.3713695  0.67593953 0.53737501]]
Step:200, total reward:-2412.6133598990914, average reward:-12.063066799495457,----
Box_Position: [[1.38282706 0.79981397 0.45820696]]
Step:200, total reward:-2889.562417414204, average reward:-14.44781208707102,----
Box_Position: [[1.34049019 0.58273558 0.56827264]]
Step:200, total reward:-2692.01700235599, average reward:-13.460085011779949,----
Box_Position: [[1.47586683 0.60108585 0.67618817]]
Step:200, total reward:-2763.334469113276, average reward:-13.816672345566381,----
Box_Position: [[1.50260399 0.68321418 0.4935279 ]]
Step:200, total reward:-3039.249564952906, average reward:-15.19624782476453,----
Box_Position: [[1.4831548  0.69102241 0.64453662]]
Step:200, total reward:-2849.870230065388, average reward:-14.249351150326941,----
Box_Position: [[1.39866347 0.73267918 0.60594307]]
Step:200, total reward:-2749.4887385808547, average reward:-13.747443692904273,----
Box_Position: [[1.40082917 1.06924065 0.47364019]]
Step:200, total reward:-3007.9189512715884, average reward:-15.039594756357943,----
Box_Position: [[1.51467883 0.8262602  0.69472477]]
Step:200, total reward:-2613.4510832554283, average reward:-13.067255416277142,----
Box_Position: [[1.42508971 0.82927165 0.52358562]]
Step:200, total reward:-2786.126897772231, average reward:-13.930634488861156,----
Box_Position: [[1.52205449 0.97488377 0.70735935]]
Step:200, total reward:-2775.8351346759036, average reward:-13.879175673379518,----
Box_Position: [[1.39165525 0.46267405 0.67276412]]

------------------Episode:500------------------
Step:200, total reward:-2733.384671750393, average reward:-13.666923358751966,----
episode 500, the accuracy is: 2%
Box_Position: [[1.40423094 0.77877157 0.60376159]]
Step:200, total reward:-2800.6264625327153, average reward:-14.003132312663576,----
Box_Position: [[1.32634646 0.77149752 0.71659485]]
Step:121, total reward:-1531.9903881846417, average reward:-12.661077588302824,success
Box_Position: [[1.45014705 0.46473367 0.49708285]]
Step:200, total reward:-2840.1146416181905, average reward:-14.200573208090953,----
Box_Position: [[1.49994331 0.57521815 0.47960168]]
Step:200, total reward:-3016.441662685908, average reward:-15.08220831342954,----
Box_Position: [[1.2889601  1.12482057 0.56785755]]
Step:200, total reward:-2645.971114507949, average reward:-13.229855572539746,----
Box_Position: [[1.25041468 0.72262618 0.64780167]]
Step:200, total reward:-2531.3060350708697, average reward:-12.656530175354348,----
Box_Position: [[1.36225451 1.0082682  0.47217694]]
Step:200, total reward:-2797.251025279505, average reward:-13.986255126397525,----
Box_Position: [[1.47747323 0.66922159 0.50726686]]
Step:200, total reward:-2937.712419578178, average reward:-14.68856209789089,----
Box_Position: [[1.3053779  0.61790035 0.49282091]]
Step:200, total reward:-2700.237311569284, average reward:-13.50118655784642,----
Box_Position: [[1.50287029 1.08434352 0.48976257]]
Step:200, total reward:-2989.810156387923, average reward:-14.949050781939615,----
Box_Position: [[1.4318965  0.67156031 0.68364603]]
Step:200, total reward:-2710.976241161887, average reward:-13.554881205809435,----
Box_Position: [[1.25108527 0.63314189 0.73993304]]
Step:200, total reward:-2389.797440583341, average reward:-11.948987202916705,----
Box_Position: [[1.33389237 0.90789514 0.59256252]]
Step:200, total reward:-2713.6678202514536, average reward:-13.568339101257267,----
Box_Position: [[1.52048607 0.83177851 0.63919039]]
Step:200, total reward:-3070.045260111924, average reward:-15.350226300559621,----
Box_Position: [[1.39010083 0.76018496 0.68412973]]
Step:200, total reward:-2694.772954599434, average reward:-13.47386477299717,----
Box_Position: [[1.43144526 0.57513072 0.53778414]]
actor_loss: tensor(10.9722, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1952, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3737.1548089855746, average reward:-18.68577404492787,----
Box_Position: [[1.50162999 0.83006473 0.65697429]]
actor_loss: tensor(11.5380, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.3544, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.6330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.9973, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2634.747173419967, average reward:-13.173735867099836,----
Box_Position: [[1.51380765 1.00318735 0.60909525]]
actor_loss: tensor(9.3388, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0344, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.1989, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.5674, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2650.366003938731, average reward:-13.251830019693655,----
Box_Position: [[1.5203267  0.77726771 0.61091861]]
actor_loss: tensor(11.5103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.8734, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9186, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.0112, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2565.0947399033257, average reward:-12.825473699516628,----
Box_Position: [[1.50310523 0.66393557 0.69690128]]
actor_loss: tensor(12.6233, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3028, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.9942, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2499.069314832906, average reward:-12.49534657416453,----
Box_Position: [[1.46437162 0.55981916 0.63173628]]
actor_loss: tensor(13.1596, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.5052, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.5618, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.8415, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2404.865301896552, average reward:-12.02432650948276,----
Box_Position: [[1.44364354 0.86144208 0.49219164]]
actor_loss: tensor(14.8483, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.3858, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.4102, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.7333, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2552.155604135368, average reward:-12.76077802067684,----
Box_Position: [[1.30597234 1.06192656 0.5796034 ]]
actor_loss: tensor(16.2940, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-1041.7602793681924, average reward:-11.838184992820368,success
Box_Position: [[1.46030889 0.54883067 0.47254796]]
actor_loss: tensor(17.8430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.2704, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.6082, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2670, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-2297.4300937148987, average reward:-12.692983943176236,success
Box_Position: [[1.30386907 1.00187399 0.60933161]]
actor_loss: tensor(19.1368, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.0543, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.6082, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3549, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2305.5176020065387, average reward:-11.527588010032694,----
Box_Position: [[1.35131218 0.69514397 0.54482394]]
actor_loss: tensor(21.7668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.6218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.6226, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.3595, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2595.959847790452, average reward:-12.97979923895226,----
Box_Position: [[1.25136059 0.97638979 0.45954473]]
actor_loss: tensor(23.1713, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.1542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.8702, device='cuda:0', grad_fn=<NegBackward>)
Step:139, total reward:-1823.7342960543763, average reward:-13.120390619096232,success
Box_Position: [[1.53264173 0.61047013 0.47977192]]
actor_loss: tensor(23.5016, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.7050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.7958, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.0381, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2518.921472526638, average reward:-12.59460736263319,----
Box_Position: [[1.51132849 0.83702576 0.54982072]]
actor_loss: tensor(25.6703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.3901, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.2172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.6466, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2716.961545123348, average reward:-13.58480772561674,----
Box_Position: [[1.39148419 0.57203964 0.51477517]]
actor_loss: tensor(28.3294, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.4415, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.0727, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5162, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2552.101215310793, average reward:-12.760506076553966,----
Box_Position: [[1.34630027 0.56759251 0.51062661]]
actor_loss: tensor(28.5479, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.1609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.8650, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2275.6426727126686, average reward:-11.378213363563344,----
Box_Position: [[1.47790408 0.7240989  0.65204431]]
actor_loss: tensor(30.3008, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.0772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.7963, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.0573, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2427.9213527166103, average reward:-12.139606763583052,----
Box_Position: [[1.3780796  1.14584944 0.51674946]]
actor_loss: tensor(32.5260, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.8883, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.4888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.3469, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2480.3304875504605, average reward:-12.401652437752302,----
Box_Position: [[1.32695083 0.65197487 0.70457567]]
actor_loss: tensor(33.4027, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.2275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.1475, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.0597, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2227.9864706293997, average reward:-11.139932353146998,----
Box_Position: [[1.35823567 1.0827251  0.50075913]]
actor_loss: tensor(33.9482, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.6694, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.4696, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.6544, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2359.90893229252, average reward:-11.799544661462601,----
Box_Position: [[1.29028088 0.92301242 0.68690785]]
actor_loss: tensor(35.1939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.7080, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.3655, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-1557.8076659831818, average reward:-11.288461347704215,success
Box_Position: [[1.35223858 0.58833263 0.67788576]]
actor_loss: tensor(37.4852, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.2257, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.3689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.1287, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2240.735694563179, average reward:-11.203678472815895,----
Box_Position: [[1.41328776 0.84180887 0.65262064]]
actor_loss: tensor(37.5603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.1477, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.2691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.0136, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2347.6155623345253, average reward:-11.738077811672627,----
Box_Position: [[1.5164885  0.88576241 0.66322008]]
actor_loss: tensor(40.1485, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-1183.6656629682618, average reward:-12.329850655919394,success
Box_Position: [[1.47256099 0.81574073 0.49892978]]
actor_loss: tensor(40.7918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.6039, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.7868, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.8195, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2563.8110807315925, average reward:-12.819055403657963,----
Box_Position: [[1.25167303 0.87053219 0.56985715]]
actor_loss: tensor(42.5105, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.0529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.6359, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.8011, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2267.117497142987, average reward:-11.335587485714933,----
Box_Position: [[1.25475429 0.7854995  0.63016698]]
actor_loss: tensor(41.8854, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-568.2293690766064, average reward:-11.14175233483542,success
Box_Position: [[1.44736041 0.53795874 0.72010701]]
actor_loss: tensor(44.0838, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.0414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.5938, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.4099, device='cuda:0', grad_fn=<NegBackward>)
Step:164, total reward:-1915.1837019859079, average reward:-11.677949402353097,success
Box_Position: [[1.39339767 1.01815656 0.65922626]]
actor_loss: tensor(40.5481, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.6190, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.9602, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.5808, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2284.876222061738, average reward:-11.42438111030869,----
Box_Position: [[1.48451686 1.04698459 0.52134323]]
actor_loss: tensor(43.0840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.7988, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.8243, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.0401, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3041.206292110421, average reward:-15.206031460552106,----
Box_Position: [[1.48039409 0.74253986 0.57807954]]
actor_loss: tensor(46.8769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.5743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.9083, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.1458, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2389.6504120222066, average reward:-11.948252060111033,----
Box_Position: [[1.53015298 0.6629899  0.48014878]]
actor_loss: tensor(47.3294, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.5556, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.6376, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.9600, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2587.162288882726, average reward:-12.93581144441363,----
Box_Position: [[1.30603491 0.84113446 0.55329773]]
actor_loss: tensor(49.2470, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.0607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4037, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.9197, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2415.592695387904, average reward:-12.07796347693952,----
Box_Position: [[1.30448642 0.8240087  0.69390073]]
actor_loss: tensor(48.6569, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-851.1942636068508, average reward:-11.199924521142773,success
Box_Position: [[1.37693163 0.82575546 0.6235487 ]]

------------------Episode:550------------------
actor_loss: tensor(48.1305, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.3134, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.6454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.6864, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2420.0885909365834, average reward:-12.100442954682917,----
Box_Position: [[1.4093659  0.63570259 0.62499707]]
actor_loss: tensor(50.5468, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.9449, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.7464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.5090, device='cuda:0', grad_fn=<NegBackward>)
Step:189, total reward:-2124.5504183286316, average reward:-11.241007504384294,success
Box_Position: [[1.38403393 0.65142094 0.55121568]]
actor_loss: tensor(52.2027, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.9184, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.6097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.4408, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2340.902600923625, average reward:-11.704513004618125,----
Box_Position: [[1.54356149 0.66128435 0.53012017]]
actor_loss: tensor(51.8113, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.1419, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.9339, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.4638, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2467.83519613184, average reward:-12.3391759806592,----
Box_Position: [[1.38466021 0.59912298 0.51306564]]
actor_loss: tensor(54.7417, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.0140, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.9085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.0128, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2532.0016298320165, average reward:-12.660008149160083,----
Box_Position: [[1.48876066 0.76235492 0.4861616 ]]
actor_loss: tensor(54.3735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.0973, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.7365, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.5593, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2603.5033415314133, average reward:-13.017516707657066,----
Box_Position: [[1.51795958 0.91690474 0.520325  ]]
actor_loss: tensor(53.4188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.9672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.0238, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.2628, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2492.3827488390275, average reward:-12.461913744195137,----
Box_Position: [[1.37719396 0.99865758 0.52122145]]
actor_loss: tensor(56.1096, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.9474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.0214, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.4214, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2517.80808245454, average reward:-12.5890404122727,----
Box_Position: [[1.25937707 0.64239526 0.47407931]]
actor_loss: tensor(57.7882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.3843, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.9278, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.2983, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2286.019061460483, average reward:-11.430095307302416,----
Box_Position: [[1.48527099 0.60674177 0.56976776]]
actor_loss: tensor(57.0306, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.5010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.9228, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.0932, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2506.4625196431493, average reward:-12.532312598215746,----
Box_Position: [[1.36228462 1.00239694 0.70974898]]
actor_loss: tensor(56.6207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.9131, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.3256, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.1501, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2186.20432996623, average reward:-10.93102164983115,----
Box_Position: [[1.51633283 1.0083705  0.6333771 ]]
actor_loss: tensor(58.3799, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.0403, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.3198, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.1611, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2416.1345926387353, average reward:-12.080672963193676,----
Box_Position: [[1.29614673 1.0986055  0.55709695]]
actor_loss: tensor(58.7097, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-280.9946205916376, average reward:-9.689469675573712,success
Box_Position: [[1.52628797 0.66767381 0.47402418]]
actor_loss: tensor(61.2301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.4174, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.6187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.0773, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2520.5546390839595, average reward:-12.602773195419797,----
Box_Position: [[1.39845867 0.6347683  0.60142778]]
actor_loss: tensor(61.3658, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.5671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.4546, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.9504, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2230.054098828174, average reward:-11.150270494140871,----
Box_Position: [[1.38541181 0.82776393 0.50110485]]
actor_loss: tensor(61.0447, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-650.2752031827474, average reward:-11.612057199691918,success
Box_Position: [[1.35931387 0.93302257 0.65922581]]
actor_loss: tensor(61.6542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.8397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.4891, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.4358, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2274.1596905500815, average reward:-11.370798452750407,----
Box_Position: [[1.48977113 0.64883571 0.70800699]]
actor_loss: tensor(64.6075, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.4810, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.6860, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.5115, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2313.3728548404565, average reward:-11.566864274202283,----
Box_Position: [[1.25902831 0.93332902 0.72230782]]
actor_loss: tensor(64.6702, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-869.6474946994967, average reward:-10.736388823450577,success
Box_Position: [[1.54483912 0.80348672 0.58038046]]
actor_loss: tensor(63.5640, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.7901, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.5303, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.2157, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2952.630485046492, average reward:-14.76315242523246,----
Box_Position: [[1.36929685 1.11783296 0.49331003]]
actor_loss: tensor(65.6481, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.2207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.6409, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.4064, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2336.4578839228243, average reward:-11.682289419614122,----
Box_Position: [[1.5079004  0.78463288 0.63333863]]
actor_loss: tensor(66.5183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.1647, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.8713, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.5564, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2301.686500761159, average reward:-11.508432503805796,----
Box_Position: [[1.5030388  1.02754988 0.65879103]]
actor_loss: tensor(66.0260, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-669.7035325639765, average reward:-12.401917269703269,success
Box_Position: [[1.49539198 0.64846265 0.68545455]]
actor_loss: tensor(68.8100, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.2376, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.9128, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.1345, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2274.2034382393776, average reward:-11.371017191196888,----
Box_Position: [[1.2772453  1.01799087 0.69749793]]
actor_loss: tensor(66.5867, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.7682, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.3840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.5781, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1953.755066126142, average reward:-9.76877533063071,----
Box_Position: [[1.51047419 1.00976639 0.51302576]]
actor_loss: tensor(70.7297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.8765, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.8542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.1506, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2385.0134601769637, average reward:-11.925067300884818,----
Box_Position: [[1.47555186 0.98991623 0.66935003]]
actor_loss: tensor(67.3485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.1130, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.9612, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.7160, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2412.7246919491868, average reward:-12.063623459745934,----
Box_Position: [[1.48721822 1.16263743 0.60982268]]
actor_loss: tensor(68.7949, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.4582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.9502, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.9410, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2262.9783123567427, average reward:-11.314891561783714,----
Box_Position: [[1.39869966 0.78281721 0.58155894]]
actor_loss: tensor(67.6474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.5616, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-596.101494789858, average reward:-11.463490284420345,success
Box_Position: [[1.3137183  0.94295513 0.74388503]]
actor_loss: tensor(70.4478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.8046, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.5418, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.6723, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2054.172006548776, average reward:-10.270860032743881,----
Box_Position: [[1.39228409 0.48044464 0.54559548]]
actor_loss: tensor(69.0430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.1307, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.9573, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.6505, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2295.3653494419013, average reward:-11.476826747209508,----
Box_Position: [[1.32576761 0.78140837 0.70420125]]
actor_loss: tensor(69.1327, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.1663, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.4290, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.8521, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2127.9078023636976, average reward:-10.639539011818488,----
Box_Position: [[1.25475098 0.97239506 0.60818696]]
actor_loss: tensor(72.2448, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.1315, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.1828, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.4729, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2218.595444916655, average reward:-11.092977224583276,----
Box_Position: [[1.30571001 0.88083416 0.50868574]]
Step:47, total reward:-526.2341818924187, average reward:-11.196471955157845,success
Box_Position: [[1.2791997  0.58888828 0.63399977]]
actor_loss: tensor(71.5744, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.4794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.7130, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-1495.0582649018393, average reward:-10.310746654495443,success
Box_Position: [[1.4109727  0.96338812 0.5063314 ]]
actor_loss: tensor(72.2417, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.3509, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.8177, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.1236, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2361.726064739317, average reward:-11.808630323696583,----
Box_Position: [[1.32713255 0.58496283 0.61464513]]
actor_loss: tensor(71.7696, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.7245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.4232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.1565, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2039.8167222312184, average reward:-10.199083611156091,----
Box_Position: [[1.54788566 0.82986349 0.58124191]]
actor_loss: tensor(79.0668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.0006, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.1772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.7421, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2347.495273660837, average reward:-11.737476368304185,----
Box_Position: [[1.43990247 0.86788946 0.60291967]]
actor_loss: tensor(71.1951, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.3661, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-619.5250722217763, average reward:-10.325417870362939,success
Box_Position: [[1.34609529 0.64553915 0.45260718]]
actor_loss: tensor(74.0690, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.5484, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.8229, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.0776, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2208.4416617615484, average reward:-11.042208308807743,----
Box_Position: [[1.39347741 0.89783551 0.45783931]]
actor_loss: tensor(70.9202, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.6609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.9416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.5587, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2348.939892287737, average reward:-11.744699461438685,----
Box_Position: [[1.38337889 0.89858642 0.61079766]]
actor_loss: tensor(73.4857, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.5743, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-1404.9952288142217, average reward:-11.150755784239855,success
Box_Position: [[1.43113286 0.81102908 0.48380962]]
actor_loss: tensor(76.1319, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.1966, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.3274, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.5244, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2468.214479133774, average reward:-12.34107239566887,----
Box_Position: [[1.48971023 0.70682483 0.46357689]]
actor_loss: tensor(74.4095, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.1516, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.9346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.3826, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2341.56451087963, average reward:-11.707822554398149,----
Box_Position: [[1.47765667 0.69521992 0.74329677]]
actor_loss: tensor(78.2598, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.0661, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.6118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.2617, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2160.676927658743, average reward:-10.803384638293714,----
Box_Position: [[1.33345179 0.55042352 0.48328754]]
actor_loss: tensor(73.4525, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.1256, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.8218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.3931, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2139.9761177285936, average reward:-10.699880588642968,----
Box_Position: [[1.54748857 0.46591949 0.68558352]]
actor_loss: tensor(75.6518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.4198, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.4968, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.2511, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2296.424391975186, average reward:-11.482121959875931,----
Box_Position: [[1.33383228 0.62701823 0.51847492]]
actor_loss: tensor(78.4811, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-400.73712661495733, average reward:-10.27531093884506,success
Box_Position: [[1.47839801 0.7178324  0.49472073]]
actor_loss: tensor(75.6301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.5743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.4187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.5623, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-2136.636575624501, average reward:-11.245455661181584,success
Box_Position: [[1.52282102 0.72799175 0.72716336]]
actor_loss: tensor(76.7249, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-806.3746230573466, average reward:-10.472397702043462,success
Box_Position: [[1.39206356 0.78970978 0.67167989]]

------------------Episode:600------------------
actor_loss: tensor(78.1118, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-630.2642328684497, average reward:-9.847878638569526,success
episode 600, the accuracy is: 23%
Box_Position: [[1.46831782 0.7288653  0.56517102]]
actor_loss: tensor(75.2716, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.0125, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.1840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.7198, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2323.6504668461835, average reward:-11.618252334230917,----
Box_Position: [[1.48151277 0.87943856 0.7049131 ]]
actor_loss: tensor(79.1513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.7687, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.1105, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.6460, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-1969.6945228217096, average reward:-11.451712341986683,success
Box_Position: [[1.51826369 0.89128853 0.61858156]]
actor_loss: tensor(76.9967, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.1662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.3826, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.9147, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2359.226525698117, average reward:-11.796132628490584,----
Box_Position: [[1.43076083 1.04430233 0.64270217]]
actor_loss: tensor(76.4210, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.5406, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.2966, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.6178, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2182.00150305451, average reward:-10.91000751527255,----
Box_Position: [[1.43939222 0.84646356 0.65575017]]
actor_loss: tensor(75.2559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.3301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.7732, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.2644, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2466.0719730267456, average reward:-12.330359865133728,----
Box_Position: [[1.38371159 0.67718045 0.70507776]]
actor_loss: tensor(77.2553, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.2050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.8820, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.9988, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2067.2557912384646, average reward:-10.336278956192324,----
Box_Position: [[1.4351018  0.90239723 0.5400414 ]]
actor_loss: tensor(81.1761, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.2948, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.9773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8467, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2249.884970864063, average reward:-11.249424854320313,----
Box_Position: [[1.40291153 0.79139511 0.58394651]]
actor_loss: tensor(76.1349, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.1397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.1607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.4001, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2303.4895793028663, average reward:-11.517447896514332,----
Box_Position: [[1.39281864 0.56554133 0.70702545]]
actor_loss: tensor(76.1577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.2508, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.4988, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-1718.082179511554, average reward:-11.378027678884463,success
Box_Position: [[1.2855071  0.77577022 0.5562094 ]]
actor_loss: tensor(78.1709, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-710.656820882164, average reward:-10.299374215683535,success
Box_Position: [[1.47388457 0.73266636 0.51944629]]
actor_loss: tensor(76.2489, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-273.2815549686904, average reward:-12.4218888622132,success
Box_Position: [[1.31494142 0.76401137 0.51838437]]
Step:27, total reward:-269.97777576363245, average reward:-9.999176880134534,success
Box_Position: [[1.53096429 1.05370289 0.71873444]]
actor_loss: tensor(81.2670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.1243, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8913, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-1196.3899792721704, average reward:-10.682053386358664,success
Box_Position: [[1.46374197 0.69679701 0.46273365]]
actor_loss: tensor(77.9331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.7495, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.6070, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.1493, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2321.0927375101664, average reward:-11.605463687550833,----
Box_Position: [[1.40569681 0.46610216 0.59367498]]
actor_loss: tensor(78.4637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.4528, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.6541, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.1750, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2166.344497787606, average reward:-10.83172248893803,----
Box_Position: [[1.43317041 0.76251751 0.50188809]]
actor_loss: tensor(80.1644, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-749.9173864703754, average reward:-11.537190561082697,success
Box_Position: [[1.40029711 1.00271537 0.49650249]]
Step:19, total reward:-275.5129510517182, average reward:-14.500681634300957,success
Box_Position: [[1.47539505 0.67545608 0.70739034]]
actor_loss: tensor(81.0479, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.1050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.8707, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2136.8957173459853, average reward:-10.684478586729927,----
Box_Position: [[1.43761577 0.62958813 0.49636251]]
actor_loss: tensor(80.0849, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.3374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.3390, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.1619, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2180.729272198751, average reward:-10.903646360993754,----
Box_Position: [[1.32112776 0.87504098 0.56124674]]
actor_loss: tensor(78.6697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.1369, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.3154, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2202.8860561611687, average reward:-11.014430280805843,----
Box_Position: [[1.34592817 1.14576469 0.69222366]]
actor_loss: tensor(78.9329, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.1547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.0846, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.3915, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2174.734918891741, average reward:-10.873674594458706,----
Box_Position: [[1.44789664 0.63267355 0.74580418]]
actor_loss: tensor(78.7662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8493, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.3406, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.0230, device='cuda:0', grad_fn=<NegBackward>)
Step:187, total reward:-1950.3408782217161, average reward:-10.429630364822012,success
Box_Position: [[1.41214155 0.7623594  0.64010396]]
actor_loss: tensor(79.5907, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.3750, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.2803, device='cuda:0', grad_fn=<NegBackward>)
Step:170, total reward:-1790.5781857789766, average reward:-10.532812857523393,success
Box_Position: [[1.49408731 0.58530762 0.66391704]]
actor_loss: tensor(79.2607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.3887, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.8775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.5396, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2170.5640914581923, average reward:-10.852820457290962,----
Box_Position: [[1.38559694 0.69752232 0.46496252]]
actor_loss: tensor(81.2064, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.6266, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-1074.0243284536743, average reward:-12.345107223605453,success
Box_Position: [[1.48619784 0.87134687 0.46634497]]
actor_loss: tensor(79.6331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.8023, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.4397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.0710, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2280.556971250313, average reward:-11.402784856251564,----
Box_Position: [[1.42893206 0.79843165 0.61725965]]
actor_loss: tensor(79.8166, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.8235, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(84.8100, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.8999, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2157.528666957281, average reward:-10.787643334786406,----
Box_Position: [[1.32936693 1.0525085  0.53181161]]
actor_loss: tensor(80.8699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.5656, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-715.4514842533893, average reward:-9.800705263745058,success
Box_Position: [[1.34475898 0.81238968 0.65577854]]
actor_loss: tensor(82.9481, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.0985, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.8106, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.8997, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2167.179910584573, average reward:-10.835899552922864,----
Box_Position: [[1.37250641 0.95444324 0.55445784]]
actor_loss: tensor(79.4699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.7459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.8177, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.0117, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2240.258313006231, average reward:-11.201291565031156,----
Box_Position: [[1.42204377 0.81575602 0.46130081]]
actor_loss: tensor(81.0589, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.0790, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-1155.6768176388082, average reward:-11.556768176388083,success
Box_Position: [[1.25706211 0.84115882 0.68863676]]
actor_loss: tensor(81.8898, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-708.2083592109944, average reward:-11.065755612671788,success
Box_Position: [[1.3049365  0.73680333 0.45676805]]
actor_loss: tensor(80.3866, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.6957, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.3775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8654, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2166.5966517550514, average reward:-10.832983258775258,----
Box_Position: [[1.44057609 0.86838953 0.6738235 ]]
actor_loss: tensor(80.2428, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.5881, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.5902, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.4751, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2208.815545059835, average reward:-11.044077725299175,----
Box_Position: [[1.41274693 0.97018112 0.73536422]]
actor_loss: tensor(83.5648, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-603.7055626267453, average reward:-13.415679169483228,success
Box_Position: [[1.41708264 0.80432304 0.52325703]]
actor_loss: tensor(82.6362, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.6317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.2234, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.0984, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2226.039916299559, average reward:-11.130199581497795,----
Box_Position: [[1.49553129 0.68923477 0.52871528]]
actor_loss: tensor(81.5172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.1787, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.6506, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.6206, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2220.767546548045, average reward:-11.103837732740226,----
Box_Position: [[1.53155246 0.57261774 0.62113824]]
actor_loss: tensor(77.4908, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.9823, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(83.2188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.5681, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2360.941098896276, average reward:-11.804705494481379,----
Box_Position: [[1.52160171 0.66328077 0.60752983]]
actor_loss: tensor(79.6748, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(84.3104, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.3871, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.5492, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2123.0037599875022, average reward:-10.615018799937511,----
Box_Position: [[1.2594379  0.51737634 0.62905493]]
Step:35, total reward:-325.3514692519346, average reward:-9.295756264340989,success
Box_Position: [[1.49380422 0.66938874 0.6313698 ]]
actor_loss: tensor(79.5621, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.0031, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.3871, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.3183, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2156.0266579629774, average reward:-10.780133289814888,----
Box_Position: [[1.54337112 0.88553787 0.47316739]]
actor_loss: tensor(81.0577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(84.3567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(83.6348, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.7428, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2258.821684614796, average reward:-11.29410842307398,----
Box_Position: [[1.31158424 0.9104215  0.60162843]]
actor_loss: tensor(80.0915, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.2169, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.7678, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.6092, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-1808.739441606104, average reward:-10.515926986082,success
Box_Position: [[1.49548671 0.9061601  0.51598343]]
actor_loss: tensor(81.5969, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.9972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.2558, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.7234, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2355.8624044851877, average reward:-11.779312022425938,----
Box_Position: [[1.41335821 0.93844581 0.59581616]]
actor_loss: tensor(80.4445, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(85.1593, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-1314.9422076354851, average reward:-10.193350446786706,success
Box_Position: [[1.29681351 0.76973943 0.50050559]]
actor_loss: tensor(79.2249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.1449, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.2118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.5303, device='cuda:0', grad_fn=<NegBackward>)
Step:197, total reward:-2224.0549219754344, average reward:-11.289618893276316,success
Box_Position: [[1.31355991 0.86596931 0.59573995]]
actor_loss: tensor(79.3062, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.6457, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.6069, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-2175.522010281331, average reward:-16.607038246422373,success
Box_Position: [[1.39466312 1.0881988  0.48213095]]
actor_loss: tensor(79.9591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.8070, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.3221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.7632, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2240.3659809321343, average reward:-11.201829904660672,----
Box_Position: [[1.41835028 0.74226407 0.72130852]]
Step:11, total reward:-105.84612886387377, average reward:-9.622375351261253,success
Box_Position: [[1.33440367 0.81215551 0.72645659]]

------------------Episode:650------------------
actor_loss: tensor(81.9625, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.2374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.9596, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.3748, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2112.2005925087765, average reward:-10.561002962543883,----
Box_Position: [[1.5217389  0.77811193 0.7312937 ]]
actor_loss: tensor(80.8814, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.8259, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.3639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.4270, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3115.6241089872574, average reward:-15.578120544936287,----
Box_Position: [[1.2644626  0.79140969 0.6966503 ]]
Step:4, total reward:-45.86098621634122, average reward:-11.465246554085304,success
Box_Position: [[1.53986217 0.70248581 0.58882718]]
actor_loss: tensor(80.9291, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.9556, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.9381, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.0686, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-2100.0570319218136, average reward:-10.769523240624686,success
Box_Position: [[1.27769293 0.78518394 0.68051132]]
actor_loss: tensor(80.0844, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-453.64765465303714, average reward:-9.86190553593559,success
Box_Position: [[1.29173671 0.84966132 0.47490614]]
actor_loss: tensor(81.4410, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-620.5116128803802, average reward:-11.080564515721075,success
Box_Position: [[1.36165599 0.89147995 0.71197523]]
actor_loss: tensor(80.7792, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(83.5752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(84.2097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(82.4316, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2057.1219956271807, average reward:-10.285609978135904,----
Box_Position: [[1.30255654 0.95164601 0.66466162]]
actor_loss: tensor(80.8065, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.4965, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-1058.0099248558467, average reward:-10.27194101801793,success
Box_Position: [[1.46063975 0.79019543 0.70890564]]
actor_loss: tensor(81.4711, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-536.5058834093583, average reward:-10.949099661415474,success
Box_Position: [[1.47305661 0.92117984 0.59331258]]
actor_loss: tensor(82.0825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.4211, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.7555, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.7488, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2324.2632068442485, average reward:-11.621316034221243,----
Box_Position: [[1.49973105 0.59501538 0.54401634]]
actor_loss: tensor(77.3934, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.3365, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(81.7654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.2316, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2304.883970968877, average reward:-11.524419854844384,----
Box_Position: [[1.51438448 1.13052148 0.68588063]]
actor_loss: tensor(78.7044, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.7065, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.8535, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.7514, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2082.5062936831823, average reward:-10.412531468415912,----
Box_Position: [[1.36493671 0.85202403 0.74249691]]
actor_loss: tensor(77.4811, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-585.3754407835332, average reward:-13.613382343803098,success
Box_Position: [[1.3334891  0.57930733 0.68839481]]
actor_loss: tensor(80.4216, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.1957, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.9391, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.4607, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2004.0533956657307, average reward:-10.020266978328653,----
Box_Position: [[1.34434577 0.70138873 0.53520587]]
actor_loss: tensor(80.1985, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.3439, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-752.2884791965765, average reward:-11.06306587053789,success
Box_Position: [[1.51402965 0.97131096 0.66557018]]
actor_loss: tensor(76.9069, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.8929, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(79.2973, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.1599, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2065.194611692313, average reward:-10.325973058461566,----
Box_Position: [[1.25530283 0.67449474 0.73528423]]
actor_loss: tensor(78.1687, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.9988, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.2328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(80.6412, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2041.1633512916628, average reward:-10.205816756458313,----
Box_Position: [[1.48113262 0.89010458 0.65515567]]
actor_loss: tensor(78.5012, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.1824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.7273, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.6026, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2091.815144278166, average reward:-10.45907572139083,----
Box_Position: [[1.30687128 0.7656872  0.72001372]]
actor_loss: tensor(78.7360, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.3741, device='cuda:0', grad_fn=<NegBackward>)
Step:132, total reward:-1391.993223656604, average reward:-10.545403209519726,success
Box_Position: [[1.47307891 0.70615661 0.71945222]]
actor_loss: tensor(76.4110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.3748, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.2174, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.8466, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1960.161832242435, average reward:-9.800809161212175,----
Box_Position: [[1.30867461 0.41422234 0.60397838]]
actor_loss: tensor(76.8827, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-211.73258357713866, average reward:-9.624208344415393,success
Box_Position: [[1.40464645 0.93675478 0.6341107 ]]
actor_loss: tensor(75.5341, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.1940, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.3744, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.9165, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2062.253554990189, average reward:-10.311267774950945,----
Box_Position: [[1.43429719 0.92804541 0.51426273]]
actor_loss: tensor(77.7849, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.5870, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.0633, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.3819, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2865.3330281356984, average reward:-14.326665140678493,----
Box_Position: [[1.42518285 0.56364936 0.73381131]]
actor_loss: tensor(73.5020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.6902, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-998.7180486597161, average reward:-9.888297511482339,success
Box_Position: [[1.39586453 0.86139793 0.49812613]]
actor_loss: tensor(74.5486, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.9743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.8569, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.4371, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2111.9922301236697, average reward:-10.55996115061835,----
Box_Position: [[1.38086712 0.82045552 0.5159001 ]]
actor_loss: tensor(77.5824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.1819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.6838, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(76.5803, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2301.6123751011155, average reward:-11.508061875505577,----
Box_Position: [[1.54957891 0.84503587 0.45865266]]
actor_loss: tensor(75.4431, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.7441, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.5158, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.5890, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2695.817095378457, average reward:-13.479085476892285,----
Box_Position: [[1.28594338 0.78822198 0.66281488]]
Step:38, total reward:-385.67400246014876, average reward:-10.149315854214441,success
Box_Position: [[1.43464899 0.73661791 0.46908498]]
actor_loss: tensor(76.1382, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.5666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.9941, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.1114, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-2008.74655541683, average reward:-10.799712663531345,success
Box_Position: [[1.3560183  0.83937026 0.51170332]]
actor_loss: tensor(73.5668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.7332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(77.8368, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.0224, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3106.09182206731, average reward:-15.530459110336551,----
Box_Position: [[1.25493859 0.65217985 0.6559499 ]]
actor_loss: tensor(73.9249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.3751, device='cuda:0', grad_fn=<NegBackward>)
Step:93, total reward:-1055.6406922862343, average reward:-11.350975185873487,success
Box_Position: [[1.34886423 0.59570264 0.65157036]]
actor_loss: tensor(73.1794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.4485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(78.1481, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.9176, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2101.302572575143, average reward:-10.506512862875717,----
Box_Position: [[1.30707713 1.06496652 0.54816353]]
actor_loss: tensor(72.8330, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-795.6178753318097, average reward:-12.054816292906208,success
Box_Position: [[1.53925125 0.94024018 0.6059146 ]]
actor_loss: tensor(71.6381, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.4965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.8976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.2199, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2394.945645650271, average reward:-11.974728228251356,----
Box_Position: [[1.54867217 0.73817748 0.477395  ]]
actor_loss: tensor(73.5095, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.3273, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.6889, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(75.2306, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2552.0705683643127, average reward:-12.760352841821565,----
Box_Position: [[1.45352794 0.6535269  0.68620358]]
actor_loss: tensor(71.6505, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.3932, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.2145, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.1770, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-2278.3502049452795, average reward:-11.86640731742333,success
Box_Position: [[1.48041523 0.98906924 0.49863965]]
actor_loss: tensor(72.6939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.0278, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.8415, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.1723, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2694.0077253135973, average reward:-13.470038626567987,----
Box_Position: [[1.33350373 1.0086847  0.59302227]]
actor_loss: tensor(72.4140, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.4794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.5435, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(74.7455, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2519.382146296072, average reward:-12.596910731480358,----
Box_Position: [[1.26014203 0.69543535 0.5483676 ]]
actor_loss: tensor(72.8487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.3513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.4349, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.1140, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2370.6075257532807, average reward:-11.853037628766403,----
Box_Position: [[1.39192565 0.60708898 0.65732753]]
actor_loss: tensor(71.3448, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.3577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.0994, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.3730, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2222.842331932841, average reward:-11.114211659664203,----
Box_Position: [[1.3701632  0.58219335 0.69392222]]
actor_loss: tensor(70.2884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.0544, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.1871, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(73.1856, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2050.5772762722313, average reward:-10.252886381361156,----
Box_Position: [[1.38713021 0.75537089 0.7459604 ]]
actor_loss: tensor(71.1021, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.1461, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.8096, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.2823, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2198.310690054772, average reward:-10.991553450273859,----
Box_Position: [[1.45362724 0.83864884 0.55370621]]
actor_loss: tensor(67.5183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.7430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(72.2447, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.9300, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2376.0169048934717, average reward:-11.880084524467359,----
Box_Position: [[1.27178279 0.51582928 0.63177451]]
actor_loss: tensor(70.6006, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.5001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.8816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.9879, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2297.4086412360853, average reward:-11.487043206180426,----
Box_Position: [[1.53215216 0.6849002  0.66984983]]
actor_loss: tensor(71.2086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(71.0718, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.6038, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.4130, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2352.2823200925145, average reward:-11.761411600462573,----
Box_Position: [[1.54518748 0.7023647  0.53172063]]
actor_loss: tensor(71.6206, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.1851, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.6139, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.7322, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2468.841985377761, average reward:-12.344209926888805,----
Box_Position: [[1.54512485 0.94718531 0.48696693]]
actor_loss: tensor(68.5950, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.6023, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.3383, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.6221, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2438.7231777730676, average reward:-12.193615888865338,----
Box_Position: [[1.39527779 0.73985463 0.71392945]]
actor_loss: tensor(70.8860, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.0156, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.8657, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.4342, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2244.871153471055, average reward:-11.224355767355275,----
Box_Position: [[1.47415783 0.78693855 0.60787976]]
actor_loss: tensor(68.2275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.5972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.6669, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.6479, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2536.5245325830338, average reward:-12.682622662915168,----
Box_Position: [[1.29957192 0.82303372 0.57589227]]
actor_loss: tensor(69.1969, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.3863, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.4223, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.6357, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2337.014536527922, average reward:-11.685072682639609,----
Box_Position: [[1.3790152  0.78322255 0.62600386]]

------------------Episode:700------------------
actor_loss: tensor(70.3191, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.0072, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.7568, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.5856, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2326.568969400959, average reward:-11.632844847004794,----
episode 700, the accuracy is: 37%
Box_Position: [[1.28097285 0.8449351  0.48279385]]
actor_loss: tensor(67.9710, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.3079, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.8636, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(70.0193, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2339.2093680976313, average reward:-11.696046840488156,----
Box_Position: [[1.54567997 0.86204552 0.72481042]]
actor_loss: tensor(66.3890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.4720, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.6452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(68.2809, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2499.5898867503133, average reward:-12.497949433751566,----
Box_Position: [[1.37711862 0.96997347 0.61479757]]
actor_loss: tensor(65.9562, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.8741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.7991, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.2522, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2272.0338983558568, average reward:-11.360169491779283,----
Box_Position: [[1.48514872 0.70997036 0.46918538]]
actor_loss: tensor(67.2900, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.3551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.1669, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.1566, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2936.679319195278, average reward:-14.68339659597639,----
Box_Position: [[1.54161845 0.71051694 0.49665673]]
actor_loss: tensor(66.1234, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.8996, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.3879, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(69.8004, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2722.634424414142, average reward:-13.61317212207071,----
Box_Position: [[1.35783325 0.95119011 0.56352144]]
actor_loss: tensor(67.9351, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.0697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.3507, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.4806, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2152.445568194283, average reward:-10.762227840971416,----
Box_Position: [[1.26851832 0.76021029 0.7037041 ]]
Step:1, total reward:-3.5070835906239766, average reward:-3.5070835906239766,success
Box_Position: [[1.50296939 0.71972247 0.62362685]]
actor_loss: tensor(65.5948, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.5287, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.5048, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.3650, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2358.2064041335075, average reward:-11.791032020667537,----
Box_Position: [[1.4015914  0.68591183 0.71164085]]
actor_loss: tensor(64.7533, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.3816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.7199, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.1969, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2651.991885376041, average reward:-13.259959426880204,----
Box_Position: [[1.48992117 0.47512076 0.6025121 ]]
actor_loss: tensor(66.9334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.7050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.3318, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.4530, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2039.5547397443233, average reward:-10.197773698721617,----
Box_Position: [[1.3886497  0.64555584 0.57535341]]
actor_loss: tensor(67.3012, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.4341, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.5060, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.8517, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2203.1196011382094, average reward:-11.015598005691047,----
Box_Position: [[1.4500298  0.83011421 0.5856604 ]]
actor_loss: tensor(67.0635, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.1434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.1473, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.7129, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2484.7155395828336, average reward:-12.423577697914167,----
Box_Position: [[1.27026137 0.70022056 0.60527753]]
actor_loss: tensor(65.6976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.7147, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.6610, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.7704, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2857.0999193754233, average reward:-14.285499596877116,----
Box_Position: [[1.4452992  0.63103907 0.45399256]]
actor_loss: tensor(65.0939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(67.0896, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.1430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.1491, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2736.897773950963, average reward:-13.684488869754814,----
Box_Position: [[1.5332541  1.12764418 0.74460796]]
actor_loss: tensor(65.7743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.6679, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.3986, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.0661, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2089.3849230694495, average reward:-10.446924615347248,----
Box_Position: [[1.39646023 1.00541161 0.74957224]]
actor_loss: tensor(65.6276, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-742.6461660471896, average reward:-13.502657564494356,success
Box_Position: [[1.52261084 0.70568127 0.67994763]]
actor_loss: tensor(67.2057, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.8830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.4324, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.1794, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2048.7283427834504, average reward:-10.243641713917253,----
Box_Position: [[1.45846416 0.72502283 0.73993828]]
actor_loss: tensor(67.1080, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.2205, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-1068.5812485643107, average reward:-10.274819697733758,success
Box_Position: [[1.28794458 0.69227252 0.50802793]]
actor_loss: tensor(67.7346, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.9032, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-951.3635385545817, average reward:-10.570705983939797,success
Box_Position: [[1.31186267 0.95285775 0.72091549]]
actor_loss: tensor(65.2379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.0857, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.1371, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.5418, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2193.256656458708, average reward:-10.96628328229354,----
Box_Position: [[1.48087717 0.54838347 0.69002607]]
actor_loss: tensor(64.2383, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-337.05745632032085, average reward:-9.913454597656497,success
Box_Position: [[1.50530959 0.81500816 0.54443308]]
actor_loss: tensor(63.8185, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-759.1104408538835, average reward:-11.678622166982823,success
Box_Position: [[1.33655887 0.69433839 0.46886812]]
actor_loss: tensor(63.7538, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.2084, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-842.1569882090014, average reward:-11.228759842786685,success
Box_Position: [[1.31393742 0.89973104 0.5888969 ]]
actor_loss: tensor(62.6760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.7232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.6018, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-1556.4249403753197, average reward:-10.307449936260396,success
Box_Position: [[1.46795661 0.88738425 0.46342172]]
actor_loss: tensor(64.0367, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.5034, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.1151, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.4704, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2288.7248181479786, average reward:-11.443624090739894,----
Box_Position: [[1.25749574 1.13420517 0.57529643]]
actor_loss: tensor(64.3479, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.6445, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.0122, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.2895, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1892.5503303889313, average reward:-9.462751651944657,----
Box_Position: [[1.41284329 0.83029559 0.47424885]]
actor_loss: tensor(64.3476, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.2898, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.2794, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.2543, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2335.6834421928593, average reward:-11.678417210964296,----
Box_Position: [[1.31626918 1.05848835 0.59079286]]
actor_loss: tensor(65.2591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.2644, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-1406.046609754216, average reward:-10.492885147419523,success
Box_Position: [[1.52264036 0.74600974 0.52855813]]
actor_loss: tensor(64.2735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.6047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.7640, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.6055, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2140.1420138842295, average reward:-10.700710069421147,----
Box_Position: [[1.52815368 0.66327576 0.74720436]]
actor_loss: tensor(65.6665, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-505.09788336639843, average reward:-9.7134208339692,success
Box_Position: [[1.32495661 0.78238603 0.51072316]]
actor_loss: tensor(64.9217, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.4074, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.5034, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.0523, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2165.037885025421, average reward:-10.825189425127105,----
Box_Position: [[1.48609403 0.98969751 0.54963349]]
actor_loss: tensor(65.6971, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.0888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.4952, device='cuda:0', grad_fn=<NegBackward>)
Step:152, total reward:-1687.9343330517288, average reward:-11.104831138498216,success
Box_Position: [[1.263605   0.7339196  0.51879722]]
actor_loss: tensor(65.5619, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.1819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.8508, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.2219, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2208.1735844497903, average reward:-11.040867922248951,----
Box_Position: [[1.27240043 0.65314011 0.4949963 ]]
actor_loss: tensor(64.8876, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-419.7761984357063, average reward:-11.046742064097534,success
Box_Position: [[1.35151028 0.55089506 0.7004822 ]]
actor_loss: tensor(62.9014, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-706.4943650935148, average reward:-12.180937329198532,success
Box_Position: [[1.28317497 0.67052526 0.63722997]]
actor_loss: tensor(65.7438, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.8063, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-1141.9379968229841, average reward:-10.381254516572582,success
Box_Position: [[1.32355629 0.68662966 0.68668619]]
actor_loss: tensor(66.2935, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.1387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.1028, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-1050.3730832120866, average reward:-9.054940372517988,success
Box_Position: [[1.44709643 0.68382093 0.65570354]]
actor_loss: tensor(61.6220, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.5869, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.9287, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-1615.1459101523594, average reward:-10.22244246931873,success
Box_Position: [[1.36379821 0.73297587 0.63200889]]
actor_loss: tensor(63.5700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.3007, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.4996, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.2547, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2017.4057160139027, average reward:-10.087028580069514,----
Box_Position: [[1.38421642 0.81410649 0.53678177]]
actor_loss: tensor(62.4136, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.9908, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.0640, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.0045, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1994.7351050606237, average reward:-9.973675525303118,----
Box_Position: [[1.32100757 1.04565557 0.64380367]]
actor_loss: tensor(61.5247, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.8110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.9540, device='cuda:0', grad_fn=<NegBackward>)
Step:141, total reward:-1524.8717093661026, average reward:-10.814692974227677,success
Box_Position: [[1.31543366 0.84766535 0.54378621]]
actor_loss: tensor(63.7474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.5837, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(66.1001, device='cuda:0', grad_fn=<NegBackward>)
Step:176, total reward:-2034.8771925289789, average reward:-11.561802230278289,success
Box_Position: [[1.52606726 0.82566243 0.61871689]]
actor_loss: tensor(63.7157, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-304.09025974413805, average reward:-10.136341991471268,success
Box_Position: [[1.50503023 0.69267457 0.68267516]]
actor_loss: tensor(63.9935, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.6908, device='cuda:0', grad_fn=<NegBackward>)
Step:102, total reward:-1089.174013685735, average reward:-10.678176604762108,success
Box_Position: [[1.45165225 0.68223138 0.59461893]]
actor_loss: tensor(66.3928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.3936, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(64.3308, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.2365, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2203.7671601587435, average reward:-11.018835800793717,----
Box_Position: [[1.54190851 0.70371398 0.49632085]]
actor_loss: tensor(63.6115, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(65.1140, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.4505, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.7064, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2136.273926886505, average reward:-10.681369634432524,----
Box_Position: [[1.30032929 1.04072965 0.49616662]]
Step:23, total reward:-273.8209271796094, average reward:-11.905257703461277,success
Box_Position: [[1.25493084 0.5680642  0.55442663]]
actor_loss: tensor(60.8359, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.8883, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.8775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.5680, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2144.0746276032014, average reward:-10.720373138016008,----
Box_Position: [[1.39809701 0.89457057 0.56049161]]
actor_loss: tensor(63.1102, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.4932, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.9426, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.5978, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2322.012220642144, average reward:-11.610061103210718,----
Box_Position: [[1.44352003 0.49623907 0.73232171]]

------------------Episode:750------------------
actor_loss: tensor(63.4921, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.6872, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.8588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.1214, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2001.0588179399256, average reward:-10.005294089699628,----
Box_Position: [[1.49041098 0.64439839 0.74194326]]
actor_loss: tensor(62.4223, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-197.9730904117571, average reward:-9.427290019607481,success
Box_Position: [[1.38704364 0.53619098 0.72749395]]
actor_loss: tensor(60.9725, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.6692, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.3613, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.7265, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2015.3330571360166, average reward:-10.076665285680082,----
Box_Position: [[1.4128781  0.56784708 0.71414243]]
actor_loss: tensor(61.1482, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-797.9589095584181, average reward:-10.783228507546191,success
Box_Position: [[1.30920481 0.85845713 0.63316489]]
actor_loss: tensor(61.8927, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-238.32378790377587, average reward:-10.361903821903299,success
Box_Position: [[1.50979445 0.53970669 0.49260414]]
actor_loss: tensor(62.7825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.4678, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.0060, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.0249, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2258.0722994759294, average reward:-11.290361497379648,----
Box_Position: [[1.46294916 0.75915789 0.65467224]]
actor_loss: tensor(60.7092, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.9897, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.0406, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.6336, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2013.6957425413789, average reward:-10.068478712706895,----
Box_Position: [[1.5127531 0.9665876 0.5932581]]
Step:29, total reward:-301.51180868852737, average reward:-10.396958920294047,success
Box_Position: [[1.44927885 0.89881176 0.4624323 ]]
actor_loss: tensor(61.8114, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.9974, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.1567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.4196, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2223.071209561831, average reward:-11.115356047809154,----
Box_Position: [[1.36658973 0.901749   0.69326624]]
actor_loss: tensor(63.4478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.6778, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.4651, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.6378, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1911.876548168174, average reward:-9.559382740840869,----
Box_Position: [[1.37539535 0.62733482 0.74840378]]
actor_loss: tensor(60.9908, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-340.6136290328264, average reward:-13.100524193570246,success
Box_Position: [[1.26430774 0.83343633 0.61010572]]
Step:10, total reward:-82.63148533865836, average reward:-8.263148533865836,success
Box_Position: [[1.45450239 0.80020697 0.74519384]]
actor_loss: tensor(61.0278, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.9325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.4802, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-1518.400403928519, average reward:-9.610129138788094,success
Box_Position: [[1.35302167 0.77659877 0.53708555]]
actor_loss: tensor(60.9111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.2731, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-683.2809963675331, average reward:-10.352742369205048,success
Box_Position: [[1.3578495  0.80312987 0.46162504]]
actor_loss: tensor(63.6936, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-777.6726853476677, average reward:-9.720908566845846,success
Box_Position: [[1.3668783  0.50713389 0.69939028]]
actor_loss: tensor(60.7250, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.7898, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.9582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.5849, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2034.306922296153, average reward:-10.171534611480766,----
Box_Position: [[1.25095575 0.53037306 0.63864988]]
actor_loss: tensor(60.9899, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.3743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.5752, device='cuda:0', grad_fn=<NegBackward>)
Step:160, total reward:-1739.3951345152268, average reward:-10.871219590720168,success
Box_Position: [[1.29660566 0.79648322 0.55639322]]
actor_loss: tensor(57.9184, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.8164, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.2063, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(63.7983, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1985.9242545200593, average reward:-9.929621272600297,----
Box_Position: [[1.2942847  0.80462517 0.45280433]]
actor_loss: tensor(61.0787, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-314.12400622556305, average reward:-12.08169254713704,success
Box_Position: [[1.28337252 0.66235276 0.68436543]]
actor_loss: tensor(62.3366, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-343.98828449190864, average reward:-9.55523012477524,success
Box_Position: [[1.45844683 0.78036683 0.53403868]]
actor_loss: tensor(59.8836, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.2471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.9947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.1615, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2010.234033768399, average reward:-10.051170168841995,----
Box_Position: [[1.36805463 0.87160124 0.61960778]]
actor_loss: tensor(57.2414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.5755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.0904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.5362, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2057.2578587133034, average reward:-10.286289293566517,----
Box_Position: [[1.36376549 0.90920508 0.5512792 ]]
Step:7, total reward:-73.05879669205042, average reward:-10.436970956007203,success
Box_Position: [[1.50525313 0.53408479 0.68836335]]
actor_loss: tensor(58.5601, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.6386, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-1044.7831254489922, average reward:-10.447831254489921,success
Box_Position: [[1.3356816  0.74386427 0.61507496]]
actor_loss: tensor(58.4255, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.4110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.2953, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(62.7414, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1987.0913255370613, average reward:-9.935456627685307,----
Box_Position: [[1.26887893 0.80281327 0.63980504]]
Step:3, total reward:-38.49623122303271, average reward:-12.832077074344236,success
Box_Position: [[1.27030601 0.81592815 0.54851082]]
actor_loss: tensor(59.9551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.8332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(61.2873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.9259, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2051.3930963019748, average reward:-10.256965481509873,----
Box_Position: [[1.37620553 0.50176439 0.64265607]]
actor_loss: tensor(58.7408, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.6652, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.0423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.1122, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2096.864117606479, average reward:-10.484320588032395,----
Box_Position: [[1.39954946 0.78831354 0.55272974]]
actor_loss: tensor(60.8481, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-585.845622942619, average reward:-9.449122950687403,success
Box_Position: [[1.42677703 0.89383363 0.54866992]]
actor_loss: tensor(58.8094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.7500, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.0260, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.7235, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2108.7626916261206, average reward:-10.543813458130604,----
Box_Position: [[1.44889273 0.85538053 0.50056678]]
actor_loss: tensor(58.9668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.8056, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.7763, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.4359, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2121.9042022752924, average reward:-10.609521011376462,----
Box_Position: [[1.34529482 0.72428049 0.56341532]]
Step:13, total reward:-116.972830834643, average reward:-8.997910064203309,success
Box_Position: [[1.51425479 0.90208176 0.59052964]]
Step:10, total reward:-108.63556111717669, average reward:-10.863556111717669,success
Box_Position: [[1.48669482 0.8433341  0.71190361]]
actor_loss: tensor(60.0578, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.4608, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.8141, device='cuda:0', grad_fn=<NegBackward>)
Step:124, total reward:-1315.3643654629082, average reward:-10.607777140829905,success
Box_Position: [[1.3856891  0.81619794 0.53259291]]
actor_loss: tensor(61.7216, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-456.6391649009173, average reward:-9.926938367411246,success
Box_Position: [[1.36624266 0.68733335 0.53892419]]
actor_loss: tensor(61.3356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.4609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.9754, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.7452, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1945.6968549227547, average reward:-9.728484274613773,----
Box_Position: [[1.45747296 0.60495131 0.52676083]]
actor_loss: tensor(59.8476, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.2589, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-1178.4875228627077, average reward:-10.617004710474845,success
Box_Position: [[1.33220675 0.89628373 0.56416803]]
actor_loss: tensor(60.3089, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-442.86191280853836, average reward:-11.071547820213459,success
Box_Position: [[1.42331986 0.61998305 0.4818144 ]]
actor_loss: tensor(58.7124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.6797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.3701, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.8778, device='cuda:0', grad_fn=<NegBackward>)
Step:182, total reward:-1930.298921232887, average reward:-10.606038028752128,success
Box_Position: [[1.35573861 1.09761272 0.53522757]]
actor_loss: tensor(58.3497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.2052, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(60.3626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.7346, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2314.8881714946165, average reward:-11.574440857473082,----
Box_Position: [[1.44418109 1.0945426  0.72540641]]
actor_loss: tensor(56.5691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.8788, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.2436, device='cuda:0', grad_fn=<NegBackward>)
Step:185, total reward:-1630.3713316976766, average reward:-8.812818009176631,success
Box_Position: [[1.32139849 0.63582863 0.65195771]]
actor_loss: tensor(58.5147, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.3321, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-1022.1600152484095, average reward:-10.221600152484095,success
Box_Position: [[1.27339744 0.97660659 0.63581388]]
actor_loss: tensor(59.7675, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.7907, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-696.397706664906, average reward:-10.881214166639156,success
Box_Position: [[1.429699   1.17364887 0.61499626]]
actor_loss: tensor(59.8462, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-662.5946269522618, average reward:-10.353041046129091,success
Box_Position: [[1.40841737 1.09653    0.50394134]]
actor_loss: tensor(57.9038, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-737.4122384131116, average reward:-8.88448480015797,success
Box_Position: [[1.49344413 0.68973141 0.69692539]]
actor_loss: tensor(59.5252, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-190.44353721526778, average reward:-11.20256101266281,success
Box_Position: [[1.4582375  0.54212989 0.53290935]]
actor_loss: tensor(57.6227, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-759.6238510693348, average reward:-10.405806179031984,success
Box_Position: [[1.54227595 0.95843844 0.58351484]]
actor_loss: tensor(57.1188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.1986, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.0450, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.0156, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2098.003892629505, average reward:-10.490019463147526,----
Box_Position: [[1.37722231 0.93041242 0.49060638]]
actor_loss: tensor(56.4604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.4159, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.8623, device='cuda:0', grad_fn=<NegBackward>)
Step:132, total reward:-1343.9076868198829, average reward:-10.181118839544567,success
Box_Position: [[1.48543793 0.4435023  0.54059149]]
actor_loss: tensor(57.0142, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.5123, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-868.3759820282925, average reward:-10.097395139863865,success
Box_Position: [[1.43075697 0.80846973 0.66271957]]

------------------Episode:800------------------
actor_loss: tensor(56.3153, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.7962, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.8330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.4880, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1923.7256531991372, average reward:-9.618628265995687,----
episode 800, the accuracy is: 53%
Box_Position: [[1.39696564 0.75681166 0.72243847]]
actor_loss: tensor(59.7239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.4073, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-1200.3846166524802, average reward:-9.526862036924445,success
Box_Position: [[1.36823892 0.68056686 0.52127619]]
actor_loss: tensor(56.8124, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-335.7747526176901, average reward:-10.492961019302816,success
Box_Position: [[1.34553606 0.65920478 0.72455775]]
Step:26, total reward:-261.2335831712013, average reward:-10.047445506584666,success
Box_Position: [[1.52138346 0.60865009 0.57884268]]
actor_loss: tensor(56.0068, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.4824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.4536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.7751, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1959.56546476824, average reward:-9.797827323841199,----
Box_Position: [[1.5238108  1.11481348 0.65328722]]
actor_loss: tensor(59.9437, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.1122, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.6559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.3302, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2597.7902067797786, average reward:-12.988951033898893,----
Box_Position: [[1.34002648 0.93071744 0.47058899]]
actor_loss: tensor(57.3239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(59.0326, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.8659, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.0997, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1980.8511166093242, average reward:-9.904255583046622,----
Box_Position: [[1.31224722 0.91149895 0.4825985 ]]
actor_loss: tensor(56.9509, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.6087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.1223, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.3023, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2022.9493440101567, average reward:-10.114746720050784,----
Box_Position: [[1.37274585 0.97325541 0.45862327]]
actor_loss: tensor(55.9992, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.5444, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.4252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.7653, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2076.3227112587524, average reward:-10.381613556293763,----
Box_Position: [[1.49831206 0.59570316 0.57520743]]
actor_loss: tensor(57.7110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.9318, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-937.2392988809088, average reward:-10.530778639111334,success
Box_Position: [[1.37054889 0.94076545 0.46536699]]
actor_loss: tensor(55.9723, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.6443, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.7427, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(58.4649, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-1717.5051388360653, average reward:-9.927775368994597,success
Box_Position: [[1.35130342 1.02386361 0.67724832]]
actor_loss: tensor(59.1558, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-675.1069954745451, average reward:-10.548546804289767,success
Box_Position: [[1.49743955 0.65756408 0.63993086]]
Step:29, total reward:-312.64164304244554, average reward:-10.780746311808468,success
Box_Position: [[1.25236099 0.86601401 0.72449232]]
actor_loss: tensor(57.7412, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.5561, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.7138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.4575, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1868.820940603324, average reward:-9.34410470301662,----
Box_Position: [[1.43975337 0.68715491 0.45911346]]
actor_loss: tensor(57.8360, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-232.15910924087788, average reward:-11.055195678137043,success
Box_Position: [[1.45711427 0.91972387 0.62627412]]
actor_loss: tensor(56.3106, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.9450, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.5592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.5617, device='cuda:0', grad_fn=<NegBackward>)
Step:185, total reward:-1814.1141129282244, average reward:-9.806022232044455,success
Box_Position: [[1.49853413 0.84257229 0.63679994]]
Step:19, total reward:-256.3547678678782, average reward:-13.492356203572536,success
Box_Position: [[1.41520998 1.17487189 0.52063754]]
actor_loss: tensor(57.4811, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.3707, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.5102, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.3063, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2536.4088631253903, average reward:-12.682044315626952,----
Box_Position: [[1.25883158 0.68246543 0.61248678]]
actor_loss: tensor(56.9618, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.2919, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.5993, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.0921, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2090.1548809578817, average reward:-10.450774404789408,----
Box_Position: [[1.33733795 0.9475339  0.70270847]]
actor_loss: tensor(55.9638, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.3523, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-853.0464465434325, average reward:-8.616630773165985,success
Box_Position: [[1.41131314 0.95149316 0.61305872]]
actor_loss: tensor(56.6692, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.4527, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-896.1376289930352, average reward:-9.740626402098208,success
Box_Position: [[1.48772533 1.05111108 0.65979358]]
actor_loss: tensor(56.1300, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.9660, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.4795, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.0276, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1954.949247199815, average reward:-9.774746235999075,----
Box_Position: [[1.44601141 0.69545678 0.66771675]]
actor_loss: tensor(55.2413, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.0640, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.8166, device='cuda:0', grad_fn=<NegBackward>)
Step:141, total reward:-1418.2850160545972, average reward:-10.05875897911062,success
Box_Position: [[1.29239052 0.79125005 0.74290076]]
actor_loss: tensor(54.8626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.4596, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(57.2960, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.4875, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1926.573338837979, average reward:-9.632866694189895,----
Box_Position: [[1.47175823 0.77559613 0.58118932]]
actor_loss: tensor(55.5180, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-582.7367813412451, average reward:-9.39898034421363,success
Box_Position: [[1.28637099 1.03665475 0.50408233]]
Step:9, total reward:-88.65031850897967, average reward:-9.85003538988663,success
Box_Position: [[1.39153708 0.68475464 0.66545595]]
actor_loss: tensor(56.2683, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-712.6316220437851, average reward:-10.180451743482644,success
Box_Position: [[1.44836363 0.52036382 0.46433625]]
actor_loss: tensor(57.2152, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.3851, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.4153, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-1486.3232033847032, average reward:-9.651449372627942,success
Box_Position: [[1.31674851 0.77941702 0.65505679]]
actor_loss: tensor(55.2623, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-550.9538015358285, average reward:-10.595265414150548,success
Box_Position: [[1.46064158 1.06083507 0.67326603]]
actor_loss: tensor(57.2538, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.9009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.7970, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.6210, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1926.832155110687, average reward:-9.634160775553434,----
Box_Position: [[1.4156375  0.58890798 0.46064289]]
actor_loss: tensor(56.5422, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-242.31859934151868, average reward:-11.538980921024699,success
Box_Position: [[1.40539239 0.68614321 0.64749709]]
actor_loss: tensor(54.2188, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-462.97442116397923, average reward:-10.064661329651722,success
Box_Position: [[1.41046296 1.05198458 0.58117455]]
Step:22, total reward:-209.26835105831032, average reward:-9.512197775377741,success
Box_Position: [[1.53301256 0.45766116 0.66502924]]
actor_loss: tensor(54.6170, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.9047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.9327, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.5013, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2017.0613213720426, average reward:-10.085306606860213,----
Box_Position: [[1.34772909 0.65769031 0.54955697]]
actor_loss: tensor(52.7796, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.3943, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-1050.4926471552512, average reward:-10.400917298566844,success
Box_Position: [[1.37466223 1.00562365 0.51922996]]
actor_loss: tensor(56.3905, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-185.47429421907245, average reward:-10.304127456615136,success
Box_Position: [[1.33464061 0.74603355 0.57939789]]
actor_loss: tensor(55.1343, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.4660, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.3523, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.1045, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1993.3439466991406, average reward:-9.966719733495703,----
Box_Position: [[1.51500296 0.86715505 0.62792256]]
actor_loss: tensor(54.2026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.6030, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.3316, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-1621.3308938018977, average reward:-9.708568226358668,success
Box_Position: [[1.32652977 1.00215222 0.59146201]]
Step:16, total reward:-163.03613626008647, average reward:-10.189758516255404,success
Box_Position: [[1.39333343 1.11045814 0.56233554]]
actor_loss: tensor(52.3042, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.9555, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.5807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(56.5034, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2155.1593603929514, average reward:-10.775796801964757,----
Box_Position: [[1.42572818 0.77971249 0.71263104]]
actor_loss: tensor(55.8915, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.7414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.6998, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.9871, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2010.0296705398716, average reward:-10.050148352699358,----
Box_Position: [[1.36597289 0.60237808 0.46920728]]
actor_loss: tensor(55.1300, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-140.22530458509823, average reward:-10.016093184649874,success
Box_Position: [[1.52481805 0.58252859 0.57945256]]
actor_loss: tensor(54.2588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.0774, device='cuda:0', grad_fn=<NegBackward>)
Step:144, total reward:-1282.683709888395, average reward:-8.907525763113854,success
Box_Position: [[1.27074043 0.94080776 0.56821009]]
actor_loss: tensor(52.9130, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.4199, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.6396, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.5180, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2022.698561872771, average reward:-10.113492809363855,----
Box_Position: [[1.53259427 0.53882594 0.72602989]]
actor_loss: tensor(53.3155, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.0199, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.4858, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.0806, device='cuda:0', grad_fn=<NegBackward>)
Step:188, total reward:-1809.3084375579044, average reward:-9.623981050839918,success
Box_Position: [[1.35530076 0.7015341  0.62267662]]
actor_loss: tensor(54.6988, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.5516, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.2523, device='cuda:0', grad_fn=<NegBackward>)
Step:124, total reward:-1191.9262793328421, average reward:-9.612308704297114,success
Box_Position: [[1.27033809 0.84004001 0.53005881]]
actor_loss: tensor(54.4818, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-495.92095381485166, average reward:-9.918419076297033,success
Box_Position: [[1.26415749 1.03731938 0.69790837]]
Step:33, total reward:-455.2845909031365, average reward:-13.7965027546405,success
Box_Position: [[1.28338274 0.64879357 0.49918829]]
actor_loss: tensor(52.1310, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.6414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.6815, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.7364, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1963.3353944597702, average reward:-9.81667697229885,----
Box_Position: [[1.3505384  0.90125521 0.73345915]]
actor_loss: tensor(52.8819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.8596, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.2964, device='cuda:0', grad_fn=<NegBackward>)
Step:132, total reward:-1227.5734150724072, average reward:-9.299798599033387,success
Box_Position: [[1.47900415 0.64007012 0.56528033]]

------------------Episode:850------------------
actor_loss: tensor(54.5380, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-217.7566502974296, average reward:-8.710266011897183,success
Box_Position: [[1.54799558 0.5832555  0.52575835]]
actor_loss: tensor(52.1548, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-713.3116556007006, average reward:-11.145494618760948,success
Box_Position: [[1.47410315 0.67213297 0.73257755]]
actor_loss: tensor(52.0364, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.9307, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.6591, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.2186, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1988.0804541343455, average reward:-9.940402270671727,----
Box_Position: [[1.45192238 0.61006359 0.54938082]]
actor_loss: tensor(55.2322, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-749.4581318603788, average reward:-11.185942266572818,success
Box_Position: [[1.41879841 0.69678125 0.68647572]]
actor_loss: tensor(51.0347, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.2542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.9403, device='cuda:0', grad_fn=<NegBackward>)
Step:139, total reward:-1425.8397605482278, average reward:-10.257840003944084,success
Box_Position: [[1.35481232 0.60670492 0.60038888]]
actor_loss: tensor(52.9462, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(55.1376, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.1531, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.6795, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2009.8558108102966, average reward:-10.049279054051484,----
Box_Position: [[1.53638489 0.58999222 0.68387017]]
actor_loss: tensor(54.8585, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(54.7491, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-988.6061024572199, average reward:-9.788179232249702,success
Box_Position: [[1.34087932 0.80073429 0.69774204]]
actor_loss: tensor(53.6796, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.1835, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.4283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.2454, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2005.1252228533015, average reward:-10.025626114266508,----
Box_Position: [[1.30592278 0.98492952 0.72196679]]
actor_loss: tensor(52.2188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.7386, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-900.7736042323219, average reward:-9.007736042323218,success
Box_Position: [[1.30535848 0.75561966 0.59906281]]
Step:20, total reward:-222.40516903842013, average reward:-11.120258451921007,success
Box_Position: [[1.2732968  0.59749682 0.72632017]]
actor_loss: tensor(52.4947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(53.2078, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.0253, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.4252, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2028.6042860605987, average reward:-10.143021430302994,----
Box_Position: [[1.33611938 0.71266597 0.57953571]]
actor_loss: tensor(51.2618, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.7063, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-762.7723011800866, average reward:-10.170297349067821,success
Box_Position: [[1.43769317 0.58366189 0.70964141]]
actor_loss: tensor(50.2822, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.6677, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4598, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-1460.0350379493277, average reward:-9.798892872143139,success
Box_Position: [[1.3666925  1.05030229 0.71605536]]
actor_loss: tensor(48.5837, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-662.1464986548103, average reward:-8.174648131540868,success
Box_Position: [[1.50135592 0.81449205 0.59311393]]
actor_loss: tensor(51.8404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.9588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.3876, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1999.312850240892, average reward:-9.99656425120446,----
Box_Position: [[1.30032206 0.67116629 0.61304699]]
actor_loss: tensor(48.5667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.0735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.2860, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.2935, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2042.828002775685, average reward:-10.214140013878426,----
Box_Position: [[1.49400423 1.08746806 0.63044631]]
actor_loss: tensor(49.0595, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-456.08149572834867, average reward:-9.501697827673931,success
Box_Position: [[1.37365383 0.91409831 0.49755471]]
actor_loss: tensor(50.1908, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-286.735315585448, average reward:-13.654062646926096,success
Box_Position: [[1.51470622 0.97574099 0.6498913 ]]
actor_loss: tensor(49.3452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.8078, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(52.5612, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4273, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1887.1914160353642, average reward:-9.435957080176822,----
Box_Position: [[1.25422227 0.67904052 0.71154891]]
actor_loss: tensor(50.3416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.8512, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.6878, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.5793, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2041.0450534495612, average reward:-10.205225267247807,----
Box_Position: [[1.44671279 0.86840178 0.69090814]]
Step:6, total reward:-71.22678950946478, average reward:-11.871131584910797,success
Box_Position: [[1.5011009  0.79695569 0.5090296 ]]
Step:24, total reward:-267.4833211959937, average reward:-11.145138383166405,success
Box_Position: [[1.32597585 0.85341492 0.66490475]]
actor_loss: tensor(46.3291, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4624, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.1755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4930, device='cuda:0', grad_fn=<NegBackward>)
Step:163, total reward:-1507.0739798334967, average reward:-9.245852637015316,success
Box_Position: [[1.51938755 0.86978078 0.65410478]]
actor_loss: tensor(49.5439, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-447.349662062848, average reward:-9.941103601396621,success
Box_Position: [[1.41104089 0.6370062  0.73943734]]
Step:1, total reward:-7.66430797526093, average reward:-7.66430797526093,success
Box_Position: [[1.49024141 0.84205848 0.62718006]]
actor_loss: tensor(46.8117, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.0114, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.1681, device='cuda:0', grad_fn=<NegBackward>)
Step:179, total reward:-1712.7785327877923, average reward:-9.568595155239063,success
Box_Position: [[1.40600033 1.16154882 0.74881839]]
Step:14, total reward:-116.99885811144811, average reward:-8.357061293674866,success
Box_Position: [[1.43417719 0.78826456 0.72609488]]
actor_loss: tensor(50.5275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.7411, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.7286, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.5243, device='cuda:0', grad_fn=<NegBackward>)
Step:157, total reward:-1435.4293409314137, average reward:-9.142862044149132,success
Box_Position: [[1.41995017 1.12920807 0.63735093]]
actor_loss: tensor(49.5416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(50.4764, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.6639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.7115, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1771.7827144701087, average reward:-8.858913572350543,----
Box_Position: [[1.32325694 0.84151319 0.70739968]]
actor_loss: tensor(47.7338, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(51.5361, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.9208, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-1499.642429019103, average reward:-9.737937850773395,success
Box_Position: [[1.31934855 0.54212475 0.46317011]]
Step:10, total reward:-89.17494354695222, average reward:-8.917494354695222,success
Box_Position: [[1.39618641 0.87235202 0.50802771]]
actor_loss: tensor(50.4658, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-502.5505377317723, average reward:-10.051010754635445,success
Box_Position: [[1.29322371 0.62637022 0.60137511]]
Step:28, total reward:-248.42215311102882, average reward:-8.872219753965314,success
Box_Position: [[1.30655976 1.03050611 0.48930678]]
actor_loss: tensor(47.7725, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-142.95068407340838, average reward:-10.210763148100598,success
Box_Position: [[1.35884872 0.93533566 0.67138034]]
actor_loss: tensor(47.3829, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-462.57532459175627, average reward:-8.727836313052006,success
Box_Position: [[1.39703022 0.74573816 0.7214581 ]]
actor_loss: tensor(48.9100, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-338.2561662533351, average reward:-8.673235032136798,success
Box_Position: [[1.26259628 0.85398194 0.74728634]]
actor_loss: tensor(47.3047, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-494.78897962759993, average reward:-8.996163265956362,success
Box_Position: [[1.33975234 0.88045879 0.47670098]]
actor_loss: tensor(46.0306, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.8830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.0000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(49.9180, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2009.8041695130216, average reward:-10.049020847565108,----
Box_Position: [[1.39150461 0.53000391 0.57338404]]
actor_loss: tensor(45.2350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.9471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.6935, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-1741.9026084974682, average reward:-10.068801205187677,success
Box_Position: [[1.38236805 0.73400177 0.61168656]]
actor_loss: tensor(48.6869, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.6216, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.2963, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.8176, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2524.8843968403635, average reward:-12.624421984201817,----
Box_Position: [[1.30669803 0.8049566  0.54531303]]
actor_loss: tensor(45.5192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.0082, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.2845, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.4875, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2105.0101367655443, average reward:-10.525050683827722,----
Box_Position: [[1.47585479 0.87694941 0.56561853]]
actor_loss: tensor(45.4158, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.8394, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.5822, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.8522, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1980.4472773712475, average reward:-9.902236386856238,----
Box_Position: [[1.32090919 0.91155773 0.59712047]]
Step:3, total reward:-51.37904282735119, average reward:-17.126347609117065,success
Box_Position: [[1.49745513 0.87476958 0.66144302]]
actor_loss: tensor(46.5182, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.8739, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-895.3279530698932, average reward:-8.953279530698932,success
Box_Position: [[1.42428538 0.92396055 0.45880725]]
actor_loss: tensor(47.4416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.5085, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-876.3234218284296, average reward:-11.380823660109474,success
Box_Position: [[1.38660883 0.9174827  0.49013956]]
Step:9, total reward:-110.35512786398654, average reward:-12.261680873776282,success
Box_Position: [[1.53727202 0.69277627 0.53819656]]
actor_loss: tensor(48.2288, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.2515, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.3188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.6572, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1962.1255484760886, average reward:-9.810627742380444,----
Box_Position: [[1.31093722 0.85348168 0.62417641]]
Step:27, total reward:-284.43834376273924, average reward:-10.534753472694046,success
Box_Position: [[1.37737486 0.82326969 0.4719814 ]]
actor_loss: tensor(46.6936, device='cuda:0', grad_fn=<NegBackward>)
Step:7, total reward:-71.89772519721792, average reward:-10.27110359960256,success
Box_Position: [[1.53545503 0.51108105 0.66167589]]
Step:22, total reward:-210.66647853812822, average reward:-9.575749024460373,success
Box_Position: [[1.39915884 0.83413174 0.63559197]]

------------------Episode:900------------------
actor_loss: tensor(45.7204, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.5434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.1241, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-1413.3988813755368, average reward:-9.485898532721723,success
episode 900, the accuracy is: 69%
Box_Position: [[1.44022432 0.5394288  0.66363414]]
actor_loss: tensor(46.0285, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.9302, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.5010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.8825, device='cuda:0', grad_fn=<NegBackward>)
Step:199, total reward:-1840.9604912138414, average reward:-9.251057744793172,success
Box_Position: [[1.53914897 0.6554355  0.66563641]]
actor_loss: tensor(43.3886, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.9507, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-1038.8285763386577, average reward:-9.112531371391734,success
Box_Position: [[1.42508593 0.69269879 0.56555498]]
actor_loss: tensor(46.0355, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.0904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.7939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.5965, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2015.0047931393306, average reward:-10.075023965696653,----
Box_Position: [[1.38453379 0.48796607 0.55393529]]
actor_loss: tensor(44.4773, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-270.7423523067108, average reward:-10.829694092268433,success
Box_Position: [[1.48651825 0.90709921 0.46520906]]
actor_loss: tensor(45.9552, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.2211, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.4884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.3144, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1998.1701203612251, average reward:-9.990850601806125,----
Box_Position: [[1.52720936 0.65755188 0.6796287 ]]
Step:27, total reward:-249.19022878206542, average reward:-9.22926773266909,success
Box_Position: [[1.30393772 0.58642043 0.47516281]]
actor_loss: tensor(44.1110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.7524, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.3789, device='cuda:0', grad_fn=<NegBackward>)
Step:148, total reward:-1565.4761770217333, average reward:-10.577541736633332,success
Box_Position: [[1.25797382 0.76688938 0.65652552]]
actor_loss: tensor(46.1101, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.7558, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(47.3227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.3291, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1967.3874785281037, average reward:-9.836937392640518,----
Box_Position: [[1.40141636 0.49943661 0.55575114]]
actor_loss: tensor(44.5087, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-592.990856258449, average reward:-9.564368649329822,success
Box_Position: [[1.44654508 0.72282347 0.73931322]]
actor_loss: tensor(44.7236, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.0412, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(48.3833, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(46.7116, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1837.257579825491, average reward:-9.186287899127455,----
Box_Position: [[1.40331029 0.55861108 0.47032711]]
actor_loss: tensor(44.1512, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.0881, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.4561, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.6583, device='cuda:0', grad_fn=<NegBackward>)
Step:180, total reward:-1791.697207116449, average reward:-9.953873372869161,success
Box_Position: [[1.32924658 0.7081469  0.49085907]]
actor_loss: tensor(44.3018, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.8967, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-678.6351067912024, average reward:-9.296371325906883,success
Box_Position: [[1.28121337 0.41068404 0.68322066]]
actor_loss: tensor(42.4423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.8950, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-1325.8031469015777, average reward:-9.336641879588576,success
Box_Position: [[1.38821036 0.69785961 0.73324917]]
actor_loss: tensor(44.1620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.6960, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.5263, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.0768, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1780.133933421608, average reward:-8.90066966710804,----
Box_Position: [[1.34530271 0.76892519 0.51329613]]
actor_loss: tensor(42.2828, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-460.7463950714885, average reward:-9.59888323065601,success
Box_Position: [[1.36390693 1.01013626 0.66396826]]
actor_loss: tensor(44.1646, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(44.2708, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.8686, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(45.6747, device='cuda:0', grad_fn=<NegBackward>)
Step:188, total reward:-1760.575281948552, average reward:-9.364762138024213,success
Box_Position: [[1.35806931 0.57845878 0.74320488]]
Step:17, total reward:-150.9026032441753, average reward:-8.876623720245606,success
Box_Position: [[1.45463536 0.5502603  0.46299023]]
actor_loss: tensor(42.7150, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.4143, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-608.780198834299, average reward:-10.680354365514017,success
Box_Position: [[1.33000006 1.03127414 0.55442321]]
Step:33, total reward:-328.30964491264325, average reward:-9.948777118564948,success
Box_Position: [[1.46336748 0.73213381 0.53958042]]
Step:6, total reward:-65.9285833351377, average reward:-10.988097222522951,success
Box_Position: [[1.34702747 0.86990549 0.50009996]]
actor_loss: tensor(43.7886, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-195.14681525305042, average reward:-10.270885013318443,success
Box_Position: [[1.29834498 0.96210391 0.53294   ]]
Step:21, total reward:-198.40129561207175, average reward:-9.447680743431988,success
Box_Position: [[1.47959928 0.67166889 0.46264965]]
actor_loss: tensor(41.5019, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.6020, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-907.6544516509446, average reward:-10.935595803023428,success
Box_Position: [[1.26485715 0.57197635 0.67021167]]
actor_loss: tensor(43.0028, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.9060, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.5951, device='cuda:0', grad_fn=<NegBackward>)
Step:149, total reward:-1414.6629987420258, average reward:-9.49438254189279,success
Box_Position: [[1.35524142 1.02631616 0.49353771]]
actor_loss: tensor(41.9865, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.8248, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.3152, device='cuda:0', grad_fn=<NegBackward>)
Step:150, total reward:-1651.0213412040912, average reward:-11.006808941360609,success
Box_Position: [[1.26016118 0.79094057 0.48382268]]
actor_loss: tensor(41.9630, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.5155, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.0326, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.6943, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2996.9766950492854, average reward:-14.984883475246427,----
Box_Position: [[1.54871082 0.78445255 0.71269703]]
actor_loss: tensor(39.7568, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.2721, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.7680, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.4906, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1909.489902359363, average reward:-9.547449511796815,----
Box_Position: [[1.42745597 1.11372198 0.47452263]]
actor_loss: tensor(39.5171, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.7234, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(43.1317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.4365, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1910.4400186379812, average reward:-9.552200093189906,----
Box_Position: [[1.5487499  0.63598285 0.66952797]]
actor_loss: tensor(40.6586, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.0751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.1982, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.3090, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1873.6085950399063, average reward:-9.36804297519953,----
Box_Position: [[1.44458886 0.5441401  0.73170558]]
actor_loss: tensor(39.2788, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.9188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.3560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.8125, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1970.7891710025672, average reward:-9.853945855012835,----
Box_Position: [[1.46612043 0.50590328 0.61406316]]
actor_loss: tensor(39.8081, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.1287, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.3979, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.3552, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1848.9616686687834, average reward:-9.244808343343918,----
Box_Position: [[1.29379199 0.65189511 0.57330735]]
actor_loss: tensor(43.0404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.8411, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.5165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(41.0014, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1827.56272129327, average reward:-9.13781360646635,----
Box_Position: [[1.48375513 0.71430929 0.68096275]]
Step:10, total reward:-74.73595842732043, average reward:-7.473595842732043,success
Box_Position: [[1.35757355 0.44003428 0.7358778 ]]
actor_loss: tensor(40.6691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.1062, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.6548, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.6601, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1952.2372806177511, average reward:-9.761186403088756,----
Box_Position: [[1.33551951 1.03964003 0.55718556]]
actor_loss: tensor(39.8853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.7640, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.9510, device='cuda:0', grad_fn=<NegBackward>)
Step:169, total reward:-1624.1833157148003, average reward:-9.610552163992901,success
Box_Position: [[1.5277393  0.80939831 0.56544258]]
actor_loss: tensor(41.9945, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(40.8926, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.8351, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(42.1221, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1908.368039407424, average reward:-9.54184019703712,----
Box_Position: [[1.528197   0.71197637 0.67488618]]
actor_loss: tensor(38.4167, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.2151, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-972.6382333119476, average reward:-9.352290704922574,success
Box_Position: [[1.31798434 0.86698822 0.69628813]]
actor_loss: tensor(40.1735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.4748, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.1887, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.5224, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1704.489957809796, average reward:-9.629886767286983,success
Box_Position: [[1.28362457 0.73288761 0.59943537]]
actor_loss: tensor(38.1623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.1349, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.9207, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.3189, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1938.8068474793572, average reward:-9.694034237396785,----
Box_Position: [[1.48653793 0.86510292 0.71823704]]
Step:2, total reward:-16.244875706278926, average reward:-8.122437853139463,success
Box_Position: [[1.42935086 0.50391424 0.72949791]]
actor_loss: tensor(38.5600, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-685.7879230282614, average reward:-10.39072610648881,success
Box_Position: [[1.43000376 0.93795218 0.54635821]]
Step:2, total reward:-31.334840016866195, average reward:-15.667420008433098,success
Box_Position: [[1.51539724 0.62060075 0.59167795]]
actor_loss: tensor(39.4272, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.1463, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.8019, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.0258, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1930.3343216762519, average reward:-9.651671608381259,----
Box_Position: [[1.30538695 0.87940989 0.53248212]]
actor_loss: tensor(38.3149, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.8702, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.8406, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.0149, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1946.1796396409236, average reward:-9.730898198204619,----
Box_Position: [[1.34316115 0.53292628 0.60373974]]
actor_loss: tensor(36.1908, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(39.1403, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.4271, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.0133, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2003.121110195134, average reward:-10.01560555097567,----
Box_Position: [[1.51845135 0.93792029 0.71385629]]
actor_loss: tensor(38.2752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.9467, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.3026, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-1123.3434626234664, average reward:-8.986747700987731,success
Box_Position: [[1.30801315 0.81222508 0.57292145]]
actor_loss: tensor(38.5487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.0237, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.7807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.1294, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1863.5509613893566, average reward:-9.317754806946784,----
Box_Position: [[1.31600778 0.64867912 0.72987993]]
actor_loss: tensor(35.4724, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.6365, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.0389, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.3285, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2081.7852685064513, average reward:-10.408926342532256,----
Box_Position: [[1.46488513 1.09818986 0.51390985]]
actor_loss: tensor(39.5317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.5270, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.9980, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.6516, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1950.4677310687264, average reward:-9.752338655343632,----
Box_Position: [[1.46750385 0.59270097 0.74188946]]

------------------Episode:950------------------
actor_loss: tensor(37.0266, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-529.4538288680961, average reward:-9.804700534594373,success
Box_Position: [[1.43001891 0.98856587 0.71266937]]
actor_loss: tensor(35.6009, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-491.141816305767, average reward:-9.630231692269941,success
Box_Position: [[1.44402565 0.90099489 0.71713584]]
Step:3, total reward:-26.367493576617306, average reward:-8.789164525539102,success
Box_Position: [[1.38857333 0.70231744 0.70943727]]
actor_loss: tensor(37.2369, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.9914, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.7893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.9430, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1810.0054885241036, average reward:-9.050027442620518,----
Box_Position: [[1.34709884 0.92370262 0.55977484]]
Step:6, total reward:-55.09129233391528, average reward:-9.181882055652546,success
Box_Position: [[1.47930156 0.62990911 0.60195186]]
actor_loss: tensor(36.7311, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.8366, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-685.7074496751349, average reward:-8.679841135128289,success
Box_Position: [[1.31099665 0.82416566 0.54954598]]
actor_loss: tensor(35.2501, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.5209, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.0078, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.6032, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1913.0907446619788, average reward:-9.565453723309894,----
Box_Position: [[1.2739382  0.9650281  0.47392222]]
Step:17, total reward:-177.6139037784092, average reward:-10.4478766928476,success
Box_Position: [[1.50431133 0.67245582 0.58200486]]
actor_loss: tensor(37.3793, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-178.64219885971124, average reward:-8.932109942985562,success
Box_Position: [[1.30138329 0.95593907 0.48121331]]
Step:13, total reward:-142.36108363169143, average reward:-10.950852587053188,success
Box_Position: [[1.31677492 0.73009027 0.61499272]]
actor_loss: tensor(37.0727, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.8566, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.4833, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(37.3638, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1906.9891188673578, average reward:-9.534945594336788,----
Box_Position: [[1.32573225 0.71134233 0.61548231]]
actor_loss: tensor(36.2319, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.6788, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(38.0393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.5388, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1983.233971950013, average reward:-9.916169859750065,----
Box_Position: [[1.42780087 0.71905559 0.63798172]]
actor_loss: tensor(36.2323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.0331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.7524, device='cuda:0', grad_fn=<NegBackward>)
Step:153, total reward:-1375.5599559236066, average reward:-8.990587947213115,success
Box_Position: [[1.39783242 0.6398846  0.74862183]]
actor_loss: tensor(36.1928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.5040, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.9103, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-1660.5620966134136, average reward:-9.598624835915686,success
Box_Position: [[1.37094166 1.04516731 0.48963395]]
actor_loss: tensor(36.4619, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.7269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.9634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.8158, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1841.786705737672, average reward:-9.20893352868836,----
Box_Position: [[1.36914958 0.52928728 0.62826212]]
actor_loss: tensor(34.8554, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.1375, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.7005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.1319, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1973.163779724667, average reward:-9.865818898623335,----
Box_Position: [[1.43163207 0.8797372  0.55654981]]
actor_loss: tensor(33.7473, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-159.31775651773341, average reward:-10.621183767848894,success
Box_Position: [[1.34118629 1.13406874 0.69656576]]
Step:15, total reward:-168.77888182551993, average reward:-11.251925455034662,success
Box_Position: [[1.30912846 0.90002935 0.71699299]]
actor_loss: tensor(35.6416, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-428.83318576743164, average reward:-9.52962635038737,success
Box_Position: [[1.43757464 0.49029651 0.67511538]]
actor_loss: tensor(35.9412, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-427.0344465826107, average reward:-9.70532833142297,success
Box_Position: [[1.36732115 0.94567787 0.64338525]]
actor_loss: tensor(35.9488, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-613.3153431992554, average reward:-9.583052237488365,success
Box_Position: [[1.25949357 0.74770383 0.72497912]]
actor_loss: tensor(33.1076, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.3213, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.0323, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-1309.4778416999084, average reward:-9.699835864443767,success
Box_Position: [[1.42409309 0.75673725 0.61175885]]
Step:9, total reward:-89.49715362710933, average reward:-9.944128180789924,success
Box_Position: [[1.39104952 0.79864032 0.59546195]]
actor_loss: tensor(34.4601, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.7374, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-1008.1384164545524, average reward:-9.787751616063616,success
Box_Position: [[1.31322819 0.6636633  0.71013383]]
actor_loss: tensor(35.1668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.7969, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.8000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.1082, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1888.697338550278, average reward:-9.443486692751389,----
Box_Position: [[1.28861421 0.75168129 0.70582399]]
Step:11, total reward:-114.02511167072505, average reward:-10.365919242793186,success
Box_Position: [[1.49509797 0.64120239 0.45217077]]
actor_loss: tensor(36.7315, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.2543, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.2475, device='cuda:0', grad_fn=<NegBackward>)
Step:159, total reward:-1546.6534933485661, average reward:-9.727380461311737,success
Box_Position: [[1.34472541 0.55702071 0.51490432]]
actor_loss: tensor(36.3773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.0404, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-597.9294545837586, average reward:-9.059537190663008,success
Box_Position: [[1.4409262  0.81773846 0.72719948]]
actor_loss: tensor(34.4656, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-669.6325189888998, average reward:-8.810954197222367,success
Box_Position: [[1.43902926 0.5766526  0.69317502]]
actor_loss: tensor(34.8774, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.1690, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.2588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.7223, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1923.489665905171, average reward:-9.617448329525855,----
Box_Position: [[1.51715778 0.91731644 0.54810244]]
Step:11, total reward:-135.58330937846722, average reward:-12.325755398042475,success
Box_Position: [[1.4457637  0.56664482 0.73094135]]
actor_loss: tensor(33.6666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.3331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.3438, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.8709, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1915.392420597725, average reward:-9.576962102988626,----
Box_Position: [[1.30951456 0.90259118 0.4756956 ]]
actor_loss: tensor(33.7335, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-514.9015169678762, average reward:-10.298030339357524,success
Box_Position: [[1.30435978 1.04661933 0.49781186]]
actor_loss: tensor(34.2244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.1396, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(36.5668, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-1421.7836556784014, average reward:-10.0125609554817,success
Box_Position: [[1.50740109 0.74986181 0.52431394]]
actor_loss: tensor(34.9017, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.5032, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.8861, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-1217.1236266271135, average reward:-9.736989013016908,success
Box_Position: [[1.25385872 0.8233054  0.70467661]]
actor_loss: tensor(33.1571, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.3657, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.2801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.7702, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2437.5602653682877, average reward:-12.187801326841438,----
Box_Position: [[1.50499602 0.54009976 0.46998596]]
actor_loss: tensor(35.0782, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.7773, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-1039.2981656852885, average reward:-9.62313116375267,success
Box_Position: [[1.38276142 0.79502038 0.4813915 ]]
Step:9, total reward:-63.639182490893944, average reward:-7.071020276765994,success
Box_Position: [[1.53257136 0.66724543 0.54572694]]
actor_loss: tensor(35.2984, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.3543, device='cuda:0', grad_fn=<NegBackward>)
Step:113, total reward:-1068.6458946693044, average reward:-9.457043315657561,success
Box_Position: [[1.54825427 0.81194288 0.54965602]]
actor_loss: tensor(37.3253, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.8860, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.9949, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.6026, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2086.1059680572425, average reward:-10.430529840286212,----
Box_Position: [[1.46868296 0.72221807 0.5356252 ]]
actor_loss: tensor(32.9691, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-493.84088410134444, average reward:-10.735671393507488,success
Box_Position: [[1.40377199 0.75345184 0.71510528]]
actor_loss: tensor(32.2090, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.3981, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.8667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.2198, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1862.7448560434486, average reward:-9.313724280217244,----
Box_Position: [[1.40473568 0.90958556 0.57231789]]
actor_loss: tensor(33.1723, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.7552, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-666.3702347274485, average reward:-9.519574781820694,success
Box_Position: [[1.25447652 0.93420227 0.6610718 ]]
actor_loss: tensor(34.1371, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-564.3686459835253, average reward:-9.565570270907209,success
Box_Position: [[1.32410068 0.64242279 0.46969349]]
actor_loss: tensor(32.4956, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.2408, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.3906, device='cuda:0', grad_fn=<NegBackward>)
Step:163, total reward:-1611.256292921269, average reward:-9.885007932032325,success
Box_Position: [[1.54834227 0.85855412 0.62048987]]
actor_loss: tensor(34.4903, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.1666, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-876.3095986060135, average reward:-9.629775808857291,success
Box_Position: [[1.42523186 0.48554165 0.58266468]]
actor_loss: tensor(32.2178, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.3173, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.5322, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.3392, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1797.2884260508686, average reward:-8.986442130254343,----
Box_Position: [[1.33502257 0.92492129 0.60246809]]
Step:2, total reward:-39.33567194098078, average reward:-19.66783597049039,success
Box_Position: [[1.32996722 0.66148446 0.490418  ]]
actor_loss: tensor(33.5021, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.9195, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.6873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.1916, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1974.3164053178753, average reward:-9.871582026589376,----
Box_Position: [[1.52024581 0.62012092 0.5732651 ]]
actor_loss: tensor(32.0538, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(34.1038, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-1000.9619822565853, average reward:-9.099654384150776,success
Box_Position: [[1.25897321 0.82992737 0.71620388]]

------------------Episode:1000------------------
actor_loss: tensor(32.0582, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.8339, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.6701, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.9040, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1844.864992816481, average reward:-9.224324964082404,----
episode 1000, the accuracy is: 64%
Box_Position: [[1.36871197 0.43735859 0.72852057]]
actor_loss: tensor(32.6086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.1215, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.0738, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.1816, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1909.4983156686087, average reward:-9.547491578343044,----
Box_Position: [[1.4885029  0.83760141 0.50319186]]
Step:11, total reward:-135.65635634886604, average reward:-12.332396031715094,success
Box_Position: [[1.29525698 0.45699768 0.62569772]]
actor_loss: tensor(32.7735, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-160.60048874230577, average reward:-9.44708757307681,success
Box_Position: [[1.32854189 0.57939332 0.6467436 ]]
actor_loss: tensor(31.4171, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.9475, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.2082, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.6538, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1814.017154628281, average reward:-9.070085773141406,----
Box_Position: [[1.50265221 0.91865876 0.47231613]]
actor_loss: tensor(32.5323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.8419, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.1002, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-1518.599020731361, average reward:-10.05694715716133,success
Box_Position: [[1.52125886 0.97376201 0.49855383]]
actor_loss: tensor(31.3467, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.2517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.0513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.7872, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2015.176308822776, average reward:-10.07588154411388,----
Box_Position: [[1.4878518  0.61894199 0.49008761]]
Step:37, total reward:-385.0098581561466, average reward:-10.405671842058016,success
Box_Position: [[1.34171333 0.89255187 0.69067916]]
actor_loss: tensor(33.1938, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-348.4027869858968, average reward:-9.168494394365705,success
Box_Position: [[1.25666069 0.68157104 0.45551009]]
actor_loss: tensor(31.8059, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.7181, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-1016.6959546034807, average reward:-10.374448516362047,success
Box_Position: [[1.54528743 0.78905604 0.48334178]]
actor_loss: tensor(32.1107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.1494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(33.0727, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.8432, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1904.8208187490336, average reward:-9.524104093745168,----
Box_Position: [[1.36467722 0.71855437 0.53177532]]
actor_loss: tensor(32.6497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.0539, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.9187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.5204, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1850.1502347868031, average reward:-9.250751173934015,----
Box_Position: [[1.52241586 0.91858091 0.45524576]]
actor_loss: tensor(32.0412, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.2732, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.3239, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.2545, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1973.3270415142294, average reward:-9.866635207571147,----
Box_Position: [[1.25236074 0.62553028 0.69912058]]
Step:1, total reward:-8.629380998123246, average reward:-8.629380998123246,success
Box_Position: [[1.50643464 0.56664757 0.61229085]]
actor_loss: tensor(29.9597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(35.0899, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.1769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.3069, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1958.6055237333737, average reward:-9.79302761866687,----
Box_Position: [[1.42857703 0.73972646 0.55371774]]
actor_loss: tensor(32.3109, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-416.1882836082124, average reward:-8.855069864004518,success
Box_Position: [[1.33780024 0.88254002 0.55075552]]
actor_loss: tensor(30.1462, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.8090, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.7005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.9456, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1869.677761480154, average reward:-9.34838880740077,----
Box_Position: [[1.28715624 0.87416092 0.69191939]]
actor_loss: tensor(31.2960, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.1148, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.7025, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.5317, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1816.4295420656836, average reward:-9.082147710328417,----
Box_Position: [[1.28242634 1.11929881 0.6918397 ]]
actor_loss: tensor(30.8380, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.6414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.6506, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.9523, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3016.785594227752, average reward:-15.08392797113876,----
Box_Position: [[1.31325253 0.70845125 0.52749124]]
actor_loss: tensor(31.6882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.1071, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.3135, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.8512, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1937.6391825817911, average reward:-9.688195912908956,----
Box_Position: [[1.42646643 0.92559013 0.73804598]]
actor_loss: tensor(29.4552, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.7195, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-1148.4003048922673, average reward:-13.836148251714064,success
Box_Position: [[1.47962785 0.78133921 0.60385331]]
actor_loss: tensor(30.7525, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-534.9068489628818, average reward:-9.066217779031895,success
Box_Position: [[1.37764038 0.91393396 0.66519742]]
actor_loss: tensor(29.5594, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(32.1825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3977, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.9231, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1756.7262831217884, average reward:-8.783631415608943,----
Box_Position: [[1.38385194 0.67278443 0.45991513]]
Step:19, total reward:-182.05514024008153, average reward:-9.581849486320081,success
Box_Position: [[1.50262875 0.96393642 0.46566178]]
actor_loss: tensor(30.9946, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.7652, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3828, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.4454, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2091.6231091295517, average reward:-10.45811554564776,----
Box_Position: [[1.26483119 0.65599971 0.60029915]]
actor_loss: tensor(29.8622, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.2965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.7292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.8158, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2004.0825022509375, average reward:-10.020412511254687,----
Box_Position: [[1.26663354 1.16392795 0.62039322]]
actor_loss: tensor(31.4047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.7816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.8797, device='cuda:0', grad_fn=<NegBackward>)
Step:188, total reward:-2531.1213426976, average reward:-13.46341139732766,success
Box_Position: [[1.37091738 0.6765569  0.61326081]]
actor_loss: tensor(29.3830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.8347, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.4212, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.2245, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1996.5430313238016, average reward:-9.982715156619008,----
Box_Position: [[1.49586793 0.64889524 0.54478794]]
Step:15, total reward:-149.43041162564333, average reward:-9.962027441709555,success
Box_Position: [[1.3090962  0.84390178 0.53924247]]
actor_loss: tensor(28.4517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.7774, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.3212, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.5119, device='cuda:0', grad_fn=<NegBackward>)
Step:187, total reward:-1728.8343097670975, average reward:-9.245103260786617,success
Box_Position: [[1.27219963 0.94778688 0.49440574]]
actor_loss: tensor(31.0107, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-598.1349255084211, average reward:-9.968915425140352,success
Box_Position: [[1.26988226 0.58945192 0.6549107 ]]
actor_loss: tensor(28.7226, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3826, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.6983, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1974.5434995409607, average reward:-9.872717497704803,----
Box_Position: [[1.52688144 1.00778597 0.4746073 ]]
actor_loss: tensor(28.5146, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.1645, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.1174, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.4744, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2086.4001433385774, average reward:-10.432000716692887,----
Box_Position: [[1.29319734 0.86518043 0.68517741]]
actor_loss: tensor(30.9076, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-276.1011288958215, average reward:-9.20337096319405,success
Box_Position: [[1.52715257 0.79536569 0.56484547]]
Step:24, total reward:-244.74993239768585, average reward:-10.197913849903577,success
Box_Position: [[1.41947599 1.0400001  0.52602696]]
actor_loss: tensor(29.7157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.4201, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.5270, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.4544, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1954.5705676654363, average reward:-9.772852838327182,----
Box_Position: [[1.29121898 0.75714749 0.63872023]]
actor_loss: tensor(30.7053, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.8642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.4875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.4603, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1858.7392061901505, average reward:-9.293696030950752,----
Box_Position: [[1.33101992 0.82319937 0.5712287 ]]
actor_loss: tensor(27.7039, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-248.90827717368492, average reward:-8.583044040471894,success
Box_Position: [[1.3261437  0.45072009 0.49006058]]
Step:10, total reward:-97.49704547762015, average reward:-9.749704547762015,success
Box_Position: [[1.42423631 1.1013495  0.6239208 ]]
actor_loss: tensor(29.4767, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.2664, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.4862, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-1122.5745083812508, average reward:-8.980596067050007,success
Box_Position: [[1.35766687 0.68307097 0.64147619]]
actor_loss: tensor(30.2213, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.1000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.4455, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.6845, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1874.3281665886066, average reward:-9.371640832943033,----
Box_Position: [[1.35002174 0.61409714 0.50916704]]
actor_loss: tensor(30.0530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.1706, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5773, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1926.3621450292776, average reward:-9.631810725146387,----
Box_Position: [[1.50561725 0.91192684 0.47322541]]
actor_loss: tensor(28.7771, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5014, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.1715, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.1076, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1895.5208787793715, average reward:-9.477604393896858,----
Box_Position: [[1.54207609 0.4607353  0.67266935]]
Step:34, total reward:-302.57861658365863, average reward:-8.89937107598996,success
Box_Position: [[1.2693007  0.80550276 0.70718936]]
actor_loss: tensor(28.3774, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3235, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.4838, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.2695, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-1678.6485248027739, average reward:-8.834992235804073,success
Box_Position: [[1.35117557 0.80087646 0.64587403]]
actor_loss: tensor(27.9936, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.0035, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.6073, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.7604, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1722.2399019646607, average reward:-8.611199509823303,----
Box_Position: [[1.37116676 0.85158578 0.60586951]]
actor_loss: tensor(28.3915, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3526, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.2677, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-1085.0362184385804, average reward:-8.893739495398199,success
Box_Position: [[1.28829055 0.9747244  0.55173484]]
Step:4, total reward:-59.5229899844402, average reward:-14.88074749611005,success
Box_Position: [[1.46087562 0.70919003 0.5027572 ]]
actor_loss: tensor(29.0697, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-603.8890321625751, average reward:-9.149833820645076,success
Box_Position: [[1.54937555 0.80675373 0.54523671]]
actor_loss: tensor(28.3956, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.9666, device='cuda:0', grad_fn=<NegBackward>)
Step:106, total reward:-979.6956001856408, average reward:-9.242411322506046,success
Box_Position: [[1.50152146 0.87977471 0.45475606]]

------------------Episode:1050------------------
actor_loss: tensor(27.8492, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.2202, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.3623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(31.3586, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1926.788285165754, average reward:-9.63394142582877,----
Box_Position: [[1.50463843 0.8814623  0.49311884]]
actor_loss: tensor(29.0834, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(29.8689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(30.2577, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.7122, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-1621.4167612230983, average reward:-8.717294415177948,success
Box_Position: [[1.32132987 0.96876933 0.53097147]]
Step:16, total reward:-149.43605613120172, average reward:-9.339753508200108,success
Box_Position: [[1.44191744 0.90447259 0.72161788]]
actor_loss: tensor(29.0773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.5885, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.3905, device='cuda:0', grad_fn=<NegBackward>)
Step:120, total reward:-1029.8211201333586, average reward:-8.581842667777988,success
Box_Position: [[1.41323067 0.77601697 0.64786314]]
actor_loss: tensor(27.3693, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-759.8305021651689, average reward:-11.340753763659238,success
Box_Position: [[1.37213619 0.91604165 0.45687119]]
Step:9, total reward:-91.67888578903947, average reward:-10.18654286544883,success
Box_Position: [[1.27077451 0.65003985 0.62067628]]
actor_loss: tensor(27.2162, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.7159, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.1100, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.6086, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1875.3909389667353, average reward:-9.376954694833676,----
Box_Position: [[1.47294787 0.97626564 0.60082287]]
actor_loss: tensor(27.6646, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.1064, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.3340, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.2938, device='cuda:0', grad_fn=<NegBackward>)
Step:179, total reward:-1587.2862220648817, average reward:-8.867520793658556,success
Box_Position: [[1.30519865 0.97257024 0.71287587]]
Step:23, total reward:-209.9496177192295, average reward:-9.128244248662153,success
Box_Position: [[1.35743407 0.93131946 0.72267299]]
actor_loss: tensor(26.7225, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.0313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.8672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.4596, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1883.9678427154267, average reward:-9.419839213577134,----
Box_Position: [[1.41990038 0.50421272 0.58173092]]
actor_loss: tensor(26.5112, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.0946, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.2563, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.2082, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1802.743729655888, average reward:-9.01371864827944,----
Box_Position: [[1.36413676 0.85696179 0.74724995]]
actor_loss: tensor(28.1157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.4285, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.9808, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5530, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1800.9937279689732, average reward:-9.004968639844867,----
Box_Position: [[1.54297652 0.75598814 0.55209987]]
actor_loss: tensor(26.3126, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.3770, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.1811, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.4676, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1781.5251391039067, average reward:-8.907625695519533,----
Box_Position: [[1.42816578 1.12941447 0.67763028]]
actor_loss: tensor(26.8134, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-410.0273571043599, average reward:-7.193462405339647,success
Box_Position: [[1.41135657 1.12897626 0.64740679]]
actor_loss: tensor(27.5019, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.2283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.2789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.4229, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2746.9248458099246, average reward:-13.734624229049622,----
Box_Position: [[1.28014124 0.74246006 0.47394254]]
actor_loss: tensor(27.3628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5574, device='cuda:0', grad_fn=<NegBackward>)
Step:81, total reward:-743.3084144631514, average reward:-9.17664709213767,success
Box_Position: [[1.51085503 0.86702509 0.68674212]]
actor_loss: tensor(27.1606, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-629.5168148491101, average reward:-8.393557531321468,success
Box_Position: [[1.43604604 0.96546226 0.61772727]]
actor_loss: tensor(25.7754, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.3776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.6154, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-1281.1966301351433, average reward:-9.022511479824953,success
Box_Position: [[1.28623397 0.75272158 0.63076853]]
actor_loss: tensor(26.3393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.5902, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.2536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5503, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1765.4275545580454, average reward:-8.827137772790227,----
Box_Position: [[1.3814068  0.98239133 0.73579381]]
actor_loss: tensor(25.8702, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.9907, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.8697, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.3883, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1747.751929092193, average reward:-8.738759645460965,----
Box_Position: [[1.52870513 0.61314587 0.59697299]]
actor_loss: tensor(27.4813, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.8089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.6795, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-1089.8387823543435, average reward:-8.718710258834747,success
Box_Position: [[1.39263279 0.78283482 0.60204122]]
actor_loss: tensor(26.4557, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-573.8763237052249, average reward:-9.407808585331555,success
Box_Position: [[1.42121362 0.79889836 0.55690445]]
Step:12, total reward:-95.84072195301319, average reward:-7.986726829417766,success
Box_Position: [[1.44578469 0.55099    0.5115837 ]]
actor_loss: tensor(25.5797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(28.4592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.1014, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-1215.2089908534524, average reward:-9.34776146810348,success
Box_Position: [[1.38640787 0.71563306 0.57278149]]
actor_loss: tensor(26.9839, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.9369, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.4030, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.8232, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-1564.1801167097178, average reward:-8.409570519944719,success
Box_Position: [[1.31433502 0.86353076 0.62493385]]
actor_loss: tensor(25.4282, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.9739, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.1434, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-1584.8652392889592, average reward:-8.903737299376175,success
Box_Position: [[1.25009198 0.73929604 0.53794159]]
actor_loss: tensor(24.9245, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-377.9215290886717, average reward:-8.998131644968375,success
Box_Position: [[1.542798   1.03936507 0.63538025]]
actor_loss: tensor(25.0718, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.9579, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.2530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.1824, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1853.4545792040904, average reward:-9.267272896020451,----
Box_Position: [[1.31248215 0.80051391 0.47875292]]
Step:4, total reward:-43.672897814690884, average reward:-10.918224453672721,success
Box_Position: [[1.53972034 0.7247563  0.53689834]]
actor_loss: tensor(24.0700, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-557.0477376218569, average reward:-9.441487078336557,success
Box_Position: [[1.32958634 0.62864465 0.62557225]]
actor_loss: tensor(26.6087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.3587, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.9565, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.3245, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1909.8809366444548, average reward:-9.549404683222274,----
Box_Position: [[1.48800711 0.73802859 0.65005665]]
actor_loss: tensor(25.8161, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-545.9183198781599, average reward:-8.665370156796188,success
Box_Position: [[1.44151402 0.71451369 0.52703959]]
actor_loss: tensor(24.3220, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-358.77221943140603, average reward:-8.750541937351366,success
Box_Position: [[1.47392415 0.75060836 0.59664576]]
actor_loss: tensor(26.6019, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-424.78679311164075, average reward:-8.849724856492516,success
Box_Position: [[1.32606354 0.90759397 0.46366081]]
Step:12, total reward:-166.51239385556755, average reward:-13.876032821297295,success
Box_Position: [[1.33923073 0.98476141 0.62812145]]
actor_loss: tensor(26.1193, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-208.56546001204387, average reward:-9.93168857200209,success
Box_Position: [[1.33217761 0.74996364 0.70607159]]
actor_loss: tensor(25.4853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(27.5849, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.2145, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.3472, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1783.5878930664169, average reward:-8.917939465332084,----
Box_Position: [[1.44721001 0.68145534 0.57767967]]
actor_loss: tensor(25.2399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.9442, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.1295, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.8642, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1725.9829666822745, average reward:-8.629914833411373,----
Box_Position: [[1.29018961 0.89057504 0.54093511]]
actor_loss: tensor(24.5592, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-528.8559479748408, average reward:-8.963660135166792,success
Box_Position: [[1.31787588 0.62608841 0.74089326]]
actor_loss: tensor(25.1063, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.4208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.9637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.4785, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1986.0015271398736, average reward:-9.930007635699369,----
Box_Position: [[1.53850704 0.57783641 0.66945334]]
actor_loss: tensor(26.5004, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-318.27745907990163, average reward:-8.60209348864599,success
Box_Position: [[1.27230886 0.86255502 0.55781344]]
actor_loss: tensor(25.6274, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-633.658538925046, average reward:-9.18345708587023,success
Box_Position: [[1.54480893 1.14890977 0.72258035]]
actor_loss: tensor(25.7431, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.5752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.4371, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.2270, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1705.9010859639602, average reward:-8.529505429819801,----
Box_Position: [[1.34389826 1.05584894 0.64317206]]
actor_loss: tensor(25.5720, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-494.3089339362372, average reward:-8.378117524343004,success
Box_Position: [[1.2835337  0.74382461 0.7158509 ]]
actor_loss: tensor(24.1245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.1475, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.6778, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(26.3052, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1987.7236499025935, average reward:-9.938618249512967,----
Box_Position: [[1.49440567 0.67983362 0.65267305]]
actor_loss: tensor(24.6532, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-261.10230418966495, average reward:-9.003527730678101,success
Box_Position: [[1.48091722 0.77527681 0.54100355]]
actor_loss: tensor(26.2936, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.3469, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.1845, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.4383, device='cuda:0', grad_fn=<NegBackward>)
Step:187, total reward:-1733.0253423114095, average reward:-9.267515199526255,success
Box_Position: [[1.48910801 0.68461344 0.74007143]]
actor_loss: tensor(23.0817, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.9324, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-958.892379913196, average reward:-8.797177797368771,success
Box_Position: [[1.26745604 0.64885289 0.47893258]]
actor_loss: tensor(24.6554, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.1873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.0004, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.5079, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1783.2004652700111, average reward:-8.916002326350055,----
Box_Position: [[1.31302482 0.79358003 0.64242141]]
actor_loss: tensor(23.5817, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.6168, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.6414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.3660, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1743.0805926387172, average reward:-8.715402963193586,----
Box_Position: [[1.4105997  0.81700796 0.46386836]]

------------------Episode:1100------------------
actor_loss: tensor(25.4742, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-389.8189692629975, average reward:-9.745474231574937,success
episode 1100, the accuracy is: 59%
Box_Position: [[1.3269091  1.0195404  0.73502608]]
Step:22, total reward:-202.58849635338973, average reward:-9.20856801606317,success
Box_Position: [[1.53796433 0.51151448 0.71628803]]
actor_loss: tensor(24.4675, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-403.7217274628139, average reward:-8.589823988570508,success
Box_Position: [[1.41886175 0.78759588 0.5807639 ]]
actor_loss: tensor(24.8446, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.9888, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.3183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.2717, device='cuda:0', grad_fn=<NegBackward>)
Step:179, total reward:-1550.7215461640621, average reward:-8.663248861251743,success
Box_Position: [[1.37140481 0.73484558 0.74556379]]
actor_loss: tensor(24.0022, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.4113, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.0792, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.2261, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2021.5580589400038, average reward:-10.107790294700019,----
Box_Position: [[1.36874249 0.68501249 0.50776125]]
actor_loss: tensor(22.4724, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-748.3889735455687, average reward:-8.909392542209151,success
Box_Position: [[1.47579268 0.85975734 0.46833481]]
actor_loss: tensor(24.6406, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-421.79061769973976, average reward:-8.435812353994795,success
Box_Position: [[1.43039791 0.92907738 0.66538069]]
actor_loss: tensor(23.2192, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-277.9092421500887, average reward:-7.9402640614311055,success
Box_Position: [[1.27135032 0.92891715 0.45014969]]
actor_loss: tensor(24.4534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.2707, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-720.2374839681397, average reward:-9.233813897027431,success
Box_Position: [[1.30049212 0.73118097 0.60888249]]
actor_loss: tensor(23.6628, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-433.1792781321684, average reward:-9.024568294420176,success
Box_Position: [[1.39511383 0.63351403 0.67166908]]
actor_loss: tensor(24.2261, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-654.471962760058, average reward:-9.21791496845152,success
Box_Position: [[1.26201907 0.84863361 0.52773211]]
Step:10, total reward:-74.6836162669448, average reward:-7.468361626694479,success
Box_Position: [[1.52303247 0.88409768 0.7205392 ]]
actor_loss: tensor(22.7006, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.1549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.9609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.5730, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1700.1158960154894, average reward:-8.500579480077446,----
Box_Position: [[1.44134384 0.62609143 0.64665503]]
actor_loss: tensor(22.4262, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.1321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.2268, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.3118, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1655.1911659412451, average reward:-8.275955829706225,----
Box_Position: [[1.50155196 0.96564239 0.69485185]]
Step:5, total reward:-61.973260496222295, average reward:-12.394652099244459,success
Box_Position: [[1.42730472 0.4628817  0.54051932]]
actor_loss: tensor(22.3471, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-442.1735865247734, average reward:-8.843471730495468,success
Box_Position: [[1.26230987 0.65633725 0.68247097]]
actor_loss: tensor(23.2607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.9246, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.4001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.3326, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2043.9241704040478, average reward:-10.219620852020238,----
Box_Position: [[1.27850206 1.19128439 0.51303829]]
actor_loss: tensor(22.9924, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.1708, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.6260, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.7502, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2439.002850017989, average reward:-12.195014250089946,----
Box_Position: [[1.31739638 0.70791776 0.58039964]]
actor_loss: tensor(22.7206, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7693, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.1438, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.8836, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-1550.8203199731531, average reward:-8.712473707714343,success
Box_Position: [[1.28485622 0.83717729 0.69221558]]
actor_loss: tensor(23.4678, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.6753, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.1728, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.5979, device='cuda:0', grad_fn=<NegBackward>)
Step:196, total reward:-1614.8245701780984, average reward:-8.238900868255604,success
Box_Position: [[1.4679265  0.89712448 0.691177  ]]
actor_loss: tensor(23.3825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.5895, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-765.5237838790604, average reward:-8.505819820878449,success
Box_Position: [[1.53473291 0.89430835 0.67776869]]
Step:16, total reward:-132.7319773988856, average reward:-8.29574858743035,success
Box_Position: [[1.26213487 1.0649579  0.56835992]]
actor_loss: tensor(23.2594, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.2637, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1613, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1359, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1510.8423411061892, average reward:-7.554211705530946,----
Box_Position: [[1.35874269 1.10076375 0.64693086]]
actor_loss: tensor(22.9325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.4673, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.2145, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.3103, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1534.7203600510247, average reward:-7.673601800255124,----
Box_Position: [[1.37996988 0.76475588 0.71770513]]
actor_loss: tensor(23.9086, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-367.25039061888526, average reward:-7.98370414388881,success
Box_Position: [[1.40528542 1.10351657 0.48944644]]
actor_loss: tensor(23.7560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.2540, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.1898, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.2748, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1839.5249510275935, average reward:-9.197624755137968,----
Box_Position: [[1.42351651 0.94898543 0.5579085 ]]
actor_loss: tensor(24.2752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.6990, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.9832, device='cuda:0', grad_fn=<NegBackward>)
Step:179, total reward:-1572.4433445390032, average reward:-8.784599690162029,success
Box_Position: [[1.27537154 0.75082371 0.69192625]]
actor_loss: tensor(23.1109, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.0672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.9603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(25.1910, device='cuda:0', grad_fn=<NegBackward>)
Step:170, total reward:-1502.1497558713302, average reward:-8.836175034537236,success
Box_Position: [[1.34721239 0.95522464 0.71867688]]
Step:7, total reward:-55.03849927677223, average reward:-7.862642753824604,success
Box_Position: [[1.45108608 0.97622437 0.67481282]]
Step:17, total reward:-157.97803219138595, average reward:-9.292825423022704,success
Box_Position: [[1.53320536 0.92230155 0.6415944 ]]
actor_loss: tensor(22.4984, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-328.86935894740196, average reward:-7.830222832080999,success
Box_Position: [[1.31953116 1.10088579 0.69368939]]
Step:14, total reward:-175.5884722808824, average reward:-12.542033734348744,success
Box_Position: [[1.43191557 0.90040318 0.66517766]]
actor_loss: tensor(22.3871, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.3292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.1809, device='cuda:0', grad_fn=<NegBackward>)
Step:127, total reward:-1083.9574393045768, average reward:-8.535097947280132,success
Box_Position: [[1.39811317 0.8585684  0.62215194]]
actor_loss: tensor(22.4791, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-417.87449308754407, average reward:-8.528050879337634,success
Box_Position: [[1.349834   0.51676998 0.70416001]]
actor_loss: tensor(23.2927, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.0405, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-726.6425060639561, average reward:-8.548735365458308,success
Box_Position: [[1.29411438 1.02635584 0.61580655]]
actor_loss: tensor(21.8291, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-797.8813723286089, average reward:-9.066833776461465,success
Box_Position: [[1.49304538 0.80202002 0.49201832]]
actor_loss: tensor(23.5843, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.5573, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.3807, device='cuda:0', grad_fn=<NegBackward>)
Step:144, total reward:-1235.6489427542951, average reward:-8.580895435793716,success
Box_Position: [[1.38226654 0.62271251 0.54689077]]
actor_loss: tensor(22.3487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.1154, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-883.0986739372822, average reward:-9.812207488192024,success
Box_Position: [[1.33749117 1.01306915 0.61560378]]
actor_loss: tensor(21.8561, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-385.3120469780515, average reward:-8.562489932845589,success
Box_Position: [[1.53327691 0.8901147  0.60925654]]
actor_loss: tensor(22.8045, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-325.9736418658456, average reward:-9.313532624738446,success
Box_Position: [[1.37252396 0.9019254  0.54674889]]
Step:16, total reward:-139.54808342544092, average reward:-8.721755214090058,success
Box_Position: [[1.45299104 0.59343341 0.51765135]]
actor_loss: tensor(21.6648, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.5196, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7978, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.0030, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1847.2348018623852, average reward:-9.236174009311926,----
Box_Position: [[1.48107734 1.05453701 0.51580736]]
actor_loss: tensor(23.0698, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7592, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.8472, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7720, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1697.3711955722613, average reward:-8.486855977861307,----
Box_Position: [[1.50298949 0.64608703 0.45616466]]
actor_loss: tensor(24.1932, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.4419, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.4320, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1075, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-1650.0197122375494, average reward:-8.593852667903903,success
Box_Position: [[1.2525252  0.96012307 0.54256208]]
actor_loss: tensor(21.3791, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0175, device='cuda:0', grad_fn=<NegBackward>)
Step:126, total reward:-1179.27602432291, average reward:-9.359333526372302,success
Box_Position: [[1.46173001 0.91073343 0.45177902]]
actor_loss: tensor(22.3292, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.2646, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.8498, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.9416, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1782.8419928270193, average reward:-8.914209964135097,----
Box_Position: [[1.35804744 0.74935473 0.69400633]]
Step:3, total reward:-20.0257800704304, average reward:-6.6752600234768,success
Box_Position: [[1.42379153 0.61099862 0.50774477]]
actor_loss: tensor(22.3863, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.4124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.6083, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0397, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1716.8078464377177, average reward:-8.584039232188589,----
Box_Position: [[1.26370896 0.51251972 0.47798914]]
actor_loss: tensor(23.0046, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(23.0774, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.4525, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(24.4590, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1730.2826050422573, average reward:-8.651413025211287,----
Box_Position: [[1.43976451 0.70964499 0.45599039]]
actor_loss: tensor(23.2208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.2132, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-757.5778943252998, average reward:-8.70779188879655,success
Box_Position: [[1.36391974 0.86550516 0.51782221]]

------------------Episode:1150------------------
actor_loss: tensor(21.8645, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-385.1178965878975, average reward:-9.39311942897311,success
Box_Position: [[1.377169   0.74510707 0.60600578]]
Step:17, total reward:-133.79332989837826, average reward:-7.870195876375192,success
Box_Position: [[1.29615234 0.81481099 0.52843131]]
actor_loss: tensor(22.3097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.3730, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.4383, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-1002.9549792078566, average reward:-8.646163613860832,success
Box_Position: [[1.34047521 0.59793791 0.59743454]]
actor_loss: tensor(21.7058, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.5104, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7535, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.1883, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1702.3402988766397, average reward:-8.511701494383198,----
Box_Position: [[1.49806429 0.80380671 0.47102809]]
Step:16, total reward:-164.04247460705108, average reward:-10.252654662940692,success
Box_Position: [[1.50217835 0.99902884 0.74129755]]
actor_loss: tensor(23.2350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.9737, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-720.3259612010022, average reward:-8.784462941475637,success
Box_Position: [[1.3777718  0.80973939 0.54458035]]
actor_loss: tensor(20.1895, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7432, device='cuda:0', grad_fn=<NegBackward>)
Step:135, total reward:-1104.3996618691567, average reward:-8.180738236067828,success
Box_Position: [[1.35294113 0.68562693 0.50678241]]
actor_loss: tensor(23.0152, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-205.15739556275207, average reward:-8.206295822510082,success
Box_Position: [[1.30486011 1.08637217 0.57131307]]
actor_loss: tensor(21.0794, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-581.0132159986492, average reward:-7.545626181800639,success
Box_Position: [[1.44839647 0.92476617 0.55494958]]
actor_loss: tensor(21.3721, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-297.09333808863516, average reward:-9.002828426928339,success
Box_Position: [[1.28329798 0.64748238 0.57208104]]
actor_loss: tensor(22.0719, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-485.0416084845842, average reward:-8.661457294367574,success
Box_Position: [[1.38579042 0.77408976 0.55913087]]
Step:20, total reward:-149.47500085360187, average reward:-7.473750042680093,success
Box_Position: [[1.31987735 0.64113223 0.66404318]]
actor_loss: tensor(22.6237, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-471.25824156480485, average reward:-8.891664935184997,success
Box_Position: [[1.45984701 0.7015883  0.51303286]]
actor_loss: tensor(23.1227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.7531, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-675.250906241156, average reward:-8.44063632801445,success
Box_Position: [[1.3507066  0.84355527 0.54862323]]
Step:8, total reward:-59.975694154179244, average reward:-7.4969617692724055,success
Box_Position: [[1.29206597 0.62617333 0.74498678]]
actor_loss: tensor(21.9783, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.6671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.5364, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.9105, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2040.0021514177652, average reward:-10.200010757088826,----
Box_Position: [[1.33449965 0.70790348 0.61918942]]
actor_loss: tensor(21.3376, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-484.3267836217319, average reward:-11.531590086231713,success
Box_Position: [[1.43032154 0.92823629 0.64305538]]
actor_loss: tensor(22.4404, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0765, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-703.3346648058169, average reward:-9.634721435696122,success
Box_Position: [[1.49776485 0.67755472 0.49051623]]
actor_loss: tensor(23.3084, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-636.3590591563564, average reward:-9.22259506023705,success
Box_Position: [[1.30108038 0.84762198 0.73849181]]
actor_loss: tensor(23.1401, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-664.8935014549071, average reward:-9.63613770224503,success
Box_Position: [[1.30822463 0.93436165 0.69745287]]
actor_loss: tensor(21.4036, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.9986, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0793, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.3464, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1688.1490414562577, average reward:-8.440745207281289,----
Box_Position: [[1.36916735 0.99395284 0.5958727 ]]
actor_loss: tensor(22.1654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1007, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-677.8943873531866, average reward:-9.415199824349815,success
Box_Position: [[1.28273024 0.70684998 0.63713761]]
actor_loss: tensor(21.9040, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.6988, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-801.8961666146743, average reward:-7.785399675870623,success
Box_Position: [[1.3349999  1.00718797 0.59408071]]
Step:6, total reward:-66.23720222472744, average reward:-11.03953370412124,success
Box_Position: [[1.48434336 0.70254493 0.4573627 ]]
actor_loss: tensor(22.9213, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.9925, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.9640, device='cuda:0', grad_fn=<NegBackward>)
Step:186, total reward:-1516.1214424375933, average reward:-8.151190550739749,success
Box_Position: [[1.33554809 0.49528585 0.49241969]]
actor_loss: tensor(21.9423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.2583, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.9737, device='cuda:0', grad_fn=<NegBackward>)
Step:156, total reward:-1306.0330503257362, average reward:-8.372006732857283,success
Box_Position: [[1.28738239 0.43425725 0.5430835 ]]
actor_loss: tensor(21.6119, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-592.9765567439149, average reward:-8.351782489350914,success
Box_Position: [[1.40618281 0.64739207 0.47658072]]
actor_loss: tensor(22.1998, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.6462, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.4740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0535, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1656.4146593787532, average reward:-8.282073296893765,----
Box_Position: [[1.49667278 1.02409287 0.47982467]]
actor_loss: tensor(21.1023, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.2356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.9084, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.3354, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1924.3523661630356, average reward:-9.621761830815178,----
Box_Position: [[1.30365518 1.04489996 0.73138916]]
actor_loss: tensor(20.7038, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.7746, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.7003, device='cuda:0', grad_fn=<NegBackward>)
Step:140, total reward:-1373.975237992321, average reward:-9.814108842802293,success
Box_Position: [[1.50339288 0.77920022 0.46870267]]
actor_loss: tensor(21.1056, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.1054, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.8220, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.4858, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1862.241128961061, average reward:-9.311205644805305,----
Box_Position: [[1.33591523 0.86736096 0.59356311]]
actor_loss: tensor(21.6732, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.4719, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.7343, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1316, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1591.9501612123697, average reward:-7.959750806061849,----
Box_Position: [[1.32987611 0.75155942 0.62882399]]
Step:13, total reward:-103.26089386457117, average reward:-7.9431456818900905,success
Box_Position: [[1.36800433 0.86050786 0.6987856 ]]
actor_loss: tensor(20.6118, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-339.84954321874426, average reward:-8.091655790922482,success
Box_Position: [[1.26516737 0.72400508 0.7235585 ]]
actor_loss: tensor(21.1234, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-459.6096789691031, average reward:-9.192193579382062,success
Box_Position: [[1.26600785 0.49450626 0.5819996 ]]
actor_loss: tensor(21.8257, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.5084, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.7572, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1072, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1749.8369854296616, average reward:-8.749184927148308,----
Box_Position: [[1.4416091  0.53437927 0.74887778]]
actor_loss: tensor(20.1011, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-265.05016297460566, average reward:-7.362504527072379,success
Box_Position: [[1.3862544  0.598866   0.69013877]]
actor_loss: tensor(21.0048, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0941, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.6377, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3419, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1936.6885483383285, average reward:-9.683442741691643,----
Box_Position: [[1.33726193 0.89676042 0.74790364]]
Step:13, total reward:-101.10894784524676, average reward:-7.77761137271129,success
Box_Position: [[1.45834412 0.98657664 0.56517619]]
actor_loss: tensor(20.5098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.3718, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.2020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3701, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-1921.7052694454496, average reward:-10.444050377420922,success
Box_Position: [[1.48939636 0.88069812 0.52481767]]
actor_loss: tensor(21.8258, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.6970, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.4495, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.1607, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1825.320895761604, average reward:-9.126604478808021,----
Box_Position: [[1.36240082 0.69629901 0.68767614]]
actor_loss: tensor(21.8427, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-600.6186334860979, average reward:-8.116468020082404,success
Box_Position: [[1.35476938 1.10310033 0.50481359]]
actor_loss: tensor(20.1880, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.0143, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.1585, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1617.3297825375873, average reward:-8.086648912687936,----
Box_Position: [[1.2535413  1.03110985 0.67953046]]
actor_loss: tensor(21.7958, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-431.7833058951267, average reward:-9.386593606415799,success
Box_Position: [[1.2733457  0.75331899 0.48038051]]
actor_loss: tensor(21.0634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.0763, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.9168, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1641.7556082492042, average reward:-8.20877804124602,success
Box_Position: [[1.41513586 0.62959434 0.74536645]]
Step:2, total reward:-14.186684271092815, average reward:-7.093342135546408,success
Box_Position: [[1.3894018  0.74054208 0.68035521]]
actor_loss: tensor(21.8702, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-340.2145994079387, average reward:-7.732149986544061,success
Box_Position: [[1.54545208 0.95979073 0.71121077]]
actor_loss: tensor(21.4694, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-260.19332004592644, average reward:-9.292618573068802,success
Box_Position: [[1.33949042 0.92992088 0.54689442]]
Step:4, total reward:-57.907551645318875, average reward:-14.476887911329719,success
Box_Position: [[1.42810221 0.72684763 0.72768794]]
actor_loss: tensor(20.1857, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.7061, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.9759, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1381.797187906115, average reward:-7.806763773480875,success
Box_Position: [[1.52769478 0.77013453 0.58840001]]

------------------Episode:1200------------------
actor_loss: tensor(20.0423, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-310.27038732121343, average reward:-8.38568614381658,success
episode 1200, the accuracy is: 76%
Box_Position: [[1.44236448 0.7695539  0.53912491]]
actor_loss: tensor(20.4145, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.2370, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.0635, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-1168.7874264377137, average reward:-8.230897369279674,success
Box_Position: [[1.53540629 0.97080009 0.47835139]]
actor_loss: tensor(20.6229, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1916, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.4128, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.0511, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1766.3541213467265, average reward:-8.831770606733633,----
Box_Position: [[1.38648729 0.86341042 0.6834386 ]]
actor_loss: tensor(19.3640, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.6133, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-708.1026985617642, average reward:-8.233752308857724,success
Box_Position: [[1.45074429 1.10474945 0.69690574]]
actor_loss: tensor(20.3819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.5047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.4097, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.9018, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1564.7092713417226, average reward:-7.823546356708613,----
Box_Position: [[1.53284189 0.94298953 0.50134916]]
actor_loss: tensor(21.4899, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.0521, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.0142, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.6051, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1718.592655513092, average reward:-8.59296327756546,----
Box_Position: [[1.25452034 1.14753997 0.69591046]]
actor_loss: tensor(21.0529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.3421, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.0439, device='cuda:0', grad_fn=<NegBackward>)
Step:180, total reward:-1169.4599181173096, average reward:-6.496999545096164,success
Box_Position: [[1.52443312 0.84458071 0.55885855]]
actor_loss: tensor(19.2628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.4046, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.0945, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.0793, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1646.3282559986246, average reward:-8.231641279993124,----
Box_Position: [[1.32205972 0.70123999 0.46942648]]
actor_loss: tensor(20.5641, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-467.258770309602, average reward:-8.495614005629127,success
Box_Position: [[1.46351966 0.62938559 0.45130163]]
actor_loss: tensor(21.6525, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.1246, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-589.0574724954697, average reward:-9.204023007741714,success
Box_Position: [[1.48413621 1.06922412 0.74350395]]
actor_loss: tensor(19.9357, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.2730, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.4550, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.0642, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1633.239657158263, average reward:-8.166198285791316,----
Box_Position: [[1.25712918 0.8824549  0.55437815]]
actor_loss: tensor(20.4879, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-563.2488349946944, average reward:-8.163026594126006,success
Box_Position: [[1.33293474 0.5024475  0.63314515]]
actor_loss: tensor(19.6387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.9847, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1476, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1611.069002160689, average reward:-8.055345010803444,----
Box_Position: [[1.35489078 0.83312533 0.62689599]]
Step:28, total reward:-216.6613668198851, average reward:-7.737905957853039,success
Box_Position: [[1.32454935 1.11505373 0.48630943]]
actor_loss: tensor(19.9925, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.8454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.5679, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1965, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1855.7231886604159, average reward:-9.278615943302079,----
Box_Position: [[1.42251164 0.65340174 0.51504976]]
actor_loss: tensor(20.3111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(21.1484, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.3031, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3538, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-1491.7429807056617, average reward:-8.107298808182945,success
Box_Position: [[1.38587385 1.1168071  0.63621494]]
actor_loss: tensor(20.2245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1887, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.9982, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-927.5386210225923, average reward:-7.860496788327054,success
Box_Position: [[1.2773723  0.71941451 0.65562435]]
Step:19, total reward:-140.0995102041063, average reward:-7.373658431795069,success
Box_Position: [[1.46402434 0.88685196 0.66398385]]
actor_loss: tensor(18.5225, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-480.9067455710031, average reward:-7.633440405888939,success
Box_Position: [[1.38166326 0.84315139 0.45071217]]
Step:4, total reward:-45.242498182340064, average reward:-11.310624545585016,success
Box_Position: [[1.53781312 1.00647292 0.59445457]]
actor_loss: tensor(19.3291, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.1283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.4671, device='cuda:0', grad_fn=<NegBackward>)
Step:128, total reward:-1099.1423151702636, average reward:-8.587049337267684,success
Box_Position: [[1.37947872 0.93257116 0.70921983]]
actor_loss: tensor(19.4740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.6060, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0874, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.3681, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-2771.075245815529, average reward:-13.855376229077644,----
Box_Position: [[1.35183093 0.61754644 0.4942617 ]]
actor_loss: tensor(20.6418, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.9058, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.5964, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-1366.3344543670382, average reward:-8.181643439323583,success
Box_Position: [[1.47961792 0.81085281 0.74711896]]
actor_loss: tensor(19.3328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.7236, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.2416, device='cuda:0', grad_fn=<NegBackward>)
Step:133, total reward:-978.5658687935869, average reward:-7.357638111229977,success
Box_Position: [[1.39883364 1.00882388 0.47149041]]
actor_loss: tensor(20.8739, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-443.1295218403846, average reward:-9.428287698731587,success
Box_Position: [[1.39649314 1.12628938 0.45389663]]
actor_loss: tensor(19.9562, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.8136, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.7242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.1772, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1825.0122494733419, average reward:-9.125061247366709,----
Box_Position: [[1.37737708 0.65333502 0.60938234]]
actor_loss: tensor(19.9745, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(22.3196, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-1113.9881769725794, average reward:-8.31334460427298,success
Box_Position: [[1.44879108 0.71982415 0.57374973]]
actor_loss: tensor(18.3171, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-391.1107742880962, average reward:-13.037025809603206,success
Box_Position: [[1.25770524 1.02847043 0.52274318]]
actor_loss: tensor(19.3098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.7662, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.5384, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.8259, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1865.230979607605, average reward:-9.326154898038025,----
Box_Position: [[1.32043888 0.94314904 0.50116861]]
actor_loss: tensor(19.2838, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.3645, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-780.2355968744816, average reward:-8.480821705157409,success
Box_Position: [[1.48754891 0.96280818 0.57821221]]
actor_loss: tensor(19.2126, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-660.170202933101, average reward:-8.573638999131182,success
Box_Position: [[1.43282955 0.97872232 0.66129789]]
actor_loss: tensor(19.7131, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-348.62822447671704, average reward:-8.715705611917926,success
Box_Position: [[1.54570307 0.88246975 0.55142359]]
actor_loss: tensor(19.9742, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.3018, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.1907, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0108, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1887.6106890012015, average reward:-9.438053445006007,----
Box_Position: [[1.46107883 0.72329079 0.60919812]]
Step:3, total reward:-19.66367788831821, average reward:-6.554559296106071,success
Box_Position: [[1.36157285 0.79210098 0.58625858]]
actor_loss: tensor(20.1407, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-241.29847235791166, average reward:-7.312074919936717,success
Box_Position: [[1.33360668 1.09325367 0.54376632]]
actor_loss: tensor(19.6632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.4677, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.6321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.2000, device='cuda:0', grad_fn=<NegBackward>)
Step:199, total reward:-1546.4024822613362, average reward:-7.7708667450318405,success
Box_Position: [[1.46365506 0.82642183 0.58571913]]
actor_loss: tensor(19.8325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.6884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.4291, device='cuda:0', grad_fn=<NegBackward>)
Step:133, total reward:-1064.4791130329402, average reward:-8.003602353631129,success
Box_Position: [[1.51048154 1.00344827 0.72154116]]
actor_loss: tensor(19.5285, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-628.7839831617235, average reward:-7.959290926097767,success
Box_Position: [[1.4945943  0.72394002 0.63274949]]
actor_loss: tensor(18.2129, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.4914, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.0872, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1386.828886184139, average reward:-7.835191447368017,success
Box_Position: [[1.30303664 0.45383371 0.50604498]]
actor_loss: tensor(20.4522, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2306, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.6165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8361, device='cuda:0', grad_fn=<NegBackward>)
Step:197, total reward:-1818.0122591347651, average reward:-9.22848862504957,success
Box_Position: [[1.53033424 0.80848439 0.55798742]]
actor_loss: tensor(19.3368, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.1714, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.6436, device='cuda:0', grad_fn=<NegBackward>)
Step:174, total reward:-1392.0571285593498, average reward:-8.000328325053735,success
Box_Position: [[1.27724619 0.85480233 0.71130475]]
actor_loss: tensor(18.2323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(20.2002, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-906.9871666684799, average reward:-8.805700647266795,success
Box_Position: [[1.25249243 1.10722414 0.61366973]]
actor_loss: tensor(18.6434, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-325.96240796845257, average reward:-8.149060199211315,success
Box_Position: [[1.3616494  0.89107224 0.70848882]]
actor_loss: tensor(19.8587, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-375.8845736809961, average reward:-7.22854949386531,success
Box_Position: [[1.31254067 0.93751251 0.65313866]]
actor_loss: tensor(18.9313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.5018, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.4626, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-1324.5696206363518, average reward:-9.07239466189282,success
Box_Position: [[1.30979964 0.70717907 0.50693368]]
actor_loss: tensor(20.3716, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-236.8607812513238, average reward:-7.401899414103869,success
Box_Position: [[1.28906756 0.43472568 0.45961231]]
Step:47, total reward:-364.0955965659728, average reward:-7.746714820552613,success
Box_Position: [[1.37366978 0.86508581 0.50277178]]
actor_loss: tensor(19.5619, device='cuda:0', grad_fn=<NegBackward>)
Step:6, total reward:-41.2132499174574, average reward:-6.8688749862429,success
Box_Position: [[1.32451058 0.62643254 0.45723684]]
Step:5, total reward:-45.34622463656099, average reward:-9.069244927312198,success
Box_Position: [[1.4370822  0.75749182 0.5287485 ]]
actor_loss: tensor(19.5566, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2615, device='cuda:0', grad_fn=<NegBackward>)
Step:102, total reward:-874.6106627232127, average reward:-8.574614340423654,success
Box_Position: [[1.26465133 0.53635076 0.50958781]]

------------------Episode:1250------------------
actor_loss: tensor(19.5244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0108, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.7861, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.6519, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1488.7030498955844, average reward:-7.443515249477922,----
Box_Position: [[1.33615427 0.804428   0.71595285]]
Step:27, total reward:-222.26941706672454, average reward:-8.23220063210091,success
Box_Position: [[1.51311704 1.1540327  0.60785989]]
actor_loss: tensor(18.2313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.7748, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.4078, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.9873, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1754.811576522536, average reward:-8.774057882612679,----
Box_Position: [[1.40805955 1.02145254 0.4567111 ]]
actor_loss: tensor(17.3389, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8726, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-764.5625528622247, average reward:-9.211597022436443,success
Box_Position: [[1.37146558 0.76515927 0.45900269]]
actor_loss: tensor(18.0969, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.1002, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-632.0058939548841, average reward:-7.6145288428299285,success
Box_Position: [[1.47150922 0.94651938 0.54031412]]
actor_loss: tensor(19.5756, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-633.4104579435875, average reward:-9.048720827765536,success
Box_Position: [[1.42866914 0.43756705 0.65889067]]
actor_loss: tensor(18.2299, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.3423, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-872.9625267388598, average reward:-8.817803300392523,success
Box_Position: [[1.48296053 0.68979513 0.56102818]]
actor_loss: tensor(17.9268, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-417.44726345943747, average reward:-6.62614703903869,success
Box_Position: [[1.54212493 0.45524122 0.47445297]]
actor_loss: tensor(17.7262, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0876, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.0566, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.3099, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1670.867791517061, average reward:-8.354338957585306,----
Box_Position: [[1.29715027 0.78244485 0.55179551]]
actor_loss: tensor(18.8078, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.5387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2308, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-1440.6454274708947, average reward:-7.387925269081511,success
Box_Position: [[1.47494287 0.78548528 0.67534879]]
Step:5, total reward:-45.733389461907464, average reward:-9.146677892381494,success
Box_Position: [[1.32594203 0.89043305 0.58217972]]
actor_loss: tensor(20.1058, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.1562, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-607.2157046032204, average reward:-8.674510065760291,success
Box_Position: [[1.3808713  0.71622029 0.51437725]]
Step:26, total reward:-192.1993050112324, average reward:-7.392280961970477,success
Box_Position: [[1.42541998 0.56264021 0.57749792]]
Step:14, total reward:-90.00662309588132, average reward:-6.429044506848666,success
Box_Position: [[1.50005503 0.60434064 0.73837662]]
actor_loss: tensor(16.9504, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.2755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8420, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.9673, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1632.1225513835582, average reward:-8.160612756917791,----
Box_Position: [[1.31274061 0.87528214 0.6629322 ]]
actor_loss: tensor(19.2408, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.3527, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2082, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-983.874412339738, average reward:-8.131193490411057,success
Box_Position: [[1.29240928 0.6191165  0.55037763]]
actor_loss: tensor(18.2904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.4995, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-920.5067061504402, average reward:-9.588611522400418,success
Box_Position: [[1.54147705 0.52575832 0.51838543]]
actor_loss: tensor(18.6646, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.3943, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.0876, device='cuda:0', grad_fn=<NegBackward>)
Step:171, total reward:-1437.1701084420438, average reward:-8.404503558140608,success
Box_Position: [[1.50380961 0.87289013 0.68712657]]
actor_loss: tensor(18.3039, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.5229, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-911.3682566324476, average reward:-9.2996760880862,success
Box_Position: [[1.30157744 1.08898659 0.52542289]]
actor_loss: tensor(17.7430, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-476.7903291413978, average reward:-9.169044791180728,success
Box_Position: [[1.27342652 0.71285188 0.7249986 ]]
actor_loss: tensor(18.9579, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.8654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0075, device='cuda:0', grad_fn=<NegBackward>)
Step:139, total reward:-950.9878549163359, average reward:-6.841639244002416,success
Box_Position: [[1.40352278 0.54334207 0.55228531]]
Step:21, total reward:-150.2797200582259, average reward:-7.156177145629805,success
Box_Position: [[1.50600438 0.80622205 0.62215152]]
actor_loss: tensor(18.3268, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-373.19838272666306, average reward:-8.113008320144848,success
Box_Position: [[1.47254622 0.74395458 0.73982803]]
actor_loss: tensor(18.4455, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.6779, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.8020, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1654.9809585543505, average reward:-8.274904792771753,----
Box_Position: [[1.48769241 0.58621915 0.58023466]]
actor_loss: tensor(17.6265, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.1549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.9872, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.7717, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1494.040280082717, average reward:-7.470201400413584,----
Box_Position: [[1.29287357 0.79153934 0.45535312]]
actor_loss: tensor(17.9092, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-263.0528851709616, average reward:-8.485576940998762,success
Box_Position: [[1.27213026 1.13330128 0.72105268]]
Step:16, total reward:-96.80008399373676, average reward:-6.050005249608548,success
Box_Position: [[1.51459164 0.88871252 0.61651354]]
actor_loss: tensor(17.4581, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8992, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-863.6421142541483, average reward:-7.996686243093966,success
Box_Position: [[1.4661084  0.57015025 0.57632294]]
actor_loss: tensor(18.3484, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2487, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-452.5788916848055, average reward:-6.962752179766238,success
Box_Position: [[1.48123616 0.67579146 0.53727315]]
actor_loss: tensor(17.3305, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.5766, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-770.5123120718263, average reward:-7.6288347729883785,success
Box_Position: [[1.35975363 0.66582069 0.68750761]]
actor_loss: tensor(17.6182, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.0206, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.1492, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.1095, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1689.1524775564872, average reward:-8.445762387782436,----
Box_Position: [[1.29774866 0.75894859 0.66127988]]
Step:37, total reward:-332.0244786244182, average reward:-8.973634557416707,success
Box_Position: [[1.28258056 0.9690704  0.56239692]]
actor_loss: tensor(17.7244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8629, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-1169.4674082111571, average reward:-8.72736871799371,success
Box_Position: [[1.33347558 0.60455037 0.59567268]]
actor_loss: tensor(17.8751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8262, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.3070, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(19.0668, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-1487.5240389784628, average reward:-7.628328405017758,success
Box_Position: [[1.39171453 0.53951688 0.55033376]]
actor_loss: tensor(17.3650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.9882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8088, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1527.082681649667, average reward:-7.6354134082483345,----
Box_Position: [[1.42253386 0.9285482  0.51280702]]
actor_loss: tensor(18.6291, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-221.7248774147652, average reward:-7.9187456219559,success
Box_Position: [[1.51793955 0.82265441 0.45609814]]
Step:22, total reward:-164.89918385725025, average reward:-7.49541744805683,success
Box_Position: [[1.3818817  0.83215155 0.66277908]]
actor_loss: tensor(18.9101, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-343.4759000554369, average reward:-7.806270455805384,success
Box_Position: [[1.35816908 0.9732042  0.63909856]]
actor_loss: tensor(17.4444, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-250.29988819742587, average reward:-8.343329606580863,success
Box_Position: [[1.43502472 0.91192115 0.69723431]]
actor_loss: tensor(17.9745, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.7222, device='cuda:0', grad_fn=<NegBackward>)
Step:141, total reward:-1168.3026987640785, average reward:-8.28583474300765,success
Box_Position: [[1.26486442 0.69742835 0.6176461 ]]
actor_loss: tensor(17.5680, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-372.56196818187817, average reward:-7.164653234266888,success
Box_Position: [[1.27705862 1.09458284 0.71512372]]
actor_loss: tensor(17.2890, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-157.9898691278829, average reward:-8.77721495154905,success
Box_Position: [[1.46863974 0.74339964 0.74910415]]
Step:2, total reward:-17.97714212251725, average reward:-8.988571061258625,success
Box_Position: [[1.53161863 0.6580222  0.71018131]]
actor_loss: tensor(16.6448, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.7398, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.1708, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.2112, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1663.8033052853914, average reward:-8.319016526426957,----
Box_Position: [[1.31292688 0.74299397 0.51276491]]
actor_loss: tensor(18.5862, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.5575, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-974.4747447167782, average reward:-7.554067788502157,success
Box_Position: [[1.51936604 0.85290894 0.73123439]]
actor_loss: tensor(17.5169, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.7268, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.6098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.7663, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1484.33085292021, average reward:-7.42165426460105,----
Box_Position: [[1.44260308 0.75379492 0.47973941]]
actor_loss: tensor(17.0285, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-97.60703797596493, average reward:-8.133919831330411,success
Box_Position: [[1.3565959  0.77908443 0.46579855]]
Step:35, total reward:-298.96983187346325, average reward:-8.541995196384665,success
Box_Position: [[1.25414418 0.64917039 0.48895764]]
actor_loss: tensor(18.5933, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-449.33795874768066, average reward:-7.747206185304839,success
Box_Position: [[1.31932226 0.71946776 0.54338238]]
actor_loss: tensor(18.8972, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-163.04972924849082, average reward:-8.152486462424541,success
Box_Position: [[1.37575494 0.8820806  0.46135881]]

------------------Episode:1300------------------
Step:8, total reward:-68.25469111198557, average reward:-8.531836388998196,success
episode 1300, the accuracy is: 79%
Box_Position: [[1.44299481 0.62302615 0.65666788]]
actor_loss: tensor(16.9913, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.9128, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.8303, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.0818, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1754.5070464735031, average reward:-8.772535232367515,----
Box_Position: [[1.42851819 0.56714261 0.47710746]]
actor_loss: tensor(17.5346, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-305.54198104906754, average reward:-9.258847910577805,success
Box_Position: [[1.33003962 0.90911105 0.59679273]]
Step:7, total reward:-75.98472013999412, average reward:-10.85496001999916,success
Box_Position: [[1.41334678 0.81236498 0.46872803]]
actor_loss: tensor(16.7557, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.0164, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.4859, device='cuda:0', grad_fn=<NegBackward>)
Step:169, total reward:-1252.128576913341, average reward:-7.409044833806751,success
Box_Position: [[1.26880273 0.7778311  0.4774635 ]]
actor_loss: tensor(15.8435, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.4749, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.9001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.1196, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1619.4449391516869, average reward:-8.097224695758435,----
Box_Position: [[1.34677937 1.0527022  0.51127592]]
actor_loss: tensor(18.0235, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-318.63102485269167, average reward:-8.611649320343018,success
Box_Position: [[1.35555707 0.88618214 0.63688496]]
actor_loss: tensor(16.4347, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.8195, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.8939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.5480, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1587.825550790003, average reward:-7.939127753950015,----
Box_Position: [[1.26576575 0.80665834 0.65349229]]
actor_loss: tensor(18.7198, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.2741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.0644, device='cuda:0', grad_fn=<NegBackward>)
Step:133, total reward:-998.39695290913, average reward:-7.506744006835564,success
Box_Position: [[1.36159218 1.05464852 0.56614823]]
Step:8, total reward:-97.44874588506146, average reward:-12.181093235632682,success
Box_Position: [[1.26220525 0.55835637 0.56679097]]
actor_loss: tensor(16.4478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.9979, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.9303, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.8224, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1557.3481769447176, average reward:-7.786740884723588,----
Box_Position: [[1.51777846 0.8918996  0.46504033]]
Step:7, total reward:-76.4108240705622, average reward:-10.915832010080313,success
Box_Position: [[1.33579138 0.77733617 0.51895249]]
actor_loss: tensor(16.8074, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.0198, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.9880, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.6672, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1602.2881336549476, average reward:-8.011440668274737,----
Box_Position: [[1.51293131 0.89245703 0.57851889]]
actor_loss: tensor(16.6491, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-457.1501758467555, average reward:-7.748308065199246,success
Box_Position: [[1.5327163  1.08160492 0.56544665]]
actor_loss: tensor(17.3760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.9459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.2131, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.3446, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1758.9705228237983, average reward:-8.79485261411899,----
Box_Position: [[1.40920407 0.74284363 0.60968957]]
Step:19, total reward:-141.04169948008158, average reward:-7.423247341056925,success
Box_Position: [[1.37178662 0.72329245 0.46654117]]
actor_loss: tensor(16.7001, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-333.8634549603557, average reward:-7.419187888007904,success
Box_Position: [[1.37662808 0.67243102 0.61563459]]
actor_loss: tensor(17.5847, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.2563, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-620.5965012352051, average reward:-7.133293117646035,success
Box_Position: [[1.51497037 0.96422059 0.71503511]]
actor_loss: tensor(17.3296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.9504, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.0635, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.1432, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1480.4575175162124, average reward:-7.402287587581062,----
Box_Position: [[1.48754123 0.98257559 0.55710224]]
actor_loss: tensor(16.9938, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.5996, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-493.7719487841146, average reward:-7.156115199769777,success
Box_Position: [[1.45872321 0.89696056 0.54488355]]
actor_loss: tensor(16.2379, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-750.7004482513111, average reward:-8.159787480992511,success
Box_Position: [[1.34102696 0.85757176 0.5837373 ]]
actor_loss: tensor(17.9801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.6498, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-842.1769301017463, average reward:-8.020732667635679,success
Box_Position: [[1.39299437 0.67130504 0.68229415]]
actor_loss: tensor(16.7941, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.6852, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.0543, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.0869, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1759.8878400674348, average reward:-8.799439200337174,----
Box_Position: [[1.25356076 0.84244985 0.72656378]]
actor_loss: tensor(18.1130, device='cuda:0', grad_fn=<NegBackward>)
Step:7, total reward:-54.078440398790065, average reward:-7.725491485541438,success
Box_Position: [[1.39994559 0.72156672 0.71171403]]
Step:1, total reward:-8.598029413730886, average reward:-8.598029413730886,success
Box_Position: [[1.36826637 0.86471501 0.62493253]]
actor_loss: tensor(17.6961, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.5244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.4620, device='cuda:0', grad_fn=<NegBackward>)
Step:173, total reward:-1288.1992064683645, average reward:-7.446238187678408,success
Box_Position: [[1.36746932 0.67948146 0.54511987]]
Step:9, total reward:-54.54001974666749, average reward:-6.0600021940741655,success
Box_Position: [[1.40172428 0.94181247 0.47352079]]
actor_loss: tensor(18.5582, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-518.5680565604936, average reward:-8.642800942674892,success
Box_Position: [[1.50282533 0.98199582 0.5954126 ]]
actor_loss: tensor(17.1839, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(18.4734, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-590.0615085889518, average reward:-9.219711071702372,success
Box_Position: [[1.27493571 0.90180701 0.50625957]]
actor_loss: tensor(16.6621, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.3808, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-991.6152339923307, average reward:-8.933470576507483,success
Box_Position: [[1.32322913 0.90703904 0.70889063]]
actor_loss: tensor(16.8275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.4986, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-574.4736877642904, average reward:-7.18092109705363,success
Box_Position: [[1.40817257 1.04552765 0.61639169]]
Step:35, total reward:-317.34507080472525, average reward:-9.06700202299215,success
Box_Position: [[1.38195861 0.66056406 0.60675361]]
actor_loss: tensor(16.3437, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.6644, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.9246, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.7905, device='cuda:0', grad_fn=<NegBackward>)
Step:169, total reward:-1355.1353829566465, average reward:-8.018552561873648,success
Box_Position: [[1.36316447 0.621156   0.55580804]]
Step:13, total reward:-125.26233845978157, average reward:-9.635564496906275,success
Box_Position: [[1.27033676 0.9224694  0.60875313]]
actor_loss: tensor(15.4598, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.3880, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.2249, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1367.5355523289147, average reward:-7.726189561180309,success
Box_Position: [[1.37946869 0.45553856 0.5480818 ]]
actor_loss: tensor(16.9975, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.2476, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.2648, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-1101.5386663673496, average reward:-8.53905942920426,success
Box_Position: [[1.43202351 0.72231776 0.46623312]]
actor_loss: tensor(17.9372, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-197.98776535386827, average reward:-7.9195106141547305,success
Box_Position: [[1.3292943  0.88530699 0.68581063]]
Step:23, total reward:-184.800254861155, average reward:-8.034793689615435,success
Box_Position: [[1.25407426 0.80662771 0.50641993]]
actor_loss: tensor(16.2676, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.8172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.8369, device='cuda:0', grad_fn=<NegBackward>)
Step:143, total reward:-1206.3540296028152, average reward:-8.436042165054651,success
Box_Position: [[1.31978276 0.56620182 0.4660325 ]]
actor_loss: tensor(16.5036, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.4546, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.9077, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.5222, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1798.5246469541348, average reward:-8.992623234770674,----
Box_Position: [[1.29664638 0.73724207 0.7039658 ]]
actor_loss: tensor(16.5900, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.6961, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.6269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.4444, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1739.5634675215151, average reward:-8.697817337607576,----
Box_Position: [[1.32628926 0.62213711 0.71787373]]
actor_loss: tensor(16.1539, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.2233, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.7065, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.9307, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1804.9022648929401, average reward:-9.0245113244647,----
Box_Position: [[1.37121492 0.56351389 0.69895814]]
actor_loss: tensor(16.6230, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.1666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(17.1364, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.3089, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1673.7366839174576, average reward:-8.368683419587288,----
Box_Position: [[1.39046676 1.11145815 0.69758074]]
actor_loss: tensor(15.7812, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.7332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.4396, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.5134, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1379.3434891601778, average reward:-6.896717445800889,----
Box_Position: [[1.40516956 0.92334737 0.52515352]]
actor_loss: tensor(15.9223, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-543.487783589261, average reward:-8.626790215702554,success
Box_Position: [[1.35938933 0.84305621 0.59623841]]
actor_loss: tensor(15.2833, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.8440, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-896.1310818638866, average reward:-7.594331202236327,success
Box_Position: [[1.41547057 0.89635594 0.51146439]]
actor_loss: tensor(16.2335, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.4963, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-540.2843438902075, average reward:-8.063945431197128,success
Box_Position: [[1.53731499 0.65248373 0.67946899]]
actor_loss: tensor(16.4760, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-542.0825386482004, average reward:-8.339731363818467,success
Box_Position: [[1.4970218  0.74919549 0.69699536]]
actor_loss: tensor(15.1422, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-451.64045284230724, average reward:-8.211644597132858,success
Box_Position: [[1.28695641 0.67662411 0.74838571]]
actor_loss: tensor(15.5309, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.6952, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.3452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.9554, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1902.9977461629026, average reward:-9.514988730814514,----
Box_Position: [[1.4962669  0.44804091 0.67970285]]

------------------Episode:1350------------------
actor_loss: tensor(15.9590, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-136.30796132072325, average reward:-8.01811537180725,success
Box_Position: [[1.34294225 0.8859714  0.5151948 ]]
Step:24, total reward:-190.7846826082186, average reward:-7.9493617753424415,success
Box_Position: [[1.49078405 0.77960755 0.46463182]]
actor_loss: tensor(16.2072, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-571.8934680328199, average reward:-8.05483757792704,success
Box_Position: [[1.30476982 0.91024398 0.72891801]]
actor_loss: tensor(16.3295, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-184.76314141450752, average reward:-9.238157070725375,success
Box_Position: [[1.28458538 0.72119053 0.51651039]]
Step:11, total reward:-109.14518447666812, average reward:-9.92228949787892,success
Box_Position: [[1.29398818 0.77932415 0.6544102 ]]
actor_loss: tensor(15.8067, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.3031, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-498.01108303011455, average reward:-6.729879500406954,success
Box_Position: [[1.36519477 0.58677326 0.59361925]]
actor_loss: tensor(14.8892, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.3301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.5141, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.3560, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1633.9488534415486, average reward:-8.169744267207744,----
Box_Position: [[1.43195637 0.94998691 0.71178128]]
actor_loss: tensor(16.1817, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.6430, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-1026.896352958386, average reward:-7.441277919988304,success
Box_Position: [[1.36937319 0.94503507 0.49234085]]
actor_loss: tensor(15.1921, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-168.23716550522005, average reward:-8.854587658169477,success
Box_Position: [[1.52496572 0.57529338 0.62791323]]
Step:9, total reward:-86.24978452413592, average reward:-9.583309391570658,success
Box_Position: [[1.30340494 0.78853979 0.56196405]]
actor_loss: tensor(14.9581, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-353.2967314770748, average reward:-8.411826939930352,success
Box_Position: [[1.33353252 1.05527879 0.5192189 ]]
Step:20, total reward:-173.26246962955628, average reward:-8.663123481477815,success
Box_Position: [[1.53246316 0.48691043 0.55975619]]
actor_loss: tensor(15.4960, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-269.30949703826656, average reward:-8.160893849644442,success
Box_Position: [[1.38536794 1.01293323 0.73478025]]
actor_loss: tensor(15.4085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.2120, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.7562, device='cuda:0', grad_fn=<NegBackward>)
Step:175, total reward:-1203.4052957414533, average reward:-6.876601689951162,success
Box_Position: [[1.25949929 0.72605108 0.62975381]]
actor_loss: tensor(15.1987, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.8493, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-775.4213734428477, average reward:-7.246928723764931,success
Box_Position: [[1.5462879  0.79664204 0.47960188]]
actor_loss: tensor(16.1170, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.3186, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-549.9053361984905, average reward:-8.728656130134771,success
Box_Position: [[1.47754359 0.74743602 0.4913753 ]]
actor_loss: tensor(15.4845, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.2226, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(16.0454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.6333, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1590.4606740653805, average reward:-7.952303370326903,----
Box_Position: [[1.4540131  0.77657168 0.73975823]]
actor_loss: tensor(15.3474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.9992, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.5035, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1514.7106872970505, average reward:-8.557687498853392,success
Box_Position: [[1.51927396 0.59353864 0.61009049]]
actor_loss: tensor(15.4997, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.1115, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-578.0865812516522, average reward:-8.142064524671158,success
Box_Position: [[1.46700857 0.94310785 0.5260801 ]]
actor_loss: tensor(15.2807, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-453.5543317112332, average reward:-9.071086634224663,success
Box_Position: [[1.40659667 0.94814395 0.56074934]]
actor_loss: tensor(14.9589, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.7687, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-948.357233169605, average reward:-8.863151711865468,success
Box_Position: [[1.46789995 0.74182412 0.72537353]]
actor_loss: tensor(15.3382, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-333.1087856885315, average reward:-8.54125091509055,success
Box_Position: [[1.28438902 0.60386994 0.52370165]]
Step:30, total reward:-251.11745752495355, average reward:-8.370581917498452,success
Box_Position: [[1.50839119 0.9178082  0.6005631 ]]
actor_loss: tensor(15.0130, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.4119, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-632.6992078114325, average reward:-9.169553736397573,success
Box_Position: [[1.42408704 0.64826222 0.66738115]]
actor_loss: tensor(14.9486, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.2121, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.6019, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.8124, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1643.8978316662817, average reward:-8.219489158331408,----
Box_Position: [[1.25852592 0.72987228 0.56604128]]
Step:21, total reward:-152.57961752311263, average reward:-7.265696072529173,success
Box_Position: [[1.34676835 0.93075972 0.49337468]]
actor_loss: tensor(13.8678, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-485.0393999994313, average reward:-8.81889818180784,success
Box_Position: [[1.28803539 0.68094689 0.72606994]]
Step:10, total reward:-66.26617407215173, average reward:-6.626617407215173,success
Box_Position: [[1.41698154 0.94127639 0.63322953]]
actor_loss: tensor(14.9745, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.9339, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-875.5701639782267, average reward:-8.182898728768473,success
Box_Position: [[1.50643351 0.5781113  0.56176506]]
actor_loss: tensor(15.4201, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.0869, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.2681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.8502, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1632.4048927248127, average reward:-8.162024463624064,----
Box_Position: [[1.31399246 0.90219237 0.62725632]]
actor_loss: tensor(14.8781, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.4029, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-543.0000510038185, average reward:-7.438356863066007,success
Box_Position: [[1.5188717  1.05037722 0.71633533]]
actor_loss: tensor(13.9099, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.2558, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.4210, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.8278, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1498.2370178550193, average reward:-7.491185089275096,----
Box_Position: [[1.49901675 0.57562333 0.61531834]]
actor_loss: tensor(14.8734, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-329.7645848014843, average reward:-9.160127355596787,success
Box_Position: [[1.42503225 0.76009857 0.68868107]]
actor_loss: tensor(12.9814, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.4187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.0744, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.1234, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1613.1360626619594, average reward:-8.065680313309796,----
Box_Position: [[1.53530664 0.45615513 0.70417569]]
actor_loss: tensor(14.4503, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-563.7976829437821, average reward:-7.723255930736741,success
Box_Position: [[1.29270877 1.07761331 0.49702021]]
Step:18, total reward:-163.80609553579544, average reward:-9.100338640877524,success
Box_Position: [[1.40606024 1.0512318  0.58162069]]
Step:6, total reward:-59.088504698045014, average reward:-9.848084116340836,success
Box_Position: [[1.48261253 0.91168669 0.57906541]]
actor_loss: tensor(14.0164, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.2093, device='cuda:0', grad_fn=<NegBackward>)
Step:93, total reward:-789.5494668153333, average reward:-8.4897792130681,success
Box_Position: [[1.37086008 0.73667162 0.47474877]]
actor_loss: tensor(14.2245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.5589, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.3819, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.3608, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1896.5930184245067, average reward:-9.482965092122534,----
Box_Position: [[1.48521773 0.4427912  0.48453287]]
actor_loss: tensor(13.7502, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(15.3775, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-572.5453133664985, average reward:-8.297758164731862,success
Box_Position: [[1.3481876  0.81747244 0.54776302]]
actor_loss: tensor(13.8581, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-632.9211096110923, average reward:-7.911513870138654,success
Box_Position: [[1.52496012 1.05663796 0.49573948]]
actor_loss: tensor(13.9752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.3768, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.2796, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4407, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1919.0653258727484, average reward:-9.595326629363742,----
Box_Position: [[1.37162895 0.90842349 0.55537785]]
actor_loss: tensor(13.6091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.5651, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-727.0126826572949, average reward:-9.202692185535378,success
Box_Position: [[1.50904778 0.50133701 0.49911017]]
actor_loss: tensor(14.6292, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-279.48286144849476, average reward:-7.763412818013744,success
Box_Position: [[1.54445274 1.08583512 0.57366129]]
actor_loss: tensor(14.8072, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.0475, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.8517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.1723, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1815.5424732713316, average reward:-9.077712366356657,----
Box_Position: [[1.51895657 0.681869   0.68641525]]
actor_loss: tensor(13.4049, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.0214, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.0121, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.6223, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1384.0815148774893, average reward:-6.920407574387447,----
Box_Position: [[1.38032092 0.93254222 0.60179773]]
actor_loss: tensor(14.3144, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.7647, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.6483, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.6068, device='cuda:0', grad_fn=<NegBackward>)
Step:198, total reward:-1376.1319979500431, average reward:-6.950161605808298,success
Box_Position: [[1.45118692 0.72222065 0.58329271]]
actor_loss: tensor(13.8651, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.7254, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.8781, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.3040, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1632.549493508851, average reward:-8.162747467544255,----
Box_Position: [[1.32370731 1.10003536 0.6556426 ]]
actor_loss: tensor(13.4124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.4703, device='cuda:0', grad_fn=<NegBackward>)
Step:97, total reward:-1046.151366564742, average reward:-10.785065634688062,success
Box_Position: [[1.35724531 0.90146701 0.64862992]]
Step:15, total reward:-134.16358257607357, average reward:-8.944238838404905,success
Box_Position: [[1.46580413 0.92537076 0.72505203]]

------------------Episode:1400------------------
actor_loss: tensor(13.4494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5147, device='cuda:0', grad_fn=<NegBackward>)
Step:117, total reward:-868.6673489554772, average reward:-7.42450725602972,success
episode 1400, the accuracy is: 75%
Box_Position: [[1.27100068 0.95719573 0.5784446 ]]
actor_loss: tensor(13.8244, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-179.86557417961208, average reward:-7.1946229671844835,success
Box_Position: [[1.38246175 0.60671796 0.58692063]]
actor_loss: tensor(12.5850, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.0677, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(14.3085, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1697.1621464161344, average reward:-8.485810732080672,----
Box_Position: [[1.39162993 0.90997907 0.6026829 ]]
Step:13, total reward:-104.91964100701031, average reward:-8.07074161592387,success
Box_Position: [[1.52779587 0.63939372 0.52466488]]
Step:8, total reward:-56.79608896888688, average reward:-7.09951112111086,success
Box_Position: [[1.40392657 0.62390096 0.61198869]]
actor_loss: tensor(13.7556, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.9776, device='cuda:0', grad_fn=<NegBackward>)
Step:95, total reward:-755.9964677338929, average reward:-7.95785755509361,success
Box_Position: [[1.53453983 0.83321481 0.52951924]]
actor_loss: tensor(13.0627, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.8542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.2893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4486, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1646.702185505113, average reward:-8.233510927525565,----
Box_Position: [[1.42929231 0.87314375 0.51679996]]
Step:21, total reward:-165.43718502814048, average reward:-7.877961191816214,success
Box_Position: [[1.31548089 0.62975865 0.48389769]]
actor_loss: tensor(14.3655, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.2126, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.3990, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-1241.8911344745677, average reward:-9.935129075796542,success
Box_Position: [[1.44063255 0.69521699 0.73420584]]
actor_loss: tensor(14.0245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.9966, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5486, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1624.7275480101591, average reward:-8.123637740050796,----
Box_Position: [[1.35493827 1.03784266 0.46469302]]
actor_loss: tensor(14.2218, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-253.82841160633947, average reward:-8.460947053544649,success
Box_Position: [[1.51210411 0.84837411 0.57269148]]
actor_loss: tensor(13.2398, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5961, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4329, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-1231.7836818529468, average reward:-7.998595336707447,success
Box_Position: [[1.25549852 0.70669938 0.64062562]]
Step:1, total reward:-4.300947319298729, average reward:-4.300947319298729,success
Box_Position: [[1.38498312 0.82065124 0.46435222]]
actor_loss: tensor(12.7343, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-508.7860442289509, average reward:-8.479767403815849,success
Box_Position: [[1.42876753 1.12263555 0.6612743 ]]
actor_loss: tensor(12.8035, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.3549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.0502, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1383.9220313376763, average reward:-6.919610156688382,----
Box_Position: [[1.40577765 0.87970521 0.54962418]]
Step:25, total reward:-157.90616750759733, average reward:-6.316246700303894,success
Box_Position: [[1.53175635 1.02374053 0.69158834]]
actor_loss: tensor(14.0483, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5159, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5451, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-792.3155930265675, average reward:-6.950136780934803,success
Box_Position: [[1.35459305 0.89747736 0.5716736 ]]
actor_loss: tensor(13.6126, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-686.9708295199413, average reward:-8.178224160951682,success
Box_Position: [[1.25627285 1.13433086 0.69266597]]
actor_loss: tensor(14.1048, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-138.12005991205703, average reward:-6.278184541457137,success
Box_Position: [[1.26835904 0.54098721 0.62892698]]
Step:3, total reward:-21.871966899065463, average reward:-7.290655633021821,success
Box_Position: [[1.35843905 0.71101078 0.53572049]]
Step:10, total reward:-87.06892885090151, average reward:-8.706892885090152,success
Box_Position: [[1.46937669 0.85626207 0.74216843]]
Step:11, total reward:-80.9651788888129, average reward:-7.3604708080739,success
Box_Position: [[1.27430447 1.07447049 0.61605995]]
actor_loss: tensor(12.5016, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8897, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-582.8547251025283, average reward:-8.447169929022149,success
Box_Position: [[1.31301925 0.70311395 0.56999788]]
actor_loss: tensor(13.9171, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.3653, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.3136, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-1443.0594479046842, average reward:-8.641074538351402,success
Box_Position: [[1.47484751 0.72055115 0.61481877]]
actor_loss: tensor(12.4440, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.6543, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.7801, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1389.1255450829156, average reward:-6.945627725414578,----
Box_Position: [[1.3412171  0.75659881 0.4909497 ]]
actor_loss: tensor(13.5074, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.9653, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8653, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7422, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1706.8713784239667, average reward:-8.534356892119833,----
Box_Position: [[1.35349694 0.97022904 0.52910615]]
actor_loss: tensor(13.8575, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8544, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-990.6850182593519, average reward:-8.540388088442688,success
Box_Position: [[1.35240914 0.74717949 0.58631923]]
actor_loss: tensor(12.6007, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-422.2416007926498, average reward:-6.810348399881449,success
Box_Position: [[1.52559984 0.78487759 0.64603409]]
actor_loss: tensor(13.0432, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-243.75367496193627, average reward:-8.705488391497724,success
Box_Position: [[1.51525355 0.83975755 0.61057746]]
actor_loss: tensor(12.1629, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6757, device='cuda:0', grad_fn=<NegBackward>)
Step:170, total reward:-1156.076999519125, average reward:-6.800452938347793,success
Box_Position: [[1.37399135 0.74161678 0.59712072]]
actor_loss: tensor(13.1173, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6956, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.6148, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6560, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1561.1690786039724, average reward:-7.805845393019862,----
Box_Position: [[1.42975531 0.69104153 0.63195414]]
actor_loss: tensor(13.4971, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.6532, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2260, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-1212.0341605613903, average reward:-6.809180677311182,success
Box_Position: [[1.29234805 0.75523688 0.61112255]]
actor_loss: tensor(13.0773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7174, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.4952, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-949.7364768176861, average reward:-7.362298269904544,success
Box_Position: [[1.28950778 0.70629261 0.59485344]]
actor_loss: tensor(12.8076, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-540.6159125748648, average reward:-7.113367270721905,success
Box_Position: [[1.36820848 1.07491313 0.58973381]]
actor_loss: tensor(12.8743, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-347.2769250063223, average reward:-11.975066379528355,success
Box_Position: [[1.27733262 0.85578573 0.64503991]]
Step:30, total reward:-246.3970878373267, average reward:-8.213236261244223,success
Box_Position: [[1.47837057 0.78639135 0.68795036]]
actor_loss: tensor(12.7532, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6883, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.6159, device='cuda:0', grad_fn=<NegBackward>)
Step:127, total reward:-812.2824684304651, average reward:-6.395924948271379,success
Box_Position: [[1.31484475 0.91007131 0.53020939]]
actor_loss: tensor(13.5499, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6849, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2980, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7381, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1493.7810104470066, average reward:-7.468905052235033,----
Box_Position: [[1.53706868 0.62614176 0.63948861]]
actor_loss: tensor(13.1254, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.2387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7202, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1435.4575185867443, average reward:-7.177287592933721,----
Box_Position: [[1.3735973  0.57347193 0.53898178]]
actor_loss: tensor(12.9495, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5526, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7518, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1539.3846473836059, average reward:-7.696923236918029,----
Box_Position: [[1.49740589 0.90542101 0.66379874]]
actor_loss: tensor(13.2515, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-464.48467651330367, average reward:-6.731661978453676,success
Box_Position: [[1.44274523 0.74054012 0.56477361]]
actor_loss: tensor(12.7016, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7736, device='cuda:0', grad_fn=<NegBackward>)
Step:133, total reward:-989.6249883044503, average reward:-7.440789385747746,success
Box_Position: [[1.37657588 1.14091255 0.73245357]]
actor_loss: tensor(11.0249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.4438, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5642, device='cuda:0', grad_fn=<NegBackward>)
Step:139, total reward:-874.4856441003715, average reward:-6.291263626621378,success
Box_Position: [[1.37157808 0.69713698 0.45029222]]
actor_loss: tensor(11.5720, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7109, device='cuda:0', grad_fn=<NegBackward>)
Step:137, total reward:-1207.2525475452362, average reward:-8.81206239084114,success
Box_Position: [[1.32314708 0.58545053 0.73450257]]
actor_loss: tensor(12.7158, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-165.81759200062982, average reward:-6.632703680025193,success
Box_Position: [[1.37354085 0.72902079 0.58034673]]
actor_loss: tensor(12.0939, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-276.07497169376694, average reward:-6.573213611756356,success
Box_Position: [[1.32144885 0.62164405 0.54478382]]
actor_loss: tensor(12.6290, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1064, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6762, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1525.2248072004377, average reward:-7.626124036002189,----
Box_Position: [[1.39491289 0.81029634 0.74406462]]
Step:27, total reward:-206.21726284334972, average reward:-7.637676401605545,success
Box_Position: [[1.45341739 0.91112226 0.5828687 ]]
actor_loss: tensor(13.0522, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8796, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-725.126195323686, average reward:-7.714108460890277,success
Box_Position: [[1.26628717 0.54278387 0.46137368]]
actor_loss: tensor(13.4719, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1806, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.1777, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1737.8734160933564, average reward:-8.689367080466782,----
Box_Position: [[1.51079057 0.80189834 0.4693775 ]]

------------------Episode:1450------------------
actor_loss: tensor(11.5232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9225, device='cuda:0', grad_fn=<NegBackward>)
Step:196, total reward:-1514.1588699159252, average reward:-7.725300356713904,success
Box_Position: [[1.39724919 0.9614313  0.5523202 ]]
Step:9, total reward:-96.24742206745715, average reward:-10.69415800749524,success
Box_Position: [[1.41562285 0.4684669  0.63001793]]
actor_loss: tensor(12.4653, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3686, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-590.5517049952932, average reward:-8.31762964782103,success
Box_Position: [[1.27531632 0.91647375 0.46196036]]
Step:23, total reward:-185.21403490340376, average reward:-8.052784126234945,success
Box_Position: [[1.49832632 0.5273167  0.49817231]]
actor_loss: tensor(12.1304, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-357.3229422500233, average reward:-8.120975960227803,success
Box_Position: [[1.54454387 0.6519607  0.61679861]]
actor_loss: tensor(12.0023, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.5063, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5216, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1432.9371150216818, average reward:-7.164685575108409,----
Box_Position: [[1.49371225 0.53664836 0.48922568]]
actor_loss: tensor(12.0811, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6687, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-915.33989979009, average reward:-7.890861205086983,success
Box_Position: [[1.5193418  0.56526785 0.67962556]]
actor_loss: tensor(12.0534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9470, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3172, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1366.440572001889, average reward:-6.832202860009445,----
Box_Position: [[1.31753465 0.61273811 0.48456113]]
actor_loss: tensor(12.6930, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-103.92906225216096, average reward:-6.49556639076006,success
Box_Position: [[1.52765686 0.73848855 0.61247769]]
actor_loss: tensor(12.6091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.0153, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9428, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.1396, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1367.4301295590942, average reward:-6.837150647795471,----
Box_Position: [[1.25712744 1.06875212 0.52589815]]
Step:32, total reward:-298.78482427609237, average reward:-9.337025758627886,success
Box_Position: [[1.47209582 1.0721578  0.69453922]]
actor_loss: tensor(12.1176, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-400.656894804197, average reward:-6.79079482718978,success
Box_Position: [[1.48014523 0.52636789 0.71213279]]
actor_loss: tensor(12.2424, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.4241, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.2049, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-1288.5854393390334, average reward:-6.782028628100176,success
Box_Position: [[1.34670246 0.63149896 0.55842429]]
actor_loss: tensor(11.9663, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-209.51845379683974, average reward:-6.983948459894658,success
Box_Position: [[1.47040374 1.07559479 0.58246346]]
actor_loss: tensor(12.0464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9991, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9766, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.5984, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1450.5225086657726, average reward:-7.252612543328863,----
Box_Position: [[1.29716775 0.85513446 0.70615778]]
actor_loss: tensor(12.7527, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.6906, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-943.5346884746365, average reward:-7.996056681988445,success
Box_Position: [[1.3764385  0.88364265 0.64561714]]
actor_loss: tensor(12.3516, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-98.96899372492734, average reward:-5.208894406575124,success
Box_Position: [[1.44334172 0.58759828 0.70507891]]
actor_loss: tensor(12.3100, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-554.7721510611555, average reward:-6.52673118895477,success
Box_Position: [[1.52625045 0.73032615 0.68210254]]
actor_loss: tensor(12.7298, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.2003, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7941, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3311.3381507472936, average reward:-16.55669075373647,----
Box_Position: [[1.34555346 0.51652825 0.71930101]]
actor_loss: tensor(11.6346, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-297.80281361216254, average reward:-5.839270855140442,success
Box_Position: [[1.35084848 0.72864413 0.57362131]]
actor_loss: tensor(13.2086, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-217.168237157397, average reward:-7.2389412385798995,success
Box_Position: [[1.52848161 0.60412673 0.61230902]]
Step:11, total reward:-81.48492846714083, average reward:-7.4077207697400755,success
Box_Position: [[1.28115419 1.14739835 0.48687317]]
actor_loss: tensor(12.2421, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3953, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-821.1462630028851, average reward:-9.123847366698724,success
Box_Position: [[1.50330509 0.69808753 0.47302053]]
actor_loss: tensor(12.0015, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-389.7867450017545, average reward:-7.218273055588047,success
Box_Position: [[1.42219708 0.72796227 0.69652177]]
actor_loss: tensor(11.3734, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3048, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-487.49443153430434, average reward:-6.249928609414158,success
Box_Position: [[1.52167386 1.15203634 0.49287933]]
actor_loss: tensor(11.7499, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3095, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.4464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.4759, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1840.1694947045166, average reward:-9.200847473522582,----
Box_Position: [[1.46206881 0.5795516  0.66390425]]
actor_loss: tensor(11.3737, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7228, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-792.5147955438649, average reward:-6.09626765802973,success
Box_Position: [[1.52992317 0.71687045 0.47623345]]
actor_loss: tensor(12.3338, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.9374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.8595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1187, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1639.7102827507351, average reward:-8.198551413753675,----
Box_Position: [[1.30505419 0.88185113 0.67831485]]
actor_loss: tensor(13.1794, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-299.6983127984295, average reward:-5.65468514714018,success
Box_Position: [[1.2549909  0.69307801 0.46840521]]
Step:2, total reward:-10.567888592062692, average reward:-5.283944296031346,success
Box_Position: [[1.35260182 0.8843891  0.59979906]]
actor_loss: tensor(12.0860, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-273.674941087817, average reward:-7.819284031080485,success
Box_Position: [[1.47024537 0.84548156 0.57163264]]
actor_loss: tensor(12.0868, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3147, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-584.871461984457, average reward:-6.800830953307639,success
Box_Position: [[1.53832339 0.7615414  0.59810376]]
actor_loss: tensor(11.7810, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7161, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1749, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1521.0676668726335, average reward:-7.605338334363167,----
Box_Position: [[1.53659518 0.71583721 0.56198589]]
actor_loss: tensor(12.2978, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1326, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.1010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.4665, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1354.058229651367, average reward:-6.770291148256835,----
Box_Position: [[1.38407328 0.76578428 0.61349821]]
Step:19, total reward:-152.23093122452389, average reward:-8.012154274974941,success
Box_Position: [[1.48294834 0.98250248 0.68512194]]
Step:21, total reward:-184.96909329364937, average reward:-8.80805206160235,success
Box_Position: [[1.39930961 0.98293856 0.69027697]]
actor_loss: tensor(11.7235, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-74.5364084111335, average reward:-6.211367367594458,success
Box_Position: [[1.30169567 0.78183927 0.62485912]]
Step:13, total reward:-81.61031772384396, average reward:-6.277716747987997,success
Box_Position: [[1.4133586  0.93750059 0.68296564]]
actor_loss: tensor(11.2280, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-272.1932465367819, average reward:-9.07310821789273,success
Box_Position: [[1.33948881 0.70175669 0.6681841 ]]
actor_loss: tensor(11.7054, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-509.5784722779814, average reward:-5.995040850329193,success
Box_Position: [[1.5421977  0.66154048 0.58921531]]
actor_loss: tensor(12.0112, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7158, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.9699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8321, device='cuda:0', grad_fn=<NegBackward>)
Step:166, total reward:-1106.104085190174, average reward:-6.663277621627554,success
Box_Position: [[1.25682374 0.72831782 0.59688733]]
actor_loss: tensor(11.5625, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-389.41672442524435, average reward:-7.2114208226897105,success
Box_Position: [[1.27845323 0.76158919 0.55607118]]
actor_loss: tensor(13.0741, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-453.8387873071021, average reward:-6.577373729088436,success
Box_Position: [[1.28985569 0.58218197 0.51642226]]
actor_loss: tensor(12.6011, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.8765, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.8464, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1587.058796001012, average reward:-7.93529398000506,----
Box_Position: [[1.47175643 1.05554798 0.74912411]]
actor_loss: tensor(12.1920, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-292.0095853875312, average reward:-6.952609175893601,success
Box_Position: [[1.38699624 0.92181467 0.63862051]]
actor_loss: tensor(12.3682, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-283.130539867769, average reward:-6.43478499699475,success
Box_Position: [[1.50410879 0.56721459 0.54181801]]
actor_loss: tensor(12.3551, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3112, device='cuda:0', grad_fn=<NegBackward>)
Step:120, total reward:-822.9697837252507, average reward:-6.858081531043756,success
Box_Position: [[1.50430837 1.06316322 0.61569764]]
actor_loss: tensor(12.2124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.4124, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3377, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.0027, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1833.3692422106092, average reward:-9.166846211053047,----
Box_Position: [[1.31171033 0.65232605 0.53915259]]
actor_loss: tensor(11.5549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.7059, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-740.069115732329, average reward:-7.327416987448802,success
Box_Position: [[1.42455069 0.86591287 0.73171208]]
actor_loss: tensor(11.2157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.0900, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-882.3978970389601, average reward:-9.804421078210668,success
Box_Position: [[1.33009034 0.73527361 0.54204647]]

------------------Episode:1500------------------
Step:6, total reward:-48.13780724192924, average reward:-8.022967873654872,success
episode 1500, the accuracy is: 77%
Box_Position: [[1.44249181 0.59413143 0.60846318]]
Step:3, total reward:-21.397044009995064, average reward:-7.132348003331688,success
Box_Position: [[1.27408287 0.53406028 0.6871138 ]]
actor_loss: tensor(11.7423, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.6080, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7259, device='cuda:0', grad_fn=<NegBackward>)
Step:123, total reward:-805.9162274065627, average reward:-6.552164450459859,success
Box_Position: [[1.44031785 1.015341   0.58709661]]
Step:42, total reward:-322.3708376093814, average reward:-7.6754961335567,success
Box_Position: [[1.29466101 0.9366466  0.66036157]]
actor_loss: tensor(12.1036, device='cuda:0', grad_fn=<NegBackward>)
Step:2, total reward:-22.96148408802018, average reward:-11.48074204401009,success
Box_Position: [[1.4915305  0.59172363 0.67833979]]
actor_loss: tensor(12.2796, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7763, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.4298, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.6180, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1277.6862316443148, average reward:-6.388431158221574,----
Box_Position: [[1.27075573 0.71192252 0.48599907]]
actor_loss: tensor(11.3411, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7739, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-1002.4546431408411, average reward:-8.716996896876879,success
Box_Position: [[1.44439093 0.87616989 0.72890131]]
Step:25, total reward:-158.5318066568289, average reward:-6.341272266273156,success
Box_Position: [[1.2610783  0.96650765 0.56019784]]
actor_loss: tensor(11.5925, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-350.52818794273264, average reward:-7.966549725971197,success
Box_Position: [[1.36404588 0.64038429 0.54738513]]
actor_loss: tensor(12.8322, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1522, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-715.6557047162026, average reward:-6.815768616344787,success
Box_Position: [[1.28294728 0.72603075 0.6590152 ]]
actor_loss: tensor(12.4753, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.8042, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-412.5917900872685, average reward:-5.81115197306012,success
Box_Position: [[1.3664539  0.99312956 0.58386897]]
Step:13, total reward:-123.83529245280101, average reward:-9.52579172713854,success
Box_Position: [[1.53749447 0.66718069 0.48260166]]
actor_loss: tensor(11.4494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.5603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.9807, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.4019, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1450.650581015442, average reward:-7.253252905077209,----
Box_Position: [[1.47926326 0.84878878 0.48357013]]
actor_loss: tensor(11.1215, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-399.5376302057738, average reward:-7.834071180505369,success
Box_Position: [[1.5163427  0.82085114 0.57984063]]
actor_loss: tensor(10.7634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.5500, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.2329, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(13.2699, device='cuda:0', grad_fn=<NegBackward>)
Step:188, total reward:-1382.7026483966054, average reward:-7.354801321258539,success
Box_Position: [[1.34617164 0.78418652 0.73403382]]
actor_loss: tensor(11.3115, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-300.62430655896975, average reward:-6.135189929774893,success
Box_Position: [[1.46209245 0.86821376 0.74483041]]
actor_loss: tensor(11.6955, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.5532, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1539, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1305.6118764006528, average reward:-6.528059382003264,----
Box_Position: [[1.25008289 0.83884608 0.50753166]]
actor_loss: tensor(11.3366, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-731.5974051662209, average reward:-8.506946571700244,success
Box_Position: [[1.4970039  0.69323963 0.62356665]]
actor_loss: tensor(12.3866, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3993, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-390.1474869547005, average reward:-5.911325559919705,success
Box_Position: [[1.4784476  0.8871022  0.50056674]]
actor_loss: tensor(11.0538, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.0560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.0664, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2698, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1575.8797602148286, average reward:-7.879398801074143,----
Box_Position: [[1.46343093 0.72199901 0.48943155]]
actor_loss: tensor(11.5092, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-245.70122542258198, average reward:-6.640573660069784,success
Box_Position: [[1.48224706 1.05013933 0.64529998]]
actor_loss: tensor(11.9507, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7048, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-935.2064369545026, average reward:-7.728978817805807,success
Box_Position: [[1.49816663 0.67172751 0.65143255]]
actor_loss: tensor(10.9484, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3682, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.9138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7775, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1241.618381814098, average reward:-6.2080919090704905,----
Box_Position: [[1.44499477 0.80748415 0.5348195 ]]
actor_loss: tensor(10.7695, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3852, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7271, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.2585, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1478.3189427292368, average reward:-7.391594713646184,----
Box_Position: [[1.31956515 0.59069209 0.51593956]]
actor_loss: tensor(10.8013, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-220.7656267363071, average reward:-6.493106668714915,success
Box_Position: [[1.52120068 1.02156615 0.57071323]]
actor_loss: tensor(11.0212, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1900, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1630.5303360585247, average reward:-8.152651680292623,----
Box_Position: [[1.35750527 0.69200481 0.62537537]]
actor_loss: tensor(10.6295, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7372, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-658.4082257054182, average reward:-6.330848324090559,success
Box_Position: [[1.40804501 0.95860912 0.56558765]]
actor_loss: tensor(12.3030, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-590.3843630299164, average reward:-7.569030295255338,success
Box_Position: [[1.38763478 0.82249281 0.54405911]]
actor_loss: tensor(10.7337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.5001, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.8979, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-887.0106705615776, average reward:-7.096085364492621,success
Box_Position: [[1.26252405 0.78192629 0.63732084]]
Step:29, total reward:-161.01083004516556, average reward:-5.5520975877643295,success
Box_Position: [[1.51709588 0.56894874 0.61426171]]
actor_loss: tensor(11.3737, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-276.5984677483584, average reward:-6.746304091423376,success
Box_Position: [[1.31260412 0.58835802 0.6214821 ]]
actor_loss: tensor(11.4577, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-278.0396124918596, average reward:-6.466037499810688,success
Box_Position: [[1.27657732 0.71283948 0.70290367]]
actor_loss: tensor(11.5789, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-380.56197804770693, average reward:-6.342699634128449,success
Box_Position: [[1.428782   0.71576056 0.7450496 ]]
actor_loss: tensor(10.4178, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.5266, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.1546, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.2893, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1110.9985036750695, average reward:-5.5549925183753475,----
Box_Position: [[1.40677488 1.04378439 0.74031033]]
actor_loss: tensor(11.6595, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-156.9131698647811, average reward:-7.472055707846719,success
Box_Position: [[1.31585498 0.860677   0.54966897]]
actor_loss: tensor(11.5094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3012, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-736.9522658516, average reward:-6.887404353753271,success
Box_Position: [[1.4752304  0.59740265 0.46217817]]
actor_loss: tensor(11.2259, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-532.2577149940113, average reward:-7.096769533253484,success
Box_Position: [[1.29323597 0.8740437  0.69814927]]
actor_loss: tensor(11.1451, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.4940, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7991, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-979.958722717193, average reward:-7.480600936772466,success
Box_Position: [[1.2676666  0.74368624 0.73643714]]
Step:14, total reward:-94.79122645651375, average reward:-6.770801889750983,success
Box_Position: [[1.36295594 1.15113084 0.6205505 ]]
actor_loss: tensor(10.4549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1671, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(12.3927, device='cuda:0', grad_fn=<NegBackward>)
Step:150, total reward:-1886.0721591718516, average reward:-12.57381439447901,success
Box_Position: [[1.30853786 1.12381508 0.66333474]]
actor_loss: tensor(11.2081, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3160, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1339, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4168, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-3010.5644268517735, average reward:-15.052822134258868,----
Box_Position: [[1.26843405 0.88302722 0.58805696]]
actor_loss: tensor(11.4759, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.0458, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-565.470927541312, average reward:-7.539612367217493,success
Box_Position: [[1.33538156 0.62240328 0.58240812]]
actor_loss: tensor(10.7286, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-577.9297482890623, average reward:-6.493592677405195,success
Box_Position: [[1.52711595 0.97994146 0.6707142 ]]
actor_loss: tensor(10.7131, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.2588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.0946, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4104, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1455.4002933485046, average reward:-7.277001466742523,----
Box_Position: [[1.37644286 0.98968655 0.50035196]]
actor_loss: tensor(11.5192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.0620, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-730.748830666264, average reward:-8.119431451847378,success
Box_Position: [[1.45956932 0.77754603 0.46762451]]
actor_loss: tensor(11.1275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0406, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-852.1017546569096, average reward:-7.889831061638052,success
Box_Position: [[1.36629838 0.75360968 0.60152866]]
actor_loss: tensor(11.1706, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3005, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-379.0121643349895, average reward:-6.213314169426058,success
Box_Position: [[1.45550841 0.65415977 0.73875949]]
actor_loss: tensor(10.6624, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4385, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-800.7757572078186, average reward:-6.15981351698322,success
Box_Position: [[1.37241741 0.61404562 0.62094873]]
Step:9, total reward:-50.687831176390176, average reward:-5.631981241821131,success
Box_Position: [[1.28845381 0.53265193 0.48729997]]
actor_loss: tensor(11.8669, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3311, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-661.2120500869041, average reward:-7.034170745605363,success
Box_Position: [[1.32131465 1.14655099 0.46099427]]

------------------Episode:1550------------------
actor_loss: tensor(10.4976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.6689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.7601, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-1214.4964585564037, average reward:-7.061025921839557,success
Box_Position: [[1.39587176 0.68269256 0.45461945]]
Step:23, total reward:-205.53870794003763, average reward:-8.936465562610332,success
Box_Position: [[1.49030825 0.50547821 0.49875225]]
Step:7, total reward:-42.49837152511984, average reward:-6.071195932159978,success
Box_Position: [[1.25343347 0.96111914 0.67660011]]
actor_loss: tensor(9.7642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.2039, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3531, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-1309.2955213658447, average reward:-6.819247507113775,success
Box_Position: [[1.26258663 0.62907973 0.51046142]]
Step:2, total reward:-11.32897758209366, average reward:-5.66448879104683,success
Box_Position: [[1.35450857 0.67940239 0.45547144]]
Step:12, total reward:-113.46076223217528, average reward:-9.45506351934794,success
Box_Position: [[1.52950755 0.78099026 0.63050626]]
actor_loss: tensor(10.6741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1266, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-619.4933939414216, average reward:-6.807619713641995,success
Box_Position: [[1.52807419 0.63875684 0.59217548]]
actor_loss: tensor(9.8711, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3768, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3059, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0861, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1272.8891622363683, average reward:-6.364445811181842,----
Box_Position: [[1.35463528 0.85202004 0.66931442]]
actor_loss: tensor(11.5609, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-327.5518232837517, average reward:-6.969187729441525,success
Box_Position: [[1.33923777 0.48951359 0.69172417]]
actor_loss: tensor(10.6036, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-202.4764579966488, average reward:-5.955189941077906,success
Box_Position: [[1.27148929 0.72935467 0.51644819]]
Step:1, total reward:-6.446742570873149, average reward:-6.446742570873149,success
Box_Position: [[1.47763781 0.83503483 0.6098134 ]]
Step:3, total reward:-26.97198208653156, average reward:-8.99066069551052,success
Box_Position: [[1.32333928 0.92712917 0.73773455]]
actor_loss: tensor(10.3447, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3970, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-695.1024934933799, average reward:-6.37708709626954,success
Box_Position: [[1.35990498 0.68392427 0.64147248]]
actor_loss: tensor(10.7271, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3240, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-546.0998612109638, average reward:-6.205680241033679,success
Box_Position: [[1.4545721  1.06824976 0.48222577]]
actor_loss: tensor(11.7313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.9332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.9948, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3332, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1721.3072236201642, average reward:-8.606536118100822,----
Box_Position: [[1.25710758 1.04396832 0.68787776]]
actor_loss: tensor(11.6410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.0739, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.9611, device='cuda:0', grad_fn=<NegBackward>)
Step:141, total reward:-913.9528220086311, average reward:-6.481934907862632,success
Box_Position: [[1.2939364  1.02532403 0.60709337]]
Step:31, total reward:-215.656316960937, average reward:-6.956655385836678,success
Box_Position: [[1.54797354 0.77241989 0.65105366]]
actor_loss: tensor(11.4331, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.8046, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.3264, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1283.1416605418249, average reward:-6.415708302709124,----
Box_Position: [[1.31423548 0.66806934 0.71624449]]
Step:3, total reward:-20.72835611571005, average reward:-6.909452038570016,success
Box_Position: [[1.2939406  0.99036232 0.45336114]]
actor_loss: tensor(9.9365, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-131.95951410830267, average reward:-8.79730094055351,success
Box_Position: [[1.50679719 0.82795438 0.64969579]]
actor_loss: tensor(11.4804, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-376.6622548529839, average reward:-8.56050579211327,success
Box_Position: [[1.51190904 0.91534279 0.57630405]]
actor_loss: tensor(10.2827, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1847, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4857, device='cuda:0', grad_fn=<NegBackward>)
Step:155, total reward:-1141.099515174046, average reward:-7.361932355961587,success
Box_Position: [[1.53617362 1.02744175 0.48593131]]
actor_loss: tensor(9.7699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.5903, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7922, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.6650, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1696.6265319233285, average reward:-8.483132659616642,----
Box_Position: [[1.48338379 0.49734838 0.581243  ]]
actor_loss: tensor(10.9662, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-274.8530845104372, average reward:-5.975067054574722,success
Box_Position: [[1.50002598 0.86674587 0.58724763]]
actor_loss: tensor(10.8843, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4558, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.4681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7567, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1413.674248587655, average reward:-7.068371242938275,----
Box_Position: [[1.40829836 0.42593185 0.54356681]]
Step:6, total reward:-34.06725510000919, average reward:-5.677875850001532,success
Box_Position: [[1.54802582 0.91680302 0.61653514]]
actor_loss: tensor(10.4241, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3066, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0724, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.9141, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1397.366510195309, average reward:-6.986832550976545,----
Box_Position: [[1.37903233 0.7098078  0.59632582]]
Step:24, total reward:-167.42930052475293, average reward:-6.976220855198039,success
Box_Position: [[1.29041224 0.69865756 0.71680769]]
actor_loss: tensor(10.7193, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-137.86864438494337, average reward:-5.994288886301885,success
Box_Position: [[1.38566346 1.01295028 0.64080126]]
Step:18, total reward:-135.57437182661948, average reward:-7.5319095459233045,success
Box_Position: [[1.38870203 0.61352912 0.54761104]]
actor_loss: tensor(10.2365, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.7853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.0884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.6230, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1494.0324962632365, average reward:-7.470162481316183,----
Box_Position: [[1.43999076 0.96829165 0.68402486]]
actor_loss: tensor(10.7014, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4849, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7375, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-914.2886206537719, average reward:-6.625279859809941,success
Box_Position: [[1.2729895  0.88979125 0.50286908]]
actor_loss: tensor(10.9880, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.6846, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(11.1756, device='cuda:0', grad_fn=<NegBackward>)
Step:169, total reward:-1487.0045075458463, average reward:-8.79884323991625,success
Box_Position: [[1.41324579 0.87295024 0.72486399]]
actor_loss: tensor(10.9027, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.2401, device='cuda:0', grad_fn=<NegBackward>)
Step:123, total reward:-758.0523844286222, average reward:-6.163027515679855,success
Box_Position: [[1.38321864 0.88299767 0.6619821 ]]
Step:15, total reward:-83.06071043158111, average reward:-5.537380695438741,success
Box_Position: [[1.43322724 0.65124145 0.54137005]]
actor_loss: tensor(11.0659, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-254.27641929203773, average reward:-7.478718214471698,success
Box_Position: [[1.47416187 1.04261958 0.59075982]]
actor_loss: tensor(10.2126, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4180, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.1488, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4205, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1519.5860076725655, average reward:-7.597930038362827,----
Box_Position: [[1.42985542 1.00573203 0.65065086]]
Step:7, total reward:-57.03326737315192, average reward:-8.147609624735988,success
Box_Position: [[1.52041896 0.87211983 0.48572183]]
actor_loss: tensor(10.2359, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0855, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.8825, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4268, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1398.2007082509458, average reward:-6.991003541254729,----
Box_Position: [[1.2669671  0.89408377 0.69260036]]
actor_loss: tensor(9.8815, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.5269, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.3467, device='cuda:0', grad_fn=<NegBackward>)
Step:168, total reward:-1110.421706689001, average reward:-6.609653016005958,success
Box_Position: [[1.2775672  0.5899612  0.56831406]]
actor_loss: tensor(9.3843, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-373.32294239236484, average reward:-5.833170974880701,success
Box_Position: [[1.32002676 1.0694697  0.56242646]]
actor_loss: tensor(10.3813, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.6531, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-470.7657541102105, average reward:-7.846095901836842,success
Box_Position: [[1.32920135 0.57965414 0.72325347]]
actor_loss: tensor(10.9146, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-443.50914166257184, average reward:-6.719835479735937,success
Box_Position: [[1.51394972 0.80937849 0.50067726]]
actor_loss: tensor(10.5584, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.4862, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.5005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4416, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1535.3256949098607, average reward:-7.676628474549303,----
Box_Position: [[1.39575666 0.72740699 0.53347467]]
Step:15, total reward:-86.37425273503754, average reward:-5.758283515669169,success
Box_Position: [[1.27217981 0.60361629 0.48131297]]
actor_loss: tensor(9.9203, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.2412, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-433.2086694127087, average reward:-6.4658010360105775,success
Box_Position: [[1.51853678 0.85691404 0.67675819]]
actor_loss: tensor(10.2527, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-368.7788234998558, average reward:-7.091900451920304,success
Box_Position: [[1.47053959 1.05027526 0.54080262]]
actor_loss: tensor(10.1628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.4248, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.9127, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.1035, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1602.2788763789713, average reward:-8.011394381894856,----
Box_Position: [[1.39243663 0.67057973 0.46157957]]
Step:23, total reward:-179.80903407994788, average reward:-7.817784090432516,success
Box_Position: [[1.38613954 0.79807021 0.73039444]]
Step:3, total reward:-19.447996565380855, average reward:-6.482665521793618,success
Box_Position: [[1.35614078 0.81130626 0.46885704]]

------------------Episode:1600------------------
actor_loss: tensor(10.1426, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-419.3582619163047, average reward:-6.7638429341339465,success
episode 1600, the accuracy is: 79%
Box_Position: [[1.45965914 1.04538406 0.67050707]]
actor_loss: tensor(9.3073, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.5013, device='cuda:0', grad_fn=<NegBackward>)
Step:127, total reward:-853.2247270480343, average reward:-6.718304937386097,success
Box_Position: [[1.43081767 0.62424365 0.50729131]]
actor_loss: tensor(9.9827, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-209.68270889262584, average reward:-6.763958351375027,success
Box_Position: [[1.54375645 0.68305747 0.47449071]]
actor_loss: tensor(10.3622, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.6486, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.1175, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.4770, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1435.8809013801638, average reward:-7.179404506900819,----
Box_Position: [[1.41717053 0.97396248 0.58961679]]
actor_loss: tensor(9.9306, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.8494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.3779, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.7908, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1345.808209585722, average reward:-6.729041047928609,----
Box_Position: [[1.52400843 0.56343238 0.48886479]]
actor_loss: tensor(10.3560, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.4334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.3201, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-1408.9996212936956, average reward:-7.338539694237998,success
Box_Position: [[1.32416365 1.10538924 0.46391926]]
actor_loss: tensor(9.3728, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.7846, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.5356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.4727, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1460.6823182162245, average reward:-7.303411591081122,----
Box_Position: [[1.45622291 0.94279989 0.52900206]]
actor_loss: tensor(10.0196, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(10.0857, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-690.6863970282423, average reward:-7.047820377839207,success
Box_Position: [[1.49218836 0.72375253 0.60229232]]
actor_loss: tensor(9.4938, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.6431, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.8626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.3307, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1146.042142174764, average reward:-5.73021071087382,----
Box_Position: [[1.52374811 0.60390389 0.45916102]]
actor_loss: tensor(10.1533, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.7842, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.6546, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-1009.989606537869, average reward:-7.7691508195220695,success
Box_Position: [[1.36207596 0.87047617 0.61994471]]
Step:25, total reward:-200.30985204627714, average reward:-8.012394081851086,success
Box_Position: [[1.54748563 1.00631623 0.50005322]]
actor_loss: tensor(8.9711, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.0137, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.8077, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.7880, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1661.0342178863114, average reward:-8.305171089431557,----
Box_Position: [[1.44603237 0.78145139 0.49957695]]
actor_loss: tensor(9.5917, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-391.72067033584017, average reward:-7.533089814150772,success
Box_Position: [[1.495304   0.76570087 0.66452637]]
actor_loss: tensor(9.3609, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.7850, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.8836, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.3171, device='cuda:0', grad_fn=<NegBackward>)
Step:183, total reward:-1227.7731951218316, average reward:-6.709143142742249,success
Box_Position: [[1.48053289 0.58357369 0.53418722]]
Step:15, total reward:-118.3292861348003, average reward:-7.888619075653353,success
Box_Position: [[1.28800424 0.73656779 0.61325569]]
Step:2, total reward:-9.661119002442375, average reward:-4.830559501221187,success
Box_Position: [[1.31444149 0.99044815 0.63903056]]
actor_loss: tensor(10.3452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.9645, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-754.4367630193041, average reward:-7.6983343165235105,success
Box_Position: [[1.32287094 0.93456203 0.49831482]]
actor_loss: tensor(9.5697, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-146.68739276366352, average reward:-7.334369638183176,success
Box_Position: [[1.53914755 0.47098791 0.65005503]]
actor_loss: tensor(9.4247, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.8233, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.4324, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.2534, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1322.8202916728053, average reward:-6.6141014583640265,----
Box_Position: [[1.53804422 0.75613878 0.56392983]]
actor_loss: tensor(9.2256, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.9541, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.8607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.6775, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1383.6036160547749, average reward:-6.918018080273875,----
Box_Position: [[1.35344005 1.00662264 0.60230843]]
Step:19, total reward:-126.81745707529555, average reward:-6.674603003962924,success
Box_Position: [[1.32778911 0.64063014 0.59486336]]
actor_loss: tensor(9.7318, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.2524, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.4962, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-978.0123502355732, average reward:-7.581491087097467,success
Box_Position: [[1.39336475 0.86452569 0.48520121]]
actor_loss: tensor(9.3755, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-393.87362881935815, average reward:-7.161338705806512,success
Box_Position: [[1.29639221 0.85702512 0.72177278]]
actor_loss: tensor(9.0518, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-301.2311216668335, average reward:-6.8461618560643975,success
Box_Position: [[1.49548274 0.73333879 0.49844991]]
actor_loss: tensor(9.3000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.9096, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-990.5375274753745, average reward:-7.924300219802996,success
Box_Position: [[1.42817226 0.97574799 0.57933287]]
actor_loss: tensor(8.6576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.8876, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-495.3104548932349, average reward:-7.392693356615447,success
Box_Position: [[1.48064741 0.95560088 0.58928359]]
actor_loss: tensor(9.5886, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.5277, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-1002.323115839245, average reward:-9.731292386788786,success
Box_Position: [[1.43305756 0.91293905 0.57397804]]
actor_loss: tensor(9.6879, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.3550, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.3734, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.0492, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1535.757265932186, average reward:-7.67878632966093,----
Box_Position: [[1.3704384  1.06539729 0.47560572]]
actor_loss: tensor(9.6676, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.4530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.7435, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.7341, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1697.6476646330518, average reward:-8.488238323165259,----
Box_Position: [[1.35669566 0.86375261 0.72256168]]
actor_loss: tensor(8.9325, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-552.6504191240291, average reward:-6.140560212489212,success
Box_Position: [[1.32108832 1.06401054 0.5493183 ]]
actor_loss: tensor(9.1234, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-336.3355281219479, average reward:-7.643989275498816,success
Box_Position: [[1.27139505 0.71319282 0.64291278]]
Step:3, total reward:-29.650574046959036, average reward:-9.88352468231968,success
Box_Position: [[1.30303907 0.99050564 0.57628728]]
actor_loss: tensor(9.5013, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-194.6228161986428, average reward:-7.784912647945712,success
Box_Position: [[1.30184869 0.85860157 0.55959999]]
Step:29, total reward:-170.56366658246841, average reward:-5.881505744223049,success
Box_Position: [[1.31354078 0.85684745 0.74511566]]
actor_loss: tensor(8.6382, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-352.65337052098425, average reward:-11.020417828780758,success
Box_Position: [[1.33070452 0.90443764 0.71349677]]
actor_loss: tensor(9.0480, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-358.8159255313036, average reward:-5.787353637601671,success
Box_Position: [[1.50923829 0.89168393 0.46615202]]
actor_loss: tensor(8.7085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.7360, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.3703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2390, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1553.5583821974733, average reward:-7.767791910987366,----
Box_Position: [[1.39504922 0.72622266 0.56477451]]
actor_loss: tensor(9.0950, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-159.32829705460531, average reward:-6.128011425177127,success
Box_Position: [[1.48351573 0.85198703 0.54426537]]
Step:27, total reward:-193.02699422972535, average reward:-7.149147934434272,success
Box_Position: [[1.37580804 0.90771404 0.74732729]]
actor_loss: tensor(8.4685, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.6626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2524, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.6016, device='cuda:0', grad_fn=<NegBackward>)
Step:189, total reward:-1080.9001125228608, average reward:-5.719048214406671,success
Box_Position: [[1.45155819 0.5121597  0.57505202]]
actor_loss: tensor(9.2990, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.1676, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.2223, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.5772, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1319.0173727517758, average reward:-6.595086863758879,----
Box_Position: [[1.43456654 0.49429956 0.62632891]]
actor_loss: tensor(8.1923, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-311.0872674021797, average reward:-5.869571083059994,success
Box_Position: [[1.32004112 0.81981535 0.7434331 ]]
actor_loss: tensor(8.0975, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-181.07717936559527, average reward:-5.487187253502887,success
Box_Position: [[1.39442611 0.65796751 0.53896475]]
actor_loss: tensor(8.4976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.9552, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-532.142592667236, average reward:-6.41135653815947,success
Box_Position: [[1.34519648 0.80921284 0.72751708]]
actor_loss: tensor(8.6024, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-371.6458374399528, average reward:-5.161747742221567,success
Box_Position: [[1.46715389 0.71366166 0.5536713 ]]
actor_loss: tensor(8.3004, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-279.7470786994375, average reward:-8.227855255865808,success
Box_Position: [[1.41414326 1.1471443  0.6979914 ]]
Step:29, total reward:-169.30966113401175, average reward:-5.838264177034888,success
Box_Position: [[1.2568163  0.87238905 0.46487993]]
Step:8, total reward:-67.19416625306334, average reward:-8.399270781632918,success
Box_Position: [[1.36143947 0.68924397 0.51665229]]
actor_loss: tensor(8.3188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(9.3204, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-530.4648364336363, average reward:-6.391142607634172,success
Box_Position: [[1.44070818 0.69828805 0.73344421]]
actor_loss: tensor(8.4496, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-352.48465982308977, average reward:-6.077321721087754,success
Box_Position: [[1.4015649  0.53927965 0.73632192]]

------------------Episode:1650------------------
Step:9, total reward:-52.38422177557509, average reward:-5.82046908617501,success
Box_Position: [[1.40448055 0.59653595 0.46993336]]
actor_loss: tensor(8.5512, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-254.41564274679445, average reward:-7.067101187410957,success
Box_Position: [[1.33561839 0.87338573 0.55452399]]
Step:10, total reward:-66.62072884216995, average reward:-6.662072884216995,success
Box_Position: [[1.47836331 1.08615294 0.47637812]]
actor_loss: tensor(8.9032, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.5595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.5166, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1682.7832194819935, average reward:-8.413916097409967,----
Box_Position: [[1.46107997 0.91964977 0.70603821]]
actor_loss: tensor(8.4445, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-75.63683794607995, average reward:-6.876076176916359,success
Box_Position: [[1.51486703 0.86343853 0.60436965]]
actor_loss: tensor(9.0949, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7085, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.9826, device='cuda:0', grad_fn=<NegBackward>)
Step:182, total reward:-1153.675421919339, average reward:-6.338875944611753,success
Box_Position: [[1.48078165 1.00803015 0.55115984]]
actor_loss: tensor(8.8854, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.3760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8532, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-1087.1305733963538, average reward:-7.446099817783246,success
Box_Position: [[1.37164014 0.78887353 0.63161706]]
actor_loss: tensor(8.4617, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.3733, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5266, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-760.0154227692207, average reward:-6.28111919643984,success
Box_Position: [[1.37687401 0.51449754 0.74000313]]
Step:45, total reward:-252.10846766456595, average reward:-5.60241039254591,success
Box_Position: [[1.37333438 0.450062   0.57741417]]
actor_loss: tensor(8.5828, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3669, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-550.1746168606554, average reward:-6.628609841694644,success
Box_Position: [[1.30295337 0.73727158 0.60151653]]
actor_loss: tensor(7.8460, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-353.7878666337897, average reward:-5.896464443896495,success
Box_Position: [[1.4460089  0.54363038 0.48941889]]
actor_loss: tensor(8.0930, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.0740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6050, device='cuda:0', grad_fn=<NegBackward>)
Step:190, total reward:-1303.7838061491836, average reward:-6.862020032364124,success
Box_Position: [[1.33894813 0.46415776 0.5303653 ]]
actor_loss: tensor(8.4379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.0103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6400, device='cuda:0', grad_fn=<NegBackward>)
Step:164, total reward:-1120.1450054090058, average reward:-6.830152472006133,success
Box_Position: [[1.49721371 0.8316197  0.74294671]]
actor_loss: tensor(8.3738, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-226.77572831589956, average reward:-6.1290737382675555,success
Box_Position: [[1.42383124 0.80651685 0.74299586]]
actor_loss: tensor(7.9659, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-185.46188080637708, average reward:-8.831518133637005,success
Box_Position: [[1.2832549  1.04069558 0.63617954]]
actor_loss: tensor(7.3891, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-445.63194516967434, average reward:-7.187612018865715,success
Box_Position: [[1.38363873 0.72992177 0.73598385]]
Step:9, total reward:-53.79391701277815, average reward:-5.977101890308684,success
Box_Position: [[1.45550228 1.05932505 0.57986987]]
actor_loss: tensor(8.8360, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3216, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.4870, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-929.3000825216112, average reward:-7.20387660869466,success
Box_Position: [[1.4666643  0.79278091 0.60123494]]
actor_loss: tensor(7.9789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.4754, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2961, device='cuda:0', grad_fn=<NegBackward>)
Step:188, total reward:-1151.950833875031, average reward:-6.127398052526761,success
Box_Position: [[1.27096938 0.856435   0.58201058]]
actor_loss: tensor(8.0397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2122, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-465.587455967805, average reward:-6.8468743524677205,success
Box_Position: [[1.3829223  0.79653611 0.73325366]]
Step:24, total reward:-182.33904172009085, average reward:-7.597460071670452,success
Box_Position: [[1.46542441 0.84410032 0.70987158]]
actor_loss: tensor(7.7666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.0261, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-456.47751929988755, average reward:-6.086366923998501,success
Box_Position: [[1.41608855 0.61796428 0.50197666]]
actor_loss: tensor(7.1686, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-409.5183488996729, average reward:-6.605134659672143,success
Box_Position: [[1.54429123 0.84230733 0.46197959]]
actor_loss: tensor(7.1541, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5511, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.1498, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3787, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1551.9506161075212, average reward:-7.759753080537606,----
Box_Position: [[1.33026466 0.82785938 0.66595825]]
Step:23, total reward:-237.6083334344832, average reward:-10.330797105847095,success
Box_Position: [[1.26210634 0.76563557 0.56111673]]
actor_loss: tensor(6.9938, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-61.093554155839996, average reward:-5.553959468712727,success
Box_Position: [[1.34061581 0.76382989 0.46210383]]
Step:20, total reward:-153.03645090428682, average reward:-7.651822545214341,success
Box_Position: [[1.49515826 0.81728657 0.67447968]]
Step:7, total reward:-38.05378369275878, average reward:-5.436254813251254,success
Box_Position: [[1.38235764 0.95961632 0.54873252]]
Step:5, total reward:-46.19724045631619, average reward:-9.239448091263238,success
Box_Position: [[1.5043096  1.09459577 0.51417179]]
actor_loss: tensor(8.1716, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6779, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5775, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1448.3732168972103, average reward:-7.241866084486052,----
Box_Position: [[1.32579851 1.04928587 0.59004296]]
actor_loss: tensor(7.1641, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6798, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-529.7859326514662, average reward:-7.063812435352882,success
Box_Position: [[1.38078655 0.61874397 0.49195801]]
actor_loss: tensor(7.5816, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-439.49045819038287, average reward:-6.658946336217922,success
Box_Position: [[1.25655639 0.86477839 0.5244055 ]]
Step:12, total reward:-83.61248121024109, average reward:-6.967706767520091,success
Box_Position: [[1.51084886 0.68066042 0.72225511]]
actor_loss: tensor(7.1402, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-253.3235366179767, average reward:-5.629411924843927,success
Box_Position: [[1.53280714 1.00332299 0.5977421 ]]
actor_loss: tensor(7.6107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5841, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5589, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1415.5253784690512, average reward:-7.077626892345256,----
Box_Position: [[1.53464882 1.09382466 0.59890534]]
actor_loss: tensor(7.8758, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.4898, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8434, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3232, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1363.0666042645157, average reward:-6.815333021322578,----
Box_Position: [[1.42204618 0.85315133 0.71041459]]
actor_loss: tensor(7.2843, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-237.03812211304447, average reward:-4.558425425250855,success
Box_Position: [[1.39525038 0.64374026 0.69824837]]
actor_loss: tensor(7.5780, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.0655, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5974, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2888, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1339.08420322568, average reward:-6.6954210161284005,----
Box_Position: [[1.37567773 0.97108364 0.61737787]]
actor_loss: tensor(7.5055, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5013, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-577.7240775267172, average reward:-6.796753853255497,success
Box_Position: [[1.44090881 0.81216869 0.5785979 ]]
Step:20, total reward:-137.6377990768329, average reward:-6.881889953841645,success
Box_Position: [[1.5228789  0.98466292 0.54292933]]
actor_loss: tensor(7.9299, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8029, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.4692, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1568.7254048326581, average reward:-7.843627024163291,----
Box_Position: [[1.39282261 0.94176026 0.70786367]]
actor_loss: tensor(7.1847, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0829, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-873.3843701806021, average reward:-5.9820847272643976,success
Box_Position: [[1.42568152 0.72025425 0.72212398]]
actor_loss: tensor(6.7654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1479, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-489.7643709583752, average reward:-5.38202605448764,success
Box_Position: [[1.25519059 0.84679639 0.47615237]]
actor_loss: tensor(7.0514, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-614.3726721319032, average reward:-8.653136227209904,success
Box_Position: [[1.41152266 0.76783737 0.72828124]]
actor_loss: tensor(7.3166, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-22.382691396075323, average reward:-5.595672849018831,success
Box_Position: [[1.48047431 0.67320413 0.45217445]]
Step:42, total reward:-320.1868122016303, average reward:-7.623495528610245,success
Box_Position: [[1.30620666 0.58826772 0.71659441]]
actor_loss: tensor(7.5818, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5035, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2460, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1493.2781524641662, average reward:-7.466390762320831,----
Box_Position: [[1.47118632 1.03519108 0.61832535]]
actor_loss: tensor(6.7480, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-262.9272599340027, average reward:-8.481524514000087,success
Box_Position: [[1.50097019 0.93808525 0.63918467]]
actor_loss: tensor(7.8518, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-172.28050928961588, average reward:-6.626173434215995,success
Box_Position: [[1.26239176 0.83249743 0.45489515]]
Step:9, total reward:-75.38949129645037, average reward:-8.37661014405004,success
Box_Position: [[1.41624555 0.93171475 0.72894288]]

------------------Episode:1700------------------
Step:7, total reward:-38.68861883001266, average reward:-5.526945547144665,success
episode 1700, the accuracy is: 81%
Box_Position: [[1.54201849 0.78645066 0.74450625]]
actor_loss: tensor(7.8729, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-264.85367061024556, average reward:-5.885637124672123,success
Box_Position: [[1.43310999 0.62025623 0.55401801]]
actor_loss: tensor(7.2402, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-472.72444941678896, average reward:-5.764932309960841,success
Box_Position: [[1.37086742 0.95821661 0.66439326]]
actor_loss: tensor(6.3233, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-76.79217658266093, average reward:-5.907090506358533,success
Box_Position: [[1.53920993 0.82785417 0.71029949]]
actor_loss: tensor(7.5374, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2257, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-598.2599790887335, average reward:-5.697714086559367,success
Box_Position: [[1.46516842 0.69174215 0.49872326]]
actor_loss: tensor(7.2690, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-605.7703849128395, average reward:-7.043841685033017,success
Box_Position: [[1.45068879 0.73414075 0.49986607]]
actor_loss: tensor(8.0067, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1924, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-394.4273278421965, average reward:-7.7338691733764025,success
Box_Position: [[1.49703967 1.02725303 0.61208374]]
actor_loss: tensor(7.4632, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-620.8349498600245, average reward:-7.054942612045733,success
Box_Position: [[1.3778749  1.09497324 0.64855567]]
Step:9, total reward:-45.29605653417596, average reward:-5.032895170463996,success
Box_Position: [[1.47627204 0.66631046 0.63899147]]
actor_loss: tensor(7.4204, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-318.34314976759066, average reward:-6.366862995351813,success
Box_Position: [[1.2795274  0.93216374 0.51088431]]
actor_loss: tensor(7.0458, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5490, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-419.27013788992485, average reward:-7.764261812776386,success
Box_Position: [[1.36922548 0.46495905 0.46872649]]
actor_loss: tensor(8.2358, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-297.50931434467657, average reward:-6.0716186600954405,success
Box_Position: [[1.25082577 0.71583787 0.72838301]]
actor_loss: tensor(7.3788, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-429.3944978179131, average reward:-5.963812469693237,success
Box_Position: [[1.43031338 0.68226691 0.63738635]]
actor_loss: tensor(6.8219, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7685, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-590.4442915837785, average reward:-5.9640837533715,success
Box_Position: [[1.49752239 0.54165232 0.47959286]]
actor_loss: tensor(7.3046, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6604, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-670.4739018259831, average reward:-6.638355463623595,success
Box_Position: [[1.30614055 0.54378089 0.50282871]]
actor_loss: tensor(7.7482, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-420.7512325423504, average reward:-7.131376822751702,success
Box_Position: [[1.44818978 0.83468869 0.62303826]]
actor_loss: tensor(7.0997, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5803, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.9563, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8496, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1183.721635275758, average reward:-5.91860817637879,----
Box_Position: [[1.52398303 0.78424976 0.68388122]]
actor_loss: tensor(6.7306, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-206.41656750664768, average reward:-5.897616214475648,success
Box_Position: [[1.3760028  0.76249378 0.71500454]]
actor_loss: tensor(6.5861, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-401.70843237243025, average reward:-5.821861338730873,success
Box_Position: [[1.38533212 0.97776317 0.48832331]]
actor_loss: tensor(7.0708, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-150.63925275810408, average reward:-7.928381724110741,success
Box_Position: [[1.46251518 0.74263929 0.6821007 ]]
actor_loss: tensor(6.7797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3369, device='cuda:0', grad_fn=<NegBackward>)
Step:140, total reward:-909.8292018082282, average reward:-6.4987800129159154,success
Box_Position: [[1.26746838 0.99986665 0.59613556]]
actor_loss: tensor(6.4785, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-261.02136616786703, average reward:-6.366374784582122,success
Box_Position: [[1.29514692 1.00030922 0.65005893]]
Step:3, total reward:-26.319155713313265, average reward:-8.773051904437756,success
Box_Position: [[1.53321194 0.84827682 0.69585787]]
actor_loss: tensor(7.0873, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-260.51472228356243, average reward:-6.202731482941963,success
Box_Position: [[1.36430231 0.99580255 0.68726557]]
actor_loss: tensor(6.9303, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5479, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-549.2392801127252, average reward:-7.041529232214425,success
Box_Position: [[1.31190387 0.72974279 0.61301053]]
Step:20, total reward:-91.21089999722574, average reward:-4.560544999861287,success
Box_Position: [[1.29992835 0.69838464 0.47381743]]
Step:7, total reward:-54.74249393616361, average reward:-7.820356276594802,success
Box_Position: [[1.40145682 1.1710019  0.65533301]]
actor_loss: tensor(7.3829, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0234, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8983, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9997, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1159.3911080487078, average reward:-5.796955540243539,----
Box_Position: [[1.37137226 0.98516889 0.52513983]]
actor_loss: tensor(7.1008, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-130.0724450518056, average reward:-8.12952781573785,success
Box_Position: [[1.3110297  0.52432546 0.5718353 ]]
Step:30, total reward:-197.2627185325718, average reward:-6.575423951085726,success
Box_Position: [[1.42558091 0.79669598 0.63290883]]
actor_loss: tensor(6.6497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5458, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-543.5592726020556, average reward:-6.107407557326467,success
Box_Position: [[1.47348695 0.95259375 0.46761213]]
actor_loss: tensor(6.9043, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6178, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0336, device='cuda:0', grad_fn=<NegBackward>)
Step:151, total reward:-1074.7698301564342, average reward:-7.117680994413472,success
Box_Position: [[1.44424347 0.64199995 0.74179589]]
Step:2, total reward:-16.09082959386486, average reward:-8.04541479693243,success
Box_Position: [[1.48114084 0.63223042 0.46532466]]
actor_loss: tensor(7.2360, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1710, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-552.4075863451882, average reward:-7.082148542887028,success
Box_Position: [[1.51137198 0.87571699 0.54222928]]
actor_loss: tensor(7.2177, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6849, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5491, device='cuda:0', grad_fn=<NegBackward>)
Step:169, total reward:-1195.0428130876146, average reward:-7.07125924903914,success
Box_Position: [[1.47607577 1.04639564 0.49340801]]
actor_loss: tensor(6.6074, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5102, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3850, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1592.9573205409963, average reward:-7.964786602704981,----
Box_Position: [[1.48591895 0.66746122 0.74803134]]
actor_loss: tensor(7.1836, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-320.0663268534021, average reward:-7.112585041186713,success
Box_Position: [[1.35652352 0.70645626 0.68991198]]
Step:10, total reward:-70.71235797956406, average reward:-7.071235797956406,success
Box_Position: [[1.38441773 1.0610673  0.58081041]]
actor_loss: tensor(6.7162, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-458.1172144313992, average reward:-6.737017859285282,success
Box_Position: [[1.3292812  0.73155266 0.54941862]]
actor_loss: tensor(6.9184, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2798, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-784.9508045154366, average reward:-7.008489326030684,success
Box_Position: [[1.33999859 1.02555577 0.59082888]]
Step:14, total reward:-117.82335656423423, average reward:-8.415954040302445,success
Box_Position: [[1.48848282 1.05074267 0.52556554]]
actor_loss: tensor(7.8408, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1272, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9473, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1458.7781510543437, average reward:-7.293890755271718,----
Box_Position: [[1.51747448 0.60907378 0.67578265]]
Step:9, total reward:-59.85644899218346, average reward:-6.650716554687051,success
Box_Position: [[1.29884217 0.63252442 0.53995651]]
Step:17, total reward:-95.91837186874831, average reward:-5.6422571687499,success
Box_Position: [[1.42547149 0.68239215 0.73014776]]
actor_loss: tensor(6.6262, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-357.2126770685231, average reward:-6.61504957534302,success
Box_Position: [[1.54762103 0.56642693 0.71663291]]
actor_loss: tensor(6.2378, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-53.489061560045634, average reward:-5.943229062227292,success
Box_Position: [[1.27057188 0.7002667  0.51337928]]
actor_loss: tensor(7.3045, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5034, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-747.4981150682933, average reward:-7.257263253090226,success
Box_Position: [[1.38706731 0.57508273 0.57366407]]
Step:22, total reward:-147.14311373143266, average reward:-6.688323351428758,success
Box_Position: [[1.29037215 0.84662702 0.57074943]]
actor_loss: tensor(7.2347, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-212.21747971589397, average reward:-7.859906656144221,success
Box_Position: [[1.31266242 0.95964766 0.58998893]]
Step:5, total reward:-43.04348551713394, average reward:-8.608697103426788,success
Box_Position: [[1.54517442 0.55946952 0.64883115]]

------------------Episode:1750------------------
actor_loss: tensor(6.7319, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9427, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0150, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1369.1854264385142, average reward:-6.845927132192571,----
Box_Position: [[1.37531124 0.58185144 0.5028019 ]]
Step:12, total reward:-83.38002057847031, average reward:-6.948335048205859,success
Box_Position: [[1.38152308 0.66480363 0.46156267]]
actor_loss: tensor(6.9291, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-401.0739495724977, average reward:-7.036385080219258,success
Box_Position: [[1.35121865 0.63097011 0.68442532]]
actor_loss: tensor(6.7825, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-245.15506653523872, average reward:-5.83702539369616,success
Box_Position: [[1.46046015 0.63234712 0.64830787]]
actor_loss: tensor(7.2910, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-294.9888478946053, average reward:-6.0201805692776595,success
Box_Position: [[1.48865014 1.02785003 0.71203372]]
actor_loss: tensor(7.5122, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7999, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-539.6728746526236, average reward:-6.581376520153946,success
Box_Position: [[1.52295268 0.82671386 0.45583048]]
actor_loss: tensor(6.4557, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5559, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1342, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1558.6633809580037, average reward:-7.793316904790019,----
Box_Position: [[1.46513304 0.96268907 0.57890913]]
Step:3, total reward:-25.47609931310012, average reward:-8.492033104366707,success
Box_Position: [[1.52662853 0.69697669 0.65388325]]
Step:11, total reward:-75.64506319020145, average reward:-6.876823926381951,success
Box_Position: [[1.4964125  0.92839192 0.57439925]]
actor_loss: tensor(7.0131, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-387.8272430103562, average reward:-7.914841694088902,success
Box_Position: [[1.54759857 0.98983337 0.47577112]]
actor_loss: tensor(6.4387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4961, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2083, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1745.4203194224463, average reward:-8.727101597112231,----
Box_Position: [[1.43497212 0.79743898 0.64113863]]
Step:13, total reward:-81.81454163197606, average reward:-6.293426279382773,success
Box_Position: [[1.38615273 0.65970095 0.60558068]]
actor_loss: tensor(6.8948, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-330.6313536223521, average reward:-6.612627072447042,success
Box_Position: [[1.5293083  0.98183942 0.53768906]]
actor_loss: tensor(7.2456, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6602, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7712, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6321, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1444.0286691601873, average reward:-7.2201433458009365,----
Box_Position: [[1.43483095 0.6654015  0.46115153]]
actor_loss: tensor(6.9757, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-193.94113765758254, average reward:-6.464704588586085,success
Box_Position: [[1.43210479 0.70254828 0.54934432]]
Step:32, total reward:-215.21975154626216, average reward:-6.7256172358206925,success
Box_Position: [[1.33206712 0.87949543 0.45359894]]
actor_loss: tensor(7.1830, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-156.44988268750987, average reward:-10.429992179167325,success
Box_Position: [[1.42643142 0.55202356 0.57899438]]
Step:20, total reward:-114.98952857535498, average reward:-5.749476428767749,success
Box_Position: [[1.41082024 0.94353109 0.58091663]]
actor_loss: tensor(7.4265, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-280.7045848083429, average reward:-7.586610400225483,success
Box_Position: [[1.46777168 0.91942066 0.7315862 ]]
actor_loss: tensor(6.6057, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1786, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-603.3079364702097, average reward:-5.97334590564564,success
Box_Position: [[1.3021533  0.83797073 0.56897004]]
Step:10, total reward:-71.51153060316568, average reward:-7.1511530603165685,success
Box_Position: [[1.45973436 0.79672127 0.69419766]]
actor_loss: tensor(6.4799, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-170.7038624048679, average reward:-5.886340082926479,success
Box_Position: [[1.52231048 0.78817968 0.5553875 ]]
actor_loss: tensor(7.9363, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5533, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5211, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5409, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1396.9789266617609, average reward:-6.984894633308804,----
Box_Position: [[1.42150339 0.86734167 0.63078373]]
Step:13, total reward:-74.9977962874496, average reward:-5.769061252880738,success
Box_Position: [[1.32587937 1.0484245  0.72641413]]
Step:13, total reward:-101.13587980783343, average reward:-7.779683062141033,success
Box_Position: [[1.51400139 0.8264218  0.49344975]]
actor_loss: tensor(7.3966, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-147.82252933161834, average reward:-7.391126466580917,success
Box_Position: [[1.41957274 0.84539977 0.56661096]]
Step:42, total reward:-265.79036945466316, average reward:-6.328342129872932,success
Box_Position: [[1.52775391 0.90961298 0.49683302]]
actor_loss: tensor(7.0875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1795, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9446, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9705, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1463.9828353908144, average reward:-7.3199141769540725,----
Box_Position: [[1.29408949 0.57788162 0.46288038]]
actor_loss: tensor(6.9349, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-116.33910373791554, average reward:-6.123110723048186,success
Box_Position: [[1.3185445  0.74342443 0.45791976]]
Step:5, total reward:-28.904355914508937, average reward:-5.780871182901787,success
Box_Position: [[1.30869429 0.63047269 0.52589192]]
actor_loss: tensor(7.0519, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-419.26964534186413, average reward:-6.762413634546196,success
Box_Position: [[1.53564276 0.73677068 0.6709492 ]]
actor_loss: tensor(7.0496, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6652, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5595, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9948, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1146.4194170736448, average reward:-5.732097085368224,----
Box_Position: [[1.3614929  0.71161194 0.50409766]]
Step:13, total reward:-120.61359931953068, average reward:-9.277969178425437,success
Box_Position: [[1.4753695  0.83417793 0.69934502]]
actor_loss: tensor(6.9688, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-80.19204113388241, average reward:-6.168618548760185,success
Box_Position: [[1.36390631 1.06882952 0.51201004]]
Step:10, total reward:-63.58850470355968, average reward:-6.358850470355968,success
Box_Position: [[1.52227411 0.58077968 0.58412654]]
actor_loss: tensor(6.6587, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3387, device='cuda:0', grad_fn=<NegBackward>)
Step:120, total reward:-737.4307178869442, average reward:-6.145255982391202,success
Box_Position: [[1.28405087 0.41465212 0.71944778]]
actor_loss: tensor(8.0746, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4511, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1092, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9772, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1487.8308210683126, average reward:-7.439154105341563,----
Box_Position: [[1.35155016 0.5921504  0.72008804]]
actor_loss: tensor(6.7022, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-210.24559846129753, average reward:-5.532778906876251,success
Box_Position: [[1.50615455 0.84759097 0.46444992]]
actor_loss: tensor(6.9838, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5868, device='cuda:0', grad_fn=<NegBackward>)
Step:117, total reward:-844.7274486334873, average reward:-7.219892723363139,success
Box_Position: [[1.47482153 0.75255015 0.56144522]]
actor_loss: tensor(7.3279, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0699, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-460.6275105815959, average reward:-5.982175462098648,success
Box_Position: [[1.28335731 0.81590802 0.62762922]]
Step:12, total reward:-79.18160404083122, average reward:-6.598467003402601,success
Box_Position: [[1.31302062 1.06762401 0.47769701]]
Step:9, total reward:-78.8950040880159, average reward:-8.7661115653351,success
Box_Position: [[1.52043465 0.99458046 0.45394044]]
actor_loss: tensor(6.8188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1088, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7641, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9329, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1561.1699833872221, average reward:-7.80584991693611,----
Box_Position: [[1.54726425 0.90309404 0.62933944]]
actor_loss: tensor(6.4350, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2281, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8018, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4839, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1256.2925393146097, average reward:-6.2814626965730485,----
Box_Position: [[1.34914939 0.57466725 0.66760654]]
actor_loss: tensor(6.7475, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-321.4248876896579, average reward:-6.181247840185729,success
Box_Position: [[1.33118367 0.82095162 0.51807733]]
actor_loss: tensor(6.6553, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-273.885173878314, average reward:-7.402301996711189,success
Box_Position: [[1.54361301 0.63056574 0.52455517]]
actor_loss: tensor(7.5036, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4882, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9004, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1243.5609331740172, average reward:-6.217804665870086,----
Box_Position: [[1.40684682 0.66656972 0.53902952]]
Step:12, total reward:-85.46235400430986, average reward:-7.1218628336924885,success
Box_Position: [[1.50824272 0.90031568 0.4969222 ]]
actor_loss: tensor(6.9600, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-204.18255289331137, average reward:-6.806085096443712,success
Box_Position: [[1.29186594 0.97944194 0.51952752]]
Step:16, total reward:-127.35031203934417, average reward:-7.959394502459011,success
Box_Position: [[1.29752404 0.76133754 0.62519736]]

------------------Episode:1800------------------
Step:6, total reward:-36.62642355388423, average reward:-6.104403925647372,success
episode 1800, the accuracy is: 85%
Box_Position: [[1.51957999 1.1452219  0.625677  ]]
actor_loss: tensor(6.2328, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8349, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0416, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1291.3526722060399, average reward:-6.456763361030199,----
Box_Position: [[1.32465688 0.77118156 0.48385201]]
actor_loss: tensor(7.3387, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-64.77660180659868, average reward:-6.477660180659868,success
Box_Position: [[1.48386318 0.77152252 0.5849139 ]]
actor_loss: tensor(7.5477, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-316.2613129815908, average reward:-5.7502056905743775,success
Box_Position: [[1.47253439 1.098898   0.73972623]]
actor_loss: tensor(6.5227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8099, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-671.0938729004838, average reward:-6.452825700966191,success
Box_Position: [[1.50693302 0.9275289  0.48038711]]
actor_loss: tensor(6.4383, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7638, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8299, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0214, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1515.094130466213, average reward:-7.575470652331066,----
Box_Position: [[1.48713161 0.60550344 0.66260776]]
actor_loss: tensor(7.3642, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2742, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-708.0241062121506, average reward:-5.803476280427464,success
Box_Position: [[1.3713332  0.69120337 0.72491926]]
actor_loss: tensor(7.0481, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-324.08203885175186, average reward:-5.892400706395488,success
Box_Position: [[1.51766245 0.6098247  0.47615487]]
actor_loss: tensor(6.8192, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-268.9422383415694, average reward:-7.077427324778142,success
Box_Position: [[1.50992131 0.68938008 0.59844517]]
actor_loss: tensor(6.3451, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-373.1868049192743, average reward:-5.831043826863661,success
Box_Position: [[1.39750383 0.72227899 0.65994342]]
actor_loss: tensor(6.9553, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-306.6618611477131, average reward:-5.287273468064019,success
Box_Position: [[1.43160579 0.66786032 0.45833015]]
actor_loss: tensor(7.0988, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-130.8682611074549, average reward:-6.543413055372746,success
Box_Position: [[1.45338646 0.76816798 0.72509073]]
Step:29, total reward:-157.2812698572956, average reward:-5.423492064044676,success
Box_Position: [[1.47339441 0.45994566 0.61524935]]
actor_loss: tensor(6.8087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6803, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3812, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-722.770047822943, average reward:-5.517328609335443,success
Box_Position: [[1.45093595 0.78814817 0.45751653]]
actor_loss: tensor(6.0072, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-203.9309506019314, average reward:-8.497122941747142,success
Box_Position: [[1.38340154 0.77979733 0.73614362]]
Step:14, total reward:-69.92094847362277, average reward:-4.994353462401627,success
Box_Position: [[1.44928998 0.84423688 0.52191354]]
actor_loss: tensor(6.3080, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9844, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-725.7887362729113, average reward:-6.480256573865279,success
Box_Position: [[1.33242569 0.95853969 0.53099763]]
Step:20, total reward:-132.40095155115495, average reward:-6.620047577557747,success
Box_Position: [[1.44791035 0.66106527 0.5753401 ]]
actor_loss: tensor(6.2931, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0345, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-673.9787103567747, average reward:-6.877333779150763,success
Box_Position: [[1.30772508 0.86036502 0.54136116]]
actor_loss: tensor(6.9457, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8361, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-364.3216180170011, average reward:-6.746696629944465,success
Box_Position: [[1.32661214 0.999041   0.48478816]]
Step:12, total reward:-144.17756994245715, average reward:-12.014797495204762,success
Box_Position: [[1.50117366 1.13470198 0.71841993]]
actor_loss: tensor(6.7916, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0341, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0160, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1266.4435817376714, average reward:-6.3322179086883565,----
Box_Position: [[1.53656948 0.45019094 0.54548937]]
actor_loss: tensor(5.8447, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3610, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0231, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4558, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1200.3115543553215, average reward:-6.001557771776607,----
Box_Position: [[1.5453119  0.5634236  0.61943073]]
actor_loss: tensor(6.6719, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7407, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5505, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9511, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1240.2574270892392, average reward:-6.201287135446196,----
Box_Position: [[1.37402347 0.75429876 0.55738138]]
Step:18, total reward:-126.89498550909863, average reward:-7.0497214171721465,success
Box_Position: [[1.35364941 0.55851981 0.72795481]]
Step:9, total reward:-40.410220215742626, average reward:-4.4900244684158475,success
Box_Position: [[1.3506592  0.97029669 0.66718701]]
actor_loss: tensor(6.1506, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-160.16739608363488, average reward:-7.627018861125471,success
Box_Position: [[1.35567276 0.56140943 0.66353238]]
Step:15, total reward:-82.35284418547441, average reward:-5.4901896123649605,success
Box_Position: [[1.33186334 0.81344222 0.64998133]]
Step:5, total reward:-23.27443727627971, average reward:-4.654887455255942,success
Box_Position: [[1.33242897 1.03037933 0.60488426]]
Step:13, total reward:-89.59828988363739, average reward:-6.892176144895184,success
Box_Position: [[1.25573258 0.8493018  0.69176596]]
actor_loss: tensor(6.2606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0881, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-439.6862897382347, average reward:-6.192764644200488,success
Box_Position: [[1.46026001 0.89764308 0.54551707]]
Step:25, total reward:-187.43817596682263, average reward:-7.497527038672905,success
Box_Position: [[1.50947201 0.6787132  0.71054052]]
actor_loss: tensor(6.4487, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-278.6864444874762, average reward:-5.359354701682235,success
Box_Position: [[1.46493171 1.08368114 0.69756539]]
actor_loss: tensor(6.5452, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-131.84122409621665, average reward:-5.49338433734236,success
Box_Position: [[1.4466329  1.0552685  0.73780368]]
actor_loss: tensor(6.0279, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-308.75875005914713, average reward:-6.3011989807989215,success
Box_Position: [[1.37192181 0.68320458 0.64597367]]
Step:16, total reward:-90.86236192477719, average reward:-5.678897620298574,success
Box_Position: [[1.52708847 0.91382032 0.58125367]]
actor_loss: tensor(6.8330, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9322, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3372, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2000, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1353.513633475796, average reward:-6.76756816737898,----
Box_Position: [[1.3393377  1.00972199 0.53846788]]
Step:11, total reward:-90.18981050292788, average reward:-8.199073682084354,success
Box_Position: [[1.51342573 1.03760741 0.5648695 ]]
actor_loss: tensor(6.0215, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0021, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9450, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0819, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1381.5034384572625, average reward:-6.907517192286313,----
Box_Position: [[1.53845755 0.69366098 0.4777505 ]]
actor_loss: tensor(6.8442, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2957, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-550.6210385509847, average reward:-6.714890714036399,success
Box_Position: [[1.45708921 0.74307055 0.55178056]]
actor_loss: tensor(6.6254, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3499, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7174, device='cuda:0', grad_fn=<NegBackward>)
Step:169, total reward:-931.2329350754923, average reward:-5.5102540537011375,success
Box_Position: [[1.45150455 0.67161828 0.6797434 ]]
actor_loss: tensor(6.4510, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-48.27885979618058, average reward:-4.827885979618058,success
Box_Position: [[1.44841539 1.09847952 0.45389523]]
actor_loss: tensor(5.9661, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3356, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8598, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1568.9685747426897, average reward:-7.844842873713449,----
Box_Position: [[1.48961701 0.89362723 0.55787776]]
Step:20, total reward:-166.22451182460324, average reward:-8.311225591230162,success
Box_Position: [[1.4035123  0.65284549 0.59040162]]
Step:20, total reward:-98.49882010018335, average reward:-4.924941005009168,success
Box_Position: [[1.43409137 0.69912762 0.63332049]]
actor_loss: tensor(6.4694, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-125.51697751372755, average reward:-5.976998929225122,success
Box_Position: [[1.48861162 0.91580066 0.690002  ]]
Step:27, total reward:-186.87093108385415, average reward:-6.9211455956983015,success
Box_Position: [[1.32916982 0.97903865 0.71997552]]
actor_loss: tensor(6.7291, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-341.4378708765928, average reward:-6.097104837082014,success
Box_Position: [[1.49042122 0.57199891 0.74721505]]
actor_loss: tensor(6.1829, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-254.0867778845233, average reward:-5.2934745392609015,success
Box_Position: [[1.43664037 0.48639273 0.45555554]]
actor_loss: tensor(6.4869, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-84.11252256897244, average reward:-5.257032660560777,success
Box_Position: [[1.45654795 0.55606593 0.54190202]]

------------------Episode:1850------------------
actor_loss: tensor(5.9597, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-402.78867544105805, average reward:-6.603093040017345,success
Box_Position: [[1.38681642 1.11217864 0.54238701]]
actor_loss: tensor(6.7447, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3945, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2403, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3555, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1258.7934821823083, average reward:-6.2939674109115415,----
Box_Position: [[1.28877601 0.61189572 0.69330041]]
actor_loss: tensor(6.8181, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-257.72629512834055, average reward:-5.602745546268273,success
Box_Position: [[1.54916118 0.9063599  0.61309758]]
actor_loss: tensor(6.0342, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-251.26842855751116, average reward:-5.843451826918864,success
Box_Position: [[1.43769753 0.66179463 0.65305385]]
Step:3, total reward:-18.943624350639602, average reward:-6.314541450213201,success
Box_Position: [[1.34543226 0.51264859 0.58044608]]
actor_loss: tensor(7.4018, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3991, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-800.2365904547091, average reward:-5.798815872860211,success
Box_Position: [[1.54410774 0.47349635 0.52783395]]
actor_loss: tensor(6.1087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5979, device='cuda:0', grad_fn=<NegBackward>)
Step:129, total reward:-745.1379086076063, average reward:-5.776262857423305,success
Box_Position: [[1.35128248 0.69386139 0.47994704]]
Step:17, total reward:-106.97666935397645, average reward:-6.292745256116262,success
Box_Position: [[1.36342661 0.90393826 0.70829271]]
actor_loss: tensor(6.1582, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-205.35857785551042, average reward:-6.039958172220895,success
Box_Position: [[1.48588943 0.79695853 0.73716376]]
Step:9, total reward:-60.83012769783078, average reward:-6.758903077536754,success
Box_Position: [[1.50230321 0.81055327 0.59992922]]
actor_loss: tensor(6.6814, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6626, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-425.6336571917442, average reward:-6.448994805935518,success
Box_Position: [[1.34544482 0.483268   0.5801533 ]]
Step:32, total reward:-189.80332647780006, average reward:-5.931353952431252,success
Box_Position: [[1.50780596 0.93618289 0.69983299]]
actor_loss: tensor(6.3847, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-76.8933600773295, average reward:-6.990305461575409,success
Box_Position: [[1.38152983 0.69787782 0.61037221]]
actor_loss: tensor(6.5113, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9386, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3992, device='cuda:0', grad_fn=<NegBackward>)
Step:183, total reward:-1039.5623838256454, average reward:-5.680668764074565,success
Box_Position: [[1.5081791  0.93194511 0.67285982]]
Step:9, total reward:-57.961816134484884, average reward:-6.440201792720543,success
Box_Position: [[1.47658183 0.7805521  0.63711286]]
Step:5, total reward:-25.440191862803868, average reward:-5.088038372560773,success
Box_Position: [[1.38401077 0.68780415 0.52761356]]
actor_loss: tensor(7.1603, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-212.03314654804882, average reward:-6.058089901372823,success
Box_Position: [[1.29892503 1.01567983 0.53295209]]
Step:14, total reward:-93.62583840366977, average reward:-6.6875598859764125,success
Box_Position: [[1.28368105 1.10797065 0.58156947]]
actor_loss: tensor(6.7214, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-215.26431043652732, average reward:-7.688011087018833,success
Box_Position: [[1.34129644 0.81974488 0.5739208 ]]
actor_loss: tensor(6.3139, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-342.69860922004943, average reward:-6.466011494717914,success
Box_Position: [[1.48944129 0.64092346 0.62569431]]
actor_loss: tensor(7.0012, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8152, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8419, device='cuda:0', grad_fn=<NegBackward>)
Step:153, total reward:-864.9713625842628, average reward:-5.653407598589953,success
Box_Position: [[1.42134564 0.67957802 0.53732118]]
actor_loss: tensor(6.4835, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6641, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-490.87340010751075, average reward:-5.914137350692901,success
Box_Position: [[1.36383267 1.00165406 0.61560658]]
actor_loss: tensor(6.6804, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2737, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-653.5044840360387, average reward:-6.283696961884987,success
Box_Position: [[1.41179425 0.62668134 0.51110362]]
Step:18, total reward:-126.22379942284236, average reward:-7.01243330126902,success
Box_Position: [[1.29978331 0.88991836 0.65954069]]
actor_loss: tensor(6.5444, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8059, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7099, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-641.5042533194556, average reward:-5.530209080340135,success
Box_Position: [[1.27473107 0.51875932 0.63977323]]
Step:17, total reward:-115.97443286655084, average reward:-6.822025462738285,success
Box_Position: [[1.51140685 0.81478887 0.56951782]]
actor_loss: tensor(6.3026, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-486.00302010022443, average reward:-6.311727533769148,success
Box_Position: [[1.46981984 0.70181746 0.68028377]]
actor_loss: tensor(6.1666, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2130, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-607.516524556746, average reward:-5.148445123362254,success
Box_Position: [[1.49070868 0.66028673 0.74601504]]
actor_loss: tensor(6.0975, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-366.33986184436185, average reward:-5.635997874528644,success
Box_Position: [[1.38972842 0.59321558 0.56749565]]
actor_loss: tensor(6.7098, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-250.79838774590823, average reward:-5.224966411373088,success
Box_Position: [[1.52071692 0.55354603 0.59266909]]
actor_loss: tensor(7.3925, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9465, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1160, device='cuda:0', grad_fn=<NegBackward>)
Step:156, total reward:-900.7105299490985, average reward:-5.773785448391657,success
Box_Position: [[1.33408079 1.11303975 0.55484675]]
actor_loss: tensor(6.4430, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-296.5731615463426, average reward:-5.931463230926852,success
Box_Position: [[1.51439313 0.77996705 0.48388356]]
Step:15, total reward:-110.10809466678171, average reward:-7.340539644452114,success
Box_Position: [[1.47724446 0.82267119 0.65233641]]
actor_loss: tensor(6.4700, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-94.38160359367203, average reward:-7.260123353359386,success
Box_Position: [[1.30787219 0.68981832 0.65281293]]
Step:5, total reward:-29.682490845230245, average reward:-5.9364981690460485,success
Box_Position: [[1.28138317 0.65818762 0.69346509]]
actor_loss: tensor(6.4505, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-192.29882856080252, average reward:-4.807470714020063,success
Box_Position: [[1.32728201 0.80461552 0.73645623]]
Step:36, total reward:-214.19578790230517, average reward:-5.949882997286255,success
Box_Position: [[1.43429162 0.70039836 0.57200681]]
actor_loss: tensor(6.1545, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4000, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0537, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5408, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1156.6819925575137, average reward:-5.783409962787569,success
Box_Position: [[1.30439566 0.56739542 0.63013629]]
actor_loss: tensor(6.4759, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2724, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9455, device='cuda:0', grad_fn=<NegBackward>)
Step:128, total reward:-705.442524260012, average reward:-5.5112697207813435,success
Box_Position: [[1.35093202 0.70090133 0.53893574]]
actor_loss: tensor(6.3051, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-291.50155516319734, average reward:-5.3981769474666175,success
Box_Position: [[1.30861224 0.61789657 0.56476269]]
Step:23, total reward:-130.2424221356868, average reward:-5.662714005899426,success
Box_Position: [[1.52316907 0.50191388 0.54507861]]
actor_loss: tensor(5.7943, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2673, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9547, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1235.6381511911075, average reward:-6.178190755955537,----
Box_Position: [[1.30635423 0.44397372 0.6432559 ]]
actor_loss: tensor(6.3119, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0878, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-322.602542476861, average reward:-5.288566270112476,success
Box_Position: [[1.31077956 0.94152839 0.58960877]]
Step:6, total reward:-45.20686683398274, average reward:-7.53447780566379,success
Box_Position: [[1.32945538 1.00827151 0.53284589]]
Step:7, total reward:-60.307059202353436, average reward:-8.615294171764777,success
Box_Position: [[1.46141234 0.60356816 0.60837234]]
Step:27, total reward:-161.40006064699583, average reward:-5.977780023962809,success
Box_Position: [[1.51614407 0.7576685  0.52725335]]
actor_loss: tensor(6.8197, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-196.13618005539763, average reward:-6.537872668513255,success
Box_Position: [[1.44854422 0.85057634 0.47658014]]
actor_loss: tensor(6.8240, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5459, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2663, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4559, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1389.121803359817, average reward:-6.945609016799085,----
Box_Position: [[1.3915942  0.49248816 0.72823814]]
actor_loss: tensor(6.2350, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-124.51265634337433, average reward:-5.188027347640597,success
Box_Position: [[1.50911195 0.92766005 0.58205868]]
Step:14, total reward:-104.20511909250247, average reward:-7.443222792321605,success
Box_Position: [[1.25427643 0.9024588  0.45735898]]

------------------Episode:1900------------------
Step:8, total reward:-75.78346002993183, average reward:-9.472932503741479,success
episode 1900, the accuracy is: 89%
Box_Position: [[1.36263798 0.71161168 0.69471306]]
Step:17, total reward:-90.86258888141194, average reward:-5.34485816949482,success
Box_Position: [[1.35120465 0.57587014 0.59724242]]
actor_loss: tensor(6.2792, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-225.53411270369756, average reward:-5.500832017163355,success
Box_Position: [[1.35298047 0.69006069 0.71822539]]
actor_loss: tensor(6.5073, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-294.95920231558193, average reward:-4.915986705259699,success
Box_Position: [[1.2620415  0.77094496 0.64209629]]
actor_loss: tensor(5.4964, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-95.22279032725886, average reward:-6.348186021817257,success
Box_Position: [[1.32657033 0.61087994 0.72171649]]
actor_loss: tensor(6.3111, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4981, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2901, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-954.6500501481453, average reward:-5.393503108181612,success
Box_Position: [[1.39563663 0.86147461 0.64230087]]
actor_loss: tensor(6.4805, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-262.06682072020607, average reward:-5.82370712711569,success
Box_Position: [[1.30549131 0.70540739 0.46627278]]
Step:4, total reward:-25.731938801281448, average reward:-6.432984700320362,success
Box_Position: [[1.26649681 0.89926799 0.55837316]]
actor_loss: tensor(6.4295, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-204.4680502392227, average reward:-7.050622422042162,success
Box_Position: [[1.44025802 0.63062184 0.63147147]]
actor_loss: tensor(5.8257, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6466, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4083, device='cuda:0', grad_fn=<NegBackward>)
Step:163, total reward:-820.7255626597323, average reward:-5.035126151286701,success
Box_Position: [[1.43754733 0.75058272 0.65877927]]
Step:14, total reward:-67.09513247883268, average reward:-4.792509462773763,success
Box_Position: [[1.43145097 0.97340693 0.67800689]]
actor_loss: tensor(6.5799, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-122.38664652212702, average reward:-5.827935548672715,success
Box_Position: [[1.28840928 0.67358406 0.67757048]]
actor_loss: tensor(6.4506, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-304.37930429197735, average reward:-5.072988404866289,success
Box_Position: [[1.47410676 0.91100532 0.70629893]]
actor_loss: tensor(6.5277, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-188.97932731632008, average reward:-5.9056039786350025,success
Box_Position: [[1.51985365 0.96325857 0.5154527 ]]
actor_loss: tensor(7.0267, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5196, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1774, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6758, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1365.5185484319516, average reward:-6.827592742159758,----
Box_Position: [[1.42591115 0.97024431 0.63500163]]
actor_loss: tensor(6.1354, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-318.99757656058586, average reward:-6.018822199256337,success
Box_Position: [[1.40910286 0.50531019 0.54894273]]
Step:6, total reward:-44.40114424195298, average reward:-7.400190706992163,success
Box_Position: [[1.28476261 0.88547954 0.45038201]]
actor_loss: tensor(6.4125, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4644, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-785.7687379082316, average reward:-7.2088875037452445,success
Box_Position: [[1.53870088 0.87767955 0.69560108]]
actor_loss: tensor(5.9373, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5235, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3782, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3681, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1154.9113225838419, average reward:-5.774556612919209,----
Box_Position: [[1.3470322  0.77458834 0.5774506 ]]
Step:22, total reward:-129.76930182795644, average reward:-5.898604628543475,success
Box_Position: [[1.51151755 0.65309669 0.68393674]]
actor_loss: tensor(6.4416, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1146, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0008, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8514, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1121.1669338863219, average reward:-5.6058346694316095,----
Box_Position: [[1.45817873 0.73743161 0.59538115]]
actor_loss: tensor(6.4675, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-142.78971046793478, average reward:-7.9327616926630435,success
Box_Position: [[1.3158451  1.02805812 0.58721623]]
Step:10, total reward:-90.06048766208934, average reward:-9.006048766208934,success
Box_Position: [[1.29294941 0.7064198  0.5949416 ]]
actor_loss: tensor(6.1480, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-193.49604179587945, average reward:-5.691060052819984,success
Box_Position: [[1.29822259 0.79050381 0.57279849]]
Step:21, total reward:-111.86630920007767, average reward:-5.326967104765603,success
Box_Position: [[1.50776761 0.85285179 0.74938964]]
actor_loss: tensor(6.1188, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-197.81542911342714, average reward:-5.994406942831126,success
Box_Position: [[1.32084415 0.43988944 0.53952522]]
actor_loss: tensor(5.8995, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-418.9014651091407, average reward:-6.756475243695818,success
Box_Position: [[1.42468135 1.02559523 0.54967947]]
actor_loss: tensor(7.0627, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5063, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0385, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-1002.0454219748646, average reward:-6.910658082585273,success
Box_Position: [[1.4865501  0.67784571 0.52991047]]
Step:29, total reward:-167.30066541510885, average reward:-5.76898846258996,success
Box_Position: [[1.30638707 0.92730499 0.57789013]]
actor_loss: tensor(6.3954, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-126.76791482895287, average reward:-8.451194321930192,success
Box_Position: [[1.26624916 0.73273423 0.71847685]]
Step:14, total reward:-83.31833211724732, average reward:-5.951309436946238,success
Box_Position: [[1.26144687 0.63537066 0.61966354]]
actor_loss: tensor(7.1079, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9950, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-521.5719559452849, average reward:-5.164078771735494,success
Box_Position: [[1.25032984 1.05907444 0.62313276]]
actor_loss: tensor(6.0235, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-300.8598645945948, average reward:-6.54043183901293,success
Box_Position: [[1.36656116 0.62886313 0.53938936]]
Step:21, total reward:-123.73154358374342, average reward:-5.8919782658925435,success
Box_Position: [[1.45942068 0.86583868 0.48731104]]
actor_loss: tensor(6.1998, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-287.6292631897439, average reward:-7.773763869993078,success
Box_Position: [[1.25059767 0.8741165  0.66705833]]
actor_loss: tensor(5.9161, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-206.44186799667298, average reward:-6.65941509666687,success
Box_Position: [[1.34570081 1.04919393 0.57079895]]
Step:25, total reward:-205.51856347598698, average reward:-8.22074253903948,success
Box_Position: [[1.25768005 1.07262287 0.64076391]]
actor_loss: tensor(5.8437, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-251.66622971255586, average reward:-5.852703016571066,success
Box_Position: [[1.25245836 0.52788636 0.70678742]]
actor_loss: tensor(6.1497, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7013, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6628, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1048.1488260380129, average reward:-5.240744130190064,----
Box_Position: [[1.51868388 0.57182608 0.45207339]]
actor_loss: tensor(6.1252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1599, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-740.3918002840574, average reward:-6.919549535365022,success
Box_Position: [[1.32057299 0.76302666 0.59618974]]
Step:10, total reward:-48.364820068676785, average reward:-4.836482006867678,success
Box_Position: [[1.49660457 0.59930917 0.7441301 ]]
actor_loss: tensor(7.1126, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-87.99939184476013, average reward:-5.866626122984008,success
Box_Position: [[1.51679544 0.48510134 0.5817981 ]]
Step:10, total reward:-65.04611769294931, average reward:-6.504611769294931,success
Box_Position: [[1.45185709 0.91013053 0.46493742]]
actor_loss: tensor(6.5010, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2268, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-1071.6213012990809, average reward:-6.95857987856546,success
Box_Position: [[1.40002423 1.01184135 0.59912052]]
actor_loss: tensor(6.3575, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-297.11409711719665, average reward:-6.4590021112434055,success
Box_Position: [[1.34277743 0.92813985 0.59157981]]
Step:10, total reward:-75.17112304200506, average reward:-7.517112304200507,success
Box_Position: [[1.35878798 0.76552777 0.69936491]]
Step:7, total reward:-42.27920249378825, average reward:-6.039886070541178,success
Box_Position: [[1.36747963 0.67326176 0.58769253]]
Step:14, total reward:-68.28296073225748, average reward:-4.8773543380183915,success
Box_Position: [[1.39999254 1.1469323  0.49866897]]
actor_loss: tensor(6.5469, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-308.7605668392517, average reward:-6.5693737625372695,success
Box_Position: [[1.50894955 0.84739973 0.6045485 ]]
actor_loss: tensor(6.1832, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5164, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5950, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1148.5491563775247, average reward:-5.742745781887623,----
Box_Position: [[1.51337234 0.77664064 0.46289877]]

------------------Episode:1950------------------
actor_loss: tensor(6.3424, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0068, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-404.15853492294826, average reward:-6.625549752835218,success
Box_Position: [[1.30707968 0.9766688  0.63481766]]
Step:39, total reward:-241.9778538407878, average reward:-6.204560354891995,success
Box_Position: [[1.26853502 0.52135361 0.65342348]]
actor_loss: tensor(6.0837, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0699, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-295.66996355775666, average reward:-5.011355314538249,success
Box_Position: [[1.34999367 1.07182983 0.4868462 ]]
actor_loss: tensor(6.1885, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-430.2703608690579, average reward:-7.418454497742378,success
Box_Position: [[1.43947891 0.75989992 0.65550268]]
actor_loss: tensor(6.6485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6373, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1791, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-739.9152034022137, average reward:-5.361704372479809,success
Box_Position: [[1.31581299 0.78570035 0.63911146]]
Step:22, total reward:-152.44090806002853, average reward:-6.929132184546751,success
Box_Position: [[1.37896322 0.44987817 0.52556684]]
Step:19, total reward:-126.95374989820914, average reward:-6.68177631043206,success
Box_Position: [[1.25044221 1.03998246 0.56684131]]
actor_loss: tensor(6.1619, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-168.02344275014144, average reward:-7.000976781255893,success
Box_Position: [[1.40216334 0.47214165 0.65239443]]
actor_loss: tensor(6.0357, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3037, device='cuda:0', grad_fn=<NegBackward>)
Step:123, total reward:-615.546524325139, average reward:-5.004443287196252,success
Box_Position: [[1.34622562 0.86095863 0.55934346]]
actor_loss: tensor(6.1697, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-142.4178542731873, average reward:-5.934077261382804,success
Box_Position: [[1.47582184 0.83597585 0.61398091]]
actor_loss: tensor(6.6475, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-505.1504536149218, average reward:-6.086150043553275,success
Box_Position: [[1.45812583 0.92018713 0.70103606]]
actor_loss: tensor(5.7765, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-173.5442609801164, average reward:-5.423258155628638,success
Box_Position: [[1.45079365 0.9977851  0.57418292]]
actor_loss: tensor(6.9117, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-360.72148398538536, average reward:-6.806065735573308,success
Box_Position: [[1.39949892 0.5597073  0.45305339]]
actor_loss: tensor(7.1276, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9532, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-678.4921956735526, average reward:-6.523963419938005,success
Box_Position: [[1.37275975 0.90401916 0.67437386]]
actor_loss: tensor(6.1565, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-137.71440993468008, average reward:-6.259745906121822,success
Box_Position: [[1.46438595 0.74136842 0.59025559]]
actor_loss: tensor(6.2165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0444, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5054, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1153.4131830606993, average reward:-5.767065915303497,----
Box_Position: [[1.26008405 0.74252751 0.60962974]]
Step:6, total reward:-44.2866119894159, average reward:-7.381101998235984,success
Box_Position: [[1.36903581 0.68852123 0.45168575]]
Step:9, total reward:-72.58601621200391, average reward:-8.06511291244488,success
Box_Position: [[1.31457379 1.13361346 0.68222754]]
Step:10, total reward:-62.13791864497236, average reward:-6.213791864497236,success
Box_Position: [[1.26801349 0.51907846 0.74476856]]
actor_loss: tensor(6.8908, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6778, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-621.4018948537116, average reward:-5.598215268952357,success
Box_Position: [[1.36103247 0.85731839 0.49961748]]
actor_loss: tensor(6.5988, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-347.19659611259385, average reward:-7.233262419012372,success
Box_Position: [[1.43303566 0.81629703 0.60910952]]
actor_loss: tensor(6.5938, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-71.45207084849535, average reward:-7.1452070848495355,success
Box_Position: [[1.40797114 0.7107461  0.57354846]]
Step:35, total reward:-210.28388872816757, average reward:-6.008111106519073,success
Box_Position: [[1.25638377 0.53277208 0.67610074]]
actor_loss: tensor(6.4237, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5748, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0561, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-606.7162163217702, average reward:-5.230312209670433,success
Box_Position: [[1.46810507 0.98522314 0.57759149]]
Step:26, total reward:-217.97991931775462, average reward:-8.38384305068287,success
Box_Position: [[1.43857255 0.99972703 0.60459044]]
actor_loss: tensor(6.2118, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-167.37968336108344, average reward:-7.608167425503793,success
Box_Position: [[1.41778053 0.79645703 0.62474579]]
Step:18, total reward:-88.1687274246674, average reward:-4.898262634703745,success
Box_Position: [[1.43561546 0.98646339 0.69590758]]
Step:10, total reward:-80.45935699102691, average reward:-8.04593569910269,success
Box_Position: [[1.37482674 1.00800188 0.64612628]]
actor_loss: tensor(6.4178, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-252.3122707394962, average reward:-5.867727226499912,success
Box_Position: [[1.29038474 0.68719509 0.47120659]]
actor_loss: tensor(6.5464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6010, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-583.4801135929766, average reward:-5.777030827653234,success
Box_Position: [[1.31247336 0.87475833 0.5587712 ]]
actor_loss: tensor(5.9329, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-408.468196435815, average reward:-7.294074936353839,success
Box_Position: [[1.37262097 0.75984111 0.72266225]]
actor_loss: tensor(5.8223, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-194.03541588541776, average reward:-4.850885397135444,success
Box_Position: [[1.28708027 0.9523876  0.67125262]]
actor_loss: tensor(6.2068, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-270.3592429249376, average reward:-4.743144612718203,success
Box_Position: [[1.50534227 0.5646553  0.62631672]]
actor_loss: tensor(6.0665, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-267.3004173700297, average reward:-5.810878638478907,success
Box_Position: [[1.3494567  1.03276311 0.46554062]]
Step:20, total reward:-171.98228581095182, average reward:-8.599114290547591,success
Box_Position: [[1.27028896 0.59379571 0.5501545 ]]
actor_loss: tensor(6.1523, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4614, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-537.7673361360224, average reward:-7.075886001789769,success
Box_Position: [[1.27322313 0.87557958 0.59450276]]
Step:10, total reward:-63.56284049184681, average reward:-6.356284049184682,success
Box_Position: [[1.49918948 0.6510105  0.61697595]]
actor_loss: tensor(6.7865, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-292.6869465521828, average reward:-4.960795704274285,success
Box_Position: [[1.54046396 0.68063218 0.67062238]]
Step:13, total reward:-81.68780145830219, average reward:-6.283677035254015,success
Box_Position: [[1.38378813 0.9325409  0.6865103 ]]
actor_loss: tensor(6.7630, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0736, device='cuda:0', grad_fn=<NegBackward>)
Step:87, total reward:-557.5771329424987, average reward:-6.408932562557456,success
Box_Position: [[1.38575627 0.85056648 0.52397957]]
actor_loss: tensor(6.7541, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6051, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-577.7422048196022, average reward:-6.14619366829364,success
Box_Position: [[1.47312615 0.67791313 0.45114624]]
Step:14, total reward:-100.34434890170486, average reward:-7.167453492978919,success
Box_Position: [[1.49496464 0.633672   0.49316999]]
actor_loss: tensor(5.8495, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6223, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-496.4968296555295, average reward:-6.709416616966615,success
Box_Position: [[1.52095164 0.89458014 0.63743021]]
Step:22, total reward:-131.02062878541304, average reward:-5.955483126609684,success
Box_Position: [[1.37698782 0.7379545  0.45249432]]
actor_loss: tensor(6.2478, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-82.00302168258072, average reward:-4.823707157798866,success
Box_Position: [[1.48771125 1.14272026 0.64640678]]
actor_loss: tensor(6.5972, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0727, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1218, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1163.0575377858238, average reward:-5.815287688929119,----
Box_Position: [[1.49139578 0.66488699 0.67304292]]
actor_loss: tensor(6.6487, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-278.7008282004694, average reward:-5.161126448156841,success
Box_Position: [[1.44133534 0.76639684 0.72753682]]
Step:20, total reward:-98.5621764203445, average reward:-4.928108821017225,success
Box_Position: [[1.54588774 0.80137963 0.74276864]]
actor_loss: tensor(6.5767, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0698, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-371.2047340691858, average reward:-5.30292477241694,success
Box_Position: [[1.38648301 0.63935509 0.58988218]]
Step:8, total reward:-43.57197885380258, average reward:-5.446497356725322,success
Box_Position: [[1.53376486 0.60282645 0.72405095]]

------------------Episode:2000------------------
actor_loss: tensor(5.6674, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-341.1588968427282, average reward:-5.68598161404547,success
episode 2000, the accuracy is: 93%
Box_Position: [[1.40729266 0.99389287 0.60796418]]
Step:9, total reward:-64.72209733793382, average reward:-7.191344148659313,success
Box_Position: [[1.36005614 0.83747036 0.45152177]]
Step:11, total reward:-99.24452446334017, average reward:-9.022229496667288,success
Box_Position: [[1.33058721 0.8038463  0.51242932]]
actor_loss: tensor(5.6517, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-280.1744306921659, average reward:-6.670819778384903,success
Box_Position: [[1.46460247 0.74523877 0.65288579]]
actor_loss: tensor(5.5998, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-237.72581287018616, average reward:-7.924193762339539,success
Box_Position: [[1.31155259 0.7750188  0.47193132]]
Step:22, total reward:-148.83522585012042, average reward:-6.765237538641838,success
Box_Position: [[1.50357944 1.09035331 0.52317455]]
actor_loss: tensor(5.6954, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9960, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6961, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1433.16560076322, average reward:-7.1658280038161,----
Box_Position: [[1.33492054 0.68840187 0.57153388]]
actor_loss: tensor(6.9021, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-201.5542313489392, average reward:-6.718474378297973,success
Box_Position: [[1.41475699 0.7620616  0.7412711 ]]
actor_loss: tensor(5.8212, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-402.9957453783663, average reward:-5.3025755970837665,success
Box_Position: [[1.48444904 0.86777842 0.73087191]]
actor_loss: tensor(6.6881, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0696, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1097.408404922934, average reward:-5.48704202461467,----
Box_Position: [[1.39368914 0.99919714 0.71632941]]
Step:10, total reward:-100.77400146385963, average reward:-10.077400146385964,success
Box_Position: [[1.37153363 0.62667433 0.58424012]]
actor_loss: tensor(6.1769, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-28.420506447091917, average reward:-7.105126611772979,success
Box_Position: [[1.50562118 0.52930656 0.68093413]]
Step:8, total reward:-41.97791771188345, average reward:-5.247239713985431,success
Box_Position: [[1.49704998 0.48627827 0.69335584]]
actor_loss: tensor(6.2382, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-314.64189044370636, average reward:-4.696147618562781,success
Box_Position: [[1.28811273 0.8759791  0.48658925]]
actor_loss: tensor(6.4014, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2177, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-625.1969202442002, average reward:-6.651031066427662,success
Box_Position: [[1.48551982 0.79029526 0.73056425]]
actor_loss: tensor(5.8015, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9878, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-511.3833941937487, average reward:-4.964887322269405,success
Box_Position: [[1.4211919  0.9185169  0.62101365]]
actor_loss: tensor(5.9882, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-175.65759722526548, average reward:-6.057158525009155,success
Box_Position: [[1.39894286 0.60371033 0.4726363 ]]
Step:12, total reward:-89.35367054198804, average reward:-7.446139211832336,success
Box_Position: [[1.29198032 0.84879486 0.65258198]]
Step:3, total reward:-23.25299407389953, average reward:-7.750998024633176,success
Box_Position: [[1.44334894 0.58649682 0.54747552]]
actor_loss: tensor(6.0976, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1570, device='cuda:0', grad_fn=<NegBackward>)
Step:85, total reward:-516.1287117561078, average reward:-6.0721024912483275,success
Box_Position: [[1.29382777 1.06455526 0.69324965]]
Step:45, total reward:-263.78363682529624, average reward:-5.8618585961176946,success
Box_Position: [[1.27643874 0.67385975 0.72030307]]
actor_loss: tensor(6.1401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9359, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4945, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1123.1014197784386, average reward:-5.615507098892193,----
Box_Position: [[1.45676384 0.85304015 0.52858526]]
actor_loss: tensor(6.3385, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3083, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0125, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-758.7289122687521, average reward:-7.295470310276462,success
Box_Position: [[1.42113722 0.6705211  0.57975653]]
actor_loss: tensor(5.3808, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-370.1792707662158, average reward:-6.169654512770263,success
Box_Position: [[1.36409737 0.88457236 0.74728904]]
actor_loss: tensor(5.8291, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7449, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-747.8809975283533, average reward:-5.26676758822784,success
Box_Position: [[1.42536456 0.67591241 0.47253135]]
Step:36, total reward:-206.77985210963163, average reward:-5.743884780823101,success
Box_Position: [[1.42920688 0.74620813 0.7478843 ]]
actor_loss: tensor(5.2171, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7861, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-492.5651949951304, average reward:-5.026175459133984,success
Box_Position: [[1.43286531 0.85795569 0.66665743]]
actor_loss: tensor(6.1437, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-126.71543984848063, average reward:-6.669233676235822,success
Box_Position: [[1.48501174 0.90049385 0.53899676]]
Step:11, total reward:-96.05133371467807, average reward:-8.731939428607097,success
Box_Position: [[1.44856965 0.43987487 0.61602217]]
Step:9, total reward:-52.644666522932106, average reward:-5.849407391436901,success
Box_Position: [[1.50628855 0.83535904 0.61757312]]
actor_loss: tensor(5.8801, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8026, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-475.79175420219605, average reward:-6.0226804329391905,success
Box_Position: [[1.46941019 0.73325475 0.54263172]]
Step:7, total reward:-32.09375161473582, average reward:-4.584821659247974,success
Box_Position: [[1.31505773 0.97453745 0.53039018]]
Step:16, total reward:-121.20904503688523, average reward:-7.575565314805327,success
Box_Position: [[1.33502502 0.51811878 0.61461402]]
actor_loss: tensor(6.2605, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-219.18129604375997, average reward:-5.21860228675619,success
Box_Position: [[1.38003529 0.77215429 0.71637641]]
actor_loss: tensor(6.1682, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-153.91720743058647, average reward:-5.130573581019549,success
Box_Position: [[1.33877029 0.46533484 0.50772523]]
Step:36, total reward:-203.827236580535, average reward:-5.661867682792638,success
Box_Position: [[1.26567438 0.88013689 0.4582224 ]]
actor_loss: tensor(5.8383, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-167.53581086293184, average reward:-7.2841656896926885,success
Box_Position: [[1.32717936 0.5434352  0.47942188]]
Step:18, total reward:-106.48282109279238, average reward:-5.91571228293291,success
Box_Position: [[1.36508116 0.62860741 0.63826128]]
Step:15, total reward:-91.79583312390234, average reward:-6.119722208260156,success
Box_Position: [[1.35129486 1.00161668 0.57090677]]
actor_loss: tensor(6.0728, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-261.4462464996318, average reward:-7.262395736100883,success
Box_Position: [[1.34381537 0.508975   0.73404908]]
actor_loss: tensor(5.9142, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1461, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6385, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8850, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1010.5013654589245, average reward:-5.052506827294622,----
Box_Position: [[1.33940608 0.69604656 0.65153879]]
actor_loss: tensor(6.2237, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2454, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-441.5286455871839, average reward:-5.588970197306126,success
Box_Position: [[1.48007949 0.76010351 0.66330505]]
Step:19, total reward:-109.55543561797812, average reward:-5.766075558840954,success
Box_Position: [[1.3335545  0.49068573 0.49343832]]
Step:12, total reward:-85.47323467316647, average reward:-7.122769556097206,success
Box_Position: [[1.42226328 0.70944854 0.64230966]]
Step:7, total reward:-38.82869879179902, average reward:-5.5469569702570025,success
Box_Position: [[1.41779287 0.69838424 0.70598572]]
actor_loss: tensor(5.7871, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-38.3508338694144, average reward:-4.7938542336768,success
Box_Position: [[1.52361764 0.7600529  0.6832059 ]]
Step:22, total reward:-140.06455761897755, average reward:-6.366570800862616,success
Box_Position: [[1.2789177  1.16334044 0.56836985]]
actor_loss: tensor(5.9082, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-415.22155921421086, average reward:-9.656315330563043,success
Box_Position: [[1.40761315 0.79208837 0.74608394]]
actor_loss: tensor(5.9287, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7957, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-434.4010615200922, average reward:-5.171441208572526,success
Box_Position: [[1.366021   0.54799179 0.46570861]]
Step:42, total reward:-243.97220541809435, average reward:-5.808862033764151,success
Box_Position: [[1.44308647 1.17923719 0.50697189]]

------------------Episode:2050------------------
actor_loss: tensor(5.9327, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8718, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6594, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8400, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1309.9613150753441, average reward:-6.549806575376721,----
Box_Position: [[1.47210086 0.62163615 0.61811391]]
actor_loss: tensor(6.5513, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2284, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-353.0320030746161, average reward:-5.516125048040877,success
Box_Position: [[1.25720117 0.77722297 0.45336769]]
Step:14, total reward:-65.31740520722832, average reward:-4.6655289433734515,success
Box_Position: [[1.47744479 0.75517889 0.45522165]]
actor_loss: tensor(5.4161, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6718, device='cuda:0', grad_fn=<NegBackward>)
Step:117, total reward:-796.5085188550817, average reward:-6.807765118419502,success
Box_Position: [[1.53309781 1.04324161 0.6597333 ]]
actor_loss: tensor(5.8564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0855, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0322, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5266, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1354.0239448879531, average reward:-6.770119724439765,----
Box_Position: [[1.36124432 0.96723979 0.53146385]]
actor_loss: tensor(5.9599, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-226.53422308888614, average reward:-7.079194471527692,success
Box_Position: [[1.42725404 0.79508054 0.73564902]]
actor_loss: tensor(5.8876, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3049, device='cuda:0', grad_fn=<NegBackward>)
Step:109, total reward:-590.0852810586208, average reward:-5.413626431730466,success
Box_Position: [[1.37441442 0.74750187 0.46996614]]
actor_loss: tensor(6.2191, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-416.50789262534846, average reward:-6.216535710826096,success
Box_Position: [[1.54177302 0.73174568 0.5759181 ]]
actor_loss: tensor(6.7261, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0154, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-416.904290099386, average reward:-8.017390194218962,success
Box_Position: [[1.42315124 0.96160399 0.55196561]]
actor_loss: tensor(5.6201, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-368.6715370689804, average reward:-7.228853668019224,success
Box_Position: [[1.52700419 0.8032149  0.57871515]]
Step:39, total reward:-223.3517894056668, average reward:-5.726968959119661,success
Box_Position: [[1.39743728 0.86645438 0.65605135]]
actor_loss: tensor(6.4576, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8648, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-418.1449853012977, average reward:-5.807569240295802,success
Box_Position: [[1.51779693 0.8030436  0.50170691]]
Step:30, total reward:-149.31130152679438, average reward:-4.977043384226479,success
Box_Position: [[1.42834412 0.86325519 0.72285017]]
actor_loss: tensor(6.0206, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-75.83545919012313, average reward:-5.055697279341542,success
Box_Position: [[1.36723106 1.05293739 0.55042778]]
Step:23, total reward:-183.06821850313906, average reward:-7.959487761006046,success
Box_Position: [[1.43069118 0.61370202 0.63825721]]
Step:5, total reward:-39.03576766160858, average reward:-7.807153532321716,success
Box_Position: [[1.39326638 0.96054957 0.63319567]]
actor_loss: tensor(5.8688, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-290.49865334572473, average reward:-5.696052026386759,success
Box_Position: [[1.31275248 0.62097848 0.68590007]]
actor_loss: tensor(5.5397, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-230.65047169611887, average reward:-5.49167789752664,success
Box_Position: [[1.2925256  0.50130879 0.70199103]]
actor_loss: tensor(6.2489, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3827, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-408.83895735006865, average reward:-5.30959684870219,success
Box_Position: [[1.29177869 0.80609348 0.72217844]]
actor_loss: tensor(6.2623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0969, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-865.1625210893015, average reward:-7.458297595597427,success
Box_Position: [[1.40071398 0.84081263 0.57101553]]
actor_loss: tensor(6.0530, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3651, device='cuda:0', grad_fn=<NegBackward>)
Step:124, total reward:-726.8884278842169, average reward:-5.862003450679168,success
Box_Position: [[1.35087343 1.03764815 0.72129641]]
actor_loss: tensor(5.5536, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5275, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8351, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1108.9655085682696, average reward:-5.544827542841348,----
Box_Position: [[1.27156005 0.71803724 0.70490429]]
Step:2, total reward:-9.391334851784357, average reward:-4.695667425892179,success
Box_Position: [[1.45712946 0.67225659 0.50597171]]
actor_loss: tensor(6.1699, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-168.78436036977342, average reward:-6.491706168068209,success
Box_Position: [[1.34265118 0.58183638 0.61466028]]
Step:17, total reward:-78.03863767090175, average reward:-4.590508098288338,success
Box_Position: [[1.29804939 0.99298442 0.47883202]]
actor_loss: tensor(6.2822, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-80.12406369570697, average reward:-8.90267374396744,success
Box_Position: [[1.31633145 0.74988717 0.52405072]]
Step:5, total reward:-38.66546808338816, average reward:-7.733093616677633,success
Box_Position: [[1.31007748 0.89058809 0.55154377]]
Step:19, total reward:-150.57066185984982, average reward:-7.924771676834201,success
Box_Position: [[1.40901781 0.7867187  0.56331487]]
actor_loss: tensor(6.3253, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0013, device='cuda:0', grad_fn=<NegBackward>)
Step:113, total reward:-673.3699580808677, average reward:-5.959026177706794,success
Box_Position: [[1.39252683 1.06745644 0.58194268]]
actor_loss: tensor(5.4466, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0011, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-537.2427274517722, average reward:-6.472803945202075,success
Box_Position: [[1.39888981 0.89332987 0.64498073]]
Step:23, total reward:-119.0344293191658, average reward:-5.175409970398513,success
Box_Position: [[1.34227726 0.82316237 0.54417909]]
actor_loss: tensor(5.6116, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7541, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-399.44517198932465, average reward:-6.6574195331554105,success
Box_Position: [[1.45422674 0.93953323 0.55068357]]
actor_loss: tensor(5.6833, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-409.04441807847303, average reward:-6.59749061416892,success
Box_Position: [[1.3320725  0.57763058 0.65073228]]
actor_loss: tensor(5.9125, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7587, device='cuda:0', grad_fn=<NegBackward>)
Step:88, total reward:-477.57341479466226, average reward:-5.426970622666617,success
Box_Position: [[1.42199245 0.74931454 0.50549647]]
Step:10, total reward:-59.00363817600529, average reward:-5.900363817600529,success
Box_Position: [[1.36460294 0.68987073 0.62165821]]
actor_loss: tensor(5.6262, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-297.9468265912699, average reward:-5.320479046272676,success
Box_Position: [[1.43623061 0.8115538  0.69761146]]
actor_loss: tensor(6.0175, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-343.86005253802404, average reward:-4.9834790222902035,success
Box_Position: [[1.27607177 0.97324325 0.52357947]]
actor_loss: tensor(6.1446, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-202.8199274143435, average reward:-9.219087609742887,success
Box_Position: [[1.34662856 0.76392613 0.4741563 ]]
Step:11, total reward:-66.95147215682425, average reward:-6.086497468802205,success
Box_Position: [[1.41143518 0.74558667 0.47066561]]
Step:18, total reward:-125.43725893401319, average reward:-6.968736607445177,success
Box_Position: [[1.45520845 0.62786979 0.59687078]]
actor_loss: tensor(5.4989, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9128, device='cuda:0', grad_fn=<NegBackward>)
Step:128, total reward:-664.7554482199405, average reward:-5.193401939218285,success
Box_Position: [[1.46669204 0.83455185 0.62405094]]
Step:28, total reward:-162.01582855977793, average reward:-5.78627959142064,success
Box_Position: [[1.4306061  0.77193619 0.45873591]]
actor_loss: tensor(5.4211, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2382, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-427.21545831190207, average reward:-7.0035321034738045,success
Box_Position: [[1.29895342 0.56940563 0.63517531]]
Step:11, total reward:-67.36437722631571, average reward:-6.1240342933014285,success
Box_Position: [[1.30932704 0.90355647 0.4727761 ]]
Step:20, total reward:-154.27031357696518, average reward:-7.713515678848259,success
Box_Position: [[1.44580777 0.76341862 0.64048109]]
Step:5, total reward:-28.091113176998274, average reward:-5.618222635399655,success
Box_Position: [[1.4013729  0.91985715 0.61664138]]
actor_loss: tensor(5.8175, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-171.66166611044278, average reward:-7.152569421268449,success
Box_Position: [[1.35106028 0.63265208 0.68413731]]
Step:33, total reward:-192.02079654154363, average reward:-5.818812016410413,success
Box_Position: [[1.30470701 0.70963505 0.69830884]]
actor_loss: tensor(5.9279, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5091, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5874, device='cuda:0', grad_fn=<NegBackward>)
Step:124, total reward:-675.7909926129602, average reward:-5.449927359781936,success
Box_Position: [[1.42894688 0.89059583 0.52388988]]
actor_loss: tensor(5.4518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5509, device='cuda:0', grad_fn=<NegBackward>)
Step:160, total reward:-1059.1965484214288, average reward:-6.61997842763393,success
Box_Position: [[1.26543788 1.01630463 0.74256572]]

------------------Episode:2100------------------
actor_loss: tensor(5.2387, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5887, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8542, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3720, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1113.7926289033219, average reward:-5.5689631445166095,----
episode 2100, the accuracy is: 92%
Box_Position: [[1.51982262 0.60250755 0.71197729]]
actor_loss: tensor(5.7001, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-92.06789905171522, average reward:-5.4157587677479535,success
Box_Position: [[1.38088908 0.81538274 0.64323404]]
Step:30, total reward:-153.04876905918152, average reward:-5.101625635306051,success
Box_Position: [[1.34629483 1.09910701 0.67866015]]
Step:13, total reward:-92.0852303686988, average reward:-7.083479259130677,success
Box_Position: [[1.5394603  0.61432816 0.6610379 ]]
actor_loss: tensor(5.2050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1610, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-458.85944654289733, average reward:-5.735743081786216,success
Box_Position: [[1.41563994 0.57537823 0.67781349]]
actor_loss: tensor(5.6667, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2645, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-527.0226163549967, average reward:-4.92544501266352,success
Box_Position: [[1.28648924 0.6225286  0.69726993]]
Step:8, total reward:-29.397714759970782, average reward:-3.6747143449963477,success
Box_Position: [[1.34534387 0.91614621 0.70377553]]
actor_loss: tensor(5.3081, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2772, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-577.159585243575, average reward:-6.34241302465467,success
Box_Position: [[1.37484685 0.84314663 0.66486148]]
actor_loss: tensor(5.3490, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-210.5942757125036, average reward:-5.014149421726276,success
Box_Position: [[1.29827729 0.99678825 0.48288088]]
actor_loss: tensor(5.3770, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-235.97286909018112, average reward:-6.940378502652386,success
Box_Position: [[1.3162022  0.9742229  0.47542272]]
Step:18, total reward:-133.01485906326155, average reward:-7.38971439240342,success
Box_Position: [[1.34040059 0.73908659 0.67900149]]
Step:2, total reward:-8.834257066198697, average reward:-4.417128533099349,success
Box_Position: [[1.30202665 0.43438497 0.57585807]]
actor_loss: tensor(5.9227, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2893, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3921, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7138, device='cuda:0', grad_fn=<NegBackward>)
Step:176, total reward:-1097.467554517995, average reward:-6.235611105215881,success
Box_Position: [[1.49631613 0.7650747  0.62189505]]
Step:5, total reward:-28.184948852087693, average reward:-5.6369897704175385,success
Box_Position: [[1.38047975 0.82248765 0.54683004]]
Step:12, total reward:-74.57181599022566, average reward:-6.214317999185472,success
Box_Position: [[1.44356859 0.6492916  0.48807456]]
actor_loss: tensor(6.0699, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9043, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0172, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-1120.4320017685543, average reward:-6.190232053969913,success
Box_Position: [[1.51225904 0.77763147 0.55381664]]
actor_loss: tensor(5.6628, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5332, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8640, device='cuda:0', grad_fn=<NegBackward>)
Step:115, total reward:-697.1577123346958, average reward:-6.062240976823442,success
Box_Position: [[1.38523104 0.72727409 0.50041824]]
Step:9, total reward:-76.71348189852154, average reward:-8.523720210946838,success
Box_Position: [[1.4987081  1.17899216 0.64081474]]
actor_loss: tensor(5.5193, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4593, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8399, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5683, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1171.6014637630537, average reward:-5.858007318815269,----
Box_Position: [[1.2692702  0.70064099 0.56204474]]
actor_loss: tensor(5.3372, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-418.5037533739171, average reward:-6.340965960210865,success
Box_Position: [[1.54890947 0.83790154 0.74262727]]
actor_loss: tensor(5.0157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0180, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-302.40475551605084, average reward:-4.8774960567104975,success
Box_Position: [[1.5383645  0.71214291 0.45244011]]
actor_loss: tensor(6.2562, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0854, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3662, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1312.498421730257, average reward:-6.562492108651285,----
Box_Position: [[1.49895868 0.72584    0.59629127]]
actor_loss: tensor(6.1719, device='cuda:0', grad_fn=<NegBackward>)
Step:75, total reward:-372.2879904127041, average reward:-4.963839872169388,success
Box_Position: [[1.54932637 0.66561937 0.68435988]]
actor_loss: tensor(5.0641, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2343, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-553.4712771268277, average reward:-5.172628758194651,success
Box_Position: [[1.33435452 0.67134598 0.68590705]]
actor_loss: tensor(6.2806, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8318, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-472.2927888068958, average reward:-6.747039840098512,success
Box_Position: [[1.53912139 0.7340878  0.5788763 ]]
actor_loss: tensor(5.4639, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7843, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9645, device='cuda:0', grad_fn=<NegBackward>)
Step:189, total reward:-938.9924167506805, average reward:-4.968213845241696,success
Box_Position: [[1.42868779 0.62555807 0.56651108]]
actor_loss: tensor(5.6424, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2643, device='cuda:0', grad_fn=<NegBackward>)
Step:78, total reward:-469.7714760804212, average reward:-6.0227112318002725,success
Box_Position: [[1.38188064 0.64963843 0.62910683]]
Step:6, total reward:-24.587212922501443, average reward:-4.097868820416907,success
Box_Position: [[1.3689889  1.14726033 0.72129083]]
Step:8, total reward:-48.65510126884086, average reward:-6.081887658605107,success
Box_Position: [[1.53480435 1.03277987 0.55950078]]
actor_loss: tensor(5.3821, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9381, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9002, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1712.2868023865194, average reward:-8.561434011932597,----
Box_Position: [[1.42543364 0.95018953 0.69828623]]
actor_loss: tensor(5.4072, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-256.4286450962557, average reward:-9.158165896294847,success
Box_Position: [[1.40084115 1.01209071 0.49249515]]
actor_loss: tensor(6.0734, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-369.5995066434434, average reward:-8.213322369854298,success
Box_Position: [[1.36391478 0.98326728 0.74044384]]
Step:3, total reward:-21.815146026866394, average reward:-7.271715342288798,success
Box_Position: [[1.41466073 0.73868695 0.6508857 ]]
Step:5, total reward:-25.522694136965878, average reward:-5.104538827393176,success
Box_Position: [[1.28176137 0.87066593 0.62266298]]
Step:23, total reward:-152.45738142526517, average reward:-6.628581801098486,success
Box_Position: [[1.33803004 0.83212603 0.45582461]]
Step:9, total reward:-50.731474400768136, average reward:-5.636830488974237,success
Box_Position: [[1.49778291 0.51672989 0.47329469]]
actor_loss: tensor(5.7180, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4916, device='cuda:0', grad_fn=<NegBackward>)
Step:152, total reward:-918.1443706468044, average reward:-6.040423491097397,success
Box_Position: [[1.44271031 0.95181496 0.58642472]]
actor_loss: tensor(5.7391, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2962, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-450.75910245426167, average reward:-5.931040821766601,success
Box_Position: [[1.43277502 0.74645863 0.59076002]]
Step:16, total reward:-105.20791518414106, average reward:-6.575494699008816,success
Box_Position: [[1.38351941 0.74389166 0.4841541 ]]
actor_loss: tensor(5.3069, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-123.44422891328581, average reward:-6.497064679646622,success
Box_Position: [[1.5046997  0.66838784 0.45356517]]
actor_loss: tensor(5.5611, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-333.20254151534397, average reward:-6.407741182987384,success
Box_Position: [[1.42998518 0.78296117 0.50792632]]
Step:5, total reward:-36.21835867187687, average reward:-7.243671734375374,success
Box_Position: [[1.37862336 0.61392104 0.62411688]]
Step:2, total reward:-11.464620377427615, average reward:-5.732310188713807,success
Box_Position: [[1.42958011 0.5955721  0.6068875 ]]
Step:22, total reward:-112.35818218965858, average reward:-5.1071900995299355,success
Box_Position: [[1.48532604 0.92509911 0.56207329]]
actor_loss: tensor(5.4856, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8411, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4217, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-719.2595008753839, average reward:-5.895569679306425,success
Box_Position: [[1.38917608 0.71097992 0.49301696]]
actor_loss: tensor(5.3620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9358, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-544.7101878189295, average reward:-5.4471018781892955,success
Box_Position: [[1.34310124 1.03195949 0.69788988]]
Step:7, total reward:-49.71240358454815, average reward:-7.101771940649735,success
Box_Position: [[1.27691034 0.84609195 0.67222383]]
actor_loss: tensor(5.7180, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-324.6962210234328, average reward:-6.012892981915423,success
Box_Position: [[1.5398379  0.83167409 0.46055774]]
actor_loss: tensor(5.7816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1907, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9382, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9457, device='cuda:0', grad_fn=<NegBackward>)
Step:189, total reward:-1251.7931814280637, average reward:-6.623244346180231,success
Box_Position: [[1.38747462 0.72566415 0.64264619]]
Step:10, total reward:-91.59487648278187, average reward:-9.159487648278187,success
Box_Position: [[1.34288676 0.71492787 0.49966534]]

------------------Episode:2150------------------
actor_loss: tensor(5.5265, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-196.26581267774992, average reward:-5.9474488690227245,success
Box_Position: [[1.27202699 0.70390226 0.46962858]]
Step:1, total reward:-7.915296658319874, average reward:-7.915296658319874,success
Box_Position: [[1.47394743 1.12748807 0.56914188]]
actor_loss: tensor(5.8769, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6835, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6173, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1377.6378806299606, average reward:-6.888189403149803,----
Box_Position: [[1.30683009 0.67860689 0.62806785]]
Step:1, total reward:-5.381414393112283, average reward:-5.381414393112283,success
Box_Position: [[1.46842134 0.58096816 0.74829815]]
Step:12, total reward:-52.03283035992633, average reward:-4.336069196660527,success
Box_Position: [[1.49755095 0.81897542 0.51807593]]
actor_loss: tensor(5.3698, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0829, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9425, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8057, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1209.2228986224382, average reward:-6.04611449311219,----
Box_Position: [[1.2691121  1.05109821 0.61381553]]
Step:24, total reward:-194.94571560711702, average reward:-8.122738150296543,success
Box_Position: [[1.33701227 0.76154422 0.6584979 ]]
actor_loss: tensor(4.9942, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6233, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-390.9019559542044, average reward:-5.354821314441157,success
Box_Position: [[1.26277742 0.83386465 0.69223448]]
actor_loss: tensor(5.8877, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2324, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-695.4280899924918, average reward:-5.3494468460960904,success
Box_Position: [[1.4475478  0.79439547 0.59570335]]
actor_loss: tensor(5.5888, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-32.476406792338615, average reward:-6.495281358467723,success
Box_Position: [[1.51769958 0.47810478 0.65650016]]
Step:15, total reward:-74.66972551503284, average reward:-4.977981701002189,success
Box_Position: [[1.25822815 0.69518942 0.62812797]]
Step:1, total reward:-3.8138062901772427, average reward:-3.8138062901772427,success
Box_Position: [[1.3087459  0.8895286  0.73816816]]
Step:5, total reward:-27.37305350648519, average reward:-5.4746107012970375,success
Box_Position: [[1.29863947 0.72648988 0.51079847]]
Step:23, total reward:-151.9763120933868, average reward:-6.607665743190731,success
Box_Position: [[1.3563166  0.77910761 0.62366822]]
actor_loss: tensor(6.5846, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-266.75856006303195, average reward:-5.675714043894297,success
Box_Position: [[1.45543954 0.57474509 0.45333147]]
actor_loss: tensor(5.8688, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9990, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5258, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0633, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1275.859872386741, average reward:-6.379299361933705,----
Box_Position: [[1.38448933 0.51121342 0.6965395 ]]
Step:1, total reward:-7.171582355695625, average reward:-7.171582355695625,success
Box_Position: [[1.50934321 0.51792801 0.61163013]]
actor_loss: tensor(5.4844, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7455, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-399.0335376622124, average reward:-5.051057438762182,success
Box_Position: [[1.35175163 0.99454646 0.611746  ]]
Step:18, total reward:-116.95792913907775, average reward:-6.497662729948764,success
Box_Position: [[1.36667247 0.41430457 0.71538943]]
actor_loss: tensor(5.9049, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7061, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-361.6319852732663, average reward:-4.953862811962552,success
Box_Position: [[1.29959923 0.80380978 0.60291035]]
Step:13, total reward:-106.34747159916039, average reward:-8.180574738396952,success
Box_Position: [[1.52284316 0.52240785 0.46970995]]
actor_loss: tensor(6.2471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8808, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4072, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6741, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1314.1688693026579, average reward:-6.570844346513289,----
Box_Position: [[1.45552666 0.74720647 0.70873447]]
actor_loss: tensor(5.8584, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-128.49881538239816, average reward:-4.759215384533265,success
Box_Position: [[1.34135931 1.00004252 0.54923831]]
Step:32, total reward:-215.18781622852455, average reward:-6.724619257141392,success
Box_Position: [[1.50089067 1.11744703 0.51095169]]
actor_loss: tensor(6.4691, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8443, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5843, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6833, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1363.2121422007965, average reward:-6.816060711003982,----
Box_Position: [[1.30375983 0.91936139 0.52697912]]
Step:5, total reward:-49.08717614135014, average reward:-9.817435228270028,success
Box_Position: [[1.2946715  0.78921608 0.70784708]]
actor_loss: tensor(5.9304, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-69.92054693488691, average reward:-4.994324781063351,success
Box_Position: [[1.51269099 0.8607678  0.51126564]]
actor_loss: tensor(5.9237, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-385.6605318104529, average reward:-6.536619183228015,success
Box_Position: [[1.49749187 0.87588175 0.61798612]]
actor_loss: tensor(5.9533, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9314, device='cuda:0', grad_fn=<NegBackward>)
Step:97, total reward:-497.27241455531424, average reward:-5.126519737683652,success
Box_Position: [[1.49806834 0.75920607 0.59314275]]
Step:28, total reward:-149.2371391054264, average reward:-5.329897825193799,success
Box_Position: [[1.37965264 1.08469527 0.73240824]]
Step:8, total reward:-75.79922098889877, average reward:-9.474902623612346,success
Box_Position: [[1.26320549 0.81902141 0.50355565]]
actor_loss: tensor(5.4986, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1997, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-317.070275281272, average reward:-5.871671764468,success
Box_Position: [[1.46321453 0.81674155 0.50712158]]
Step:12, total reward:-76.05765298653417, average reward:-6.338137748877847,success
Box_Position: [[1.54164016 0.84960727 0.72957136]]
actor_loss: tensor(5.9005, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-399.00622388266817, average reward:-4.865929559544734,success
Box_Position: [[1.38796724 0.75005587 0.6259536 ]]
actor_loss: tensor(5.8380, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-20.121489361397543, average reward:-4.024297872279509,success
Box_Position: [[1.5096172  0.42820701 0.45660661]]
actor_loss: tensor(5.1518, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3573, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3680, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1356.236939141245, average reward:-6.781184695706226,----
Box_Position: [[1.32427208 0.98124912 0.71312089]]
actor_loss: tensor(6.3058, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5684, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0678, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5383, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1060.3470293649336, average reward:-5.301735146824668,----
Box_Position: [[1.36794536 1.14242753 0.68359429]]
Step:13, total reward:-76.21530195414756, average reward:-5.862715534934428,success
Box_Position: [[1.42894782 0.56830322 0.61928501]]
Step:32, total reward:-160.52295478407498, average reward:-5.016342337002343,success
Box_Position: [[1.32853898 0.88692183 0.50088366]]
actor_loss: tensor(5.7699, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-56.316845763641524, average reward:-6.25742730707128,success
Box_Position: [[1.29377344 0.54600777 0.5035844 ]]
Step:9, total reward:-40.159535183175855, average reward:-4.462170575908428,success
Box_Position: [[1.4851928  1.12114478 0.54566123]]
actor_loss: tensor(5.2402, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2586, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5683, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1165, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1225.1732572491903, average reward:-6.125866286245952,----
Box_Position: [[1.38896943 0.73382528 0.69536292]]
Step:20, total reward:-83.73555732526015, average reward:-4.186777866263007,success
Box_Position: [[1.36016443 0.68781716 0.59452288]]
actor_loss: tensor(5.2562, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-226.08223714902283, average reward:-5.138232662477791,success
Box_Position: [[1.37397204 0.95909763 0.65591803]]
Step:12, total reward:-58.856434827590675, average reward:-4.904702902299223,success
Box_Position: [[1.37234313 0.83468229 0.70130729]]
actor_loss: tensor(5.9089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6514, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-287.35709586896195, average reward:-4.634791868854225,success
Box_Position: [[1.39691879 0.41094271 0.52814988]]
actor_loss: tensor(5.6825, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-357.6620835755507, average reward:-5.863312845500831,success
Box_Position: [[1.33925939 0.85659371 0.46420872]]
Step:25, total reward:-173.94743283797044, average reward:-6.957897313518817,success
Box_Position: [[1.39927072 0.99097364 0.49019354]]
actor_loss: tensor(5.4371, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-144.90054946771195, average reward:-7.626344708826945,success
Box_Position: [[1.40733487 0.64048578 0.62293278]]
actor_loss: tensor(5.8747, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-280.8859273017534, average reward:-4.927823285995673,success
Box_Position: [[1.44952055 0.52863909 0.51731738]]

------------------Episode:2200------------------
Step:9, total reward:-57.230363322220285, average reward:-6.358929258024476,success
episode 2200, the accuracy is: 89%
Box_Position: [[1.43221902 0.68318137 0.49843841]]
actor_loss: tensor(5.3276, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2534, device='cuda:0', grad_fn=<NegBackward>)
Step:148, total reward:-771.316999861411, average reward:-5.211601350414939,success
Box_Position: [[1.25259301 0.63567377 0.57321541]]
Step:4, total reward:-32.29163211640132, average reward:-8.07290802910033,success
Box_Position: [[1.38170728 0.97623849 0.56157028]]
actor_loss: tensor(5.4830, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-258.35070664705995, average reward:-6.458767666176499,success
Box_Position: [[1.36667701 0.97210996 0.51269216]]
Step:9, total reward:-68.73343127169215, average reward:-7.637047919076906,success
Box_Position: [[1.31898855 0.93606078 0.5356784 ]]
Step:5, total reward:-36.06607648890309, average reward:-7.213215297780619,success
Box_Position: [[1.2665282  0.65067923 0.53114202]]
actor_loss: tensor(5.7982, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-263.03136243050744, average reward:-6.117008428616452,success
Box_Position: [[1.31364582 0.93316379 0.45649355]]
Step:7, total reward:-71.60203167352492, average reward:-10.228861667646417,success
Box_Position: [[1.27898064 1.0038694  0.54656178]]
Step:20, total reward:-147.7307909569859, average reward:-7.386539547849296,success
Box_Position: [[1.51733254 0.75597924 0.61891215]]
actor_loss: tensor(5.1475, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8582, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-627.6001052652584, average reward:-6.404082706788351,success
Box_Position: [[1.27868586 1.03880828 0.7133436 ]]
actor_loss: tensor(5.9595, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-156.36215390734733, average reward:-5.791190885457309,success
Box_Position: [[1.38873627 0.6078621  0.70296194]]
Step:4, total reward:-25.168521408754426, average reward:-6.2921303521886065,success
Box_Position: [[1.3591179  0.85170451 0.48556717]]
actor_loss: tensor(5.8082, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2153, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-604.3349849960485, average reward:-6.641043791165369,success
Box_Position: [[1.28799477 0.66644008 0.54119884]]
Step:4, total reward:-20.313002263878193, average reward:-5.078250565969548,success
Box_Position: [[1.43802677 0.54343009 0.47595434]]
actor_loss: tensor(5.1698, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-161.0087911268585, average reward:-5.366959704228617,success
Box_Position: [[1.3059959  0.6210535  0.61392473]]
Step:11, total reward:-57.18765160239013, average reward:-5.198877418399103,success
Box_Position: [[1.40926454 0.94434089 0.65942922]]
Step:4, total reward:-37.88061701220771, average reward:-9.470154253051927,success
Box_Position: [[1.45864742 0.77031721 0.72014561]]
actor_loss: tensor(5.0452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8118, device='cuda:0', grad_fn=<NegBackward>)
Step:123, total reward:-657.6689873509707, average reward:-5.346902336186754,success
Box_Position: [[1.25865197 0.62594249 0.52358296]]
actor_loss: tensor(4.9132, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3064, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1919, device='cuda:0', grad_fn=<NegBackward>)
Step:136, total reward:-790.5708725389014, average reward:-5.8130211216095695,success
Box_Position: [[1.46057195 0.55302386 0.71692601]]
Step:4, total reward:-23.360504024666387, average reward:-5.840126006166597,success
Box_Position: [[1.47056582 0.46086679 0.59579927]]
actor_loss: tensor(5.6074, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7150, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8596, device='cuda:0', grad_fn=<NegBackward>)
Step:122, total reward:-621.0453727291458, average reward:-5.090535842042179,success
Box_Position: [[1.33357385 0.89151773 0.52387148]]
Step:5, total reward:-39.69841686195872, average reward:-7.939683372391744,success
Box_Position: [[1.25817553 0.84788578 0.56551319]]
Step:12, total reward:-72.66290007691856, average reward:-6.055241673076547,success
Box_Position: [[1.44664473 0.54805235 0.5953715 ]]
actor_loss: tensor(5.1430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7375, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-398.93260962225594, average reward:-4.806416983400674,success
Box_Position: [[1.42979049 0.87635791 0.5052611 ]]
actor_loss: tensor(4.9159, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2317, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2395, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9046, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1107.5908684712856, average reward:-5.537954342356428,----
Box_Position: [[1.4653263  0.58329831 0.52806626]]
Step:13, total reward:-74.22795148365054, average reward:-5.709842421819273,success
Box_Position: [[1.40963504 0.57639433 0.73800141]]
actor_loss: tensor(5.8865, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-186.71221411419765, average reward:-5.186450392061046,success
Box_Position: [[1.34273018 1.09944637 0.45495291]]
Step:38, total reward:-278.74662927599417, average reward:-7.335437612526162,success
Box_Position: [[1.34462557 0.59310452 0.48004978]]
actor_loss: tensor(5.2587, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-85.26559595197052, average reward:-5.684373063464702,success
Box_Position: [[1.44136397 0.60080942 0.6569984 ]]
Step:37, total reward:-172.81959583275298, average reward:-4.670799887371702,success
Box_Position: [[1.41472848 1.14302839 0.47341614]]
actor_loss: tensor(5.4304, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6734, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-815.4222476069054, average reward:-7.840598534681783,success
Box_Position: [[1.30293804 1.11686103 0.47004014]]
actor_loss: tensor(5.0141, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-275.7746955098173, average reward:-5.995102076300377,success
Box_Position: [[1.51100829 0.5881657  0.56681015]]
actor_loss: tensor(5.0945, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2276, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-525.7924012354566, average reward:-5.205865358766897,success
Box_Position: [[1.35716648 0.82408263 0.73314968]]
actor_loss: tensor(5.1631, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7832, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9536, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1030.4238964883207, average reward:-5.152119482441603,----
Box_Position: [[1.29526825 0.49789944 0.72808202]]
actor_loss: tensor(4.8503, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1818, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9913, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2075, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-951.5797974054178, average reward:-4.757898987027089,----
Box_Position: [[1.39101929 0.80178691 0.4583651 ]]
actor_loss: tensor(5.1552, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-272.9483829880683, average reward:-5.807412404001454,success
Box_Position: [[1.4062513  0.93545931 0.68290584]]
actor_loss: tensor(5.4919, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0640, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-348.4839396889608, average reward:-5.445061557640012,success
Box_Position: [[1.54717941 0.57018899 0.56661614]]
Step:28, total reward:-136.10760483879554, average reward:-4.860985887099841,success
Box_Position: [[1.37919567 0.92973787 0.5370681 ]]
actor_loss: tensor(5.1583, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2732, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-526.8349028473589, average reward:-5.853721142748432,success
Box_Position: [[1.44456725 0.69895681 0.48352644]]
actor_loss: tensor(4.6982, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-387.21487334620116, average reward:-5.232633423597313,success
Box_Position: [[1.28755177 0.59841408 0.7210034 ]]
actor_loss: tensor(5.1550, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2258, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5229, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2038, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-943.5337005946587, average reward:-4.717668502973294,----
Box_Position: [[1.48633606 0.78320425 0.64782165]]
actor_loss: tensor(5.1413, device='cuda:0', grad_fn=<NegBackward>)
Step:6, total reward:-48.00295394538375, average reward:-8.000492324230626,success
Box_Position: [[1.51285139 0.5491087  0.45717642]]
actor_loss: tensor(5.1291, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-445.6514669149056, average reward:-6.2767812241536,success
Box_Position: [[1.2689155  1.10299515 0.69522497]]
actor_loss: tensor(5.4140, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-219.92247340766883, average reward:-5.11447612575974,success
Box_Position: [[1.31782819 0.64523977 0.64220223]]
actor_loss: tensor(4.6113, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-344.2033397622526, average reward:-5.295435996342348,success
Box_Position: [[1.4229738  1.04636523 0.45524617]]
actor_loss: tensor(5.1371, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-383.37181940896943, average reward:-7.517094498215087,success
Box_Position: [[1.42150116 0.48973349 0.46690937]]
Step:4, total reward:-31.327753319079743, average reward:-7.831938329769936,success
Box_Position: [[1.46265252 1.02438658 0.66488434]]
actor_loss: tensor(5.6946, device='cuda:0', grad_fn=<NegBackward>)
Step:17, total reward:-153.06032486923644, average reward:-9.003548521719791,success
Box_Position: [[1.37816629 0.79413426 0.62381341]]
Step:46, total reward:-287.806881759401, average reward:-6.2566713425956735,success
Box_Position: [[1.43513603 0.60919658 0.49781584]]
actor_loss: tensor(5.1126, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-218.53934588961522, average reward:-6.427627820282801,success
Box_Position: [[1.45877487 0.57183701 0.69990188]]

------------------Episode:2250------------------
Step:10, total reward:-53.486810344293424, average reward:-5.348681034429342,success
Box_Position: [[1.41689014 0.84796379 0.49721565]]
actor_loss: tensor(5.1567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6911, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-404.1564821690226, average reward:-6.625516101131518,success
Box_Position: [[1.39545012 0.6750399  0.68054501]]
Step:4, total reward:-23.980950364837003, average reward:-5.995237591209251,success
Box_Position: [[1.45124445 0.9017759  0.69726548]]
actor_loss: tensor(5.0929, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-459.6710615219526, average reward:-5.472274541928007,success
Box_Position: [[1.4584115  0.70042613 0.51426902]]
actor_loss: tensor(5.6500, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3221, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9736, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6578, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-966.4379908167969, average reward:-5.252380384873896,success
Box_Position: [[1.52662081 0.80916009 0.46068797]]
actor_loss: tensor(4.7107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5108, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8140, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-809.3562354144686, average reward:-6.225817195495913,success
Box_Position: [[1.28033432 0.77687662 0.45452562]]
actor_loss: tensor(4.9411, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-390.2238908934807, average reward:-6.846033173569837,success
Box_Position: [[1.43452213 1.03072487 0.5825182 ]]
Step:4, total reward:-23.63813116694138, average reward:-5.909532791735345,success
Box_Position: [[1.44325046 1.13061447 0.70186933]]
actor_loss: tensor(4.9694, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-281.1887052066547, average reward:-5.982738408652227,success
Box_Position: [[1.33293286 0.63749443 0.53726845]]
Step:4, total reward:-20.92124422946226, average reward:-5.230311057365565,success
Box_Position: [[1.36749494 0.77248145 0.72555323]]
actor_loss: tensor(4.9479, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-251.47628512853927, average reward:-4.122562051287529,success
Box_Position: [[1.461062   0.99767701 0.50019712]]
actor_loss: tensor(5.0274, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9165, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3906, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0190, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1386.7007715287955, average reward:-6.933503857643977,----
Box_Position: [[1.54694593 0.81177893 0.65504156]]
actor_loss: tensor(5.5045, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9389, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0363, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-679.4072025804493, average reward:-5.070203004331711,success
Box_Position: [[1.44895236 1.02431419 0.6232923 ]]
Step:5, total reward:-34.19913033475334, average reward:-6.8398260669506685,success
Box_Position: [[1.42254109 0.56388478 0.61381139]]
Step:10, total reward:-52.53303107001046, average reward:-5.253303107001046,success
Box_Position: [[1.47439842 0.76989439 0.55066115]]
Step:11, total reward:-81.40211338985242, average reward:-7.40019212635022,success
Box_Position: [[1.36571945 0.8203769  0.65624525]]
Step:7, total reward:-29.838142672123496, average reward:-4.262591810303356,success
Box_Position: [[1.35055868 0.8147914  0.51673064]]
actor_loss: tensor(5.1452, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-52.01323758729947, average reward:-5.779248620811052,success
Box_Position: [[1.40361406 0.67858805 0.5338928 ]]
actor_loss: tensor(5.2323, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-416.8001328869649, average reward:-6.129413718925954,success
Box_Position: [[1.47025059 0.88091964 0.68552564]]
actor_loss: tensor(5.1113, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-284.30242393154725, average reward:-6.0489877432244095,success
Box_Position: [[1.32984632 0.6929814  0.60994324]]
actor_loss: tensor(5.7695, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-194.9135798261842, average reward:-5.906472115944975,success
Box_Position: [[1.50156879 0.66660311 0.69750527]]
Step:7, total reward:-37.55287816676705, average reward:-5.364696880966721,success
Box_Position: [[1.38221215 0.83796138 0.73747185]]
Step:21, total reward:-117.10545397187717, average reward:-5.576450189137008,success
Box_Position: [[1.54761625 1.03716922 0.72992642]]
actor_loss: tensor(4.8916, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-195.76932264177972, average reward:-5.019726221584095,success
Box_Position: [[1.36049062 1.03540462 0.66688716]]
Step:12, total reward:-65.816586116118, average reward:-5.484715509676501,success
Box_Position: [[1.35854137 0.91641191 0.6108117 ]]
actor_loss: tensor(5.0155, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-333.80570952958374, average reward:-5.057662265599753,success
Box_Position: [[1.4374539 0.7417236 0.4954139]]
actor_loss: tensor(5.9654, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0897, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-318.95373027766686, average reward:-5.695602326386909,success
Box_Position: [[1.54800268 0.90057279 0.50172911]]
actor_loss: tensor(5.3831, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-593.5174610035249, average reward:-6.451276750038314,success
Box_Position: [[1.52473736 1.05320027 0.49390612]]
actor_loss: tensor(5.8668, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3315, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8471, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1525.4811944287983, average reward:-7.6274059721439915,----
Box_Position: [[1.3545075  0.9456814  0.52996867]]
actor_loss: tensor(5.8091, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-298.54689056542236, average reward:-6.785156603759599,success
Box_Position: [[1.26011982 1.07892441 0.51492666]]
actor_loss: tensor(5.6463, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-299.9025380437446, average reward:-4.99837563406241,success
Box_Position: [[1.4610656  0.55776646 0.49606718]]
actor_loss: tensor(5.3292, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-174.10012506967394, average reward:-6.217861609631212,success
Box_Position: [[1.39631515 0.77020601 0.67091532]]
actor_loss: tensor(5.7583, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-179.8618108075266, average reward:-4.386873434329917,success
Box_Position: [[1.53965558 0.94022148 0.64530185]]
actor_loss: tensor(5.6549, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6100, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-506.9156532387314, average reward:-5.632396147097015,success
Box_Position: [[1.41458506 0.72846079 0.49613925]]
Step:41, total reward:-228.78897750648764, average reward:-5.580218963572869,success
Box_Position: [[1.3284619  0.60812715 0.65462159]]
actor_loss: tensor(4.9223, device='cuda:0', grad_fn=<NegBackward>)
Step:1, total reward:-7.490446867495456, average reward:-7.490446867495456,success
Box_Position: [[1.45642601 0.70514706 0.56250441]]
Step:18, total reward:-122.97695150880867, average reward:-6.832052861600482,success
Box_Position: [[1.46810257 0.66701389 0.68717916]]
Step:9, total reward:-64.0766818426662, average reward:-7.119631315851801,success
Box_Position: [[1.40010717 0.71107538 0.65188191]]
Step:8, total reward:-33.687421643085365, average reward:-4.210927705385671,success
Box_Position: [[1.26344713 0.4487163  0.66224496]]
actor_loss: tensor(4.2098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3237, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-378.7528303563354, average reward:-4.734410379454192,success
Box_Position: [[1.46627703 0.89648272 0.5069135 ]]
actor_loss: tensor(4.6529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8235, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0011, device='cuda:0', grad_fn=<NegBackward>)
Step:157, total reward:-1038.439711183857, average reward:-6.6142656763303,success
Box_Position: [[1.41971904 1.08544227 0.53301888]]
actor_loss: tensor(4.6977, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0716, device='cuda:0', grad_fn=<NegBackward>)
Step:97, total reward:-530.455143543932, average reward:-5.46860972725703,success
Box_Position: [[1.28518615 0.67706369 0.65218913]]
Step:4, total reward:-21.0521029467863, average reward:-5.263025736696575,success
Box_Position: [[1.26963061 0.72411704 0.66463955]]
Step:20, total reward:-117.05233790890256, average reward:-5.852616895445128,success
Box_Position: [[1.27762773 0.46607812 0.69436448]]
actor_loss: tensor(5.0979, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5895, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-280.67370129575534, average reward:-4.757181377894158,success
Box_Position: [[1.34562985 0.83985983 0.54946324]]
Step:45, total reward:-309.46295416152884, average reward:-6.876954536922863,success
Box_Position: [[1.26820429 0.84547851 0.71612239]]
actor_loss: tensor(5.7016, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3200, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1271, device='cuda:0', grad_fn=<NegBackward>)
Step:162, total reward:-805.0704794150602, average reward:-4.969570860586791,success
Box_Position: [[1.34449646 0.93602725 0.46586001]]
Step:3, total reward:-32.25203110315135, average reward:-10.750677034383784,success
Box_Position: [[1.53238175 0.77806553 0.54471501]]
actor_loss: tensor(5.3979, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9309, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6095, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1042.0058741812927, average reward:-5.210029370906463,----
Box_Position: [[1.29126565 0.80574419 0.63098954]]
Step:6, total reward:-40.310019387263544, average reward:-6.718336564543924,success
Box_Position: [[1.52841277 0.73744153 0.62178986]]

------------------Episode:2300------------------
actor_loss: tensor(4.5673, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-209.46647856590502, average reward:-5.818513293497362,success
episode 2300, the accuracy is: 93%
Box_Position: [[1.53784807 0.77215373 0.61879866]]
actor_loss: tensor(5.3440, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7090, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5051, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-1007.057039660099, average reward:-5.1643950751799945,success
Box_Position: [[1.54000779 0.68258011 0.50590905]]
actor_loss: tensor(5.4735, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7410, device='cuda:0', grad_fn=<NegBackward>)
Step:101, total reward:-583.3604789005003, average reward:-5.775846325747528,success
Box_Position: [[1.36211053 0.85360689 0.54572055]]
Step:7, total reward:-60.92603572092532, average reward:-8.703719388703616,success
Box_Position: [[1.50597616 0.87213478 0.55467999]]
actor_loss: tensor(5.4842, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0381, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3074, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1037.0028059904346, average reward:-5.858772915200196,success
Box_Position: [[1.49043899 0.8301866  0.48915083]]
actor_loss: tensor(5.1715, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-401.09040973151207, average reward:-6.267037652054876,success
Box_Position: [[1.26936879 1.02089615 0.58369955]]
actor_loss: tensor(5.5739, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-171.8102572398096, average reward:-5.206371431509382,success
Box_Position: [[1.52002412 0.78296296 0.70685631]]
actor_loss: tensor(4.5684, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-224.58852904635523, average reward:-5.222989047589657,success
Box_Position: [[1.44845095 0.60661772 0.73327693]]
Step:8, total reward:-62.14494349893347, average reward:-7.768117937366684,success
Box_Position: [[1.38596516 1.02249845 0.67480865]]
actor_loss: tensor(5.3905, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0550, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-365.8641838633808, average reward:-5.380355645049717,success
Box_Position: [[1.43346678 0.69575001 0.52533015]]
Step:49, total reward:-333.4501097597932, average reward:-6.805104280812106,success
Box_Position: [[1.3756898  0.61811959 0.66321709]]
actor_loss: tensor(5.2208, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-71.76215366101832, average reward:-6.523832151001665,success
Box_Position: [[1.44779762 0.94003047 0.51792166]]
Step:30, total reward:-187.33015705342117, average reward:-6.244338568447373,success
Box_Position: [[1.45738843 0.80414361 0.663778  ]]
Step:8, total reward:-36.08020589175123, average reward:-4.510025736468903,success
Box_Position: [[1.47877109 0.51408137 0.73190184]]
actor_loss: tensor(5.0814, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-63.49780070721916, average reward:-4.884446208247628,success
Box_Position: [[1.34992642 0.87690111 0.58259982]]
Step:14, total reward:-103.07078110817969, average reward:-7.362198650584263,success
Box_Position: [[1.34215804 0.61138952 0.72002863]]
Step:22, total reward:-110.253440552676, average reward:-5.011520025121636,success
Box_Position: [[1.47707386 0.86990026 0.51614748]]
actor_loss: tensor(5.1783, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6152, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5351, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1090.542166217349, average reward:-5.452710831086745,----
Box_Position: [[1.43419267 0.80926766 0.64861686]]
actor_loss: tensor(4.7163, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-151.420274675667, average reward:-4.4535374904607945,success
Box_Position: [[1.3441936  0.75579342 0.70622768]]
actor_loss: tensor(4.5607, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9238, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-360.5677184555413, average reward:-4.872536735885693,success
Box_Position: [[1.49868707 0.76344952 0.52305325]]
actor_loss: tensor(5.1501, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-300.98772762984686, average reward:-5.573846807960127,success
Box_Position: [[1.49738721 0.68422348 0.64468433]]
Step:11, total reward:-48.95983902959016, average reward:-4.450894457235469,success
Box_Position: [[1.31510878 0.63261806 0.57164655]]
actor_loss: tensor(4.9004, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-259.5934566432715, average reward:-4.399889095648669,success
Box_Position: [[1.47795398 0.90619476 0.59063824]]
actor_loss: tensor(5.1110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8516, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1636, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7623, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1066.7645635794368, average reward:-5.333822817897183,----
Box_Position: [[1.54712427 0.57204708 0.59190784]]
actor_loss: tensor(4.6490, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7393, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5716, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1490, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1006.618158285267, average reward:-5.033090791426335,----
Box_Position: [[1.25401812 0.66085687 0.47667267]]
actor_loss: tensor(4.8350, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-186.4650217028787, average reward:-5.827031928214959,success
Box_Position: [[1.54618774 0.7318668  0.59708027]]
actor_loss: tensor(4.7936, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-234.71793538322274, average reward:-5.33449853143688,success
Box_Position: [[1.2686655  1.02963909 0.70259197]]
actor_loss: tensor(4.6244, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1649, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0464, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2115, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1063.2448120870658, average reward:-5.316224060435329,----
Box_Position: [[1.26091508 0.68058353 0.66815753]]
actor_loss: tensor(5.5810, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8690, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-487.40460708257194, average reward:-4.686582760409346,success
Box_Position: [[1.53058086 0.93128073 0.46911438]]
actor_loss: tensor(5.1839, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0970, device='cuda:0', grad_fn=<NegBackward>)
Step:131, total reward:-880.5516125647339, average reward:-6.721768034845297,success
Box_Position: [[1.40134966 0.74099918 0.72909847]]
Step:9, total reward:-63.06433687067157, average reward:-7.00714854118573,success
Box_Position: [[1.34106524 0.69236161 0.45189689]]
actor_loss: tensor(4.6880, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-133.56139129499127, average reward:-6.678069564749563,success
Box_Position: [[1.33635601 0.76465429 0.51578311]]
actor_loss: tensor(4.9695, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-240.27279804701098, average reward:-5.005683292646062,success
Box_Position: [[1.49378537 0.96950578 0.47238275]]
actor_loss: tensor(5.2884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1096, device='cuda:0', grad_fn=<NegBackward>)
Step:114, total reward:-792.0802936272237, average reward:-6.948072751115998,success
Box_Position: [[1.41092932 0.8087907  0.64655646]]
actor_loss: tensor(5.0102, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-160.6423996021325, average reward:-4.589782845775215,success
Box_Position: [[1.50347028 1.11164048 0.51466809]]
actor_loss: tensor(4.7545, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8045, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2798, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8181, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1192.0404792376287, average reward:-5.960202396188143,----
Box_Position: [[1.46352132 0.71756599 0.51147261]]
Step:12, total reward:-72.57244742059737, average reward:-6.047703951716447,success
Box_Position: [[1.41685501 0.9204418  0.73309873]]
Step:5, total reward:-24.2277377705358, average reward:-4.84554755410716,success
Box_Position: [[1.4609022  0.58909375 0.55849569]]
Step:8, total reward:-47.532862137512495, average reward:-5.941607767189062,success
Box_Position: [[1.36274819 0.68110508 0.70609722]]
actor_loss: tensor(5.1555, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-133.63081804756655, average reward:-4.94928955731728,success
Box_Position: [[1.44953954 1.09267729 0.52675856]]
actor_loss: tensor(5.0563, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-409.5953797250336, average reward:-5.688824718403244,success
Box_Position: [[1.54877621 0.90149914 0.49743938]]
actor_loss: tensor(4.9606, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4710, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5253, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9598, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1244.4179108657659, average reward:-6.2220895543288295,----
Box_Position: [[1.51761714 0.69718242 0.65645314]]
actor_loss: tensor(4.7006, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8720, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-461.2236946707324, average reward:-4.612236946707324,success
Box_Position: [[1.32251191 0.75675257 0.6412981 ]]
Step:4, total reward:-27.329972580885993, average reward:-6.832493145221498,success
Box_Position: [[1.35686671 0.72291483 0.65544915]]
actor_loss: tensor(5.1673, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-215.71850662600406, average reward:-4.4024185025715115,success
Box_Position: [[1.26786973 0.83113533 0.70980523]]
actor_loss: tensor(4.9632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7699, device='cuda:0', grad_fn=<NegBackward>)
Step:93, total reward:-596.7063986398016, average reward:-6.416197834836576,success
Box_Position: [[1.37249803 0.46691786 0.52697265]]
actor_loss: tensor(4.9709, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-168.80559160417647, average reward:-5.4453416646508535,success
Box_Position: [[1.36803569 0.46264613 0.60111592]]
Step:2, total reward:-13.62000452645506, average reward:-6.81000226322753,success
Box_Position: [[1.25353452 0.91494023 0.51770295]]
Step:18, total reward:-124.87681626300665, average reward:-6.937600903500369,success
Box_Position: [[1.26163836 0.92885581 0.72535169]]
actor_loss: tensor(4.9001, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-325.8323689448788, average reward:-6.1477805461297885,success
Box_Position: [[1.47825758 0.83537066 0.4898968 ]]

------------------Episode:2350------------------
actor_loss: tensor(4.8398, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4190, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-415.8962260270834, average reward:-6.207406358613185,success
Box_Position: [[1.53441077 0.53027678 0.5409551 ]]
Step:25, total reward:-147.70886795627345, average reward:-5.908354718250938,success
Box_Position: [[1.53308873 0.70891981 0.72506658]]
actor_loss: tensor(4.8522, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-214.47634126510582, average reward:-4.563326409895868,success
Box_Position: [[1.46696546 0.67187486 0.47155462]]
actor_loss: tensor(4.9512, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9290, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9678, device='cuda:0', grad_fn=<NegBackward>)
Step:140, total reward:-780.3106443607363, average reward:-5.573647459719545,success
Box_Position: [[1.52859075 0.71559725 0.69217851]]
actor_loss: tensor(4.8791, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-331.843906488472, average reward:-4.809331978093797,success
Box_Position: [[1.36472099 0.68761911 0.71171989]]
actor_loss: tensor(4.4326, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-114.34738200086427, average reward:-3.9430131724435955,success
Box_Position: [[1.51677806 0.87670519 0.50770404]]
actor_loss: tensor(5.1241, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9326, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8077, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.2507, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1156.8846663575105, average reward:-5.784423331787552,----
Box_Position: [[1.31930751 0.60280159 0.64590515]]
actor_loss: tensor(4.8639, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-326.2383267577776, average reward:-4.86922875757877,success
Box_Position: [[1.27818631 1.01175147 0.6141683 ]]
actor_loss: tensor(4.3110, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-368.29647842998475, average reward:-5.940265781128786,success
Box_Position: [[1.34989255 1.01767387 0.50301532]]
actor_loss: tensor(4.8705, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-47.324637207407974, average reward:-11.831159301851994,success
Box_Position: [[1.31515895 0.67928482 0.59869777]]
Step:6, total reward:-37.39504288742558, average reward:-6.232507147904264,success
Box_Position: [[1.40576546 0.7194981  0.58636582]]
Step:16, total reward:-95.15265102323566, average reward:-5.947040688952229,success
Box_Position: [[1.50931423 0.80457225 0.68928545]]
actor_loss: tensor(5.0304, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-188.47239331628765, average reward:-5.711284645948111,success
Box_Position: [[1.25599126 0.74488149 0.660166  ]]
Step:40, total reward:-239.51627417007816, average reward:-5.987906854251954,success
Box_Position: [[1.36919557 1.08325285 0.50403661]]
actor_loss: tensor(5.1911, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-71.75756901783932, average reward:-5.125540644131379,success
Box_Position: [[1.51713994 0.50535828 0.63448183]]
Step:14, total reward:-63.70183429208927, average reward:-4.550131020863519,success
Box_Position: [[1.42035671 0.78242811 0.55716675]]
Step:7, total reward:-46.13024471066987, average reward:-6.5900349586671245,success
Box_Position: [[1.5419897  0.88127767 0.55639661]]
actor_loss: tensor(5.2791, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3569, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5944, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0767, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1231.7711945722995, average reward:-6.158855972861497,----
Box_Position: [[1.49417827 0.77030107 0.72140424]]
actor_loss: tensor(5.1333, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-252.83074845335972, average reward:-4.862129777949225,success
Box_Position: [[1.4001333  0.73130495 0.54587476]]
actor_loss: tensor(4.8152, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-157.32141980539066, average reward:-6.0508238386688715,success
Box_Position: [[1.32990886 0.97053999 0.62018881]]
Step:27, total reward:-133.08262193930187, average reward:-4.928985997751921,success
Box_Position: [[1.41836967 0.6434038  0.55157938]]
actor_loss: tensor(4.7212, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-93.62295528708782, average reward:-4.25558887668581,success
Box_Position: [[1.54051771 0.52122266 0.70083605]]
actor_loss: tensor(4.4922, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-411.03655261884967, average reward:-4.467788615422279,success
Box_Position: [[1.48542128 0.64731192 0.67249051]]
actor_loss: tensor(4.7291, device='cuda:0', grad_fn=<NegBackward>)
Step:7, total reward:-35.35635743103407, average reward:-5.050908204433439,success
Box_Position: [[1.30882291 1.10216005 0.51182898]]
actor_loss: tensor(5.0219, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8214, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3495, device='cuda:0', grad_fn=<NegBackward>)
Step:146, total reward:-701.5634411515, average reward:-4.805229048982877,success
Box_Position: [[1.32152088 0.54101794 0.74407457]]
Step:4, total reward:-19.754677941980713, average reward:-4.938669485495178,success
Box_Position: [[1.48018278 0.67639824 0.70738008]]
Step:15, total reward:-79.0537769225392, average reward:-5.270251794835946,success
Box_Position: [[1.37133452 0.61873619 0.48437329]]
Step:22, total reward:-113.77624602273536, average reward:-5.171647546487971,success
Box_Position: [[1.45363104 0.58837043 0.61244216]]
actor_loss: tensor(4.5764, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8941, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-319.61785064565044, average reward:-4.439136814522922,success
Box_Position: [[1.4082668  0.96364407 0.72133918]]
actor_loss: tensor(4.8026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3741, device='cuda:0', grad_fn=<NegBackward>)
Step:111, total reward:-531.7026777481, average reward:-4.790114213946847,success
Box_Position: [[1.37412467 0.76457371 0.60217955]]
Step:7, total reward:-52.36824938830281, average reward:-7.481178484043258,success
Box_Position: [[1.54127935 1.10748506 0.55216566]]
actor_loss: tensor(4.6327, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7341, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6026, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9619, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1431.6428074409785, average reward:-7.158214037204893,----
Box_Position: [[1.33003313 1.01223165 0.72903304]]
actor_loss: tensor(4.9205, device='cuda:0', grad_fn=<NegBackward>)
Step:62, total reward:-339.405939104989, average reward:-5.474289340403049,success
Box_Position: [[1.42407516 1.13122237 0.50530419]]
actor_loss: tensor(5.1650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1323, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5868, device='cuda:0', grad_fn=<NegBackward>)
Step:147, total reward:-770.5212100626247, average reward:-5.24164088477976,success
Box_Position: [[1.27966594 1.02664802 0.63847082]]
actor_loss: tensor(4.4083, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0027, device='cuda:0', grad_fn=<NegBackward>)
Step:73, total reward:-444.6310851923199, average reward:-6.090836783456437,success
Box_Position: [[1.53695829 0.76004559 0.61756933]]
actor_loss: tensor(4.7985, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-394.1127507346979, average reward:-7.436089636503734,success
Box_Position: [[1.44594874 0.91528633 0.45476183]]
actor_loss: tensor(4.7434, device='cuda:0', grad_fn=<NegBackward>)
Step:34, total reward:-276.8077635686897, average reward:-8.141404810843815,success
Box_Position: [[1.46055675 1.07045453 0.70393648]]
Step:32, total reward:-166.94732446858694, average reward:-5.217103889643342,success
Box_Position: [[1.3930115  0.59418876 0.62207184]]
Step:15, total reward:-66.22914144336441, average reward:-4.415276096224294,success
Box_Position: [[1.36871861 0.75852357 0.63603528]]
actor_loss: tensor(4.4454, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-120.92197201976059, average reward:-7.557623251235037,success
Box_Position: [[1.30406196 0.80344897 0.54384978]]
actor_loss: tensor(4.9259, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-378.2961430679567, average reward:-5.731759743453889,success
Box_Position: [[1.42816333 1.09715978 0.54896859]]
actor_loss: tensor(4.7509, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1993, device='cuda:0', grad_fn=<NegBackward>)
Step:118, total reward:-627.4023157523454, average reward:-5.316968777562249,success
Box_Position: [[1.38100461 1.09068561 0.69207086]]
actor_loss: tensor(4.5825, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-222.30773984652603, average reward:-5.169947438291303,success
Box_Position: [[1.41956958 0.78245478 0.4618948 ]]
actor_loss: tensor(4.8773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3738, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-450.40133346849314, average reward:-6.2555740759512934,success
Box_Position: [[1.43894943 0.77446213 0.60592314]]
actor_loss: tensor(4.7147, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-299.3732720567243, average reward:-5.074123255198717,success
Box_Position: [[1.40190699 0.9239245  0.61044554]]
Step:16, total reward:-151.55826722686913, average reward:-9.47239170167932,success
Box_Position: [[1.31974347 0.73179941 0.51789027]]
actor_loss: tensor(4.8004, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-331.9813247599847, average reward:-6.147802310370087,success
Box_Position: [[1.41875603 0.87462171 0.6315355 ]]
actor_loss: tensor(5.1405, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-101.58240518011088, average reward:-5.079120259005544,success
Box_Position: [[1.28851972 1.14585885 0.52191136]]
Step:32, total reward:-141.32294884258965, average reward:-4.416342151330927,success
Box_Position: [[1.32336892 0.61215475 0.5609605 ]]
actor_loss: tensor(4.6626, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2975, device='cuda:0', grad_fn=<NegBackward>)
Step:136, total reward:-677.9386639451369, average reward:-4.984843117243654,success
Box_Position: [[1.5423741  0.87317335 0.53697546]]

------------------Episode:2400------------------
actor_loss: tensor(5.1590, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-155.7865746916849, average reward:-7.418408318651662,success
episode 2400, the accuracy is: 91%
Box_Position: [[1.45794744 0.61959012 0.71103726]]
Step:7, total reward:-32.30743179337601, average reward:-4.615347399053716,success
Box_Position: [[1.51624528 0.59747774 0.52820704]]
Step:21, total reward:-119.10103001288458, average reward:-5.671477619661171,success
Box_Position: [[1.38986994 0.77093122 0.66646279]]
actor_loss: tensor(4.2192, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-150.56248708152745, average reward:-7.528124354076373,success
Box_Position: [[1.39575858 0.81764493 0.64924088]]
Step:6, total reward:-51.71478054277653, average reward:-8.619130090462756,success
Box_Position: [[1.54182667 0.58573479 0.4644285 ]]
actor_loss: tensor(4.7650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0127, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7474, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5404, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1237.3856211156458, average reward:-6.186928105578229,----
Box_Position: [[1.46908518 1.03630134 0.58680312]]
actor_loss: tensor(4.6999, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6970, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-568.9598678762446, average reward:-5.74706937248732,success
Box_Position: [[1.29049248 0.57352663 0.68835353]]
actor_loss: tensor(5.1662, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-224.9699078166548, average reward:-4.499398156333096,success
Box_Position: [[1.4373342  1.03074547 0.48471536]]
actor_loss: tensor(5.4792, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3097, device='cuda:0', grad_fn=<NegBackward>)
Step:120, total reward:-805.4175685206233, average reward:-6.711813071005194,success
Box_Position: [[1.30016924 0.5798314  0.71782507]]
actor_loss: tensor(4.5054, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-127.23255006914738, average reward:-4.241085002304913,success
Box_Position: [[1.34391781 0.84454494 0.65515846]]
Step:3, total reward:-12.276279099607795, average reward:-4.092093033202598,success
Box_Position: [[1.38369736 0.70305684 0.49196908]]
Step:32, total reward:-197.8990296980108, average reward:-6.184344678062837,success
Box_Position: [[1.48233284 1.14678592 0.74410073]]
actor_loss: tensor(5.2666, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-273.22163705352864, average reward:-8.53817615792277,success
Box_Position: [[1.50495695 0.97736736 0.57168433]]
actor_loss: tensor(4.6584, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7995, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6672, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.1427, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1137.1083603910663, average reward:-5.685541801955331,success
Box_Position: [[1.287598   1.10109553 0.57500148]]
actor_loss: tensor(4.9005, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7669, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9092, device='cuda:0', grad_fn=<NegBackward>)
Step:171, total reward:-732.6216779027783, average reward:-4.284337297677066,success
Box_Position: [[1.30711033 0.60672364 0.58985897]]
Step:2, total reward:-16.766345430336244, average reward:-8.383172715168122,success
Box_Position: [[1.32224305 0.69331434 0.52663057]]
actor_loss: tensor(4.7746, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-254.38841360154063, average reward:-6.056866990512872,success
Box_Position: [[1.47141469 0.86414271 0.54123795]]
actor_loss: tensor(4.3181, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.1802, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7988, device='cuda:0', grad_fn=<NegBackward>)
Step:168, total reward:-907.713293292669, average reward:-5.403055317218268,success
Box_Position: [[1.39984079 0.64118248 0.59475721]]
Step:5, total reward:-29.171914580674418, average reward:-5.834382916134883,success
Box_Position: [[1.38721015 0.74546291 0.67261552]]
actor_loss: tensor(4.7083, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-440.0047425491704, average reward:-4.943873511788431,success
Box_Position: [[1.29956941 0.65916697 0.51570369]]
actor_loss: tensor(4.5634, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-51.87382560861508, average reward:-3.7052732577582197,success
Box_Position: [[1.35930328 0.72938344 0.45327684]]
Step:27, total reward:-171.40891328225487, average reward:-6.348478269713143,success
Box_Position: [[1.49978173 0.79139771 0.51101836]]
actor_loss: tensor(4.8478, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7054, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-478.73304087065543, average reward:-5.984163010883193,success
Box_Position: [[1.34309036 0.96670402 0.55603309]]
actor_loss: tensor(4.1004, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-260.32281534891916, average reward:-6.054018961602771,success
Box_Position: [[1.26580285 0.53896894 0.72171202]]
Step:20, total reward:-83.21226928881366, average reward:-4.160613464440683,success
Box_Position: [[1.40189604 0.84750589 0.69350453]]
Step:13, total reward:-84.15800190245966, average reward:-6.473692454035358,success
Box_Position: [[1.39899208 0.61098423 0.60354421]]
actor_loss: tensor(4.5809, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-157.39309997620714, average reward:-4.769487878066883,success
Box_Position: [[1.54140876 0.63074574 0.73165192]]
Step:10, total reward:-59.39616080663021, average reward:-5.939616080663021,success
Box_Position: [[1.48852108 0.57546226 0.51285439]]
actor_loss: tensor(4.4759, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-141.06179841152039, average reward:-5.642471936460815,success
Box_Position: [[1.31647878 0.84226246 0.74497623]]
Step:2, total reward:-13.079921814917316, average reward:-6.539960907458658,success
Box_Position: [[1.50579481 0.75733645 0.45583819]]
actor_loss: tensor(4.5181, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4389, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9314, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3076, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1210.8648540582665, average reward:-6.054324270291333,----
Box_Position: [[1.5321704  1.04798884 0.74166223]]
actor_loss: tensor(5.0250, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-354.216880569, average reward:-5.90361467615,success
Box_Position: [[1.45248106 0.83056049 0.59622357]]
actor_loss: tensor(5.2068, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6627, device='cuda:0', grad_fn=<NegBackward>)
Step:104, total reward:-554.9383441614967, average reward:-5.335945616937469,success
Box_Position: [[1.44828495 0.89828226 0.50893326]]
Step:6, total reward:-49.92014096439645, average reward:-8.320023494066076,success
Box_Position: [[1.31197289 0.72006946 0.51064773]]
actor_loss: tensor(5.0195, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-135.56278608307034, average reward:-6.778139304153517,success
Box_Position: [[1.52843597 0.90534219 0.47800397]]
actor_loss: tensor(4.8168, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0033, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6807, device='cuda:0', grad_fn=<NegBackward>)
Step:177, total reward:-1189.3560178465475, average reward:-6.719525524556765,success
Box_Position: [[1.25544914 0.80680677 0.5564027 ]]
actor_loss: tensor(4.5579, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-197.72192892298162, average reward:-6.37812673945102,success
Box_Position: [[1.31035371 1.02929479 0.58409215]]
actor_loss: tensor(4.7343, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6780, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9865, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0497, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-973.4891353029016, average reward:-4.8674456765145075,----
Box_Position: [[1.40888014 1.05184477 0.52320588]]
actor_loss: tensor(5.4772, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3202, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-706.2276411716489, average reward:-7.133612537087362,success
Box_Position: [[1.27528134 0.8857924  0.743183  ]]
actor_loss: tensor(4.6771, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2084, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4397, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9407, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-975.5344544743839, average reward:-4.877672272371919,----
Box_Position: [[1.25150264 0.67688332 0.68864084]]
actor_loss: tensor(4.9543, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4186, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-541.6872060975896, average reward:-4.669717293944738,success
Box_Position: [[1.39857746 0.75133413 0.73643791]]
actor_loss: tensor(4.6155, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8636, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-427.1384037833246, average reward:-4.642808736775267,success
Box_Position: [[1.53152503 0.82202766 0.52965129]]
actor_loss: tensor(4.7337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.2184, device='cuda:0', grad_fn=<NegBackward>)
Step:106, total reward:-719.0604288116679, average reward:-6.783588951053471,success
Box_Position: [[1.45937563 1.05673441 0.5345852 ]]
actor_loss: tensor(4.7263, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8324, device='cuda:0', grad_fn=<NegBackward>)
Step:84, total reward:-534.9916120191563, average reward:-6.368947762132812,success
Box_Position: [[1.3460569  0.9036623  0.64514152]]
Step:29, total reward:-176.3663207946894, average reward:-6.081597268782392,success
Box_Position: [[1.46695685 0.98656472 0.46317618]]
actor_loss: tensor(5.2625, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1977, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0110, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3398, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1344.3694602443425, average reward:-6.721847301221712,----
Box_Position: [[1.53935824 1.0611827  0.57119389]]
actor_loss: tensor(5.0426, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3463, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-325.60112287418025, average reward:-4.788251806973239,success
Box_Position: [[1.31074647 0.83055225 0.69287536]]
Step:16, total reward:-85.30858396708692, average reward:-5.331786497942932,success
Box_Position: [[1.49286777 0.76317981 0.54338002]]
actor_loss: tensor(4.9953, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-323.5891344189971, average reward:-5.05608022529683,success
Box_Position: [[1.38397048 0.98803525 0.45414258]]
Step:11, total reward:-106.22455316445443, average reward:-9.656777560404949,success
Box_Position: [[1.27631656 0.69286483 0.54409295]]

------------------Episode:2450------------------
actor_loss: tensor(5.4472, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-23.270475048899197, average reward:-5.817618762224799,success
Box_Position: [[1.45138612 0.57893558 0.46800479]]
Step:5, total reward:-25.53942930148969, average reward:-5.107885860297938,success
Box_Position: [[1.37631811 0.9503629  0.4698289 ]]
actor_loss: tensor(4.8232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8428, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7446, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-1040.7978948186583, average reward:-6.051150551271269,success
Box_Position: [[1.52804146 0.88747056 0.66644165]]
actor_loss: tensor(4.6836, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-390.12184914361603, average reward:-5.822714166322627,success
Box_Position: [[1.46876848 0.84176586 0.73772653]]
actor_loss: tensor(4.9931, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-126.26459258639474, average reward:-5.261024691099781,success
Box_Position: [[1.34999812 0.49383358 0.55557104]]
actor_loss: tensor(5.1689, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7414, device='cuda:0', grad_fn=<NegBackward>)
Step:125, total reward:-724.7083906871835, average reward:-5.797667125497468,success
Box_Position: [[1.53031109 0.88535353 0.63497735]]
actor_loss: tensor(4.2370, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-171.04284307557532, average reward:-5.701428102519177,success
Box_Position: [[1.51625163 0.87880793 0.63181449]]
actor_loss: tensor(5.1044, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-154.4125661847491, average reward:-5.9389448532595805,success
Box_Position: [[1.47155074 0.73278128 0.59536268]]
actor_loss: tensor(5.3137, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6909, device='cuda:0', grad_fn=<NegBackward>)
Step:134, total reward:-653.0919542715121, average reward:-4.8738205542650155,success
Box_Position: [[1.44066713 0.50181496 0.49265651]]
actor_loss: tensor(5.1240, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-161.6685607251226, average reward:-5.215114862100729,success
Box_Position: [[1.29903766 0.68389582 0.52722924]]
actor_loss: tensor(5.8715, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9310, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6950, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9842, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1570.971844657641, average reward:-7.854859223288205,----
Box_Position: [[1.4515757  0.78245635 0.72487878]]
actor_loss: tensor(5.0081, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-214.22986951335542, average reward:-3.9672198058028783,success
Box_Position: [[1.42331909 0.51264173 0.65230224]]
actor_loss: tensor(5.8138, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-220.77274408516692, average reward:-4.165523473305036,success
Box_Position: [[1.31002349 0.75976183 0.47801569]]
actor_loss: tensor(5.4267, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8598, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3454, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9388, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1734.6667183375891, average reward:-8.673333591687946,----
Box_Position: [[1.38514354 0.86432083 0.53825726]]
actor_loss: tensor(5.0830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0708, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-486.7167230620027, average reward:-6.404167408710562,success
Box_Position: [[1.54253561 0.93103856 0.48584728]]
actor_loss: tensor(5.8460, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7334, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3277, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3858, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1560.2681237602183, average reward:-7.801340618801091,----
Box_Position: [[1.37443579 0.98563362 0.6479632 ]]
Step:20, total reward:-95.84053033858645, average reward:-4.792026516929322,success
Box_Position: [[1.52361018 0.6815713  0.6885318 ]]
actor_loss: tensor(5.8050, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-219.3223919790603, average reward:-4.5692164995637565,success
Box_Position: [[1.51574288 1.0871074  0.483799  ]]
actor_loss: tensor(6.0827, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9457, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4154, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1657, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1092.3410473278204, average reward:-5.461705236639102,----
Box_Position: [[1.40632799 0.66894049 0.56585391]]
Step:16, total reward:-89.15783008971302, average reward:-5.5723643806070635,success
Box_Position: [[1.53109016 0.78891965 0.61125628]]
actor_loss: tensor(6.3457, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4853, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4645, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4921, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1140.5938026809474, average reward:-5.702969013404737,----
Box_Position: [[1.36813834 0.84362307 0.48101305]]
Step:5, total reward:-37.317338403954174, average reward:-7.463467680790835,success
Box_Position: [[1.50501334 1.0428457  0.58985026]]
actor_loss: tensor(5.9321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2488, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-290.0867595119994, average reward:-4.755520647737695,success
Box_Position: [[1.35079337 0.88615056 0.50776453]]
actor_loss: tensor(6.2078, device='cuda:0', grad_fn=<NegBackward>)
Step:82, total reward:-564.0493169422901, average reward:-6.878650206613295,success
Box_Position: [[1.46909579 1.05156073 0.59420862]]
actor_loss: tensor(6.4311, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-181.01049254213234, average reward:-4.7634340142666405,success
Box_Position: [[1.41531045 0.45353585 0.64320823]]
Step:11, total reward:-48.84131752636505, average reward:-4.440119775124096,success
Box_Position: [[1.29590797 0.92719093 0.53146114]]
actor_loss: tensor(6.3785, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-279.5781928060191, average reward:-6.501818437349281,success
Box_Position: [[1.3328386  1.06971213 0.67915952]]
actor_loss: tensor(6.4047, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1013, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3925, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7090, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1048.1516479363793, average reward:-5.240758239681896,----
Box_Position: [[1.47279861 0.95601634 0.53986373]]
Step:22, total reward:-173.56429538340123, average reward:-7.889286153790965,success
Box_Position: [[1.40276881 0.65184626 0.54193452]]
actor_loss: tensor(6.7851, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-56.259845918706226, average reward:-5.1145314471551115,success
Box_Position: [[1.34386661 0.87608497 0.63681802]]
Step:4, total reward:-17.743852906953496, average reward:-4.435963226738374,success
Box_Position: [[1.26690657 0.48484299 0.58597188]]
actor_loss: tensor(6.6279, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-228.11648897138883, average reward:-4.22437942539609,success
Box_Position: [[1.45953065 0.52297181 0.70012123]]
actor_loss: tensor(6.8832, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8910, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-378.4851958403111, average reward:-4.159177976267155,success
Box_Position: [[1.36989145 0.59669657 0.54408642]]
Step:16, total reward:-67.937997519943, average reward:-4.246124844996437,success
Box_Position: [[1.47015227 0.97790583 0.50975136]]
actor_loss: tensor(7.0709, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3556, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4894, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1058, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1437.3380489986723, average reward:-7.186690244993361,----
Box_Position: [[1.39655378 0.75590166 0.74187164]]
actor_loss: tensor(6.4502, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5071, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-441.54800840549444, average reward:-4.599458420890567,success
Box_Position: [[1.49530061 0.68839882 0.48969889]]
actor_loss: tensor(6.6958, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0871, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3218, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5558, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1126.7417236924011, average reward:-5.6337086184620055,----
Box_Position: [[1.45327658 0.89326014 0.64626506]]
Step:29, total reward:-150.4982006649656, average reward:-5.189593126378124,success
Box_Position: [[1.34204879 0.98149319 0.72382416]]
actor_loss: tensor(6.5331, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-147.09866588834228, average reward:-5.25352378172651,success
Box_Position: [[1.54731697 0.80258603 0.65060524]]
actor_loss: tensor(7.0623, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6714, device='cuda:0', grad_fn=<NegBackward>)
Step:90, total reward:-396.9589035896324, average reward:-4.410654484329249,success
Box_Position: [[1.40484465 0.77417305 0.55636549]]
actor_loss: tensor(7.6645, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-195.9969851108615, average reward:-5.157815397654249,success
Box_Position: [[1.40776722 0.53999856 0.71009285]]
Step:4, total reward:-17.95520388622171, average reward:-4.488800971555428,success
Box_Position: [[1.33254929 0.64737587 0.5681103 ]]
actor_loss: tensor(7.2677, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-256.2863346311356, average reward:-4.496251484756765,success
Box_Position: [[1.38202507 0.72187512 0.53538009]]
Step:22, total reward:-108.5123066856294, average reward:-4.932377576619518,success
Box_Position: [[1.28310346 0.72798685 0.65008853]]
actor_loss: tensor(7.2846, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7365, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-346.5562468592485, average reward:-4.881073899426036,success
Box_Position: [[1.26445349 1.16731096 0.6327873 ]]
Step:17, total reward:-80.33592507403878, average reward:-4.725642651414046,success
Box_Position: [[1.45009428 0.47716674 0.67023738]]
actor_loss: tensor(7.1563, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6731, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3850, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5054, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-916.7881114009385, average reward:-4.583940557004692,----
Box_Position: [[1.29041778 0.86025654 0.68351118]]
actor_loss: tensor(7.3156, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-331.2060868446117, average reward:-5.710449773182961,success
Box_Position: [[1.49281202 0.76128425 0.50335205]]
actor_loss: tensor(6.9067, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1786, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1223, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0492, device='cuda:0', grad_fn=<NegBackward>)
Step:175, total reward:-1067.5610509640894, average reward:-6.1003488626519395,success
Box_Position: [[1.44665735 0.91157363 0.50831782]]
Step:22, total reward:-133.32195573745037, average reward:-6.0600888971568345,success
Box_Position: [[1.38608964 0.95485376 0.51423573]]

------------------Episode:2500------------------
Step:7, total reward:-44.219933608298206, average reward:-6.3171333726140295,success
episode 2500, the accuracy is: 86%
Box_Position: [[1.50952575 0.75620613 0.5359344 ]]
actor_loss: tensor(7.0121, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6580, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-351.3661522001476, average reward:-5.092263075364458,success
Box_Position: [[1.32463624 0.9224682  0.57532391]]
Step:2, total reward:-16.014326073472667, average reward:-8.007163036736333,success
Box_Position: [[1.26581888 1.02667448 0.67271557]]
actor_loss: tensor(7.7208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1159, device='cuda:0', grad_fn=<NegBackward>)
Step:100, total reward:-442.53701239777985, average reward:-4.425370123977799,success
Box_Position: [[1.46942012 0.66097855 0.7102378 ]]
actor_loss: tensor(7.0505, device='cuda:0', grad_fn=<NegBackward>)
Step:89, total reward:-352.5747927988787, average reward:-3.961514525830098,success
Box_Position: [[1.54733714 0.66357053 0.73419808]]
actor_loss: tensor(6.6315, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8129, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1326, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1173, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-863.22245866666, average reward:-4.3161122933333,----
Box_Position: [[1.46780013 0.70309678 0.60133589]]
actor_loss: tensor(7.0834, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5062, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7220, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8099, device='cuda:0', grad_fn=<NegBackward>)
Step:165, total reward:-737.9367836284727, average reward:-4.472344143202864,success
Box_Position: [[1.27051544 0.50163984 0.48953855]]
actor_loss: tensor(7.3005, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-897.490595190877, average reward:-12.821294217012529,success
Box_Position: [[1.25590721 1.05082742 0.72102331]]
actor_loss: tensor(7.5954, device='cuda:0', grad_fn=<NegBackward>)
Step:51, total reward:-246.16076173732566, average reward:-4.82668160269266,success
Box_Position: [[1.41296764 0.56756707 0.60547305]]
actor_loss: tensor(7.4329, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-122.04722745726055, average reward:-4.520267683602243,success
Box_Position: [[1.52951915 0.67606569 0.62774689]]
actor_loss: tensor(7.0208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5956, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-501.65221867087826, average reward:-4.688338492251199,success
Box_Position: [[1.44559806 1.10996264 0.64891454]]
Step:26, total reward:-144.4283599167828, average reward:-5.554936919876261,success
Box_Position: [[1.48442221 0.77463395 0.52925259]]
actor_loss: tensor(6.8846, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-145.26814517610626, average reward:-6.917530722671726,success
Box_Position: [[1.43733203 0.77703161 0.50015104]]
Step:19, total reward:-129.9553215942551, average reward:-6.83975376811869,success
Box_Position: [[1.26791661 0.68134699 0.53126661]]
Step:2, total reward:-7.686299521330888, average reward:-3.843149760665444,success
Box_Position: [[1.48600049 0.86504885 0.65092995]]
actor_loss: tensor(7.2965, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-239.6534796716601, average reward:-6.144961017222054,success
Box_Position: [[1.42194224 0.69838077 0.59388404]]
actor_loss: tensor(7.2953, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9809, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9370, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-725.7663015027682, average reward:-4.345905997022564,success
Box_Position: [[1.2948116  0.82747376 0.508637  ]]
actor_loss: tensor(7.8410, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-111.91780409998343, average reward:-5.595890204999171,success
Box_Position: [[1.34843503 1.02199904 0.49956674]]
Step:20, total reward:-122.0153040400488, average reward:-6.1007652020024405,success
Box_Position: [[1.29007689 1.09233921 0.4732213 ]]
Step:18, total reward:-118.03725863812211, average reward:-6.557625479895673,success
Box_Position: [[1.30795228 0.98380915 0.73814465]]
actor_loss: tensor(6.6269, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-50.53121248623778, average reward:-6.316401560779722,success
Box_Position: [[1.36958042 1.08931078 0.62344881]]
Step:14, total reward:-87.51498929051508, average reward:-6.251070663608219,success
Box_Position: [[1.52535796 0.50332525 0.51157246]]
actor_loss: tensor(6.9187, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5675, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0547, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1478, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1078.1024566098042, average reward:-5.390512283049021,----
Box_Position: [[1.36013382 0.94192935 0.61692771]]
actor_loss: tensor(7.3496, device='cuda:0', grad_fn=<NegBackward>)
Step:56, total reward:-257.80785412246297, average reward:-4.603711680758267,success
Box_Position: [[1.54860093 0.88885896 0.51301229]]
actor_loss: tensor(7.6776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9603, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3755, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8246, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1161.2015890739935, average reward:-5.806007945369967,----
Box_Position: [[1.41942769 0.77844663 0.68630726]]
actor_loss: tensor(7.7237, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-161.4653962813009, average reward:-4.892890796403058,success
Box_Position: [[1.53803365 0.63019137 0.48996959]]
actor_loss: tensor(7.6806, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5936, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3477, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5494, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1128.1934104430948, average reward:-5.640967052215474,----
Box_Position: [[1.42637001 0.92974549 0.45630709]]
actor_loss: tensor(7.5792, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.9666, device='cuda:0', grad_fn=<NegBackward>)
Step:98, total reward:-654.3919981449908, average reward:-6.677469368826436,success
Box_Position: [[1.44091589 0.55043145 0.50717794]]
actor_loss: tensor(7.8272, device='cuda:0', grad_fn=<NegBackward>)
Step:64, total reward:-329.1647813136828, average reward:-5.143199708026294,success
Box_Position: [[1.44295904 0.97607545 0.46062056]]
actor_loss: tensor(7.3050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.0583, device='cuda:0', grad_fn=<NegBackward>)
Step:91, total reward:-542.2780191035762, average reward:-5.959099111028309,success
Box_Position: [[1.50821381 0.90316007 0.58906892]]
actor_loss: tensor(7.3574, device='cuda:0', grad_fn=<NegBackward>)
Step:53, total reward:-253.3417422224368, average reward:-4.780032872121449,success
Box_Position: [[1.48377817 0.59574779 0.60501995]]
actor_loss: tensor(7.4705, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0541, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2082, device='cuda:0', grad_fn=<NegBackward>)
Step:158, total reward:-692.1061993831471, average reward:-4.3804189834376395,success
Box_Position: [[1.36629518 0.72397318 0.58442415]]
Step:5, total reward:-29.10325587480148, average reward:-5.820651174960296,success
Box_Position: [[1.26459377 0.8656623  0.57415566]]
actor_loss: tensor(7.2696, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-108.72026512964308, average reward:-4.941830233165595,success
Box_Position: [[1.38021252 0.97190831 0.62641327]]
Step:22, total reward:-112.99362516725137, average reward:-5.136073871238699,success
Box_Position: [[1.50844976 0.85466962 0.54768156]]
actor_loss: tensor(7.6604, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5489, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5121, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9335, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1060.566104783401, average reward:-5.302830523917005,----
Box_Position: [[1.38290315 0.94654511 0.62529769]]
actor_loss: tensor(7.5745, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-159.44494057731129, average reward:-4.982654393040978,success
Box_Position: [[1.25188619 0.96547693 0.45875991]]
actor_loss: tensor(8.3966, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.6057, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-1668.4319962706095, average reward:-11.506427560486962,success
Box_Position: [[1.31250518 0.92602218 0.47689132]]
actor_loss: tensor(7.5452, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-30.344209643503255, average reward:-6.068841928700651,success
Box_Position: [[1.35569147 0.59180037 0.6039972 ]]
actor_loss: tensor(7.1375, device='cuda:0', grad_fn=<NegBackward>)
Step:83, total reward:-614.7107124343227, average reward:-7.406153161859309,success
Box_Position: [[1.50447394 0.79176475 0.56975561]]
actor_loss: tensor(7.1986, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-233.25124847907907, average reward:-4.859401009980814,success
Box_Position: [[1.54814314 1.02391843 0.46686674]]
actor_loss: tensor(7.5648, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7051, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7099, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7403, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1398.0745134531105, average reward:-6.990372567265553,----
Box_Position: [[1.46798415 0.5018358  0.59093786]]
actor_loss: tensor(7.9115, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5890, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.7297, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.1163, device='cuda:0', grad_fn=<NegBackward>)
Step:176, total reward:-756.3429887424626, average reward:-4.297403345127628,success
Box_Position: [[1.4995276  0.8078198  0.59016116]]
actor_loss: tensor(8.2058, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-273.34910442422296, average reward:-4.9699837168040535,success
Box_Position: [[1.52018536 0.84044912 0.54961327]]
actor_loss: tensor(7.4821, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-297.07181585831603, average reward:-6.06269011955747,success
Box_Position: [[1.48804098 0.79041118 0.58047142]]
actor_loss: tensor(7.3599, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5528, device='cuda:0', grad_fn=<NegBackward>)
Step:105, total reward:-512.6378112002297, average reward:-4.882264868573617,success
Box_Position: [[1.41051523 0.56149664 0.64789602]]
Step:9, total reward:-42.74329107025983, average reward:-4.749254563362204,success
Box_Position: [[1.35573503 0.62081249 0.58615857]]
actor_loss: tensor(7.1194, device='cuda:0', grad_fn=<NegBackward>)
Step:66, total reward:-257.330453029556, average reward:-3.898946258023576,success
Box_Position: [[1.28343666 0.60252381 0.57018609]]
actor_loss: tensor(7.9186, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3393, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-476.45629577306136, average reward:-4.812689856293549,success
Box_Position: [[1.47613575 0.79197292 0.74797739]]
actor_loss: tensor(7.5852, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8388, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3839, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.9949, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-828.8633582501334, average reward:-4.144316791250667,----
Box_Position: [[1.3736992  0.83939594 0.57448245]]

------------------Episode:2550------------------
Step:3, total reward:-20.255198811784872, average reward:-6.751732937261624,success
Box_Position: [[1.39692544 0.71392361 0.6085552 ]]
actor_loss: tensor(7.4676, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-53.09784707421504, average reward:-4.42482058951792,success
Box_Position: [[1.32493417 0.72391395 0.6100127 ]]
Step:40, total reward:-208.76869454030037, average reward:-5.219217363507509,success
Box_Position: [[1.38751096 0.90634742 0.67500271]]
actor_loss: tensor(7.0838, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-198.67733147820007, average reward:-4.319072423439132,success
Box_Position: [[1.45053325 0.86855268 0.73811796]]
actor_loss: tensor(7.2047, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-44.545538544103294, average reward:-4.949504282678144,success
Box_Position: [[1.43625472 0.68256874 0.49001624]]
actor_loss: tensor(8.0025, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2246, device='cuda:0', grad_fn=<NegBackward>)
Step:143, total reward:-832.4108374978722, average reward:-5.821054807677428,success
Box_Position: [[1.37855522 0.962795   0.67903616]]
actor_loss: tensor(7.3572, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-145.744440060817, average reward:-5.6055553869545,success
Box_Position: [[1.30464942 0.86773732 0.53627557]]
Step:4, total reward:-27.430909237730994, average reward:-6.857727309432748,success
Box_Position: [[1.43684768 0.74818032 0.48025446]]
actor_loss: tensor(7.4179, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.0757, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-588.2651881892433, average reward:-5.497805497095732,success
Box_Position: [[1.46149097 0.71349197 0.72594474]]
actor_loss: tensor(7.3371, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7071, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-285.3780578788134, average reward:-4.019409265898781,success
Box_Position: [[1.3272565  0.60795351 0.54530389]]
actor_loss: tensor(7.8700, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8156, device='cuda:0', grad_fn=<NegBackward>)
Step:138, total reward:-616.9294346287325, average reward:-4.4705031494835685,success
Box_Position: [[1.51247502 1.17148644 0.7402237 ]]
actor_loss: tensor(7.3775, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2830, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3293, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.1207, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1033.3142531743235, average reward:-5.166571265871617,----
Box_Position: [[1.29900837 1.09569745 0.46337617]]
actor_loss: tensor(7.6888, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-94.57798832439873, average reward:-7.881499027033228,success
Box_Position: [[1.43441142 1.01151266 0.70712199]]
actor_loss: tensor(7.6373, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-374.0446201251253, average reward:-4.857722339287341,success
Box_Position: [[1.26545471 0.97912933 0.69552361]]
actor_loss: tensor(7.2021, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-320.97318468915716, average reward:-4.938048995217803,success
Box_Position: [[1.52282626 1.07438873 0.4848361 ]]
actor_loss: tensor(7.5820, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.9568, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(8.2528, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5395, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1392.874191725608, average reward:-6.96437095862804,----
Box_Position: [[1.3945608  0.90680771 0.64040067]]
actor_loss: tensor(7.1742, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-138.5659864126729, average reward:-5.773582767194704,success
Box_Position: [[1.28583644 0.87167476 0.55392337]]
Step:19, total reward:-116.53461022251106, average reward:-6.133400538026898,success
Box_Position: [[1.26887977 0.7418369  0.45610204]]
actor_loss: tensor(7.6495, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-87.74004155336688, average reward:-6.267145825240491,success
Box_Position: [[1.41670229 0.89068635 0.4934814 ]]
Step:23, total reward:-200.3287074395113, average reward:-8.709943801717882,success
Box_Position: [[1.36124922 0.75661408 0.56880142]]
actor_loss: tensor(7.7528, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-474.8404861266009, average reward:-10.322619263621759,success
Box_Position: [[1.25667476 0.52131482 0.61806054]]
Step:9, total reward:-43.7152539726887, average reward:-4.857250441409856,success
Box_Position: [[1.44768616 1.04264517 0.51264969]]
actor_loss: tensor(7.6904, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3102, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0517, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8928, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1383.0674535590347, average reward:-6.915337267795174,----
Box_Position: [[1.34335373 0.58964368 0.69494076]]
actor_loss: tensor(7.4509, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-70.0230866742963, average reward:-3.334432698776014,success
Box_Position: [[1.30766452 0.71908194 0.48460272]]
Step:19, total reward:-84.70141143966872, average reward:-4.457969023140459,success
Box_Position: [[1.27572748 0.82018467 0.68357506]]
actor_loss: tensor(7.2970, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5855, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-544.8064213582651, average reward:-5.7958129931730324,success
Box_Position: [[1.52441438 0.60460378 0.67721308]]
actor_loss: tensor(7.6228, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.9928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.8632, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2573, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-889.6391537380779, average reward:-4.44819576869039,----
Box_Position: [[1.4542779  0.96073642 0.61497746]]
actor_loss: tensor(7.1965, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1723, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1133, device='cuda:0', grad_fn=<NegBackward>)
Step:172, total reward:-864.1606547162794, average reward:-5.024189853001625,success
Box_Position: [[1.48083925 0.96287892 0.45620448]]
actor_loss: tensor(6.7534, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4918, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7754, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2658, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1201.5446850077906, average reward:-6.007723425038953,----
Box_Position: [[1.45426204 0.83855032 0.5550907 ]]
actor_loss: tensor(7.0979, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-246.16737545512365, average reward:-5.237603733087737,success
Box_Position: [[1.27356463 0.73945871 0.66561345]]
Step:1, total reward:-4.3244260154289655, average reward:-4.3244260154289655,success
Box_Position: [[1.40688573 1.0387961  0.63265485]]
actor_loss: tensor(7.2030, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-168.11496194306525, average reward:-6.0041057836809015,success
Box_Position: [[1.30808068 0.74978674 0.70939428]]
Step:8, total reward:-41.847963320572234, average reward:-5.230995415071529,success
Box_Position: [[1.27697201 0.93622728 0.65428033]]
Step:11, total reward:-65.3324770691853, average reward:-5.939316097198664,success
Box_Position: [[1.51393224 0.53847639 0.5794216 ]]
actor_loss: tensor(6.5909, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.4406, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3656, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-964.0207330227518, average reward:-4.820103665113759,----
Box_Position: [[1.52059888 1.00669709 0.56497489]]
actor_loss: tensor(6.9823, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8146, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8713, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.1429, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1132.0561533040254, average reward:-5.660280766520128,----
Box_Position: [[1.41566781 0.88881895 0.73750218]]
actor_loss: tensor(6.5983, device='cuda:0', grad_fn=<NegBackward>)
Step:19, total reward:-72.42794204806633, average reward:-3.811996949898228,success
Box_Position: [[1.5483646  1.00627694 0.50703939]]
actor_loss: tensor(6.4178, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3055, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8118, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3597, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1326.5400351869507, average reward:-6.632700175934754,----
Box_Position: [[1.40102013 0.81802087 0.63879526]]
Step:27, total reward:-120.21730374083323, average reward:-4.452492731141971,success
Box_Position: [[1.53391033 0.91262158 0.61157504]]
actor_loss: tensor(6.6392, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0751, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.5597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2080, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-964.9107669106501, average reward:-4.82455383455325,----
Box_Position: [[1.53025465 0.93248036 0.74396318]]
actor_loss: tensor(7.4917, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6741, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.3511, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7539, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-953.9214261989733, average reward:-4.769607130994867,----
Box_Position: [[1.35590336 0.7330804  0.59008361]]
Step:3, total reward:-20.27993144162115, average reward:-6.75997714720705,success
Box_Position: [[1.46669216 0.78411572 0.51147634]]
Step:13, total reward:-94.61196625642881, average reward:-7.277843558186832,success
Box_Position: [[1.43828056 1.10945576 0.72338729]]
actor_loss: tensor(7.3642, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-121.92809195707957, average reward:-5.806099617003789,success
Box_Position: [[1.28974065 0.87971074 0.71719043]]
actor_loss: tensor(6.5751, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-233.90495386692993, average reward:-6.155393522813945,success
Box_Position: [[1.27710299 0.84829344 0.70156298]]
Step:4, total reward:-24.2322312094079, average reward:-6.058057802351975,success
Box_Position: [[1.31178525 0.95942981 0.60341788]]
Step:36, total reward:-187.943581196395, average reward:-5.220655033233195,success
Box_Position: [[1.3627812  0.73286312 0.70055402]]
actor_loss: tensor(6.4924, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-174.30492485944924, average reward:-4.357623121486231,success
Box_Position: [[1.30366095 0.43183021 0.67130074]]
actor_loss: tensor(7.5395, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4129, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3635, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5812, device='cuda:0', grad_fn=<NegBackward>)
Step:184, total reward:-696.2964443085241, average reward:-3.7842198060245873,success
Box_Position: [[1.52942897 0.71336899 0.57348198]]
actor_loss: tensor(6.9670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7557, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3146, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-935.340885453234, average reward:-4.67670442726617,----
Box_Position: [[1.45403643 0.6297005  0.63532423]]

------------------Episode:2600------------------
Step:10, total reward:-52.06474880014325, average reward:-5.206474880014325,success
episode 2600, the accuracy is: 82%
Box_Position: [[1.40183067 0.87796742 0.53449124]]
Step:18, total reward:-115.79365241249218, average reward:-6.432980689582899,success
Box_Position: [[1.28081386 1.05952393 0.66303985]]
actor_loss: tensor(6.9556, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-41.94574212976129, average reward:-5.243217766220162,success
Box_Position: [[1.38513898 0.65098738 0.67868788]]
actor_loss: tensor(6.2140, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9616, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5650, device='cuda:0', grad_fn=<NegBackward>)
Step:167, total reward:-679.0040111831446, average reward:-4.0658922825338,success
Box_Position: [[1.51547634 0.68596381 0.48157429]]
actor_loss: tensor(6.4044, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6900, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7139, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4946, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1232.434398342369, average reward:-6.162171991711845,----
Box_Position: [[1.26784274 0.88319396 0.46296484]]
Step:9, total reward:-77.47076691980752, average reward:-8.607862991089725,success
Box_Position: [[1.41849715 1.05946674 0.52171894]]
actor_loss: tensor(6.2548, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6319, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7169, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2911, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1128.1211759677342, average reward:-5.640605879838671,----
Box_Position: [[1.46330673 0.87227995 0.66903274]]
actor_loss: tensor(6.2154, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0912, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-492.884465219094, average reward:-4.249004010509431,success
Box_Position: [[1.36832031 0.61824524 0.54438641]]
actor_loss: tensor(6.8005, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-18.69204139049845, average reward:-3.7384082780996897,success
Box_Position: [[1.35688182 0.48817827 0.54958939]]
Step:14, total reward:-55.43593381478282, average reward:-3.959709558198773,success
Box_Position: [[1.45317049 1.09711194 0.6596923 ]]
actor_loss: tensor(6.1544, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0619, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-998.9501199621499, average reward:-4.994750599810749,----
Box_Position: [[1.33493723 0.59461408 0.46714705]]
actor_loss: tensor(6.3694, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.0224, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-470.9672811202414, average reward:-5.119209577393929,success
Box_Position: [[1.26026222 0.68815447 0.4764971 ]]
Step:22, total reward:-107.4218830526102, average reward:-4.882812866027736,success
Box_Position: [[1.35052549 0.59916712 0.49102861]]
actor_loss: tensor(6.4242, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2915, device='cuda:0', grad_fn=<NegBackward>)
Step:95, total reward:-462.2818496123554, average reward:-4.866124732761636,success
Box_Position: [[1.30920088 0.66803808 0.73808369]]
actor_loss: tensor(6.0360, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-177.43647099987592, average reward:-4.9287908611076645,success
Box_Position: [[1.44427432 0.58599259 0.55167463]]
actor_loss: tensor(6.3909, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4786, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8912, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2178, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-839.1362684275796, average reward:-4.195681342137898,----
Box_Position: [[1.28608713 1.07188048 0.46310333]]
Step:19, total reward:-133.1031912028939, average reward:-7.005431115941784,success
Box_Position: [[1.41988134 0.89553772 0.56690615]]
Step:18, total reward:-114.49253734334434, average reward:-6.360696519074685,success
Box_Position: [[1.44738845 0.6830338  0.53494824]]
actor_loss: tensor(6.4665, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-72.4986834677916, average reward:-5.576821805214738,success
Box_Position: [[1.29871651 0.6958038  0.52991296]]
actor_loss: tensor(6.4757, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-237.0637394326576, average reward:-5.268083098503502,success
Box_Position: [[1.42102367 0.87702154 0.45928404]]
Step:36, total reward:-245.79419378931777, average reward:-6.8276164941477155,success
Box_Position: [[1.4428162  0.95229241 0.65439261]]
actor_loss: tensor(6.2195, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-104.45463618951938, average reward:-6.528414761844961,success
Box_Position: [[1.33696744 0.90874619 0.72372873]]
Step:40, total reward:-197.74114640652638, average reward:-4.943528660163159,success
Box_Position: [[1.34884245 0.76242749 0.52746145]]
actor_loss: tensor(5.5147, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-223.01417086019072, average reward:-6.758005177581537,success
Box_Position: [[1.30022829 0.77578675 0.73658671]]
actor_loss: tensor(6.1813, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-104.90400447109936, average reward:-4.371000186295807,success
Box_Position: [[1.47434566 0.83341048 0.60557235]]
actor_loss: tensor(6.4347, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-366.10804644929436, average reward:-4.57635058061618,success
Box_Position: [[1.27508271 0.61948515 0.49730189]]
actor_loss: tensor(6.5457, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-203.66772629211266, average reward:-5.819077894060362,success
Box_Position: [[1.47851481 0.46343416 0.63094623]]
actor_loss: tensor(6.0913, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(7.2557, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3555, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9371, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-909.1007722348943, average reward:-4.545503861174471,----
Box_Position: [[1.29306403 0.91281658 0.73729132]]
Step:4, total reward:-22.772764557437434, average reward:-5.693191139359358,success
Box_Position: [[1.5302316  0.80469558 0.51798827]]
actor_loss: tensor(6.8585, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0302, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3499, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.6342, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1234.3493818688196, average reward:-6.1717469093440975,----
Box_Position: [[1.46474272 0.45901732 0.70434421]]
actor_loss: tensor(5.9498, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7897, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2603, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-918.2669625605317, average reward:-4.591334812802659,----
Box_Position: [[1.53841074 0.88859648 0.6989257 ]]
Step:19, total reward:-84.31709340743502, average reward:-4.437741758286054,success
Box_Position: [[1.31932817 0.87330743 0.5987503 ]]
actor_loss: tensor(6.7132, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-71.17339534828236, average reward:-5.4748765652524884,success
Box_Position: [[1.43306142 0.82381771 0.62536862]]
Step:39, total reward:-190.37099689796804, average reward:-4.881307612768412,success
Box_Position: [[1.52964756 0.48014549 0.50390142]]
actor_loss: tensor(6.0722, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7634, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2379, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1003.5898250263695, average reward:-5.017949125131847,----
Box_Position: [[1.51148925 0.58821503 0.52533433]]
actor_loss: tensor(6.1648, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8367, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8567, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1927, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-995.4464432119528, average reward:-4.977232216059764,----
Box_Position: [[1.41607931 0.50343621 0.73590825]]
actor_loss: tensor(6.2677, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8828, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.8619, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9236, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-871.0464106299327, average reward:-4.355232053149663,----
Box_Position: [[1.52104624 0.55851056 0.54957671]]
actor_loss: tensor(5.7426, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6553, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1731, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-929.1206971739281, average reward:-4.64560348586964,----
Box_Position: [[1.38316753 0.86629793 0.68892367]]
Step:4, total reward:-20.338759601879385, average reward:-5.084689900469846,success
Box_Position: [[1.5086312  0.57286973 0.70902252]]
actor_loss: tensor(6.0813, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-107.6352070236907, average reward:-4.305408280947628,success
Box_Position: [[1.33617663 0.66640186 0.74766745]]
actor_loss: tensor(5.7701, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-213.12608201972387, average reward:-4.84377459135736,success
Box_Position: [[1.53926043 1.00993206 0.69902797]]
actor_loss: tensor(5.8605, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1220, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7216, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7522, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1054.8588227226485, average reward:-5.274294113613243,----
Box_Position: [[1.3249648  0.73744827 0.57127465]]
Step:16, total reward:-108.85456276242572, average reward:-6.803410172651607,success
Box_Position: [[1.32092542 0.85342872 0.6874305 ]]
Step:16, total reward:-77.39595968377066, average reward:-4.837247480235666,success
Box_Position: [[1.53733481 0.7125592  0.69348298]]
actor_loss: tensor(5.7355, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0062, device='cuda:0', grad_fn=<NegBackward>)
Step:96, total reward:-437.43464542542836, average reward:-4.556610889848212,success
Box_Position: [[1.25152185 0.89708097 0.60804792]]
actor_loss: tensor(6.8109, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-263.0862016463425, average reward:-7.307950045731736,success
Box_Position: [[1.37088166 0.80142965 0.55923608]]
Step:13, total reward:-72.80238982709024, average reward:-5.600183832853095,success
Box_Position: [[1.36254042 0.47371721 0.58082676]]
actor_loss: tensor(6.7783, device='cuda:0', grad_fn=<NegBackward>)
Step:9, total reward:-28.6888135866895, average reward:-3.187645954076611,success
Box_Position: [[1.26433947 0.72202066 0.5655737 ]]
Step:24, total reward:-119.33965350278135, average reward:-4.97248556261589,success
Box_Position: [[1.37545729 0.97811067 0.47521175]]
actor_loss: tensor(4.9714, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4103, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9843, device='cuda:0', grad_fn=<NegBackward>)
Step:144, total reward:-787.0433581075636, average reward:-5.465578875746969,success
Box_Position: [[1.26848038 0.84092119 0.60177459]]

------------------Episode:2650------------------
Step:24, total reward:-109.9105904213323, average reward:-4.579607934222179,success
Box_Position: [[1.47330233 0.67350276 0.49045184]]
actor_loss: tensor(5.8834, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7421, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4869, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3756, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1217.3496386710276, average reward:-6.086748193355138,----
Box_Position: [[1.54590961 0.94502758 0.73568501]]
actor_loss: tensor(5.6151, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2864, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7617, device='cuda:0', grad_fn=<NegBackward>)
Step:148, total reward:-672.7665120042027, average reward:-4.545719675704072,success
Box_Position: [[1.49508742 0.63705827 0.64672247]]
actor_loss: tensor(5.7192, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9262, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8557, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-850.5518475671503, average reward:-4.252759237835751,----
Box_Position: [[1.33333894 0.8716764  0.57302846]]
actor_loss: tensor(6.0299, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-192.22069286926336, average reward:-4.271570952650297,success
Box_Position: [[1.37746029 1.04946054 0.56754123]]
actor_loss: tensor(5.6973, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-206.29984404589362, average reward:-4.584440978797636,success
Box_Position: [[1.38092857 1.12906085 0.59603901]]
Step:10, total reward:-71.2050365446412, average reward:-7.1205036544641205,success
Box_Position: [[1.54029673 0.98370411 0.62135243]]
actor_loss: tensor(5.8462, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2018, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8514, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5758, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1261.2574646096073, average reward:-6.3062873230480365,----
Box_Position: [[1.36620413 0.76747334 0.54004684]]
actor_loss: tensor(5.6140, device='cuda:0', grad_fn=<NegBackward>)
Step:13, total reward:-85.7672914165349, average reward:-6.5974839551180695,success
Box_Position: [[1.51984088 0.79009046 0.63628794]]
actor_loss: tensor(6.3725, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-205.2196631611473, average reward:-4.664083253662439,success
Box_Position: [[1.25178483 0.84776467 0.46636825]]
Step:30, total reward:-240.54821678166897, average reward:-8.018273892722299,success
Box_Position: [[1.30707029 1.18231672 0.62138067]]
actor_loss: tensor(6.0398, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-125.87538104198595, average reward:-4.841360809307152,success
Box_Position: [[1.30314166 0.93970777 0.69394997]]
Step:4, total reward:-32.07368147528717, average reward:-8.018420368821792,success
Box_Position: [[1.2627288  0.86823196 0.48559429]]
Step:21, total reward:-147.8959706310508, average reward:-7.042665268145276,success
Box_Position: [[1.39700445 0.90185615 0.73343464]]
Step:16, total reward:-83.53357176265199, average reward:-5.220848235165749,success
Box_Position: [[1.46948099 0.69884463 0.48034003]]
actor_loss: tensor(5.8544, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3392, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8314, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7715, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1145.5337299177172, average reward:-5.727668649588586,----
Box_Position: [[1.29251514 1.05551793 0.50762834]]
actor_loss: tensor(5.7797, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-138.5509988248929, average reward:-4.777620649134238,success
Box_Position: [[1.50820784 0.72803785 0.74232855]]
actor_loss: tensor(5.9813, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8324, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0721, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6399, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-854.0756357759249, average reward:-4.270378178879624,----
Box_Position: [[1.28497632 0.72282317 0.62515822]]
actor_loss: tensor(6.4790, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-158.05465716814555, average reward:-4.78953506570138,success
Box_Position: [[1.49656317 0.76893074 0.66784233]]
Step:17, total reward:-71.20841678878456, average reward:-4.188730399340268,success
Box_Position: [[1.48413012 0.71615901 0.69909509]]
actor_loss: tensor(5.8215, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7684, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6947, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-829.5302363198367, average reward:-4.1476511815991834,----
Box_Position: [[1.36915537 0.98549313 0.60546392]]
actor_loss: tensor(5.9569, device='cuda:0', grad_fn=<NegBackward>)
Step:24, total reward:-117.43061070441036, average reward:-4.892942112683765,success
Box_Position: [[1.42163621 1.03814088 0.46081986]]
actor_loss: tensor(6.1424, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-265.69705682010874, average reward:-5.109558785002092,success
Box_Position: [[1.54446491 0.85864462 0.67875725]]
actor_loss: tensor(5.7050, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9485, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1426, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.7213, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-832.4068585394081, average reward:-4.16203429269704,----
Box_Position: [[1.32067196 0.61144218 0.73722307]]
Step:18, total reward:-73.53638523395912, average reward:-4.085354735219951,success
Box_Position: [[1.31129921 0.69521775 0.69846506]]
Step:11, total reward:-62.526327142180094, average reward:-5.684211558380008,success
Box_Position: [[1.43861911 0.53892397 0.60221243]]
actor_loss: tensor(6.2065, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-167.30473399443912, average reward:-3.9834460474866455,success
Box_Position: [[1.44317602 0.62843882 0.51243157]]
actor_loss: tensor(6.5249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8542, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-531.1577875177685, average reward:-4.578946444118694,success
Box_Position: [[1.29627618 1.00692933 0.6529902 ]]
actor_loss: tensor(5.7640, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-144.0919449533222, average reward:-5.763677798132888,success
Box_Position: [[1.45620008 1.00788148 0.65433615]]
Step:31, total reward:-176.38216351905328, average reward:-5.689747210292041,success
Box_Position: [[1.2684871  0.63827014 0.53914046]]
actor_loss: tensor(6.0584, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-99.46006064735421, average reward:-6.630670709823614,success
Box_Position: [[1.35249021 0.85855996 0.47039462]]
Step:8, total reward:-45.48526699323225, average reward:-5.685658374154031,success
Box_Position: [[1.34256111 0.6697702  0.69888182]]
Step:17, total reward:-59.440750715684686, average reward:-3.4965147479814522,success
Box_Position: [[1.25788704 0.96740681 0.69497612]]
actor_loss: tensor(5.6155, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-168.57483962214565, average reward:-4.3224317851832215,success
Box_Position: [[1.44561159 0.85576165 0.72322967]]
Step:25, total reward:-116.28538496964441, average reward:-4.651415398785776,success
Box_Position: [[1.32951067 0.95509807 0.56122797]]
actor_loss: tensor(5.5149, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-130.17587727016956, average reward:-6.198851298579503,success
Box_Position: [[1.52548877 0.89703997 0.57636647]]
actor_loss: tensor(5.8650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5812, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1410, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3953, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1002.9099394589177, average reward:-5.014549697294589,success
Box_Position: [[1.28491725 0.79220634 0.74456479]]
actor_loss: tensor(5.7693, device='cuda:0', grad_fn=<NegBackward>)
Step:55, total reward:-267.29923768586247, average reward:-4.859986139742954,success
Box_Position: [[1.37311371 0.91300631 0.73202174]]
Step:13, total reward:-75.84354172380483, average reward:-5.834118594138833,success
Box_Position: [[1.42222323 0.75700231 0.60191094]]
actor_loss: tensor(5.7958, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-91.72362437926564, average reward:-5.095756909959203,success
Box_Position: [[1.3496441  1.12613184 0.6898941 ]]
Step:15, total reward:-77.78206511046473, average reward:-5.185471007364315,success
Box_Position: [[1.47374421 0.84644067 0.73344411]]
actor_loss: tensor(5.8902, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2089, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4343, device='cuda:0', grad_fn=<NegBackward>)
Step:168, total reward:-673.0038053347195, average reward:-4.005975031754282,success
Box_Position: [[1.50740721 0.89419039 0.67133268]]
actor_loss: tensor(5.5347, device='cuda:0', grad_fn=<NegBackward>)
Step:21, total reward:-94.97383580349312, average reward:-4.522563609690148,success
Box_Position: [[1.44744289 0.85172073 0.62200722]]
Step:12, total reward:-49.141005869793375, average reward:-4.095083822482781,success
Box_Position: [[1.45902431 0.92764198 0.58272799]]
actor_loss: tensor(6.7875, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7565, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6234, device='cuda:0', grad_fn=<NegBackward>)
Step:150, total reward:-792.4821338104091, average reward:-5.283214225402728,success
Box_Position: [[1.38490962 0.9575481  0.64929986]]
actor_loss: tensor(6.2513, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-342.3319925548261, average reward:-4.5043683230898175,success
Box_Position: [[1.52300834 0.77209843 0.59294654]]
actor_loss: tensor(6.0539, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8537, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5588, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1182, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-889.599928304223, average reward:-4.447999641521115,----
Box_Position: [[1.49641332 0.67747988 0.5898908 ]]
actor_loss: tensor(5.7650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0245, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2157, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5934, device='cuda:0', grad_fn=<NegBackward>)
Step:178, total reward:-767.9663181002678, average reward:-4.314417517417235,success
Box_Position: [[1.34633717 0.87319795 0.71005187]]
actor_loss: tensor(5.5806, device='cuda:0', grad_fn=<NegBackward>)
Step:31, total reward:-178.84759918340276, average reward:-5.769277393012993,success
Box_Position: [[1.37370592 0.72881043 0.57115541]]
Step:3, total reward:-13.052886879262694, average reward:-4.350962293087565,success
Box_Position: [[1.32787264 0.82028684 0.59085067]]

------------------Episode:2700------------------
Step:30, total reward:-154.3130694622414, average reward:-5.143768982074714,success
episode 2700, the accuracy is: 80%
Box_Position: [[1.5159031  0.63761311 0.59042253]]
actor_loss: tensor(5.8679, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1631, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3681, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8799, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-862.8107691959425, average reward:-4.314053845979712,----
Box_Position: [[1.52404026 0.9118004  0.46372222]]
actor_loss: tensor(6.3733, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2505, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8495, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1358.7715834344044, average reward:-6.793857917172022,----
Box_Position: [[1.32830848 0.62711363 0.50678237]]
actor_loss: tensor(5.9428, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-79.41981839018679, average reward:-4.963738649386674,success
Box_Position: [[1.25736708 0.74464739 0.63354806]]
Step:6, total reward:-41.722697863039514, average reward:-6.953782977173252,success
Box_Position: [[1.518272   0.62371084 0.62458698]]
actor_loss: tensor(5.6776, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.4468, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-533.3578633336443, average reward:-4.1027527948741875,success
Box_Position: [[1.39554018 1.0494675  0.69107655]]
actor_loss: tensor(6.3851, device='cuda:0', grad_fn=<NegBackward>)
Step:29, total reward:-134.86104980009782, average reward:-4.65038102758958,success
Box_Position: [[1.50413385 0.70936299 0.71870061]]
actor_loss: tensor(5.6734, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5086, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2321, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8353, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-823.8019831808485, average reward:-4.224625554773582,success
Box_Position: [[1.54122319 0.89536688 0.61676029]]
actor_loss: tensor(5.9161, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5797, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0840, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9532, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-981.5764588248737, average reward:-4.907882294124368,----
Box_Position: [[1.41490548 0.82028551 0.73925632]]
Step:32, total reward:-147.80332856493928, average reward:-4.618854017654352,success
Box_Position: [[1.4674411  0.75002076 0.66988737]]
actor_loss: tensor(6.0841, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-85.18180889571693, average reward:-4.259090444785846,success
Box_Position: [[1.42540897 0.97125312 0.61201595]]
Step:23, total reward:-121.10767317707358, average reward:-5.265551007698852,success
Box_Position: [[1.26276154 0.53500997 0.54988172]]
actor_loss: tensor(6.3796, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-42.45434016613715, average reward:-4.245434016613715,success
Box_Position: [[1.49555847 0.78336015 0.65057141]]
actor_loss: tensor(5.9452, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3193, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8501, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7554, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-856.2047308678011, average reward:-4.2810236543390054,----
Box_Position: [[1.26381575 0.8364684  0.56778634]]
actor_loss: tensor(6.0181, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-461.6362853733814, average reward:-5.017785710580233,success
Box_Position: [[1.31095936 0.69223931 0.74373732]]
actor_loss: tensor(6.9333, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-60.498284498019025, average reward:-3.3610158054455015,success
Box_Position: [[1.25022192 0.59237133 0.70805325]]
actor_loss: tensor(5.5021, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-181.8633614874173, average reward:-3.7888200309878606,success
Box_Position: [[1.30508924 0.52845787 0.57665568]]
Step:20, total reward:-86.39292217892698, average reward:-4.319646108946349,success
Box_Position: [[1.3812481  1.12517923 0.50160889]]
actor_loss: tensor(5.8589, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-207.61735859980578, average reward:-4.718576331813768,success
Box_Position: [[1.50260547 0.98756583 0.59922286]]
actor_loss: tensor(5.8027, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-234.72798778788137, average reward:-6.177052310207404,success
Box_Position: [[1.28000057 0.70961606 0.64776818]]
actor_loss: tensor(6.0928, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-238.9351532112245, average reward:-4.594906792523548,success
Box_Position: [[1.52095952 0.96866738 0.73158554]]
Step:34, total reward:-164.90719586348553, average reward:-4.850211643043692,success
Box_Position: [[1.39455721 0.96821205 0.53394692]]
actor_loss: tensor(6.2190, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7812, device='cuda:0', grad_fn=<NegBackward>)
Step:79, total reward:-451.1560206480776, average reward:-5.710835704406045,success
Box_Position: [[1.34688029 1.08220683 0.65555033]]
actor_loss: tensor(5.6687, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-202.59791055699515, average reward:-4.604497967204435,success
Box_Position: [[1.37055852 0.60402469 0.61580247]]
actor_loss: tensor(5.6313, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7777, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6289, device='cuda:0', grad_fn=<NegBackward>)
Step:148, total reward:-547.8689611267708, average reward:-3.701817304910614,success
Box_Position: [[1.39435626 0.89333548 0.55048282]]
Step:10, total reward:-75.16102449226992, average reward:-7.516102449226992,success
Box_Position: [[1.32553528 0.99661415 0.53335293]]
Step:20, total reward:-160.96953507964483, average reward:-8.048476753982241,success
Box_Position: [[1.5169464  1.00753294 0.7331604 ]]
actor_loss: tensor(5.5357, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-101.42690758297951, average reward:-5.634828199054417,success
Box_Position: [[1.4187686  0.56399914 0.4645811 ]]
actor_loss: tensor(6.1624, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2550, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4333, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0198, device='cuda:0', grad_fn=<NegBackward>)
Step:195, total reward:-1011.5361089044982, average reward:-5.187364661048709,success
Box_Position: [[1.32127284 0.92786626 0.58945031]]
Step:2, total reward:-21.01349647171382, average reward:-10.50674823585691,success
Box_Position: [[1.26582295 0.76636931 0.55201957]]
Step:20, total reward:-116.50043161851451, average reward:-5.825021580925726,success
Box_Position: [[1.31817784 0.89771071 0.67787465]]
actor_loss: tensor(5.7684, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-156.91990818772072, average reward:-6.035381084143105,success
Box_Position: [[1.41870431 1.10800752 0.62058388]]
Step:12, total reward:-61.345626606962064, average reward:-5.112135550580172,success
Box_Position: [[1.29671592 0.74544132 0.72622687]]
Step:11, total reward:-52.8401921472707, average reward:-4.803653831570063,success
Box_Position: [[1.42458255 0.88137642 0.52479431]]
Step:9, total reward:-59.30490754541192, average reward:-6.589434171712436,success
Box_Position: [[1.31441165 0.86418676 0.7262442 ]]
actor_loss: tensor(5.6888, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-253.15572127746026, average reward:-6.174529787255128,success
Box_Position: [[1.37248381 0.70096204 0.68540719]]
Step:16, total reward:-63.00941308793231, average reward:-3.9380883179957693,success
Box_Position: [[1.3595201  0.43204691 0.53453456]]
actor_loss: tensor(5.8895, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-205.62009121100164, average reward:-4.781862586302363,success
Box_Position: [[1.36640712 0.75572949 0.59925389]]
Step:4, total reward:-13.945433599096386, average reward:-3.4863583997740966,success
Box_Position: [[1.51127389 0.41192729 0.64197248]]
actor_loss: tensor(5.7018, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-239.21759617827223, average reward:-4.429955484782819,success
Box_Position: [[1.36710221 1.01619008 0.46922452]]
actor_loss: tensor(5.6867, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9977, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-335.3380339122132, average reward:-5.322825935114495,success
Box_Position: [[1.30809807 0.95041805 0.55802591]]
Step:13, total reward:-85.24140368190885, average reward:-6.557031052454527,success
Box_Position: [[1.25739253 0.67525976 0.5416681 ]]
Step:6, total reward:-37.75843647363114, average reward:-6.2930727456051905,success
Box_Position: [[1.48267173 0.82608591 0.53845554]]
actor_loss: tensor(5.4917, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6364, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-429.62233186660694, average reward:-4.995608510076825,success
Box_Position: [[1.39913353 0.55439134 0.54041453]]
actor_loss: tensor(5.8081, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-138.1932888819141, average reward:-3.7349537535652457,success
Box_Position: [[1.49643338 0.86797385 0.58054446]]
actor_loss: tensor(6.0182, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.3448, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8476, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3942, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-892.8974893076414, average reward:-4.464487446538207,----
Box_Position: [[1.53777801 0.68399509 0.74172438]]
actor_loss: tensor(5.8169, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7436, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9141, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6063, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-922.4690828068626, average reward:-4.612345414034313,----
Box_Position: [[1.4914856  0.52591695 0.61194507]]
Step:27, total reward:-106.93437571398702, average reward:-3.9605324338513714,success
Box_Position: [[1.50734451 0.68027156 0.70277595]]
actor_loss: tensor(5.5158, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.0487, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9885, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9455, device='cuda:0', grad_fn=<NegBackward>)
Step:192, total reward:-787.1617713777237, average reward:-4.09980089259231,success
Box_Position: [[1.29343411 0.8694103  0.51605572]]
Step:23, total reward:-135.74677623584142, average reward:-5.90203374938441,success
Box_Position: [[1.33002893 1.07061311 0.55060223]]

------------------Episode:2750------------------
actor_loss: tensor(5.4450, device='cuda:0', grad_fn=<NegBackward>)
Step:52, total reward:-307.41222938952495, average reward:-5.911773642106249,success
Box_Position: [[1.43431795 0.85862934 0.55265886]]
actor_loss: tensor(5.6424, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5911, device='cuda:0', grad_fn=<NegBackward>)
Step:63, total reward:-315.14196054263476, average reward:-5.0022533419465836,success
Box_Position: [[1.53949479 1.01671539 0.49411004]]
actor_loss: tensor(5.6900, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.5282, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1337, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6894, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1050.3564615664075, average reward:-5.251782307832038,----
Box_Position: [[1.27849153 0.90762701 0.6180984 ]]
Step:33, total reward:-164.9159639438914, average reward:-4.9974534528451935,success
Box_Position: [[1.26025999 0.62834467 0.53581005]]
Step:4, total reward:-18.786816787127005, average reward:-4.696704196781751,success
Box_Position: [[1.4949638  0.5948737  0.58698132]]
actor_loss: tensor(5.9582, device='cuda:0', grad_fn=<NegBackward>)
Step:25, total reward:-98.61456416452606, average reward:-3.944582566581042,success
Box_Position: [[1.27365737 0.98466212 0.68257525]]
actor_loss: tensor(5.8355, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-177.78140645797524, average reward:-4.678458064683559,success
Box_Position: [[1.28037933 0.66244927 0.45472035]]
Step:11, total reward:-59.81724517037442, average reward:-5.437931379124947,success
Box_Position: [[1.3735651  0.64943319 0.72365967]]
Step:21, total reward:-80.60157914617926, average reward:-3.8381704355323456,success
Box_Position: [[1.26214274 1.00506751 0.55687447]]
actor_loss: tensor(6.1662, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-216.19867613591265, average reward:-4.323973522718253,success
Box_Position: [[1.50990482 0.65442181 0.68075282]]
actor_loss: tensor(5.7301, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6084, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.2564, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3277, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-816.8147779934447, average reward:-4.0840738899672235,----
Box_Position: [[1.35265874 0.53131967 0.56623801]]
actor_loss: tensor(6.1762, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-62.83815640725791, average reward:-3.4910086892921064,success
Box_Position: [[1.53950963 0.81544146 0.52397907]]
actor_loss: tensor(5.1750, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-226.5273249346246, average reward:-4.924507063796187,success
Box_Position: [[1.51679849 0.70013577 0.66045165]]
Step:34, total reward:-148.58395672902125, average reward:-4.370116374382978,success
Box_Position: [[1.30949775 0.99495547 0.45582387]]
actor_loss: tensor(5.7059, device='cuda:0', grad_fn=<NegBackward>)
Step:14, total reward:-95.92108724300444, average reward:-6.851506231643174,success
Box_Position: [[1.42571589 0.62487919 0.6262379 ]]
Step:16, total reward:-72.1946602443853, average reward:-4.5121662652740815,success
Box_Position: [[1.39874845 0.9414851  0.4548302 ]]
Step:16, total reward:-86.24027470493743, average reward:-5.39001716905859,success
Box_Position: [[1.36881062 1.08690759 0.45613552]]
Step:10, total reward:-68.90980363611632, average reward:-6.890980363611632,success
Box_Position: [[1.38611909 0.6785285  0.64638991]]
actor_loss: tensor(5.5538, device='cuda:0', grad_fn=<NegBackward>)
Step:6, total reward:-18.805002610847307, average reward:-3.1341671018078845,success
Box_Position: [[1.30280559 0.94611769 0.64442332]]
Step:33, total reward:-185.34920136396318, average reward:-5.616642465574642,success
Box_Position: [[1.43647521 0.75251037 0.70298107]]
actor_loss: tensor(5.6584, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-164.22706328323108, average reward:-4.321764823242923,success
Box_Position: [[1.30502865 0.63932075 0.60329365]]
Step:4, total reward:-11.415953014356319, average reward:-2.8539882535890797,success
Box_Position: [[1.40190852 1.12974243 0.71518932]]
actor_loss: tensor(6.0657, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-146.96809408541645, average reward:-4.898936469513882,success
Box_Position: [[1.35255106 0.87718555 0.6302264 ]]
Step:19, total reward:-88.98846960294574, average reward:-4.683603663312934,success
Box_Position: [[1.31049986 0.87746786 0.52794659]]
Step:8, total reward:-45.442465436984016, average reward:-5.680308179623002,success
Box_Position: [[1.32118974 0.74300675 0.51432861]]
actor_loss: tensor(5.8275, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-227.10459551883753, average reward:-4.937056424322555,success
Box_Position: [[1.52097984 0.66179829 0.57985349]]
actor_loss: tensor(6.0928, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3820, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8923, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.9111, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-868.1491373919336, average reward:-4.340745686959668,----
Box_Position: [[1.28258181 0.90334752 0.50448232]]
actor_loss: tensor(5.9742, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-324.7976144744195, average reward:-6.766616968217073,success
Box_Position: [[1.43016294 0.71048081 0.71698013]]
actor_loss: tensor(5.1769, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-189.15877828689966, average reward:-4.503780435402373,success
Box_Position: [[1.49801063 0.8930746  0.6106404 ]]
Step:23, total reward:-121.30867521510704, average reward:-5.274290226743784,success
Box_Position: [[1.32773556 0.67785565 0.59586804]]
actor_loss: tensor(5.4002, device='cuda:0', grad_fn=<NegBackward>)
Step:8, total reward:-28.059965739391124, average reward:-3.5074957174238905,success
Box_Position: [[1.39341825 0.77376372 0.58679887]]
Step:6, total reward:-29.663952070456446, average reward:-4.943992011742741,success
Box_Position: [[1.25652207 1.14620236 0.50895721]]
Step:15, total reward:-84.70055041917776, average reward:-5.646703361278517,success
Box_Position: [[1.41375303 0.89554977 0.46969421]]
Step:20, total reward:-136.1260255424072, average reward:-6.80630127712036,success
Box_Position: [[1.3753387  0.90865028 0.68571853]]
actor_loss: tensor(5.9465, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-88.2917695926639, average reward:-5.88611797284426,success
Box_Position: [[1.5274707  0.94676329 0.59165683]]
actor_loss: tensor(5.3605, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6098, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3703, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4116, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1032.1038693021655, average reward:-5.160519346510828,----
Box_Position: [[1.3036773  0.98283401 0.6057359 ]]
Step:21, total reward:-146.7381588350352, average reward:-6.987531373096914,success
Box_Position: [[1.25781713 0.84907841 0.55932097]]
actor_loss: tensor(5.7578, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-355.33447212193676, average reward:-5.303499583909503,success
Box_Position: [[1.48768543 0.78877392 0.68243064]]
actor_loss: tensor(5.2163, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-118.66580773016464, average reward:-4.564069528083255,success
Box_Position: [[1.31234173 0.8158952  0.46635425]]
Step:13, total reward:-86.32934084449496, average reward:-6.6407185264996125,success
Box_Position: [[1.32590388 0.57003788 0.62790549]]
Step:4, total reward:-11.78482768099167, average reward:-2.9462069202479175,success
Box_Position: [[1.30478269 0.60026214 0.59861087]]
Step:6, total reward:-19.396740812828575, average reward:-3.2327901354714292,success
Box_Position: [[1.48286575 0.84400285 0.6401997 ]]
actor_loss: tensor(5.8068, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-177.02194127070666, average reward:-5.531935664709583,success
Box_Position: [[1.53764027 0.90179876 0.66693046]]
actor_loss: tensor(5.2283, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5456, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-452.73551222339387, average reward:-4.2311730114335875,success
Box_Position: [[1.53831282 0.88131431 0.50867518]]
actor_loss: tensor(5.3498, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6903, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3529, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1691, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1119.042219284462, average reward:-5.595211096422309,----
Box_Position: [[1.36804535 0.76220796 0.67160459]]
actor_loss: tensor(5.6809, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-82.66263520878135, average reward:-4.133131760439068,success
Box_Position: [[1.37303644 0.72926724 0.63659387]]
Step:12, total reward:-49.46292455737324, average reward:-4.121910379781103,success
Box_Position: [[1.26059878 1.03360505 0.68463952]]
Step:13, total reward:-79.48541851183934, average reward:-6.11426296244918,success
Box_Position: [[1.4404132  0.80055365 0.46481256]]
actor_loss: tensor(5.6945, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8752, device='cuda:0', grad_fn=<NegBackward>)
Step:94, total reward:-542.2762725800565, average reward:-5.768896516809111,success
Box_Position: [[1.51422939 0.90886048 0.74673848]]
actor_loss: tensor(5.4114, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5056, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-396.7973238776726, average reward:-4.313014389974702,success
Box_Position: [[1.29131575 0.63583053 0.66669104]]

------------------Episode:2800------------------
Step:3, total reward:-9.793065427449651, average reward:-3.264355142483217,success
episode 2800, the accuracy is: 89%
Box_Position: [[1.39869376 0.62534935 0.46707801]]
actor_loss: tensor(5.1726, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-198.3924719383472, average reward:-5.086986459957621,success
Box_Position: [[1.25514579 0.69506058 0.57709027]]
Step:1, total reward:-4.434966603590355, average reward:-4.434966603590355,success
Box_Position: [[1.25787029 0.71447779 0.59289729]]
actor_loss: tensor(5.3520, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-374.50263141477427, average reward:-4.681282892684679,success
Box_Position: [[1.43112787 0.73191697 0.515016  ]]
actor_loss: tensor(5.3085, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-132.42257489144356, average reward:-4.904539810794206,success
Box_Position: [[1.35228255 0.81324432 0.65540274]]
Step:7, total reward:-40.871844702585626, average reward:-5.8388349575122325,success
Box_Position: [[1.51533921 1.00828736 0.50967571]]
actor_loss: tensor(5.2172, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.7325, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8253, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.8451, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1244.4615534011339, average reward:-6.2223077670056695,----
Box_Position: [[1.36272541 0.72021529 0.61441684]]
Step:13, total reward:-56.043304442433566, average reward:-4.311023418648736,success
Box_Position: [[1.42446885 0.91499748 0.50703302]]
actor_loss: tensor(5.3416, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-112.11894909576203, average reward:-6.228830505320113,success
Box_Position: [[1.52518199 0.66781515 0.47288165]]
actor_loss: tensor(5.3107, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6850, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4170, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6285, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1054.813236524879, average reward:-5.274066182624394,----
Box_Position: [[1.27409929 0.72290984 0.73435566]]
Step:20, total reward:-90.23828533674478, average reward:-4.511914266837239,success
Box_Position: [[1.48020253 0.53395395 0.69100772]]
actor_loss: tensor(5.3009, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1020, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4403, device='cuda:0', grad_fn=<NegBackward>)
Step:132, total reward:-513.4416123782108, average reward:-3.8897091846834155,success
Box_Position: [[1.50444582 0.72779273 0.64671091]]
actor_loss: tensor(5.7981, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(6.1092, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5664, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2204, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-770.8658202815571, average reward:-3.8543291014077856,----
Box_Position: [[1.53961488 1.03193397 0.70868324]]
actor_loss: tensor(5.0597, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1732, device='cuda:0', grad_fn=<NegBackward>)
Step:130, total reward:-630.2645219799603, average reward:-4.848188630615079,success
Box_Position: [[1.42720575 0.62160828 0.47034814]]
actor_loss: tensor(5.8465, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-58.67264840352859, average reward:-3.9115098935685726,success
Box_Position: [[1.36089815 0.58789534 0.60350341]]
Step:23, total reward:-88.7686312696935, average reward:-3.8595057073779784,success
Box_Position: [[1.2558553  0.81501352 0.70256836]]
actor_loss: tensor(5.4732, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-146.2746424892546, average reward:-5.224094374616236,success
Box_Position: [[1.40416238 0.87466832 0.64390395]]
Step:47, total reward:-199.4107853508833, average reward:-4.24278266704007,success
Box_Position: [[1.42501665 0.85134304 0.68637282]]
actor_loss: tensor(5.3702, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-24.63508660823265, average reward:-4.92701732164653,success
Box_Position: [[1.44616404 0.50690807 0.69365646]]
Step:7, total reward:-29.64176489564067, average reward:-4.234537842234381,success
Box_Position: [[1.44663171 0.90872832 0.6057545 ]]
Step:24, total reward:-145.56279193964048, average reward:-6.065116330818353,success
Box_Position: [[1.36784653 0.89345785 0.6101731 ]]
Step:3, total reward:-12.6813430748607, average reward:-4.2271143582869,success
Box_Position: [[1.36670753 0.99969312 0.4533571 ]]
actor_loss: tensor(5.0954, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-181.19013666862034, average reward:-6.039671222287344,success
Box_Position: [[1.25164518 0.68119036 0.71635959]]
Step:1, total reward:-3.1552642312767913, average reward:-3.1552642312767913,success
Box_Position: [[1.37303535 0.85019372 0.47644776]]
Step:12, total reward:-80.55467448789146, average reward:-6.7128895406576214,success
Box_Position: [[1.46974444 0.83383455 0.60778415]]
Step:16, total reward:-97.10870970052912, average reward:-6.06929435628307,success
Box_Position: [[1.29715748 0.97046442 0.74612305]]
actor_loss: tensor(5.6033, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-18.742900350917477, average reward:-4.685725087729369,success
Box_Position: [[1.25847244 0.82225709 0.61669573]]
Step:13, total reward:-72.93906688605725, average reward:-5.610697452773635,success
Box_Position: [[1.49504935 0.66779081 0.70712987]]
Step:13, total reward:-55.332759045038834, average reward:-4.256366080387602,success
Box_Position: [[1.48089921 1.03808995 0.66962579]]
actor_loss: tensor(5.6301, device='cuda:0', grad_fn=<NegBackward>)
Step:57, total reward:-282.2893191932728, average reward:-4.952444196373206,success
Box_Position: [[1.41096174 0.64647791 0.72380488]]
Step:7, total reward:-26.667239539113037, average reward:-3.8096056484447196,success
Box_Position: [[1.27282939 1.0479836  0.58954147]]
Step:9, total reward:-43.981409529475165, average reward:-4.886823281052796,success
Box_Position: [[1.44839665 0.50814949 0.66553783]]
actor_loss: tensor(5.4864, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-53.082237730849336, average reward:-3.538815848723289,success
Box_Position: [[1.31250956 1.00333434 0.68922453]]
Step:4, total reward:-17.269630436966096, average reward:-4.317407609241524,success
Box_Position: [[1.38835533 0.71747751 0.62985851]]
Step:9, total reward:-43.15956138475663, average reward:-4.795506820528514,success
Box_Position: [[1.26495973 0.9569679  0.49487447]]
actor_loss: tensor(5.3912, device='cuda:0', grad_fn=<NegBackward>)
Step:44, total reward:-195.58852479003704, average reward:-4.4451937452281145,success
Box_Position: [[1.37952128 0.61180078 0.47951534]]
Step:14, total reward:-93.20209411643013, average reward:-6.657292436887866,success
Box_Position: [[1.40161961 0.73989673 0.59018239]]
actor_loss: tensor(5.4469, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-82.14609108016255, average reward:-4.563671726675697,success
Box_Position: [[1.36116487 0.91429242 0.59870732]]
Step:11, total reward:-67.98068333384654, average reward:-6.180062121258777,success
Box_Position: [[1.51364407 0.65589388 0.67918708]]
Step:34, total reward:-125.05495826830082, average reward:-3.6780870078912007,success
Box_Position: [[1.53094844 0.95190494 0.59469739]]
actor_loss: tensor(5.5940, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-220.05842100585505, average reward:-5.3672785611184155,success
Box_Position: [[1.53979243 0.84798185 0.55223733]]
actor_loss: tensor(5.6267, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-176.9482918620191, average reward:-4.782386266541057,success
Box_Position: [[1.5315201  0.74132173 0.58065826]]
actor_loss: tensor(5.6340, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4991, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-557.508206367116, average reward:-4.806105227302725,success
Box_Position: [[1.48415572 0.80664106 0.65282581]]
actor_loss: tensor(5.6768, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-72.66542577530893, average reward:-6.055452147942411,success
Box_Position: [[1.41560681 0.7092752  0.73752839]]
Step:11, total reward:-36.08692275151278, average reward:-3.2806293410466165,success
Box_Position: [[1.53334968 1.00139163 0.51333075]]
actor_loss: tensor(5.2815, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6022, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5434, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1323.8608684270744, average reward:-6.619304342135372,----
Box_Position: [[1.43321481 0.86102423 0.50928359]]
Step:24, total reward:-133.24002543214363, average reward:-5.551667726339318,success
Box_Position: [[1.36247056 0.92036923 0.59079743]]
Step:5, total reward:-40.53324162072731, average reward:-8.106648324145462,success
Box_Position: [[1.47986023 0.80130104 0.5845173 ]]
actor_loss: tensor(5.6826, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-97.10895099427, average reward:-4.8554475497135,success
Box_Position: [[1.44961614 0.72901683 0.57654484]]
Step:18, total reward:-82.22645206832794, average reward:-4.568136226018219,success
Box_Position: [[1.37485549 0.89727433 0.59913635]]

------------------Episode:2850------------------
Step:12, total reward:-84.43808623102046, average reward:-7.036507185918372,success
Box_Position: [[1.47562064 0.44325764 0.4671855 ]]
actor_loss: tensor(5.1909, device='cuda:0', grad_fn=<NegBackward>)
Step:11, total reward:-56.43258063660395, average reward:-5.130234603327632,success
Box_Position: [[1.40252802 0.90695181 0.55339632]]
Step:5, total reward:-22.75589351180746, average reward:-4.551178702361492,success
Box_Position: [[1.42765196 1.12845034 0.68257426]]
actor_loss: tensor(6.0053, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4670, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.6740, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2760, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1053.3681417393907, average reward:-5.266840708696954,----
Box_Position: [[1.53013921 1.06816229 0.7153079 ]]
actor_loss: tensor(5.2173, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.5470, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8947, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4063, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1066.7293615206372, average reward:-5.333646807603186,----
Box_Position: [[1.42132613 0.66188817 0.56439773]]
Step:25, total reward:-116.15024066754064, average reward:-4.646009626701626,success
Box_Position: [[1.53262204 1.00449464 0.71096437]]
Step:13, total reward:-74.28074392807493, average reward:-5.713903379082686,success
Box_Position: [[1.52687404 0.90125408 0.56502218]]
actor_loss: tensor(5.2418, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2878, device='cuda:0', grad_fn=<NegBackward>)
Step:74, total reward:-405.37162680388684, average reward:-5.477994956809281,success
Box_Position: [[1.33407476 0.8745483  0.67385366]]
actor_loss: tensor(5.1602, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-263.64886323214125, average reward:-4.056136357417557,success
Box_Position: [[1.39487729 0.48865078 0.60610289]]
Step:9, total reward:-32.51759374185054, average reward:-3.613065971316727,success
Box_Position: [[1.5086002  0.64132835 0.53812565]]
actor_loss: tensor(4.9250, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4769, device='cuda:0', grad_fn=<NegBackward>)
Step:70, total reward:-283.7073145038992, average reward:-4.052961635769989,success
Box_Position: [[1.36920821 0.78635739 0.71020401]]
Step:17, total reward:-66.88697316948804, average reward:-3.934527833499297,success
Box_Position: [[1.42014208 1.02371322 0.64015468]]
actor_loss: tensor(5.1160, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-213.2224365282237, average reward:-5.2005472323957,success
Box_Position: [[1.5010954  0.4634408  0.72186615]]
actor_loss: tensor(5.1194, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0071, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-397.4479956480008, average reward:-3.7144672490467365,success
Box_Position: [[1.52269757 0.65153166 0.6207851 ]]
actor_loss: tensor(5.2927, device='cuda:0', grad_fn=<NegBackward>)
Step:61, total reward:-245.6938484105658, average reward:-4.027768006730587,success
Box_Position: [[1.26799428 0.68886686 0.7114103 ]]
actor_loss: tensor(5.4776, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-181.5677448547969, average reward:-4.034838774551043,success
Box_Position: [[1.29170218 0.80081271 0.60271496]]
actor_loss: tensor(5.5880, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3760, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3884, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1209, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1040.7433569641985, average reward:-5.203716784820992,----
Box_Position: [[1.35219027 0.58288742 0.74991367]]
Step:2, total reward:-10.13736663224466, average reward:-5.06868331612233,success
Box_Position: [[1.39741457 0.83665248 0.70685947]]
actor_loss: tensor(4.5252, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8374, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-291.2694348453071, average reward:-4.283374041842752,success
Box_Position: [[1.46092331 0.4806615  0.63895978]]
Step:26, total reward:-104.62379392553886, average reward:-4.023992074059187,success
Box_Position: [[1.38787568 0.82257171 0.47278016]]
actor_loss: tensor(4.9067, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-138.4389195598283, average reward:-6.921945977991415,success
Box_Position: [[1.44006697 0.67629515 0.68527103]]
Step:36, total reward:-148.89856570945147, average reward:-4.136071269706985,success
Box_Position: [[1.51786512 0.58546882 0.50286709]]
actor_loss: tensor(4.8580, device='cuda:0', grad_fn=<NegBackward>)
Step:49, total reward:-263.2154711719177, average reward:-5.371744309630974,success
Box_Position: [[1.51249269 0.72645182 0.67816128]]
actor_loss: tensor(5.7991, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0738, device='cuda:0', grad_fn=<NegBackward>)
Step:77, total reward:-336.68501462201425, average reward:-4.372532657428756,success
Box_Position: [[1.45843101 0.93299467 0.54159028]]
Step:22, total reward:-95.23734934915866, average reward:-4.328970424961757,success
Box_Position: [[1.34923306 0.92248319 0.66482694]]
actor_loss: tensor(5.3789, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1471, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1577, device='cuda:0', grad_fn=<NegBackward>)
Step:160, total reward:-746.5343410605578, average reward:-4.6658396316284865,success
Box_Position: [[1.54605917 0.78837982 0.72318065]]
actor_loss: tensor(4.8713, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.3899, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.4773, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9535, device='cuda:0', grad_fn=<NegBackward>)
Step:189, total reward:-823.3329063141413, average reward:-4.356258763566885,success
Box_Position: [[1.30136927 0.7391096  0.47351404]]
Step:3, total reward:-20.380931296276408, average reward:-6.793643765425469,success
Box_Position: [[1.26646335 0.5099919  0.47783156]]
Step:9, total reward:-47.055101479990356, average reward:-5.228344608887817,success
Box_Position: [[1.46195812 0.72794798 0.7161929 ]]
actor_loss: tensor(4.8562, device='cuda:0', grad_fn=<NegBackward>)
Step:6, total reward:-30.163330751603475, average reward:-5.027221791933912,success
Box_Position: [[1.46538475 0.59729013 0.50619598]]
Step:39, total reward:-209.6870618853397, average reward:-5.3765913303933255,success
Box_Position: [[1.2656597  0.74628834 0.63962704]]
actor_loss: tensor(5.3450, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-99.8987022804124, average reward:-4.540850103655109,success
Box_Position: [[1.36917611 0.74765111 0.72586211]]
Step:17, total reward:-69.61910646201615, average reward:-4.095241556589185,success
Box_Position: [[1.37930979 0.79304354 0.62858337]]
Step:15, total reward:-69.1972294694215, average reward:-4.6131486312947665,success
Box_Position: [[1.48073769 0.71348861 0.62122751]]
actor_loss: tensor(5.3902, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-150.16825800645404, average reward:-4.171340500179279,success
Box_Position: [[1.39057627 0.70770553 0.74834052]]
actor_loss: tensor(5.5348, device='cuda:0', grad_fn=<NegBackward>)
Step:20, total reward:-78.3394139150384, average reward:-3.91697069575192,success
Box_Position: [[1.5360673  1.03843249 0.73784006]]
actor_loss: tensor(4.9320, device='cuda:0', grad_fn=<NegBackward>)
Step:54, total reward:-238.3280604540826, average reward:-4.41348260100153,success
Box_Position: [[1.33067775 0.70427303 0.49606012]]
Step:5, total reward:-23.025370672732524, average reward:-4.605074134546505,success
Box_Position: [[1.51586861 1.02204745 0.73976686]]
Step:34, total reward:-132.31727011943127, average reward:-3.8916844152773904,success
Box_Position: [[1.40661    0.53857983 0.4960733 ]]
actor_loss: tensor(4.9546, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-208.86753906060423, average reward:-5.221688476515106,success
Box_Position: [[1.32803267 1.18023026 0.49069037]]
actor_loss: tensor(4.9112, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-176.29764898450182, average reward:-5.509301530765682,success
Box_Position: [[1.38497529 0.54697313 0.48618195]]
Step:18, total reward:-82.92510770152494, average reward:-4.606950427862497,success
Box_Position: [[1.27864393 0.78306064 0.61290926]]
actor_loss: tensor(4.4188, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8253, device='cuda:0', grad_fn=<NegBackward>)
Step:68, total reward:-352.86512928300465, average reward:-5.189193077691245,success
Box_Position: [[1.30591425 0.86145197 0.63270649]]
Step:36, total reward:-189.18803802768778, average reward:-5.255223278546882,success
Box_Position: [[1.41839975 0.98004667 0.60518688]]
actor_loss: tensor(4.8557, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-111.53446018980138, average reward:-6.970903761862586,success
Box_Position: [[1.47080272 0.89460978 0.51218964]]
actor_loss: tensor(5.1938, device='cuda:0', grad_fn=<NegBackward>)
Step:67, total reward:-369.0346055789165, average reward:-5.507979187745023,success
Box_Position: [[1.28670741 0.7017539  0.537879  ]]
Step:13, total reward:-82.71634714223642, average reward:-6.362795934018186,success
Box_Position: [[1.52307841 0.77195229 0.59683455]]
actor_loss: tensor(5.0264, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7407, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-414.95743645133655, average reward:-4.0287129752556945,success
Box_Position: [[1.5033011  0.73436517 0.70914743]]
actor_loss: tensor(5.1566, device='cuda:0', grad_fn=<NegBackward>)
Step:46, total reward:-169.487067364405, average reward:-3.6845014644435867,success
Box_Position: [[1.40405768 0.95231438 0.59445457]]
Step:11, total reward:-67.44136784560035, average reward:-6.131033440509123,success
Box_Position: [[1.44046567 0.5085274  0.56891595]]

------------------Episode:2900------------------
actor_loss: tensor(5.3081, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-185.66005868029285, average reward:-3.8679178891727677,success
episode 2900, the accuracy is: 93%
Box_Position: [[1.2557594  0.93938843 0.53163707]]
actor_loss: tensor(5.4628, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-234.06739106545908, average reward:-5.708960757694124,success
Box_Position: [[1.50484584 0.56946772 0.65524448]]
actor_loss: tensor(5.0546, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8147, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3901, device='cuda:0', grad_fn=<NegBackward>)
Step:116, total reward:-434.6342572313338, average reward:-3.746847045097705,success
Box_Position: [[1.43127629 0.77187398 0.62746419]]
Step:12, total reward:-50.34581817219797, average reward:-4.195484847683164,success
Box_Position: [[1.30190094 0.60457314 0.54927962]]
Step:17, total reward:-61.48163036558162, average reward:-3.6165664920930367,success
Box_Position: [[1.40407188 0.50909814 0.58511568]]
actor_loss: tensor(5.3499, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-105.93349914668728, average reward:-3.923462931358788,success
Box_Position: [[1.30113726 1.10871956 0.69011617]]
Step:32, total reward:-137.80607431232494, average reward:-4.306439822260154,success
Box_Position: [[1.2568905  0.83603519 0.61611951]]
actor_loss: tensor(4.8308, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9709, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9208, device='cuda:0', grad_fn=<NegBackward>)
Step:142, total reward:-704.0382343991427, average reward:-4.95801573520523,success
Box_Position: [[1.31710536 0.82462848 0.59564779]]
Step:6, total reward:-34.72101167737888, average reward:-5.786835279563147,success
Box_Position: [[1.28864945 0.75203535 0.60557867]]
actor_loss: tensor(5.1208, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6695, device='cuda:0', grad_fn=<NegBackward>)
Step:112, total reward:-542.9628499250236, average reward:-4.847882588616282,success
Box_Position: [[1.3546263  0.83589223 0.62129483]]
actor_loss: tensor(4.8615, device='cuda:0', grad_fn=<NegBackward>)
Step:5, total reward:-37.12382968746078, average reward:-7.424765937492156,success
Box_Position: [[1.44565069 0.7412464  0.56692081]]
Step:21, total reward:-89.45722520557776, average reward:-4.259867866932274,success
Box_Position: [[1.37976322 0.81633858 0.66120087]]
Step:3, total reward:-9.843161243569867, average reward:-3.2810537478566224,success
Box_Position: [[1.293457   1.02399291 0.45890881]]
actor_loss: tensor(5.1744, device='cuda:0', grad_fn=<NegBackward>)
Step:71, total reward:-398.93648847471655, average reward:-5.618823781334036,success
Box_Position: [[1.36537995 0.59804977 0.55462718]]
actor_loss: tensor(5.1307, device='cuda:0', grad_fn=<NegBackward>)
Step:33, total reward:-118.22969800224294, average reward:-3.582718121280089,success
Box_Position: [[1.5019452  0.89802863 0.55464433]]
actor_loss: tensor(5.1572, device='cuda:0', grad_fn=<NegBackward>)
Step:23, total reward:-117.70352716215832, average reward:-5.117544659224275,success
Box_Position: [[1.31526166 0.68022717 0.63007305]]
Step:9, total reward:-37.169845790800835, average reward:-4.129982865644537,success
Box_Position: [[1.30208656 0.7042257  0.56803198]]
Step:25, total reward:-116.66034938373251, average reward:-4.6664139753493,success
Box_Position: [[1.39445509 0.9827224  0.70861168]]
Step:5, total reward:-38.749738387937384, average reward:-7.7499476775874765,success
Box_Position: [[1.41684909 0.73945675 0.55591522]]
actor_loss: tensor(4.7856, device='cuda:0', grad_fn=<NegBackward>)
Step:41, total reward:-164.15602169448897, average reward:-4.003805407182658,success
Box_Position: [[1.47220906 0.46952696 0.63462696]]
actor_loss: tensor(4.9618, device='cuda:0', grad_fn=<NegBackward>)
Step:22, total reward:-79.96316365163695, average reward:-3.6346892568925884,success
Box_Position: [[1.52762479 0.76596635 0.58647721]]
Step:10, total reward:-63.92222971417551, average reward:-6.392222971417551,success
Box_Position: [[1.39867823 0.78080791 0.73676933]]
Step:21, total reward:-83.36978788805638, average reward:-3.969989899431256,success
Box_Position: [[1.37669492 1.05239588 0.5022221 ]]
actor_loss: tensor(5.2555, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5430, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6722, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6699, device='cuda:0', grad_fn=<NegBackward>)
Step:165, total reward:-805.8620286184439, average reward:-4.884012294657236,success
Box_Position: [[1.51132255 0.82261658 0.69938058]]
actor_loss: tensor(4.7483, device='cuda:0', grad_fn=<NegBackward>)
Step:86, total reward:-375.6088894229395, average reward:-4.367545225848134,success
Box_Position: [[1.35984489 0.75447942 0.73977467]]
Step:3, total reward:-9.572877343502523, average reward:-3.1909591145008407,success
Box_Position: [[1.49519963 0.71958995 0.50657491]]
actor_loss: tensor(4.7469, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6487, device='cuda:0', grad_fn=<NegBackward>)
Step:65, total reward:-279.38924208342735, average reward:-4.298296032052728,success
Box_Position: [[1.52040851 0.54704596 0.72127756]]
Step:16, total reward:-72.14109221147281, average reward:-4.508818263217051,success
Box_Position: [[1.36123381 0.52946651 0.48749962]]
Step:14, total reward:-68.98599498963449, average reward:-4.927571070688178,success
Box_Position: [[1.25072873 0.85864726 0.55086347]]
actor_loss: tensor(4.9201, device='cuda:0', grad_fn=<NegBackward>)
Step:30, total reward:-167.86270822455396, average reward:-5.595423607485132,success
Box_Position: [[1.32110049 1.16799346 0.48108824]]
actor_loss: tensor(5.0437, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6527, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4235, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9471, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1020.4915794234469, average reward:-5.102457897117234,----
Box_Position: [[1.49837699 0.84816703 0.57263842]]
actor_loss: tensor(4.8948, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9619, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-483.3481218530898, average reward:-4.517272166851307,success
Box_Position: [[1.26519579 0.52113198 0.46473719]]
actor_loss: tensor(4.5491, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-139.79379569912535, average reward:-4.992635560683048,success
Box_Position: [[1.35900503 0.94926256 0.6464028 ]]
Step:17, total reward:-163.25619309659044, average reward:-9.603305476270025,success
Box_Position: [[1.3937786  0.69637777 0.48709822]]
actor_loss: tensor(5.1031, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-149.54970262508286, average reward:-4.673428207033839,success
Box_Position: [[1.42868358 0.64499166 0.46034717]]
actor_loss: tensor(4.6493, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7135, device='cuda:0', grad_fn=<NegBackward>)
Step:121, total reward:-621.2244565019723, average reward:-5.134086417371672,success
Box_Position: [[1.42880781 0.45820151 0.65675102]]
Step:9, total reward:-37.319712733352546, average reward:-4.146634748150283,success
Box_Position: [[1.3285774  1.19689104 0.57009753]]
actor_loss: tensor(4.4133, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4124, device='cuda:0', grad_fn=<NegBackward>)
Step:72, total reward:-364.8886951809358, average reward:-5.0678985441796645,success
Box_Position: [[1.47857526 0.99743084 0.52710273]]
actor_loss: tensor(4.9723, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4049, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3183, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0014, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1128.792087219372, average reward:-5.64396043609686,----
Box_Position: [[1.44754296 0.69772402 0.53176154]]
actor_loss: tensor(4.8864, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4788, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0310, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8807, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-781.7655267861976, average reward:-3.908827633930988,----
Box_Position: [[1.28578867 0.67259212 0.55619602]]
Step:4, total reward:-14.753215261182792, average reward:-3.688303815295698,success
Box_Position: [[1.38459031 1.08643598 0.55946286]]
actor_loss: tensor(4.7087, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0379, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.2249, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.1016, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-988.5915543371389, average reward:-4.942957771685695,----
Box_Position: [[1.34355616 0.98737122 0.45113426]]
actor_loss: tensor(4.4344, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4094, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7998, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8557, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1155.8765266200076, average reward:-5.779382633100038,----
Box_Position: [[1.47080973 0.69143067 0.50363372]]
actor_loss: tensor(4.4563, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-216.66316277857177, average reward:-4.814736950634928,success
Box_Position: [[1.42372049 0.70433778 0.54665363]]
Step:40, total reward:-135.07843565908462, average reward:-3.3769608914771156,success
Box_Position: [[1.49574615 0.69473478 0.64289037]]
actor_loss: tensor(4.8502, device='cuda:0', grad_fn=<NegBackward>)
Step:40, total reward:-150.5836991694593, average reward:-3.7645924792364824,success
Box_Position: [[1.40680493 0.72236255 0.73191151]]
actor_loss: tensor(5.2984, device='cuda:0', grad_fn=<NegBackward>)
Step:60, total reward:-238.18783543906687, average reward:-3.969797257317781,success
Box_Position: [[1.47036525 0.69947595 0.74759485]]
Step:6, total reward:-23.938438347458877, average reward:-3.9897397245764794,success
Box_Position: [[1.37770697 0.79016534 0.49298027]]
actor_loss: tensor(4.6333, device='cuda:0', grad_fn=<NegBackward>)
Step:12, total reward:-90.078204760536, average reward:-7.506517063377999,success
Box_Position: [[1.35829483 0.62721505 0.69615763]]
Step:21, total reward:-63.701826349631496, average reward:-3.0334203023634045,success
Box_Position: [[1.52230223 0.70193261 0.49258181]]

------------------Episode:2950------------------
actor_loss: tensor(4.5414, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5338, device='cuda:0', grad_fn=<NegBackward>)
Step:103, total reward:-579.9167515211685, average reward:-5.630259723506491,success
Box_Position: [[1.27351567 0.7963996  0.46273521]]
Step:5, total reward:-32.91529283812805, average reward:-6.583058567625611,success
Box_Position: [[1.42941218 0.85587978 0.45226525]]
actor_loss: tensor(4.8284, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8708, device='cuda:0', grad_fn=<NegBackward>)
Step:99, total reward:-634.5189491800583, average reward:-6.409282314950083,success
Box_Position: [[1.25779406 1.07772418 0.48308654]]
actor_loss: tensor(4.5749, device='cuda:0', grad_fn=<NegBackward>)
Step:26, total reward:-168.7479860328822, average reward:-6.490307155110854,success
Box_Position: [[1.43437682 0.72501091 0.51275219]]
actor_loss: tensor(5.2302, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7824, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7559, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-756.2798462611122, average reward:-4.178341692050344,success
Box_Position: [[1.25169712 0.68433652 0.73725428]]
actor_loss: tensor(4.5232, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6260, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-265.2504576937714, average reward:-3.8442095317937883,success
Box_Position: [[1.28412537 0.94236936 0.6619216 ]]
Step:33, total reward:-169.85869830249433, average reward:-5.147233281893768,success
Box_Position: [[1.48011463 0.73904902 0.50714159]]
actor_loss: tensor(4.8608, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4295, device='cuda:0', grad_fn=<NegBackward>)
Step:76, total reward:-412.93631282890397, average reward:-5.433372537222421,success
Box_Position: [[1.34968688 0.67527647 0.71784957]]
actor_loss: tensor(4.8304, device='cuda:0', grad_fn=<NegBackward>)
Step:38, total reward:-144.04464071289195, average reward:-3.790648439812946,success
Box_Position: [[1.30937134 0.60960004 0.5462003 ]]
Step:8, total reward:-34.60830845407715, average reward:-4.326038556759643,success
Box_Position: [[1.34857822 1.09304241 0.60969576]]
Step:16, total reward:-86.25399483050671, average reward:-5.3908746769066695,success
Box_Position: [[1.2939382  0.64143114 0.5220078 ]]
actor_loss: tensor(4.9610, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-156.64627549362461, average reward:-4.895196109175769,success
Box_Position: [[1.42575842 0.73256272 0.65293581]]
Step:11, total reward:-51.18326782821877, average reward:-4.653024348019888,success
Box_Position: [[1.28008764 0.89197486 0.62571658]]
actor_loss: tensor(5.4513, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-248.05315241316686, average reward:-5.167774008607643,success
Box_Position: [[1.48693971 0.8918649  0.55427635]]
actor_loss: tensor(5.2665, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.7533, device='cuda:0', grad_fn=<NegBackward>)
Step:145, total reward:-655.1135944610993, average reward:-4.5180247893868914,success
Box_Position: [[1.45890797 0.96224869 0.7089083 ]]
actor_loss: tensor(4.6409, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6847, device='cuda:0', grad_fn=<NegBackward>)
Step:107, total reward:-518.1492310113453, average reward:-4.842516177676123,success
Box_Position: [[1.54065231 0.69917189 0.70650214]]
actor_loss: tensor(4.7265, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5735, device='cuda:0', grad_fn=<NegBackward>)
Step:108, total reward:-413.4632731835676, average reward:-3.828363640588589,success
Box_Position: [[1.42032148 0.79617521 0.62400266]]
actor_loss: tensor(4.1958, device='cuda:0', grad_fn=<NegBackward>)
Step:15, total reward:-80.4717980562067, average reward:-5.364786537080446,success
Box_Position: [[1.37993588 0.9060613  0.74133838]]
Step:22, total reward:-110.73486183936892, average reward:-5.033402810880405,success
Box_Position: [[1.35302719 1.02676338 0.58875305]]
actor_loss: tensor(4.3848, device='cuda:0', grad_fn=<NegBackward>)
Step:47, total reward:-229.8591633347261, average reward:-4.8906204964835345,success
Box_Position: [[1.43904181 0.82229434 0.52843008]]
actor_loss: tensor(4.8933, device='cuda:0', grad_fn=<NegBackward>)
Step:39, total reward:-216.9978779958074, average reward:-5.564048153738652,success
Box_Position: [[1.38799068 0.61050939 0.61505461]]
Step:27, total reward:-90.08916768383878, average reward:-3.336635840142177,success
Box_Position: [[1.31234857 0.65394889 0.7048379 ]]
Step:3, total reward:-8.06457188444664, average reward:-2.6881906281488797,success
Box_Position: [[1.37144217 0.54850525 0.66741267]]
actor_loss: tensor(4.3266, device='cuda:0', grad_fn=<NegBackward>)
Step:16, total reward:-64.70129426927176, average reward:-4.043830891829485,success
Box_Position: [[1.49252065 0.96792851 0.67163926]]
Step:29, total reward:-152.30687967599494, average reward:-5.251961368137756,success
Box_Position: [[1.54258593 1.0120946  0.5867019 ]]
actor_loss: tensor(4.6650, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.8620, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5043, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3137, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1102.7315413496765, average reward:-5.513657706748383,----
Box_Position: [[1.42693115 0.59156264 0.56684974]]
actor_loss: tensor(4.4851, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4786, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6873, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.9110, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-761.8995581256935, average reward:-3.8094977906284675,----
Box_Position: [[1.27155834 0.77986225 0.58808163]]
Step:7, total reward:-34.17070483494909, average reward:-4.881529262135585,success
Box_Position: [[1.31889981 1.01500311 0.46372481]]
actor_loss: tensor(5.2235, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5990, device='cuda:0', grad_fn=<NegBackward>)
Step:80, total reward:-403.46807215264437, average reward:-5.043350901908054,success
Box_Position: [[1.29042474 0.70383361 0.48936598]]
Step:1, total reward:-7.028876751162106, average reward:-7.028876751162106,success
Box_Position: [[1.48539901 0.94994144 0.69879639]]
actor_loss: tensor(4.5831, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-177.62158003562178, average reward:-4.229085238943376,success
Box_Position: [[1.26468478 0.73883525 0.50727869]]
Step:15, total reward:-79.47628975263544, average reward:-5.298419316842362,success
Box_Position: [[1.54112122 0.77363848 0.54298429]]
actor_loss: tensor(4.5714, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-144.7422397797878, average reward:-5.360823695547697,success
Box_Position: [[1.39447633 0.84648241 0.4717932 ]]
Step:29, total reward:-172.78049110483158, average reward:-5.957947969132124,success
Box_Position: [[1.48803905 0.65444035 0.54691423]]
actor_loss: tensor(4.7308, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-132.30061939339163, average reward:-4.134394356043488,success
Box_Position: [[1.30083832 0.80479111 0.74109005]]
Step:20, total reward:-88.74452358209967, average reward:-4.437226179104984,success
Box_Position: [[1.47238258 0.89140064 0.65077179]]
actor_loss: tensor(4.3487, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-134.30941327767323, average reward:-4.974422713987898,success
Box_Position: [[1.34107058 0.9405071  0.72807955]]
Step:4, total reward:-17.293398479195346, average reward:-4.323349619798837,success
Box_Position: [[1.44902356 0.90032384 0.50229584]]
Step:29, total reward:-187.7507582594384, average reward:-6.474164077911669,success
Box_Position: [[1.39016111 1.0812293  0.56870257]]
actor_loss: tensor(4.8977, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.5578, device='cuda:0', grad_fn=<NegBackward>)
Step:69, total reward:-307.83276185927264, average reward:-4.461344374772067,success
Box_Position: [[1.45899995 0.84920245 0.47197073]]
actor_loss: tensor(5.2676, device='cuda:0', grad_fn=<NegBackward>)
Step:36, total reward:-252.69793740396545, average reward:-7.019387150110152,success
Box_Position: [[1.31744725 0.79267619 0.61956891]]
Step:14, total reward:-52.41165621860489, average reward:-3.7436897299003493,success
Box_Position: [[1.44755253 1.07638487 0.6986676 ]]
Step:13, total reward:-58.64204328245766, average reward:-4.510926406342897,success
Box_Position: [[1.38985531 1.05578022 0.65664362]]
actor_loss: tensor(4.5908, device='cuda:0', grad_fn=<NegBackward>)
Step:27, total reward:-113.85478338157634, average reward:-4.216843828947272,success
Box_Position: [[1.52522859 0.80884137 0.52915897]]
actor_loss: tensor(4.2822, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0710, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3752, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4413, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-865.5159008359938, average reward:-4.327579504179969,----
Box_Position: [[1.53322336 0.83217424 0.53725819]]
actor_loss: tensor(4.2433, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4655, device='cuda:0', grad_fn=<NegBackward>)
Step:110, total reward:-534.5946953072391, average reward:-4.859951775520356,success
Box_Position: [[1.40989077 0.64412931 0.47794076]]
actor_loss: tensor(4.0722, device='cuda:0', grad_fn=<NegBackward>)
Step:50, total reward:-257.3888630467783, average reward:-5.147777260935566,success
Box_Position: [[1.28783426 0.86481964 0.74930367]]
actor_loss: tensor(4.2034, device='cuda:0', grad_fn=<NegBackward>)
Step:43, total reward:-204.0663929094184, average reward:-4.745730067660893,success
Box_Position: [[1.38307065 0.69294554 0.63341038]]
Step:23, total reward:-83.72585550083505, average reward:-3.6402545869928282,success
Box_Position: [[1.32246737 0.63641807 0.46222955]]
actor_loss: tensor(4.0684, device='cuda:0', grad_fn=<NegBackward>)
Step:32, total reward:-146.58838310418486, average reward:-4.580886972005777,success
Box_Position: [[1.26742084 0.74098683 0.49003883]]

------------------Episode:3000------------------
Step:22, total reward:-96.25491921608183, average reward:-4.375223600730992,success
episode 3000, the accuracy is: 92%
Box_Position: [[1.44972273 0.84298122 0.55988112]]
actor_loss: tensor(4.0615, device='cuda:0', grad_fn=<NegBackward>)
Step:18, total reward:-113.43070280227762, average reward:-6.301705711237646,success
Box_Position: [[1.46106604 0.91197344 0.69023677]]
Step:35, total reward:-140.78195686266017, average reward:-4.022341624647433,success
Box_Position: [[1.31255451 0.88805059 0.48228867]]
Step:8, total reward:-49.43013982143732, average reward:-6.178767477679665,success
Box_Position: [[1.36809916 0.77723524 0.58357501]]
actor_loss: tensor(4.1049, device='cuda:0', grad_fn=<NegBackward>)
Step:4, total reward:-22.020832021219796, average reward:-5.505208005304949,success
Box_Position: [[1.54252426 0.75314001 0.6383924 ]]
Step:25, total reward:-109.7170770680864, average reward:-4.388683082723456,success
Box_Position: [[1.27943569 0.9531356  0.48060315]]
actor_loss: tensor(4.5274, device='cuda:0', grad_fn=<NegBackward>)
Step:48, total reward:-241.57804022132905, average reward:-5.0328758379443554,success
Box_Position: [[1.28142859 1.10893105 0.58011298]]
Step:11, total reward:-42.44089104603948, average reward:-3.8582628223672257,success
Box_Position: [[1.32827006 0.69038024 0.46588567]]
actor_loss: tensor(4.4522, device='cuda:0', grad_fn=<NegBackward>)
Step:59, total reward:-264.089338113855, average reward:-4.476090476506017,success
Box_Position: [[1.43107451 0.87088054 0.5620863 ]]
actor_loss: tensor(4.7219, device='cuda:0', grad_fn=<NegBackward>)
Step:10, total reward:-63.50387934633622, average reward:-6.350387934633622,success
Box_Position: [[1.47412798 0.6119271  0.59040683]]
Step:17, total reward:-71.6915755814368, average reward:-4.2171515047904,success
Box_Position: [[1.42679932 0.72311524 0.48000198]]
actor_loss: tensor(4.1734, device='cuda:0', grad_fn=<NegBackward>)
Step:45, total reward:-221.15394240943374, average reward:-4.914532053542972,success
Box_Position: [[1.32804621 0.85820527 0.61395968]]
actor_loss: tensor(3.9385, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-157.9342600219806, average reward:-4.268493514107584,success
Box_Position: [[1.31872381 1.11723651 0.66419615]]
actor_loss: tensor(4.6222, device='cuda:0', grad_fn=<NegBackward>)
Step:58, total reward:-253.8737655056191, average reward:-4.377133888027916,success
Box_Position: [[1.36903455 0.7864824  0.53912842]]
Step:5, total reward:-27.973811377704664, average reward:-5.5947622755409325,success
Box_Position: [[1.53794302 0.76337865 0.46891177]]
actor_loss: tensor(4.6494, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.6083, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0771, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0918, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-991.5850054179342, average reward:-4.957925027089671,----
Box_Position: [[1.31083183 0.66026052 0.71781558]]
actor_loss: tensor(4.1244, device='cuda:0', grad_fn=<NegBackward>)
Step:35, total reward:-152.57330156774236, average reward:-4.359237187649782,success
Box_Position: [[1.43385405 0.77969267 0.48674573]]
Step:22, total reward:-113.28626123453405, average reward:-5.149375510660639,success
Box_Position: [[1.54836819 0.91261296 0.46516953]]
actor_loss: tensor(4.3920, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.1052, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(5.0401, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.7298, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1281.466792171419, average reward:-6.407333960857095,----
Box_Position: [[1.43804112 0.69723532 0.69236703]]
actor_loss: tensor(4.6080, device='cuda:0', grad_fn=<NegBackward>)
Step:28, total reward:-132.3950100533666, average reward:-4.728393216191664,success
Box_Position: [[1.40569692 0.57157806 0.68160872]]
Step:23, total reward:-79.13405246983588, average reward:-3.4406109769493862,success
Box_Position: [[1.51826202 0.9842689  0.5552682 ]]
actor_loss: tensor(4.3501, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.2296, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0024, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0650, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1033.8315124146516, average reward:-5.1691575620732575,----
Box_Position: [[1.46074459 0.98749996 0.57027441]]
actor_loss: tensor(4.2142, device='cuda:0', grad_fn=<NegBackward>)
Step:37, total reward:-179.48301569090438, average reward:-4.8508923159703885,success
Box_Position: [[1.39747391 0.43761986 0.6376409 ]]
actor_loss: tensor(3.7884, device='cuda:0', grad_fn=<NegBackward>)
Step:42, total reward:-154.2507705789941, average reward:-3.6726373947379547,success
Box_Position: [[1.27260825 0.89274475 0.55495711]]
Step:19, total reward:-102.25561629970186, average reward:-5.381874542089571,success
Box_Position: [[1.42526189 1.16656237 0.54205293]]
actor_loss: tensor(4.0277, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.7743, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.2128, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0923, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-898.249010667291, average reward:-4.491245053336455,----
Box_Position: [[1.44743807 0.69151781 0.72732237]]
actor_loss: tensor(3.8816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.9003, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.1450, device='cuda:0', grad_fn=<NegBackward>)
Step:154, total reward:-539.6903657962622, average reward:-3.5044828947809235,success
Box_Position: [[1.48377757 1.0563648  0.49057006]]
actor_loss: tensor(4.1335, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0265, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.9939, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4535, device='cuda:0', grad_fn=<NegBackward>)
Step:200, total reward:-1123.4256205460774, average reward:-5.617128102730387,----
Box_Position: [[1.27738364 1.07186245 0.54742517]]
Step:18, total reward:-94.55891801437248, average reward:-5.2532732230206935,success
Box_Position: [[1.53353742 0.7364173  0.70231183]]
actor_loss: tensor(4.7719, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.7479, device='cuda:0', grad_fn=<NegBackward>)
Step:92, total reward:-374.8921842241019, average reward:-4.074915045914151,success
Box_Position: [[1.42134326 1.10429845 0.46555303]]
actor_loss: tensor(4.2002, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.1138, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.3162, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.0980, device='cuda:0', grad_fn=<NegBackward>)
Step:181, total reward:-1029.5193384776564, average reward:-5.687952146285395,success
Box_Position: [[1.31932673 0.77735379 0.51176309]]
Step:17, total reward:-106.82718075627817, average reward:-6.283951809192834,success
Box_Position: [[1.28339333 0.87275855 0.72378352]]
actor_loss: tensor(4.2818, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.5816, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.8378, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(3.9158, device='cuda:0', grad_fn=<NegBackward>)
Step:170, total reward:-713.7364386148831, average reward:-4.198449638911077,success
Box_Position: [[1.38349591 0.70613565 0.46751759]]
actor_loss: tensor(4.1377, device='cuda:0', grad_fn=<NegBackward>)
actor_loss: tensor(4.4009, device='cuda:0', grad_fn=<NegBackward>)
Step:124, total reward:-659.570197228821, average reward:-5.319114493780814,success
Box_Position: [[1.49153191 0.77434847 0.56750105]]

Process finished with exit code -1
